input {
  file {    
    path => [ "/root/out-5.dat" ]
    start_position => "beginning"  
    sincedb_path => "/dev/new/null"
    codec => plain {
      charset => "UTF-8"
    }
  }
}

filter {
  csv {
    columns => [
      "id",
      "modelno",
      "pl_no",
      "modelno_group",
      "category",
      "ca_code",
      "ca_dept_mcode",
      "ca_dept_code",
      "ca_dept_dcode",
      "ca_lcode_ran",
      "ca_mcode_ran",
      "ca_scode_ran",
      "ca_dcode_ran",
      "shop_code",
      "shop_name",
      "shop_name_code",
      "modelnm",
      "modelnm2",
      "factory",
      "brand",
      "popular",
      "popular2",
      "sale_cnt",
      "model_factory",
      "minprice",
      "maxprice",
      "minprices",
      "c_date",
      "mallcnt",
      "spec",
      "openexpectflag",
      "condiname",
      "keyword",
      "keyword2",
      "brandcode1",
      "brandcode2",
      "specopt",
      "bookflag",
      "useflag",
      "weight",
      "minprice3",
      "minprice2",
      "maxprice3",
      "mobile_flag",
      "minprice4",
      "store_flag",
      "zum_check",
      "service_gubun",
      "minprice5",
      "ext_condi_flag"
    ]
    separator => ","
    skip_empty_columns => true
    #quote_char => "\""
    #convert => {
    #  "movieid" => "integer"
    #}
  }
  mutate {
   remove_field => ["message", "host", "path"]
  }

}
output {

    elasticsearch {
        hosts => ["localhost:9200"]
        index => "idxenr-%{+YYYY.MM.dd}"
        document_id => "%{id}"
        action => index
    }
  #stdout { codec => rubydebug }
}


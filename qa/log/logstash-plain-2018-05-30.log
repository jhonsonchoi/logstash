[2018-05-30T08:59:41,979][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"fb_apache", :directory=>"/usr/share/logstash/modules/fb_apache/configuration"}
[2018-05-30T08:59:42,004][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"netflow", :directory=>"/usr/share/logstash/modules/netflow/configuration"}
[2018-05-30T08:59:43,575][WARN ][logstash.config.source.multilocal] Ignoring the 'pipelines.yml' file because modules or command line options are specified
[2018-05-30T08:59:44,304][INFO ][logstash.runner          ] Starting Logstash {"logstash.version"=>"6.2.3"}
[2018-05-30T08:59:44,482][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"fb_apache", :directory=>"/usr/share/logstash/modules/fb_apache/configuration"}
[2018-05-30T08:59:44,489][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"netflow", :directory=>"/usr/share/logstash/modules/netflow/configuration"}
[2018-05-30T08:59:44,528][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"fb_apache", :directory=>"/usr/share/logstash/modules/fb_apache/configuration"}
[2018-05-30T08:59:44,605][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"netflow", :directory=>"/usr/share/logstash/modules/netflow/configuration"}
[2018-05-30T08:59:44,677][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=>9600}
[2018-05-30T08:59:44,710][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"fb_apache", :directory=>"/usr/share/logstash/modules/fb_apache/configuration"}
[2018-05-30T08:59:44,738][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"netflow", :directory=>"/usr/share/logstash/modules/netflow/configuration"}
[2018-05-30T08:59:45,848][WARN ][logstash.config.source.multilocal] Ignoring the 'pipelines.yml' file because modules or command line options are specified
[2018-05-30T08:59:46,275][INFO ][logstash.runner          ] Starting Logstash {"logstash.version"=>"6.2.3"}
[2018-05-30T08:59:46,443][WARN ][logstash.config.source.multilocal] Ignoring the 'pipelines.yml' file because modules or command line options are specified
[2018-05-30T08:59:46,501][WARN ][logstash.config.source.multilocal] Ignoring the 'pipelines.yml' file because modules or command line options are specified
[2018-05-30T08:59:46,712][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=>9602}
[2018-05-30T08:59:47,019][INFO ][logstash.runner          ] Starting Logstash {"logstash.version"=>"6.2.3"}
[2018-05-30T08:59:47,585][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=>9603}
[2018-05-30T08:59:47,613][INFO ][logstash.runner          ] Starting Logstash {"logstash.version"=>"6.2.3"}
[2018-05-30T08:59:47,629][DEBUG][org.logstash.secret.store.SecretStoreFactory] Attempting to exists or secret store with implementation: org.logstash.secret.store.backend.JavaKeyStore
[2018-05-30T08:59:48,042][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=>9604}
[2018-05-30T08:59:48,101][DEBUG][org.logstash.secret.store.SecretStoreFactory] Attempting to exists or secret store with implementation: org.logstash.secret.store.backend.JavaKeyStore
[2018-05-30T08:59:48,477][INFO ][logstash.filters.ruby.script] Test run complete {:script_path=>"rubyfilter.rb", :results=>{:passed=>0, :failed=>0, :errored=>0}}
[2018-05-30T08:59:49,157][DEBUG][org.logstash.secret.store.SecretStoreFactory] Attempting to exists or secret store with implementation: org.logstash.secret.store.backend.JavaKeyStore
[2018-05-30T08:59:49,238][WARN ][logstash.outputs.elasticsearch] You are using a deprecated config setting "document_type" set in elasticsearch. Deprecated settings will continue to work, but are scheduled for removal from logstash in the future. Document types are being deprecated in Elasticsearch 6.0, and removed entirely in 7.0. You should avoid this feature If you have any questions about this, please visit the #logstash channel on freenode irc. {:name=>"document_type", :plugin=><LogStash::Outputs::ElasticSearch hosts=>[//100.100.100.111:9200, //100.100.100.112:9200, //100.100.100.113:9200], index=>"qa-enuri-main-as-is-2018.05.29.23.58", document_type=>"_doc", document_id=>"%{id}", action=>"index", id=>"ec2e7209120401ff8ce6f1bf881afce389606f2f172cbfead5336a4a708867ff", enable_metric=>true, codec=><LogStash::Codecs::Plain id=>"plain_0b27f516-b787-44ff-bbad-8fa5b37d7fa7", enable_metric=>true, charset=>"UTF-8">, workers=>1, manage_template=>true, template_name=>"logstash", template_overwrite=>false, doc_as_upsert=>false, script_type=>"inline", script_lang=>"painless", script_var_name=>"event", scripted_upsert=>false, retry_initial_interval=>2, retry_max_interval=>64, retry_on_conflict=>1, ssl_certificate_verification=>true, sniffing=>false, sniffing_delay=>5, timeout=>60, pool_max=>1000, pool_max_per_route=>100, resurrect_delay=>5, validate_after_inactivity=>10000, http_compression=>false>}
[2018-05-30T08:59:49,352][INFO ][logstash.pipeline        ] Starting pipeline {:pipeline_id=>"main", "pipeline.workers"=>8, "pipeline.batch.size"=>125, "pipeline.batch.delay"=>50}
[2018-05-30T08:59:49,443][DEBUG][org.logstash.secret.store.SecretStoreFactory] Attempting to exists or secret store with implementation: org.logstash.secret.store.backend.JavaKeyStore
[2018-05-30T08:59:49,791][DEBUG][org.logstash.secret.store.SecretStoreFactory] Attempting to exists or secret store with implementation: org.logstash.secret.store.backend.JavaKeyStore
[2018-05-30T08:59:50,045][DEBUG][org.logstash.secret.store.SecretStoreFactory] Attempting to exists or secret store with implementation: org.logstash.secret.store.backend.JavaKeyStore
[2018-05-30T08:59:50,090][INFO ][logstash.filters.ruby.script] Test run complete {:script_path=>"rubyfilter.rb", :results=>{:passed=>0, :failed=>0, :errored=>0}}
[2018-05-30T08:59:50,262][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"fb_apache", :directory=>"/usr/share/logstash/modules/fb_apache/configuration"}
[2018-05-30T08:59:50,323][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"netflow", :directory=>"/usr/share/logstash/modules/netflow/configuration"}
[2018-05-30T08:59:50,327][INFO ][logstash.outputs.elasticsearch] Elasticsearch pool URLs updated {:changes=>{:removed=>[], :added=>[http://100.100.100.111:9200/, http://100.100.100.112:9200/, http://100.100.100.113:9200/]}}
[2018-05-30T08:59:50,329][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://100.100.100.111:9200/, :path=>"/"}
[2018-05-30T08:59:50,454][DEBUG][org.logstash.secret.store.SecretStoreFactory] Attempting to exists or secret store with implementation: org.logstash.secret.store.backend.JavaKeyStore
[2018-05-30T08:59:50,520][DEBUG][org.logstash.secret.store.SecretStoreFactory] Attempting to exists or secret store with implementation: org.logstash.secret.store.backend.JavaKeyStore
[2018-05-30T08:59:50,542][WARN ][logstash.outputs.elasticsearch] You are using a deprecated config setting "document_type" set in elasticsearch. Deprecated settings will continue to work, but are scheduled for removal from logstash in the future. Document types are being deprecated in Elasticsearch 6.0, and removed entirely in 7.0. You should avoid this feature If you have any questions about this, please visit the #logstash channel on freenode irc. {:name=>"document_type", :plugin=><LogStash::Outputs::ElasticSearch hosts=>[//100.100.100.111:9200, //100.100.100.112:9200, //100.100.100.113:9200], index=>"qa-enuri-main-as-is-2018.05.29.23.58", document_type=>"_doc", document_id=>"%{id}", action=>"index", id=>"ec2e7209120401ff8ce6f1bf881afce389606f2f172cbfead5336a4a708867ff", enable_metric=>true, codec=><LogStash::Codecs::Plain id=>"plain_eba19662-ece6-4610-b2dc-fe7a4789bff2", enable_metric=>true, charset=>"UTF-8">, workers=>1, manage_template=>true, template_name=>"logstash", template_overwrite=>false, doc_as_upsert=>false, script_type=>"inline", script_lang=>"painless", script_var_name=>"event", scripted_upsert=>false, retry_initial_interval=>2, retry_max_interval=>64, retry_on_conflict=>1, ssl_certificate_verification=>true, sniffing=>false, sniffing_delay=>5, timeout=>60, pool_max=>1000, pool_max_per_route=>100, resurrect_delay=>5, validate_after_inactivity=>10000, http_compression=>false>}
[2018-05-30T08:59:50,562][INFO ][logstash.pipeline        ] Starting pipeline {:pipeline_id=>"main", "pipeline.workers"=>8, "pipeline.batch.size"=>125, "pipeline.batch.delay"=>50}
[2018-05-30T08:59:50,626][INFO ][logstash.filters.ruby.script] Test run complete {:script_path=>"rubyfilter.rb", :results=>{:passed=>0, :failed=>0, :errored=>0}}
[2018-05-30T08:59:50,702][DEBUG][org.logstash.secret.store.SecretStoreFactory] Attempting to exists or secret store with implementation: org.logstash.secret.store.backend.JavaKeyStore
[2018-05-30T08:59:50,719][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://100.100.100.111:9200/"}
[2018-05-30T08:59:50,895][INFO ][logstash.outputs.elasticsearch] ES Output version determined {:es_version=>6}
[2018-05-30T08:59:50,896][WARN ][logstash.outputs.elasticsearch] Detected a 6.x and above cluster: the `type` event field won't be used to determine the document _type {:es_version=>6}
[2018-05-30T08:59:50,896][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://100.100.100.112:9200/, :path=>"/"}
[2018-05-30T08:59:50,907][DEBUG][org.logstash.secret.store.SecretStoreFactory] Attempting to exists or secret store with implementation: org.logstash.secret.store.backend.JavaKeyStore
[2018-05-30T08:59:50,936][WARN ][logstash.outputs.elasticsearch] You are using a deprecated config setting "document_type" set in elasticsearch. Deprecated settings will continue to work, but are scheduled for removal from logstash in the future. Document types are being deprecated in Elasticsearch 6.0, and removed entirely in 7.0. You should avoid this feature If you have any questions about this, please visit the #logstash channel on freenode irc. {:name=>"document_type", :plugin=><LogStash::Outputs::ElasticSearch hosts=>[//100.100.100.111:9200, //100.100.100.112:9200, //100.100.100.113:9200], index=>"qa-enuri-main-as-is-2018.05.29.23.58", document_type=>"_doc", document_id=>"%{id}", action=>"index", id=>"ec2e7209120401ff8ce6f1bf881afce389606f2f172cbfead5336a4a708867ff", enable_metric=>true, codec=><LogStash::Codecs::Plain id=>"plain_19b0a0c5-41a3-4b79-89fb-2c843e6586f3", enable_metric=>true, charset=>"UTF-8">, workers=>1, manage_template=>true, template_name=>"logstash", template_overwrite=>false, doc_as_upsert=>false, script_type=>"inline", script_lang=>"painless", script_var_name=>"event", scripted_upsert=>false, retry_initial_interval=>2, retry_max_interval=>64, retry_on_conflict=>1, ssl_certificate_verification=>true, sniffing=>false, sniffing_delay=>5, timeout=>60, pool_max=>1000, pool_max_per_route=>100, resurrect_delay=>5, validate_after_inactivity=>10000, http_compression=>false>}
[2018-05-30T08:59:50,951][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://100.100.100.112:9200/"}
[2018-05-30T08:59:50,956][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://100.100.100.113:9200/, :path=>"/"}
[2018-05-30T08:59:50,971][DEBUG][org.logstash.secret.store.SecretStoreFactory] Attempting to exists or secret store with implementation: org.logstash.secret.store.backend.JavaKeyStore
[2018-05-30T08:59:50,980][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://100.100.100.113:9200/"}
[2018-05-30T08:59:50,990][INFO ][logstash.pipeline        ] Starting pipeline {:pipeline_id=>"main", "pipeline.workers"=>8, "pipeline.batch.size"=>125, "pipeline.batch.delay"=>50}
[2018-05-30T08:59:51,013][INFO ][logstash.outputs.elasticsearch] Using mapping template from {:path=>nil}
[2018-05-30T08:59:51,017][INFO ][logstash.outputs.elasticsearch] Attempting to install template {:manage_template=>{"template"=>"logstash-*", "version"=>60001, "settings"=>{"index.refresh_interval"=>"5s"}, "mappings"=>{"_default_"=>{"dynamic_templates"=>[{"message_field"=>{"path_match"=>"message", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false}}}, {"string_fields"=>{"match"=>"*", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false, "fields"=>{"keyword"=>{"type"=>"keyword", "ignore_above"=>256}}}}}], "properties"=>{"@timestamp"=>{"type"=>"date"}, "@version"=>{"type"=>"keyword"}, "geoip"=>{"dynamic"=>true, "properties"=>{"ip"=>{"type"=>"ip"}, "location"=>{"type"=>"geo_point"}, "latitude"=>{"type"=>"half_float"}, "longitude"=>{"type"=>"half_float"}}}}}}}}
[2018-05-30T08:59:51,066][INFO ][logstash.outputs.elasticsearch] New Elasticsearch output {:class=>"LogStash::Outputs::ElasticSearch", :hosts=>["//100.100.100.111:9200", "//100.100.100.112:9200", "//100.100.100.113:9200"]}
[2018-05-30T08:59:51,344][INFO ][logstash.filters.ruby.script] Test run complete {:script_path=>"rubyfilter.rb", :results=>{:passed=>0, :failed=>0, :errored=>0}}
[2018-05-30T08:59:51,387][INFO ][logstash.outputs.elasticsearch] Elasticsearch pool URLs updated {:changes=>{:removed=>[], :added=>[http://100.100.100.111:9200/, http://100.100.100.112:9200/, http://100.100.100.113:9200/]}}
[2018-05-30T08:59:51,389][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://100.100.100.111:9200/, :path=>"/"}
[2018-05-30T08:59:51,689][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://100.100.100.111:9200/"}
[2018-05-30T08:59:51,766][INFO ][logstash.pipeline        ] Pipeline started succesfully {:pipeline_id=>"main", :thread=>"#<Thread:0x26d4dd94@/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:246 run>"}
[2018-05-30T08:59:51,805][INFO ][logstash.outputs.elasticsearch] ES Output version determined {:es_version=>6}
[2018-05-30T08:59:51,806][WARN ][logstash.outputs.elasticsearch] Detected a 6.x and above cluster: the `type` event field won't be used to determine the document _type {:es_version=>6}
[2018-05-30T08:59:51,806][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://100.100.100.112:9200/, :path=>"/"}
[2018-05-30T08:59:51,813][INFO ][logstash.agent           ] Pipelines running {:count=>1, :pipelines=>["main"]}
[2018-05-30T08:59:51,847][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://100.100.100.112:9200/"}
[2018-05-30T08:59:51,860][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://100.100.100.113:9200/, :path=>"/"}
[2018-05-30T08:59:51,880][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://100.100.100.113:9200/"}
[2018-05-30T08:59:51,879][INFO ][logstash.outputs.elasticsearch] Elasticsearch pool URLs updated {:changes=>{:removed=>[], :added=>[http://100.100.100.111:9200/, http://100.100.100.112:9200/, http://100.100.100.113:9200/]}}
[2018-05-30T08:59:51,894][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://100.100.100.111:9200/, :path=>"/"}
[2018-05-30T08:59:51,896][DEBUG][org.logstash.secret.store.SecretStoreFactory] Attempting to exists or secret store with implementation: org.logstash.secret.store.backend.JavaKeyStore
[2018-05-30T08:59:51,909][INFO ][logstash.outputs.elasticsearch] Using mapping template from {:path=>nil}
[2018-05-30T08:59:51,912][INFO ][logstash.outputs.elasticsearch] Attempting to install template {:manage_template=>{"template"=>"logstash-*", "version"=>60001, "settings"=>{"index.refresh_interval"=>"5s"}, "mappings"=>{"_default_"=>{"dynamic_templates"=>[{"message_field"=>{"path_match"=>"message", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false}}}, {"string_fields"=>{"match"=>"*", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false, "fields"=>{"keyword"=>{"type"=>"keyword", "ignore_above"=>256}}}}}], "properties"=>{"@timestamp"=>{"type"=>"date"}, "@version"=>{"type"=>"keyword"}, "geoip"=>{"dynamic"=>true, "properties"=>{"ip"=>{"type"=>"ip"}, "location"=>{"type"=>"geo_point"}, "latitude"=>{"type"=>"half_float"}, "longitude"=>{"type"=>"half_float"}}}}}}}}
[2018-05-30T08:59:51,936][INFO ][logstash.outputs.elasticsearch] New Elasticsearch output {:class=>"LogStash::Outputs::ElasticSearch", :hosts=>["//100.100.100.111:9200", "//100.100.100.112:9200", "//100.100.100.113:9200"]}
[2018-05-30T08:59:52,018][WARN ][logstash.outputs.elasticsearch] You are using a deprecated config setting "document_type" set in elasticsearch. Deprecated settings will continue to work, but are scheduled for removal from logstash in the future. Document types are being deprecated in Elasticsearch 6.0, and removed entirely in 7.0. You should avoid this feature If you have any questions about this, please visit the #logstash channel on freenode irc. {:name=>"document_type", :plugin=><LogStash::Outputs::ElasticSearch hosts=>[//100.100.100.111:9200, //100.100.100.112:9200, //100.100.100.113:9200], index=>"qa-enuri-main-as-is-2018.05.29.23.58", document_type=>"_doc", document_id=>"%{id}", action=>"index", id=>"ec2e7209120401ff8ce6f1bf881afce389606f2f172cbfead5336a4a708867ff", enable_metric=>true, codec=><LogStash::Codecs::Plain id=>"plain_211c9801-810c-4c1e-b542-c3680713736a", enable_metric=>true, charset=>"UTF-8">, workers=>1, manage_template=>true, template_name=>"logstash", template_overwrite=>false, doc_as_upsert=>false, script_type=>"inline", script_lang=>"painless", script_var_name=>"event", scripted_upsert=>false, retry_initial_interval=>2, retry_max_interval=>64, retry_on_conflict=>1, ssl_certificate_verification=>true, sniffing=>false, sniffing_delay=>5, timeout=>60, pool_max=>1000, pool_max_per_route=>100, resurrect_delay=>5, validate_after_inactivity=>10000, http_compression=>false>}
[2018-05-30T08:59:52,035][INFO ][logstash.pipeline        ] Starting pipeline {:pipeline_id=>"main", "pipeline.workers"=>8, "pipeline.batch.size"=>125, "pipeline.batch.delay"=>50}
[2018-05-30T08:59:52,292][WARN ][logstash.config.source.multilocal] Ignoring the 'pipelines.yml' file because modules or command line options are specified
[2018-05-30T08:59:52,422][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://100.100.100.111:9200/"}
[2018-05-30T08:59:52,534][INFO ][logstash.outputs.elasticsearch] ES Output version determined {:es_version=>6}
[2018-05-30T08:59:52,534][WARN ][logstash.outputs.elasticsearch] Detected a 6.x and above cluster: the `type` event field won't be used to determine the document _type {:es_version=>6}
[2018-05-30T08:59:52,534][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://100.100.100.112:9200/, :path=>"/"}
[2018-05-30T08:59:52,594][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://100.100.100.112:9200/"}
[2018-05-30T08:59:52,622][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://100.100.100.113:9200/, :path=>"/"}
[2018-05-30T08:59:52,674][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://100.100.100.113:9200/"}
[2018-05-30T08:59:52,721][INFO ][logstash.pipeline        ] Pipeline started succesfully {:pipeline_id=>"main", :thread=>"#<Thread:0x490e42b5@/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:246 run>"}
[2018-05-30T08:59:52,742][INFO ][logstash.agent           ] Pipelines running {:count=>1, :pipelines=>["main"]}
[2018-05-30T08:59:52,751][INFO ][logstash.outputs.elasticsearch] Using mapping template from {:path=>nil}
[2018-05-30T08:59:52,754][INFO ][logstash.outputs.elasticsearch] Attempting to install template {:manage_template=>{"template"=>"logstash-*", "version"=>60001, "settings"=>{"index.refresh_interval"=>"5s"}, "mappings"=>{"_default_"=>{"dynamic_templates"=>[{"message_field"=>{"path_match"=>"message", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false}}}, {"string_fields"=>{"match"=>"*", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false, "fields"=>{"keyword"=>{"type"=>"keyword", "ignore_above"=>256}}}}}], "properties"=>{"@timestamp"=>{"type"=>"date"}, "@version"=>{"type"=>"keyword"}, "geoip"=>{"dynamic"=>true, "properties"=>{"ip"=>{"type"=>"ip"}, "location"=>{"type"=>"geo_point"}, "latitude"=>{"type"=>"half_float"}, "longitude"=>{"type"=>"half_float"}}}}}}}}
[2018-05-30T08:59:52,777][INFO ][logstash.outputs.elasticsearch] New Elasticsearch output {:class=>"LogStash::Outputs::ElasticSearch", :hosts=>["//100.100.100.111:9200", "//100.100.100.112:9200", "//100.100.100.113:9200"]}
[2018-05-30T08:59:53,177][INFO ][logstash.runner          ] Starting Logstash {"logstash.version"=>"6.2.3"}
[2018-05-30T08:59:53,377][INFO ][logstash.outputs.elasticsearch] Elasticsearch pool URLs updated {:changes=>{:removed=>[], :added=>[http://100.100.100.111:9200/, http://100.100.100.112:9200/, http://100.100.100.113:9200/]}}
[2018-05-30T08:59:53,380][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://100.100.100.111:9200/, :path=>"/"}
[2018-05-30T08:59:53,545][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=>9605}
[2018-05-30T08:59:53,735][INFO ][logstash.pipeline        ] Pipeline started succesfully {:pipeline_id=>"main", :thread=>"#<Thread:0x3d5c25c3@/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:246 run>"}
[2018-05-30T08:59:53,762][INFO ][logstash.agent           ] Pipelines running {:count=>1, :pipelines=>["main"]}
[2018-05-30T08:59:53,920][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://100.100.100.111:9200/"}
[2018-05-30T08:59:54,186][INFO ][logstash.outputs.elasticsearch] ES Output version determined {:es_version=>6}
[2018-05-30T08:59:54,186][WARN ][logstash.outputs.elasticsearch] Detected a 6.x and above cluster: the `type` event field won't be used to determine the document _type {:es_version=>6}
[2018-05-30T08:59:54,186][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://100.100.100.112:9200/, :path=>"/"}
[2018-05-30T08:59:54,203][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://100.100.100.112:9200/"}
[2018-05-30T08:59:54,208][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://100.100.100.113:9200/, :path=>"/"}
[2018-05-30T08:59:54,213][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://100.100.100.113:9200/"}
[2018-05-30T08:59:54,242][INFO ][logstash.outputs.elasticsearch] Using mapping template from {:path=>nil}
[2018-05-30T08:59:54,258][INFO ][logstash.outputs.elasticsearch] Attempting to install template {:manage_template=>{"template"=>"logstash-*", "version"=>60001, "settings"=>{"index.refresh_interval"=>"5s"}, "mappings"=>{"_default_"=>{"dynamic_templates"=>[{"message_field"=>{"path_match"=>"message", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false}}}, {"string_fields"=>{"match"=>"*", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false, "fields"=>{"keyword"=>{"type"=>"keyword", "ignore_above"=>256}}}}}], "properties"=>{"@timestamp"=>{"type"=>"date"}, "@version"=>{"type"=>"keyword"}, "geoip"=>{"dynamic"=>true, "properties"=>{"ip"=>{"type"=>"ip"}, "location"=>{"type"=>"geo_point"}, "latitude"=>{"type"=>"half_float"}, "longitude"=>{"type"=>"half_float"}}}}}}}}
[2018-05-30T08:59:54,273][INFO ][logstash.outputs.elasticsearch] New Elasticsearch output {:class=>"LogStash::Outputs::ElasticSearch", :hosts=>["//100.100.100.111:9200", "//100.100.100.112:9200", "//100.100.100.113:9200"]}
[2018-05-30T08:59:55,524][INFO ][logstash.pipeline        ] Pipeline started succesfully {:pipeline_id=>"main", :thread=>"#<Thread:0x5a95671d@/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:246 run>"}
[2018-05-30T08:59:55,579][INFO ][logstash.agent           ] Pipelines running {:count=>1, :pipelines=>["main"]}
[2018-05-30T08:59:55,792][DEBUG][org.logstash.secret.store.SecretStoreFactory] Attempting to exists or secret store with implementation: org.logstash.secret.store.backend.JavaKeyStore
[2018-05-30T08:59:56,129][DEBUG][org.logstash.secret.store.SecretStoreFactory] Attempting to exists or secret store with implementation: org.logstash.secret.store.backend.JavaKeyStore
[2018-05-30T08:59:56,244][INFO ][logstash.inputs.jdbc     ] (2.382189s) select
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    DECODE(NVL(MODELNO_GROUP,0),0,0,1) AS MODELNO_GROUP_FLAG,
    category,
    '' as cg,
    '' as cat1,
    '' as cat2,
    '' as cat3,
    '' as cat4,
    ca_code,
    ca_dept_mcode,
    ca_dept_code,
    ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,
    shop_name,
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    '' as model_factory,
    minprice,
    maxprice,
    minprices,
    C_DATE,
    mallcnt,
    DECODE(NVL(MALLCNT,0),0,0,1) AS MALLCNT_FLAG,
    spec,
    openexpectflag,
    condiname,
    KEYWORD,
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    MODELNM || ' ' || FACTORY || ' ' || SPEC || ' ' || KEYWORD || ' ' || KEYWORD2 || ' ' || CONDINAME AS to_all
from (

select
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    CASE WHEN service_gubun='2' AND store_flag='1' AND ca_dept_code IS NOT NULL THEN RTRIM(category || ' '  || ca_dept_code) ELSE category END AS category,
    ca_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),3,8)='000000' OR SUBSTR(RTRIM(ca_dept_code),3,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,4) END AS ca_dept_mcode,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),5,8)='0000' OR SUBSTR(RTRIM(ca_dept_code),5,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,6) END AS ca_dept_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),7,8)='00' OR SUBSTR(RTRIM(ca_dept_code),7,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,8) END AS ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,    
    shop_name,    
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    model_factory,
    minprice,
    maxprice,
    replace(minprices, ' ', '    ') as minprices,
    C_DATE,
    mallcnt,
    replace(replace(spec,',',' '),'/',' ') spec,
    openexpectflag,
    replace(condiname, ' ', '    ') as condiname,    
    CASE WHEN socialprice=0 THEN keyword ELSE keyword || ' ' || UDF_SOCIAL_GOODSNM(modelno_group,modelno) END AS KEYWORD,    
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag
FROM tmp_es_price_data_01
WHERE mod_no = '5'

)

[2018-05-30T08:59:56,255][INFO ][logstash.inputs.jdbc     ] (2.380964s) select 
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    DECODE(NVL(MODELNO_GROUP,0),0,0,1) AS MODELNO_GROUP_FLAG,
    category,
    '' as cg,
    '' as cat1,
    '' as cat2,
    '' as cat3,
    '' as cat4,
    ca_code,
    ca_dept_mcode,
    ca_dept_code,
    ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,
    shop_name,
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    MODELNM || ' ' || FACTORY as model_factory,
    minprice,
    maxprice,
    minprices,
    C_DATE,
    mallcnt,
    DECODE(NVL(MALLCNT,0),0,0,1) AS MALLCNT_FLAG,
    spec,
    openexpectflag,
    condiname,
    KEYWORD,
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    MODELNM || ' ' || FACTORY || ' ' || SPEC || ' ' || KEYWORD || ' ' || KEYWORD2 || ' ' || CONDINAME AS to_all
from (

select
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    CASE WHEN service_gubun='2' AND store_flag='1' AND ca_dept_code IS NOT NULL THEN RTRIM(category || ' '  || ca_dept_code) ELSE category END AS category,
    ca_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),3,8)='000000' OR SUBSTR(RTRIM(ca_dept_code),3,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,4) END AS ca_dept_mcode,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),5,8)='0000' OR SUBSTR(RTRIM(ca_dept_code),5,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,6) END AS ca_dept_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),7,8)='00' OR SUBSTR(RTRIM(ca_dept_code),7,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,8) END AS ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,    
    shop_name,    
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    model_factory,
    minprice,
    maxprice,
    replace(minprices, ' ', '    ') as minprices,
    C_DATE,
    mallcnt,
    replace(replace(spec,',',' '),'/',' ') spec,
    openexpectflag,
    replace(condiname, ' ', '    ') as condiname,    
    CASE WHEN socialprice=0 THEN keyword ELSE keyword || ' ' || UDF_SOCIAL_GOODSNM(modelno_group,modelno) END AS KEYWORD,    
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag
FROM tmp_es_goods_data_01    
WHERE mod_no = '5'

)

[2018-05-30T08:59:56,298][INFO ][logstash.filters.ruby.script] Test run complete {:script_path=>"rubyfilter.rb", :results=>{:passed=>0, :failed=>0, :errored=>0}}
[2018-05-30T08:59:56,603][DEBUG][org.logstash.secret.store.SecretStoreFactory] Attempting to exists or secret store with implementation: org.logstash.secret.store.backend.JavaKeyStore
[2018-05-30T08:59:56,782][WARN ][logstash.outputs.elasticsearch] You are using a deprecated config setting "document_type" set in elasticsearch. Deprecated settings will continue to work, but are scheduled for removal from logstash in the future. Document types are being deprecated in Elasticsearch 6.0, and removed entirely in 7.0. You should avoid this feature If you have any questions about this, please visit the #logstash channel on freenode irc. {:name=>"document_type", :plugin=><LogStash::Outputs::ElasticSearch hosts=>[//100.100.100.111:9200, //100.100.100.112:9200, //100.100.100.113:9200], index=>"qa-enuri-main-as-is-2018.05.29.23.58", document_type=>"_doc", document_id=>"%{id}", action=>"index", id=>"ec2e7209120401ff8ce6f1bf881afce389606f2f172cbfead5336a4a708867ff", enable_metric=>true, codec=><LogStash::Codecs::Plain id=>"plain_eb8fff86-0a37-49f8-9469-d5b259670260", enable_metric=>true, charset=>"UTF-8">, workers=>1, manage_template=>true, template_name=>"logstash", template_overwrite=>false, doc_as_upsert=>false, script_type=>"inline", script_lang=>"painless", script_var_name=>"event", scripted_upsert=>false, retry_initial_interval=>2, retry_max_interval=>64, retry_on_conflict=>1, ssl_certificate_verification=>true, sniffing=>false, sniffing_delay=>5, timeout=>60, pool_max=>1000, pool_max_per_route=>100, resurrect_delay=>5, validate_after_inactivity=>10000, http_compression=>false>}
[2018-05-30T08:59:56,888][INFO ][logstash.pipeline        ] Starting pipeline {:pipeline_id=>"main", "pipeline.workers"=>8, "pipeline.batch.size"=>125, "pipeline.batch.delay"=>50}
[2018-05-30T08:59:57,679][INFO ][logstash.outputs.elasticsearch] Elasticsearch pool URLs updated {:changes=>{:removed=>[], :added=>[http://100.100.100.111:9200/, http://100.100.100.112:9200/, http://100.100.100.113:9200/]}}
[2018-05-30T08:59:57,690][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://100.100.100.111:9200/, :path=>"/"}
[2018-05-30T08:59:57,899][INFO ][logstash.inputs.jdbc     ] (3.338651s) select
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    DECODE(NVL(MODELNO_GROUP,0),0,0,1) AS MODELNO_GROUP_FLAG,
    category,
    '' as cg,
    '' as cat1,
    '' as cat2,
    '' as cat3,
    '' as cat4,
    ca_code,
    ca_dept_mcode,
    ca_dept_code,
    ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,
    shop_name,
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    '' as model_factory,
    minprice,
    maxprice,
    minprices,
    C_DATE,
    mallcnt,
    DECODE(NVL(MALLCNT,0),0,0,1) AS MALLCNT_FLAG,
    spec,
    openexpectflag,
    condiname,
    KEYWORD,
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    MODELNM || ' ' || FACTORY || ' ' || SPEC || ' ' || KEYWORD || ' ' || KEYWORD2 || ' ' || CONDINAME AS to_all
from (

select
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    CASE WHEN service_gubun='2' AND store_flag='1' AND ca_dept_code IS NOT NULL THEN RTRIM(category || ' '  || ca_dept_code) ELSE category END AS category,
    ca_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),3,8)='000000' OR SUBSTR(RTRIM(ca_dept_code),3,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,4) END AS ca_dept_mcode,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),5,8)='0000' OR SUBSTR(RTRIM(ca_dept_code),5,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,6) END AS ca_dept_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),7,8)='00' OR SUBSTR(RTRIM(ca_dept_code),7,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,8) END AS ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,    
    shop_name,    
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    model_factory,
    minprice,
    maxprice,
    replace(minprices, ' ', '    ') as minprices,
    C_DATE,
    mallcnt,
    replace(replace(spec,',',' '),'/',' ') spec,
    openexpectflag,
    replace(condiname, ' ', '    ') as condiname,    
    CASE WHEN socialprice=0 THEN keyword ELSE keyword || ' ' || UDF_SOCIAL_GOODSNM(modelno_group,modelno) END AS KEYWORD,    
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag
FROM tmp_es_price_data_01
WHERE mod_no = '0'

)

[2018-05-30T08:59:57,907][INFO ][logstash.inputs.jdbc     ] (3.299484s) select 
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    DECODE(NVL(MODELNO_GROUP,0),0,0,1) AS MODELNO_GROUP_FLAG,
    category,
    '' as cg,
    '' as cat1,
    '' as cat2,
    '' as cat3,
    '' as cat4,
    ca_code,
    ca_dept_mcode,
    ca_dept_code,
    ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,
    shop_name,
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    MODELNM || ' ' || FACTORY as model_factory,
    minprice,
    maxprice,
    minprices,
    C_DATE,
    mallcnt,
    DECODE(NVL(MALLCNT,0),0,0,1) AS MALLCNT_FLAG,
    spec,
    openexpectflag,
    condiname,
    KEYWORD,
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    MODELNM || ' ' || FACTORY || ' ' || SPEC || ' ' || KEYWORD || ' ' || KEYWORD2 || ' ' || CONDINAME AS to_all
from (

select
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    CASE WHEN service_gubun='2' AND store_flag='1' AND ca_dept_code IS NOT NULL THEN RTRIM(category || ' '  || ca_dept_code) ELSE category END AS category,
    ca_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),3,8)='000000' OR SUBSTR(RTRIM(ca_dept_code),3,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,4) END AS ca_dept_mcode,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),5,8)='0000' OR SUBSTR(RTRIM(ca_dept_code),5,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,6) END AS ca_dept_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),7,8)='00' OR SUBSTR(RTRIM(ca_dept_code),7,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,8) END AS ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,    
    shop_name,    
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    model_factory,
    minprice,
    maxprice,
    replace(minprices, ' ', '    ') as minprices,
    C_DATE,
    mallcnt,
    replace(replace(spec,',',' '),'/',' ') spec,
    openexpectflag,
    replace(condiname, ' ', '    ') as condiname,    
    CASE WHEN socialprice=0 THEN keyword ELSE keyword || ' ' || UDF_SOCIAL_GOODSNM(modelno_group,modelno) END AS KEYWORD,    
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag
FROM tmp_es_goods_data_01    
WHERE mod_no = '0'

)

[2018-05-30T08:59:58,117][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://100.100.100.111:9200/"}
[2018-05-30T08:59:58,254][INFO ][logstash.inputs.jdbc     ] (2.764396s) select
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    DECODE(NVL(MODELNO_GROUP,0),0,0,1) AS MODELNO_GROUP_FLAG,
    category,
    '' as cg,
    '' as cat1,
    '' as cat2,
    '' as cat3,
    '' as cat4,
    ca_code,
    ca_dept_mcode,
    ca_dept_code,
    ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,
    shop_name,
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    '' as model_factory,
    minprice,
    maxprice,
    minprices,
    C_DATE,
    mallcnt,
    DECODE(NVL(MALLCNT,0),0,0,1) AS MALLCNT_FLAG,
    spec,
    openexpectflag,
    condiname,
    KEYWORD,
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    MODELNM || ' ' || FACTORY || ' ' || SPEC || ' ' || KEYWORD || ' ' || KEYWORD2 || ' ' || CONDINAME AS to_all
from (

select
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    CASE WHEN service_gubun='2' AND store_flag='1' AND ca_dept_code IS NOT NULL THEN RTRIM(category || ' '  || ca_dept_code) ELSE category END AS category,
    ca_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),3,8)='000000' OR SUBSTR(RTRIM(ca_dept_code),3,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,4) END AS ca_dept_mcode,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),5,8)='0000' OR SUBSTR(RTRIM(ca_dept_code),5,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,6) END AS ca_dept_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),7,8)='00' OR SUBSTR(RTRIM(ca_dept_code),7,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,8) END AS ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,    
    shop_name,    
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    model_factory,
    minprice,
    maxprice,
    replace(minprices, ' ', '    ') as minprices,
    C_DATE,
    mallcnt,
    replace(replace(spec,',',' '),'/',' ') spec,
    openexpectflag,
    replace(condiname, ' ', '    ') as condiname,    
    CASE WHEN socialprice=0 THEN keyword ELSE keyword || ' ' || UDF_SOCIAL_GOODSNM(modelno_group,modelno) END AS KEYWORD,    
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag
FROM tmp_es_price_data_01
WHERE mod_no = '2'

)

[2018-05-30T08:59:58,299][INFO ][logstash.outputs.elasticsearch] ES Output version determined {:es_version=>6}
[2018-05-30T08:59:58,300][WARN ][logstash.outputs.elasticsearch] Detected a 6.x and above cluster: the `type` event field won't be used to determine the document _type {:es_version=>6}
[2018-05-30T08:59:58,300][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://100.100.100.112:9200/, :path=>"/"}
[2018-05-30T08:59:58,301][INFO ][logstash.inputs.jdbc     ] (2.812415s) select 
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    DECODE(NVL(MODELNO_GROUP,0),0,0,1) AS MODELNO_GROUP_FLAG,
    category,
    '' as cg,
    '' as cat1,
    '' as cat2,
    '' as cat3,
    '' as cat4,
    ca_code,
    ca_dept_mcode,
    ca_dept_code,
    ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,
    shop_name,
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    MODELNM || ' ' || FACTORY as model_factory,
    minprice,
    maxprice,
    minprices,
    C_DATE,
    mallcnt,
    DECODE(NVL(MALLCNT,0),0,0,1) AS MALLCNT_FLAG,
    spec,
    openexpectflag,
    condiname,
    KEYWORD,
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    MODELNM || ' ' || FACTORY || ' ' || SPEC || ' ' || KEYWORD || ' ' || KEYWORD2 || ' ' || CONDINAME AS to_all
from (

select
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    CASE WHEN service_gubun='2' AND store_flag='1' AND ca_dept_code IS NOT NULL THEN RTRIM(category || ' '  || ca_dept_code) ELSE category END AS category,
    ca_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),3,8)='000000' OR SUBSTR(RTRIM(ca_dept_code),3,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,4) END AS ca_dept_mcode,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),5,8)='0000' OR SUBSTR(RTRIM(ca_dept_code),5,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,6) END AS ca_dept_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),7,8)='00' OR SUBSTR(RTRIM(ca_dept_code),7,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,8) END AS ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,    
    shop_name,    
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    model_factory,
    minprice,
    maxprice,
    replace(minprices, ' ', '    ') as minprices,
    C_DATE,
    mallcnt,
    replace(replace(spec,',',' '),'/',' ') spec,
    openexpectflag,
    replace(condiname, ' ', '    ') as condiname,    
    CASE WHEN socialprice=0 THEN keyword ELSE keyword || ' ' || UDF_SOCIAL_GOODSNM(modelno_group,modelno) END AS KEYWORD,    
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag
FROM tmp_es_goods_data_01    
WHERE mod_no = '2'

)

[2018-05-30T08:59:58,340][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://100.100.100.112:9200/"}
[2018-05-30T08:59:58,346][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://100.100.100.113:9200/, :path=>"/"}
[2018-05-30T08:59:58,363][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://100.100.100.113:9200/"}
[2018-05-30T08:59:58,484][INFO ][logstash.outputs.elasticsearch] Using mapping template from {:path=>nil}
[2018-05-30T08:59:58,503][INFO ][logstash.outputs.elasticsearch] Attempting to install template {:manage_template=>{"template"=>"logstash-*", "version"=>60001, "settings"=>{"index.refresh_interval"=>"5s"}, "mappings"=>{"_default_"=>{"dynamic_templates"=>[{"message_field"=>{"path_match"=>"message", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false}}}, {"string_fields"=>{"match"=>"*", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false, "fields"=>{"keyword"=>{"type"=>"keyword", "ignore_above"=>256}}}}}], "properties"=>{"@timestamp"=>{"type"=>"date"}, "@version"=>{"type"=>"keyword"}, "geoip"=>{"dynamic"=>true, "properties"=>{"ip"=>{"type"=>"ip"}, "location"=>{"type"=>"geo_point"}, "latitude"=>{"type"=>"half_float"}, "longitude"=>{"type"=>"half_float"}}}}}}}}
[2018-05-30T08:59:58,526][INFO ][logstash.outputs.elasticsearch] New Elasticsearch output {:class=>"LogStash::Outputs::ElasticSearch", :hosts=>["//100.100.100.111:9200", "//100.100.100.112:9200", "//100.100.100.113:9200"]}
[2018-05-30T08:59:59,722][INFO ][logstash.pipeline        ] Pipeline started succesfully {:pipeline_id=>"main", :thread=>"#<Thread:0x3d5c25c3@/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:246 run>"}
[2018-05-30T08:59:59,755][INFO ][logstash.agent           ] Pipelines running {:count=>1, :pipelines=>["main"]}
[2018-05-30T09:00:00,069][INFO ][logstash.inputs.jdbc     ] (2.047252s) select
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    DECODE(NVL(MODELNO_GROUP,0),0,0,1) AS MODELNO_GROUP_FLAG,
    category,
    '' as cg,
    '' as cat1,
    '' as cat2,
    '' as cat3,
    '' as cat4,
    ca_code,
    ca_dept_mcode,
    ca_dept_code,
    ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,
    shop_name,
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    '' as model_factory,
    minprice,
    maxprice,
    minprices,
    C_DATE,
    mallcnt,
    DECODE(NVL(MALLCNT,0),0,0,1) AS MALLCNT_FLAG,
    spec,
    openexpectflag,
    condiname,
    KEYWORD,
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    MODELNM || ' ' || FACTORY || ' ' || SPEC || ' ' || KEYWORD || ' ' || KEYWORD2 || ' ' || CONDINAME AS to_all
from (

select
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    CASE WHEN service_gubun='2' AND store_flag='1' AND ca_dept_code IS NOT NULL THEN RTRIM(category || ' '  || ca_dept_code) ELSE category END AS category,
    ca_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),3,8)='000000' OR SUBSTR(RTRIM(ca_dept_code),3,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,4) END AS ca_dept_mcode,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),5,8)='0000' OR SUBSTR(RTRIM(ca_dept_code),5,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,6) END AS ca_dept_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),7,8)='00' OR SUBSTR(RTRIM(ca_dept_code),7,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,8) END AS ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,    
    shop_name,    
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    model_factory,
    minprice,
    maxprice,
    replace(minprices, ' ', '    ') as minprices,
    C_DATE,
    mallcnt,
    replace(replace(spec,',',' '),'/',' ') spec,
    openexpectflag,
    replace(condiname, ' ', '    ') as condiname,    
    CASE WHEN socialprice=0 THEN keyword ELSE keyword || ' ' || UDF_SOCIAL_GOODSNM(modelno_group,modelno) END AS KEYWORD,    
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag
FROM tmp_es_price_data_01
WHERE mod_no = '4'

)

[2018-05-30T09:00:00,076][INFO ][logstash.inputs.jdbc     ] (2.060369s) select 
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    DECODE(NVL(MODELNO_GROUP,0),0,0,1) AS MODELNO_GROUP_FLAG,
    category,
    '' as cg,
    '' as cat1,
    '' as cat2,
    '' as cat3,
    '' as cat4,
    ca_code,
    ca_dept_mcode,
    ca_dept_code,
    ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,
    shop_name,
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    MODELNM || ' ' || FACTORY as model_factory,
    minprice,
    maxprice,
    minprices,
    C_DATE,
    mallcnt,
    DECODE(NVL(MALLCNT,0),0,0,1) AS MALLCNT_FLAG,
    spec,
    openexpectflag,
    condiname,
    KEYWORD,
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    MODELNM || ' ' || FACTORY || ' ' || SPEC || ' ' || KEYWORD || ' ' || KEYWORD2 || ' ' || CONDINAME AS to_all
from (

select
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    CASE WHEN service_gubun='2' AND store_flag='1' AND ca_dept_code IS NOT NULL THEN RTRIM(category || ' '  || ca_dept_code) ELSE category END AS category,
    ca_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),3,8)='000000' OR SUBSTR(RTRIM(ca_dept_code),3,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,4) END AS ca_dept_mcode,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),5,8)='0000' OR SUBSTR(RTRIM(ca_dept_code),5,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,6) END AS ca_dept_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),7,8)='00' OR SUBSTR(RTRIM(ca_dept_code),7,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,8) END AS ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,    
    shop_name,    
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    model_factory,
    minprice,
    maxprice,
    replace(minprices, ' ', '    ') as minprices,
    C_DATE,
    mallcnt,
    replace(replace(spec,',',' '),'/',' ') spec,
    openexpectflag,
    replace(condiname, ' ', '    ') as condiname,    
    CASE WHEN socialprice=0 THEN keyword ELSE keyword || ' ' || UDF_SOCIAL_GOODSNM(modelno_group,modelno) END AS KEYWORD,    
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag
FROM tmp_es_goods_data_01    
WHERE mod_no = '4'

)

[2018-05-30T09:00:01,876][INFO ][logstash.inputs.jdbc     ] (0.963890s) select 
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    DECODE(NVL(MODELNO_GROUP,0),0,0,1) AS MODELNO_GROUP_FLAG,
    category,
    '' as cg,
    '' as cat1,
    '' as cat2,
    '' as cat3,
    '' as cat4,
    ca_code,
    ca_dept_mcode,
    ca_dept_code,
    ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,
    shop_name,
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    MODELNM || ' ' || FACTORY as model_factory,
    minprice,
    maxprice,
    minprices,
    C_DATE,
    mallcnt,
    DECODE(NVL(MALLCNT,0),0,0,1) AS MALLCNT_FLAG,
    spec,
    openexpectflag,
    condiname,
    KEYWORD,
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    MODELNM || ' ' || FACTORY || ' ' || SPEC || ' ' || KEYWORD || ' ' || KEYWORD2 || ' ' || CONDINAME AS to_all
from (

select
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    CASE WHEN service_gubun='2' AND store_flag='1' AND ca_dept_code IS NOT NULL THEN RTRIM(category || ' '  || ca_dept_code) ELSE category END AS category,
    ca_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),3,8)='000000' OR SUBSTR(RTRIM(ca_dept_code),3,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,4) END AS ca_dept_mcode,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),5,8)='0000' OR SUBSTR(RTRIM(ca_dept_code),5,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,6) END AS ca_dept_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),7,8)='00' OR SUBSTR(RTRIM(ca_dept_code),7,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,8) END AS ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,    
    shop_name,    
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    model_factory,
    minprice,
    maxprice,
    replace(minprices, ' ', '    ') as minprices,
    C_DATE,
    mallcnt,
    replace(replace(spec,',',' '),'/',' ') spec,
    openexpectflag,
    replace(condiname, ' ', '    ') as condiname,    
    CASE WHEN socialprice=0 THEN keyword ELSE keyword || ' ' || UDF_SOCIAL_GOODSNM(modelno_group,modelno) END AS KEYWORD,    
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag
FROM tmp_es_goods_data_01    
WHERE mod_no = '3'

)

[2018-05-30T09:00:01,879][INFO ][logstash.inputs.jdbc     ] (0.971090s) select
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    DECODE(NVL(MODELNO_GROUP,0),0,0,1) AS MODELNO_GROUP_FLAG,
    category,
    '' as cg,
    '' as cat1,
    '' as cat2,
    '' as cat3,
    '' as cat4,
    ca_code,
    ca_dept_mcode,
    ca_dept_code,
    ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,
    shop_name,
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    '' as model_factory,
    minprice,
    maxprice,
    minprices,
    C_DATE,
    mallcnt,
    DECODE(NVL(MALLCNT,0),0,0,1) AS MALLCNT_FLAG,
    spec,
    openexpectflag,
    condiname,
    KEYWORD,
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    MODELNM || ' ' || FACTORY || ' ' || SPEC || ' ' || KEYWORD || ' ' || KEYWORD2 || ' ' || CONDINAME AS to_all
from (

select
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    CASE WHEN service_gubun='2' AND store_flag='1' AND ca_dept_code IS NOT NULL THEN RTRIM(category || ' '  || ca_dept_code) ELSE category END AS category,
    ca_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),3,8)='000000' OR SUBSTR(RTRIM(ca_dept_code),3,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,4) END AS ca_dept_mcode,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),5,8)='0000' OR SUBSTR(RTRIM(ca_dept_code),5,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,6) END AS ca_dept_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),7,8)='00' OR SUBSTR(RTRIM(ca_dept_code),7,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,8) END AS ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,    
    shop_name,    
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    model_factory,
    minprice,
    maxprice,
    replace(minprices, ' ', '    ') as minprices,
    C_DATE,
    mallcnt,
    replace(replace(spec,',',' '),'/',' ') spec,
    openexpectflag,
    replace(condiname, ' ', '    ') as condiname,    
    CASE WHEN socialprice=0 THEN keyword ELSE keyword || ' ' || UDF_SOCIAL_GOODSNM(modelno_group,modelno) END AS KEYWORD,    
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag
FROM tmp_es_price_data_01
WHERE mod_no = '3'

)

[2018-05-30T09:21:50,193][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"fb_apache", :directory=>"/usr/share/logstash/modules/fb_apache/configuration"}
[2018-05-30T09:21:50,203][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"netflow", :directory=>"/usr/share/logstash/modules/netflow/configuration"}
[2018-05-30T09:21:50,331][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"fb_apache", :directory=>"/usr/share/logstash/modules/fb_apache/configuration"}
[2018-05-30T09:21:50,356][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"netflow", :directory=>"/usr/share/logstash/modules/netflow/configuration"}
[2018-05-30T09:21:51,384][WARN ][logstash.config.source.multilocal] Ignoring the 'pipelines.yml' file because modules or command line options are specified
[2018-05-30T09:21:51,463][WARN ][logstash.config.source.multilocal] Ignoring the 'pipelines.yml' file because modules or command line options are specified
[2018-05-30T09:21:51,489][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"fb_apache", :directory=>"/usr/share/logstash/modules/fb_apache/configuration"}
[2018-05-30T09:21:51,531][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"netflow", :directory=>"/usr/share/logstash/modules/netflow/configuration"}
[2018-05-30T09:21:51,901][INFO ][logstash.runner          ] Starting Logstash {"logstash.version"=>"6.2.3"}
[2018-05-30T09:21:52,117][INFO ][logstash.runner          ] Starting Logstash {"logstash.version"=>"6.2.3"}
[2018-05-30T09:21:52,153][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"fb_apache", :directory=>"/usr/share/logstash/modules/fb_apache/configuration"}
[2018-05-30T09:21:52,192][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"netflow", :directory=>"/usr/share/logstash/modules/netflow/configuration"}
[2018-05-30T09:21:52,425][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=>9600}
[2018-05-30T09:21:52,434][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"fb_apache", :directory=>"/usr/share/logstash/modules/fb_apache/configuration"}
[2018-05-30T09:21:52,465][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"netflow", :directory=>"/usr/share/logstash/modules/netflow/configuration"}
[2018-05-30T09:21:52,619][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=>9601}
[2018-05-30T09:21:52,716][WARN ][logstash.config.source.multilocal] Ignoring the 'pipelines.yml' file because modules or command line options are specified
[2018-05-30T09:21:53,388][INFO ][logstash.runner          ] Starting Logstash {"logstash.version"=>"6.2.3"}
[2018-05-30T09:21:53,662][WARN ][logstash.config.source.multilocal] Ignoring the 'pipelines.yml' file because modules or command line options are specified
[2018-05-30T09:21:53,863][WARN ][logstash.config.source.multilocal] Ignoring the 'pipelines.yml' file because modules or command line options are specified
[2018-05-30T09:21:54,078][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=>9602}
[2018-05-30T09:21:54,380][INFO ][logstash.runner          ] Starting Logstash {"logstash.version"=>"6.2.3"}
[2018-05-30T09:21:54,492][INFO ][logstash.runner          ] Starting Logstash {"logstash.version"=>"6.2.3"}
[2018-05-30T09:21:54,738][DEBUG][org.logstash.secret.store.SecretStoreFactory] Attempting to exists or secret store with implementation: org.logstash.secret.store.backend.JavaKeyStore
[2018-05-30T09:21:54,948][DEBUG][org.logstash.secret.store.SecretStoreFactory] Attempting to exists or secret store with implementation: org.logstash.secret.store.backend.JavaKeyStore
[2018-05-30T09:21:55,219][INFO ][logstash.filters.ruby.script] Test run complete {:script_path=>"rubyfilter.rb", :results=>{:passed=>0, :failed=>0, :errored=>0}}
[2018-05-30T09:21:55,337][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=>9603}
[2018-05-30T09:21:55,482][DEBUG][org.logstash.secret.store.SecretStoreFactory] Attempting to exists or secret store with implementation: org.logstash.secret.store.backend.JavaKeyStore
[2018-05-30T09:21:55,577][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=>9604}
[2018-05-30T09:21:55,605][DEBUG][org.logstash.secret.store.SecretStoreFactory] Attempting to exists or secret store with implementation: org.logstash.secret.store.backend.JavaKeyStore
[2018-05-30T09:21:55,805][WARN ][logstash.outputs.elasticsearch] You are using a deprecated config setting "document_type" set in elasticsearch. Deprecated settings will continue to work, but are scheduled for removal from logstash in the future. Document types are being deprecated in Elasticsearch 6.0, and removed entirely in 7.0. You should avoid this feature If you have any questions about this, please visit the #logstash channel on freenode irc. {:name=>"document_type", :plugin=><LogStash::Outputs::ElasticSearch hosts=>[//100.100.100.111:9200, //100.100.100.112:9200, //100.100.100.113:9200], index=>"qa-enuri-main-as-is-2018.05.30.00.21", document_type=>"_doc", document_id=>"%{id}", action=>"index", id=>"ec2e7209120401ff8ce6f1bf881afce389606f2f172cbfead5336a4a708867ff", enable_metric=>true, codec=><LogStash::Codecs::Plain id=>"plain_bd507746-b52f-4bc9-a863-bfe0deef68aa", enable_metric=>true, charset=>"UTF-8">, workers=>1, manage_template=>true, template_name=>"logstash", template_overwrite=>false, doc_as_upsert=>false, script_type=>"inline", script_lang=>"painless", script_var_name=>"event", scripted_upsert=>false, retry_initial_interval=>2, retry_max_interval=>64, retry_on_conflict=>1, ssl_certificate_verification=>true, sniffing=>false, sniffing_delay=>5, timeout=>60, pool_max=>1000, pool_max_per_route=>100, resurrect_delay=>5, validate_after_inactivity=>10000, http_compression=>false>}
[2018-05-30T09:21:55,815][DEBUG][org.logstash.secret.store.SecretStoreFactory] Attempting to exists or secret store with implementation: org.logstash.secret.store.backend.JavaKeyStore
[2018-05-30T09:21:55,916][INFO ][logstash.pipeline        ] Starting pipeline {:pipeline_id=>"main", "pipeline.workers"=>8, "pipeline.batch.size"=>125, "pipeline.batch.delay"=>50}
[2018-05-30T09:21:56,067][INFO ][logstash.filters.ruby.script] Test run complete {:script_path=>"rubyfilter.rb", :results=>{:passed=>0, :failed=>0, :errored=>0}}
[2018-05-30T09:21:56,417][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"fb_apache", :directory=>"/usr/share/logstash/modules/fb_apache/configuration"}
[2018-05-30T09:21:56,425][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"netflow", :directory=>"/usr/share/logstash/modules/netflow/configuration"}
[2018-05-30T09:21:56,479][DEBUG][org.logstash.secret.store.SecretStoreFactory] Attempting to exists or secret store with implementation: org.logstash.secret.store.backend.JavaKeyStore
[2018-05-30T09:21:56,496][DEBUG][org.logstash.secret.store.SecretStoreFactory] Attempting to exists or secret store with implementation: org.logstash.secret.store.backend.JavaKeyStore
[2018-05-30T09:21:56,574][WARN ][logstash.outputs.elasticsearch] You are using a deprecated config setting "document_type" set in elasticsearch. Deprecated settings will continue to work, but are scheduled for removal from logstash in the future. Document types are being deprecated in Elasticsearch 6.0, and removed entirely in 7.0. You should avoid this feature If you have any questions about this, please visit the #logstash channel on freenode irc. {:name=>"document_type", :plugin=><LogStash::Outputs::ElasticSearch hosts=>[//100.100.100.111:9200, //100.100.100.112:9200, //100.100.100.113:9200], index=>"qa-enuri-main-as-is-2018.05.30.00.21", document_type=>"_doc", document_id=>"%{id}", action=>"index", id=>"ec2e7209120401ff8ce6f1bf881afce389606f2f172cbfead5336a4a708867ff", enable_metric=>true, codec=><LogStash::Codecs::Plain id=>"plain_10374523-ef4a-4f61-9630-5b134291c1e1", enable_metric=>true, charset=>"UTF-8">, workers=>1, manage_template=>true, template_name=>"logstash", template_overwrite=>false, doc_as_upsert=>false, script_type=>"inline", script_lang=>"painless", script_var_name=>"event", scripted_upsert=>false, retry_initial_interval=>2, retry_max_interval=>64, retry_on_conflict=>1, ssl_certificate_verification=>true, sniffing=>false, sniffing_delay=>5, timeout=>60, pool_max=>1000, pool_max_per_route=>100, resurrect_delay=>5, validate_after_inactivity=>10000, http_compression=>false>}
[2018-05-30T09:21:56,625][INFO ][logstash.pipeline        ] Starting pipeline {:pipeline_id=>"main", "pipeline.workers"=>8, "pipeline.batch.size"=>125, "pipeline.batch.delay"=>50}
[2018-05-30T09:21:56,647][DEBUG][org.logstash.secret.store.SecretStoreFactory] Attempting to exists or secret store with implementation: org.logstash.secret.store.backend.JavaKeyStore
[2018-05-30T09:21:56,837][INFO ][logstash.filters.ruby.script] Test run complete {:script_path=>"rubyfilter.rb", :results=>{:passed=>0, :failed=>0, :errored=>0}}
[2018-05-30T09:21:57,131][INFO ][logstash.outputs.elasticsearch] Elasticsearch pool URLs updated {:changes=>{:removed=>[], :added=>[http://100.100.100.111:9200/, http://100.100.100.112:9200/, http://100.100.100.113:9200/]}}
[2018-05-30T09:21:57,163][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://100.100.100.111:9200/, :path=>"/"}
[2018-05-30T09:21:57,200][DEBUG][org.logstash.secret.store.SecretStoreFactory] Attempting to exists or secret store with implementation: org.logstash.secret.store.backend.JavaKeyStore
[2018-05-30T09:21:57,278][DEBUG][org.logstash.secret.store.SecretStoreFactory] Attempting to exists or secret store with implementation: org.logstash.secret.store.backend.JavaKeyStore
[2018-05-30T09:21:57,358][WARN ][logstash.outputs.elasticsearch] You are using a deprecated config setting "document_type" set in elasticsearch. Deprecated settings will continue to work, but are scheduled for removal from logstash in the future. Document types are being deprecated in Elasticsearch 6.0, and removed entirely in 7.0. You should avoid this feature If you have any questions about this, please visit the #logstash channel on freenode irc. {:name=>"document_type", :plugin=><LogStash::Outputs::ElasticSearch hosts=>[//100.100.100.111:9200, //100.100.100.112:9200, //100.100.100.113:9200], index=>"qa-enuri-main-as-is-2018.05.30.00.21", document_type=>"_doc", document_id=>"%{id}", action=>"index", id=>"ec2e7209120401ff8ce6f1bf881afce389606f2f172cbfead5336a4a708867ff", enable_metric=>true, codec=><LogStash::Codecs::Plain id=>"plain_9f059e22-e36f-41ba-96ae-31b24d68b3f1", enable_metric=>true, charset=>"UTF-8">, workers=>1, manage_template=>true, template_name=>"logstash", template_overwrite=>false, doc_as_upsert=>false, script_type=>"inline", script_lang=>"painless", script_var_name=>"event", scripted_upsert=>false, retry_initial_interval=>2, retry_max_interval=>64, retry_on_conflict=>1, ssl_certificate_verification=>true, sniffing=>false, sniffing_delay=>5, timeout=>60, pool_max=>1000, pool_max_per_route=>100, resurrect_delay=>5, validate_after_inactivity=>10000, http_compression=>false>}
[2018-05-30T09:21:57,386][INFO ][logstash.pipeline        ] Starting pipeline {:pipeline_id=>"main", "pipeline.workers"=>8, "pipeline.batch.size"=>125, "pipeline.batch.delay"=>50}
[2018-05-30T09:21:57,470][DEBUG][org.logstash.secret.store.SecretStoreFactory] Attempting to exists or secret store with implementation: org.logstash.secret.store.backend.JavaKeyStore
[2018-05-30T09:21:57,682][WARN ][logstash.config.source.multilocal] Ignoring the 'pipelines.yml' file because modules or command line options are specified
[2018-05-30T09:21:57,684][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://100.100.100.111:9200/"}
[2018-05-30T09:21:57,711][DEBUG][org.logstash.secret.store.SecretStoreFactory] Attempting to exists or secret store with implementation: org.logstash.secret.store.backend.JavaKeyStore
[2018-05-30T09:21:57,741][INFO ][logstash.filters.ruby.script] Test run complete {:script_path=>"rubyfilter.rb", :results=>{:passed=>0, :failed=>0, :errored=>0}}
[2018-05-30T09:21:57,813][INFO ][logstash.outputs.elasticsearch] ES Output version determined {:es_version=>6}
[2018-05-30T09:21:57,814][WARN ][logstash.outputs.elasticsearch] Detected a 6.x and above cluster: the `type` event field won't be used to determine the document _type {:es_version=>6}
[2018-05-30T09:21:57,814][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://100.100.100.112:9200/, :path=>"/"}
[2018-05-30T09:21:57,831][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://100.100.100.112:9200/"}
[2018-05-30T09:21:57,844][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://100.100.100.113:9200/, :path=>"/"}
[2018-05-30T09:21:57,862][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://100.100.100.113:9200/"}
[2018-05-30T09:21:57,917][INFO ][logstash.outputs.elasticsearch] Using mapping template from {:path=>nil}
[2018-05-30T09:21:57,998][DEBUG][org.logstash.secret.store.SecretStoreFactory] Attempting to exists or secret store with implementation: org.logstash.secret.store.backend.JavaKeyStore
[2018-05-30T09:21:57,997][INFO ][logstash.outputs.elasticsearch] Attempting to install template {:manage_template=>{"template"=>"logstash-*", "version"=>60001, "settings"=>{"index.refresh_interval"=>"5s"}, "mappings"=>{"_default_"=>{"dynamic_templates"=>[{"message_field"=>{"path_match"=>"message", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false}}}, {"string_fields"=>{"match"=>"*", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false, "fields"=>{"keyword"=>{"type"=>"keyword", "ignore_above"=>256}}}}}], "properties"=>{"@timestamp"=>{"type"=>"date"}, "@version"=>{"type"=>"keyword"}, "geoip"=>{"dynamic"=>true, "properties"=>{"ip"=>{"type"=>"ip"}, "location"=>{"type"=>"geo_point"}, "latitude"=>{"type"=>"half_float"}, "longitude"=>{"type"=>"half_float"}}}}}}}}
[2018-05-30T09:21:58,001][INFO ][logstash.outputs.elasticsearch] Elasticsearch pool URLs updated {:changes=>{:removed=>[], :added=>[http://100.100.100.111:9200/, http://100.100.100.112:9200/, http://100.100.100.113:9200/]}}
[2018-05-30T09:21:58,008][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://100.100.100.111:9200/, :path=>"/"}
[2018-05-30T09:21:58,011][INFO ][logstash.outputs.elasticsearch] New Elasticsearch output {:class=>"LogStash::Outputs::ElasticSearch", :hosts=>["//100.100.100.111:9200", "//100.100.100.112:9200", "//100.100.100.113:9200"]}
[2018-05-30T09:21:58,023][DEBUG][org.logstash.secret.store.SecretStoreFactory] Attempting to exists or secret store with implementation: org.logstash.secret.store.backend.JavaKeyStore
[2018-05-30T09:21:58,133][WARN ][logstash.outputs.elasticsearch] You are using a deprecated config setting "document_type" set in elasticsearch. Deprecated settings will continue to work, but are scheduled for removal from logstash in the future. Document types are being deprecated in Elasticsearch 6.0, and removed entirely in 7.0. You should avoid this feature If you have any questions about this, please visit the #logstash channel on freenode irc. {:name=>"document_type", :plugin=><LogStash::Outputs::ElasticSearch hosts=>[//100.100.100.111:9200, //100.100.100.112:9200, //100.100.100.113:9200], index=>"qa-enuri-main-as-is-2018.05.30.00.21", document_type=>"_doc", document_id=>"%{id}", action=>"index", id=>"ec2e7209120401ff8ce6f1bf881afce389606f2f172cbfead5336a4a708867ff", enable_metric=>true, codec=><LogStash::Codecs::Plain id=>"plain_e7fbccd9-e433-44a3-b7ae-a84cd55e4277", enable_metric=>true, charset=>"UTF-8">, workers=>1, manage_template=>true, template_name=>"logstash", template_overwrite=>false, doc_as_upsert=>false, script_type=>"inline", script_lang=>"painless", script_var_name=>"event", scripted_upsert=>false, retry_initial_interval=>2, retry_max_interval=>64, retry_on_conflict=>1, ssl_certificate_verification=>true, sniffing=>false, sniffing_delay=>5, timeout=>60, pool_max=>1000, pool_max_per_route=>100, resurrect_delay=>5, validate_after_inactivity=>10000, http_compression=>false>}
[2018-05-30T09:21:58,147][INFO ][logstash.pipeline        ] Starting pipeline {:pipeline_id=>"main", "pipeline.workers"=>8, "pipeline.batch.size"=>125, "pipeline.batch.delay"=>50}
[2018-05-30T09:21:58,211][INFO ][logstash.filters.ruby.script] Test run complete {:script_path=>"rubyfilter.rb", :results=>{:passed=>0, :failed=>0, :errored=>0}}
[2018-05-30T09:21:58,383][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://100.100.100.111:9200/"}
[2018-05-30T09:21:58,468][DEBUG][org.logstash.secret.store.SecretStoreFactory] Attempting to exists or secret store with implementation: org.logstash.secret.store.backend.JavaKeyStore
[2018-05-30T09:21:58,478][INFO ][logstash.runner          ] Starting Logstash {"logstash.version"=>"6.2.3"}
[2018-05-30T09:21:58,498][INFO ][logstash.outputs.elasticsearch] ES Output version determined {:es_version=>6}
[2018-05-30T09:21:58,499][WARN ][logstash.outputs.elasticsearch] Detected a 6.x and above cluster: the `type` event field won't be used to determine the document _type {:es_version=>6}
[2018-05-30T09:21:58,499][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://100.100.100.112:9200/, :path=>"/"}
[2018-05-30T09:21:58,524][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://100.100.100.112:9200/"}
[2018-05-30T09:21:58,529][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://100.100.100.113:9200/, :path=>"/"}
[2018-05-30T09:21:58,541][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://100.100.100.113:9200/"}
[2018-05-30T09:21:58,573][WARN ][logstash.outputs.elasticsearch] You are using a deprecated config setting "document_type" set in elasticsearch. Deprecated settings will continue to work, but are scheduled for removal from logstash in the future. Document types are being deprecated in Elasticsearch 6.0, and removed entirely in 7.0. You should avoid this feature If you have any questions about this, please visit the #logstash channel on freenode irc. {:name=>"document_type", :plugin=><LogStash::Outputs::ElasticSearch hosts=>[//100.100.100.111:9200, //100.100.100.112:9200, //100.100.100.113:9200], index=>"qa-enuri-main-as-is-2018.05.30.00.21", document_type=>"_doc", document_id=>"%{id}", action=>"index", id=>"ec2e7209120401ff8ce6f1bf881afce389606f2f172cbfead5336a4a708867ff", enable_metric=>true, codec=><LogStash::Codecs::Plain id=>"plain_f274ab38-3f07-47ef-be0a-2fa0984cd9b4", enable_metric=>true, charset=>"UTF-8">, workers=>1, manage_template=>true, template_name=>"logstash", template_overwrite=>false, doc_as_upsert=>false, script_type=>"inline", script_lang=>"painless", script_var_name=>"event", scripted_upsert=>false, retry_initial_interval=>2, retry_max_interval=>64, retry_on_conflict=>1, ssl_certificate_verification=>true, sniffing=>false, sniffing_delay=>5, timeout=>60, pool_max=>1000, pool_max_per_route=>100, resurrect_delay=>5, validate_after_inactivity=>10000, http_compression=>false>}
[2018-05-30T09:21:58,573][INFO ][logstash.outputs.elasticsearch] Using mapping template from {:path=>nil}
[2018-05-30T09:21:58,585][INFO ][logstash.outputs.elasticsearch] Attempting to install template {:manage_template=>{"template"=>"logstash-*", "version"=>60001, "settings"=>{"index.refresh_interval"=>"5s"}, "mappings"=>{"_default_"=>{"dynamic_templates"=>[{"message_field"=>{"path_match"=>"message", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false}}}, {"string_fields"=>{"match"=>"*", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false, "fields"=>{"keyword"=>{"type"=>"keyword", "ignore_above"=>256}}}}}], "properties"=>{"@timestamp"=>{"type"=>"date"}, "@version"=>{"type"=>"keyword"}, "geoip"=>{"dynamic"=>true, "properties"=>{"ip"=>{"type"=>"ip"}, "location"=>{"type"=>"geo_point"}, "latitude"=>{"type"=>"half_float"}, "longitude"=>{"type"=>"half_float"}}}}}}}}
[2018-05-30T09:21:58,597][INFO ][logstash.outputs.elasticsearch] New Elasticsearch output {:class=>"LogStash::Outputs::ElasticSearch", :hosts=>["//100.100.100.111:9200", "//100.100.100.112:9200", "//100.100.100.113:9200"]}
[2018-05-30T09:21:58,597][INFO ][logstash.pipeline        ] Starting pipeline {:pipeline_id=>"main", "pipeline.workers"=>8, "pipeline.batch.size"=>125, "pipeline.batch.delay"=>50}
[2018-05-30T09:21:58,613][INFO ][logstash.outputs.elasticsearch] Elasticsearch pool URLs updated {:changes=>{:removed=>[], :added=>[http://100.100.100.111:9200/, http://100.100.100.112:9200/, http://100.100.100.113:9200/]}}
[2018-05-30T09:21:58,616][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://100.100.100.111:9200/, :path=>"/"}
[2018-05-30T09:21:58,954][INFO ][logstash.outputs.elasticsearch] Elasticsearch pool URLs updated {:changes=>{:removed=>[], :added=>[http://100.100.100.111:9200/, http://100.100.100.112:9200/, http://100.100.100.113:9200/]}}
[2018-05-30T09:21:58,993][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://100.100.100.111:9200/, :path=>"/"}
[2018-05-30T09:21:59,078][INFO ][logstash.pipeline        ] Pipeline started succesfully {:pipeline_id=>"main", :thread=>"#<Thread:0x3322c7d9@/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:246 run>"}
[2018-05-30T09:21:59,123][INFO ][logstash.agent           ] Pipelines running {:count=>1, :pipelines=>["main"]}
[2018-05-30T09:21:59,429][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://100.100.100.111:9200/"}
[2018-05-30T09:21:59,434][INFO ][logstash.pipeline        ] Pipeline started succesfully {:pipeline_id=>"main", :thread=>"#<Thread:0x121d8d1b@/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:246 run>"}
[2018-05-30T09:21:59,458][INFO ][logstash.agent           ] Pipelines running {:count=>1, :pipelines=>["main"]}
[2018-05-30T09:21:59,463][INFO ][logstash.outputs.elasticsearch] Elasticsearch pool URLs updated {:changes=>{:removed=>[], :added=>[http://100.100.100.111:9200/, http://100.100.100.112:9200/, http://100.100.100.113:9200/]}}
[2018-05-30T09:21:59,468][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://100.100.100.111:9200/, :path=>"/"}
[2018-05-30T09:21:59,448][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=>9605}
[2018-05-30T09:21:59,495][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://100.100.100.111:9200/"}
[2018-05-30T09:21:59,598][INFO ][logstash.outputs.elasticsearch] ES Output version determined {:es_version=>6}
[2018-05-30T09:21:59,599][WARN ][logstash.outputs.elasticsearch] Detected a 6.x and above cluster: the `type` event field won't be used to determine the document _type {:es_version=>6}
[2018-05-30T09:21:59,599][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://100.100.100.112:9200/, :path=>"/"}
[2018-05-30T09:21:59,619][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://100.100.100.112:9200/"}
[2018-05-30T09:21:59,625][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://100.100.100.113:9200/, :path=>"/"}
[2018-05-30T09:21:59,631][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://100.100.100.113:9200/"}
[2018-05-30T09:21:59,670][INFO ][logstash.outputs.elasticsearch] Using mapping template from {:path=>nil}
[2018-05-30T09:21:59,680][INFO ][logstash.outputs.elasticsearch] Attempting to install template {:manage_template=>{"template"=>"logstash-*", "version"=>60001, "settings"=>{"index.refresh_interval"=>"5s"}, "mappings"=>{"_default_"=>{"dynamic_templates"=>[{"message_field"=>{"path_match"=>"message", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false}}}, {"string_fields"=>{"match"=>"*", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false, "fields"=>{"keyword"=>{"type"=>"keyword", "ignore_above"=>256}}}}}], "properties"=>{"@timestamp"=>{"type"=>"date"}, "@version"=>{"type"=>"keyword"}, "geoip"=>{"dynamic"=>true, "properties"=>{"ip"=>{"type"=>"ip"}, "location"=>{"type"=>"geo_point"}, "latitude"=>{"type"=>"half_float"}, "longitude"=>{"type"=>"half_float"}}}}}}}}
[2018-05-30T09:21:59,703][INFO ][logstash.outputs.elasticsearch] ES Output version determined {:es_version=>6}
[2018-05-30T09:21:59,703][WARN ][logstash.outputs.elasticsearch] Detected a 6.x and above cluster: the `type` event field won't be used to determine the document _type {:es_version=>6}
[2018-05-30T09:21:59,703][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://100.100.100.112:9200/, :path=>"/"}
[2018-05-30T09:21:59,723][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://100.100.100.112:9200/"}
[2018-05-30T09:21:59,740][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://100.100.100.113:9200/, :path=>"/"}
[2018-05-30T09:21:59,747][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://100.100.100.113:9200/"}
[2018-05-30T09:21:59,777][INFO ][logstash.outputs.elasticsearch] New Elasticsearch output {:class=>"LogStash::Outputs::ElasticSearch", :hosts=>["//100.100.100.111:9200", "//100.100.100.112:9200", "//100.100.100.113:9200"]}
[2018-05-30T09:21:59,786][INFO ][logstash.outputs.elasticsearch] Using mapping template from {:path=>nil}
[2018-05-30T09:21:59,815][INFO ][logstash.outputs.elasticsearch] Attempting to install template {:manage_template=>{"template"=>"logstash-*", "version"=>60001, "settings"=>{"index.refresh_interval"=>"5s"}, "mappings"=>{"_default_"=>{"dynamic_templates"=>[{"message_field"=>{"path_match"=>"message", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false}}}, {"string_fields"=>{"match"=>"*", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false, "fields"=>{"keyword"=>{"type"=>"keyword", "ignore_above"=>256}}}}}], "properties"=>{"@timestamp"=>{"type"=>"date"}, "@version"=>{"type"=>"keyword"}, "geoip"=>{"dynamic"=>true, "properties"=>{"ip"=>{"type"=>"ip"}, "location"=>{"type"=>"geo_point"}, "latitude"=>{"type"=>"half_float"}, "longitude"=>{"type"=>"half_float"}}}}}}}}
[2018-05-30T09:21:59,860][INFO ][logstash.outputs.elasticsearch] New Elasticsearch output {:class=>"LogStash::Outputs::ElasticSearch", :hosts=>["//100.100.100.111:9200", "//100.100.100.112:9200", "//100.100.100.113:9200"]}
[2018-05-30T09:21:59,940][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://100.100.100.111:9200/"}
[2018-05-30T09:22:00,095][INFO ][logstash.outputs.elasticsearch] ES Output version determined {:es_version=>6}
[2018-05-30T09:22:00,096][WARN ][logstash.outputs.elasticsearch] Detected a 6.x and above cluster: the `type` event field won't be used to determine the document _type {:es_version=>6}
[2018-05-30T09:22:00,096][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://100.100.100.112:9200/, :path=>"/"}
[2018-05-30T09:22:00,134][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://100.100.100.112:9200/"}
[2018-05-30T09:22:00,161][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://100.100.100.113:9200/, :path=>"/"}
[2018-05-30T09:22:00,171][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://100.100.100.113:9200/"}
[2018-05-30T09:22:00,242][INFO ][logstash.outputs.elasticsearch] Using mapping template from {:path=>nil}
[2018-05-30T09:22:00,255][INFO ][logstash.outputs.elasticsearch] Attempting to install template {:manage_template=>{"template"=>"logstash-*", "version"=>60001, "settings"=>{"index.refresh_interval"=>"5s"}, "mappings"=>{"_default_"=>{"dynamic_templates"=>[{"message_field"=>{"path_match"=>"message", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false}}}, {"string_fields"=>{"match"=>"*", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false, "fields"=>{"keyword"=>{"type"=>"keyword", "ignore_above"=>256}}}}}], "properties"=>{"@timestamp"=>{"type"=>"date"}, "@version"=>{"type"=>"keyword"}, "geoip"=>{"dynamic"=>true, "properties"=>{"ip"=>{"type"=>"ip"}, "location"=>{"type"=>"geo_point"}, "latitude"=>{"type"=>"half_float"}, "longitude"=>{"type"=>"half_float"}}}}}}}}
[2018-05-30T09:22:00,268][INFO ][logstash.outputs.elasticsearch] New Elasticsearch output {:class=>"LogStash::Outputs::ElasticSearch", :hosts=>["//100.100.100.111:9200", "//100.100.100.112:9200", "//100.100.100.113:9200"]}
[2018-05-30T09:22:00,671][INFO ][logstash.pipeline        ] Pipeline started succesfully {:pipeline_id=>"main", :thread=>"#<Thread:0x42edf71@/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:246 run>"}
[2018-05-30T09:22:00,686][INFO ][logstash.agent           ] Pipelines running {:count=>1, :pipelines=>["main"]}
[2018-05-30T09:22:00,713][INFO ][logstash.pipeline        ] Pipeline started succesfully {:pipeline_id=>"main", :thread=>"#<Thread:0x19adf0cd@/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:246 run>"}
[2018-05-30T09:22:00,826][INFO ][logstash.agent           ] Pipelines running {:count=>1, :pipelines=>["main"]}
[2018-05-30T09:22:00,972][INFO ][logstash.pipeline        ] Pipeline started succesfully {:pipeline_id=>"main", :thread=>"#<Thread:0x70120a18@/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:246 run>"}
[2018-05-30T09:22:01,014][INFO ][logstash.agent           ] Pipelines running {:count=>1, :pipelines=>["main"]}
[2018-05-30T09:22:01,872][DEBUG][org.logstash.secret.store.SecretStoreFactory] Attempting to exists or secret store with implementation: org.logstash.secret.store.backend.JavaKeyStore
[2018-05-30T09:22:02,241][DEBUG][org.logstash.secret.store.SecretStoreFactory] Attempting to exists or secret store with implementation: org.logstash.secret.store.backend.JavaKeyStore
[2018-05-30T09:22:02,392][INFO ][logstash.filters.ruby.script] Test run complete {:script_path=>"rubyfilter.rb", :results=>{:passed=>0, :failed=>0, :errored=>0}}
[2018-05-30T09:22:02,762][DEBUG][org.logstash.secret.store.SecretStoreFactory] Attempting to exists or secret store with implementation: org.logstash.secret.store.backend.JavaKeyStore
[2018-05-30T09:22:02,827][WARN ][logstash.outputs.elasticsearch] You are using a deprecated config setting "document_type" set in elasticsearch. Deprecated settings will continue to work, but are scheduled for removal from logstash in the future. Document types are being deprecated in Elasticsearch 6.0, and removed entirely in 7.0. You should avoid this feature If you have any questions about this, please visit the #logstash channel on freenode irc. {:name=>"document_type", :plugin=><LogStash::Outputs::ElasticSearch hosts=>[//100.100.100.111:9200, //100.100.100.112:9200, //100.100.100.113:9200], index=>"qa-enuri-main-as-is-2018.05.30.00.21", document_type=>"_doc", document_id=>"%{id}", action=>"index", id=>"ec2e7209120401ff8ce6f1bf881afce389606f2f172cbfead5336a4a708867ff", enable_metric=>true, codec=><LogStash::Codecs::Plain id=>"plain_4711290f-5901-49f6-ba86-10d6cd7b6049", enable_metric=>true, charset=>"UTF-8">, workers=>1, manage_template=>true, template_name=>"logstash", template_overwrite=>false, doc_as_upsert=>false, script_type=>"inline", script_lang=>"painless", script_var_name=>"event", scripted_upsert=>false, retry_initial_interval=>2, retry_max_interval=>64, retry_on_conflict=>1, ssl_certificate_verification=>true, sniffing=>false, sniffing_delay=>5, timeout=>60, pool_max=>1000, pool_max_per_route=>100, resurrect_delay=>5, validate_after_inactivity=>10000, http_compression=>false>}
[2018-05-30T09:22:02,862][INFO ][logstash.pipeline        ] Starting pipeline {:pipeline_id=>"main", "pipeline.workers"=>8, "pipeline.batch.size"=>125, "pipeline.batch.delay"=>50}
[2018-05-30T09:22:03,546][INFO ][logstash.inputs.jdbc     ] (2.473777s) select
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    DECODE(NVL(MODELNO_GROUP,0),0,0,1) AS MODELNO_GROUP_FLAG,
    category,
    '' as cg,
    '' as cat1,
    '' as cat2,
    '' as cat3,
    '' as cat4,
    ca_code,
    ca_dept_mcode,
    ca_dept_code,
    ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,
    shop_name,
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    '' as model_factory,
    minprice,
    maxprice,
    minprices,
    C_DATE,
    mallcnt,
    DECODE(NVL(MALLCNT,0),0,0,1) AS MALLCNT_FLAG,
    spec,
    openexpectflag,
    condiname,
    KEYWORD,
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    MODELNM || ' ' || FACTORY || ' ' || SPEC || ' ' || KEYWORD || ' ' || KEYWORD2 || ' ' || CONDINAME AS to_all
from (

select
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    CASE WHEN service_gubun='2' AND store_flag='1' AND ca_dept_code IS NOT NULL THEN RTRIM(category || ' '  || ca_dept_code) ELSE category END AS category,
    ca_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),3,8)='000000' OR SUBSTR(RTRIM(ca_dept_code),3,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,4) END AS ca_dept_mcode,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),5,8)='0000' OR SUBSTR(RTRIM(ca_dept_code),5,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,6) END AS ca_dept_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),7,8)='00' OR SUBSTR(RTRIM(ca_dept_code),7,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,8) END AS ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,    
    shop_name,    
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    model_factory,
    minprice,
    maxprice,
    replace(minprices, ' ', '    ') as minprices,
    C_DATE,
    mallcnt,
    replace(replace(spec,',',' '),'/',' ') spec,
    openexpectflag,
    replace(condiname, ' ', '    ') as condiname,    
    CASE WHEN socialprice=0 THEN keyword ELSE keyword || ' ' || UDF_SOCIAL_GOODSNM(modelno_group,modelno) END AS KEYWORD,    
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag
FROM tmp_es_price_data_01
WHERE mod_no = '4'

)

[2018-05-30T09:22:03,548][INFO ][logstash.inputs.jdbc     ] (2.473278s) select 
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    DECODE(NVL(MODELNO_GROUP,0),0,0,1) AS MODELNO_GROUP_FLAG,
    category,
    '' as cg,
    '' as cat1,
    '' as cat2,
    '' as cat3,
    '' as cat4,
    ca_code,
    ca_dept_mcode,
    ca_dept_code,
    ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,
    shop_name,
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    MODELNM || ' ' || FACTORY as model_factory,
    minprice,
    maxprice,
    minprices,
    C_DATE,
    mallcnt,
    DECODE(NVL(MALLCNT,0),0,0,1) AS MALLCNT_FLAG,
    spec,
    openexpectflag,
    condiname,
    KEYWORD,
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    MODELNM || ' ' || FACTORY || ' ' || SPEC || ' ' || KEYWORD || ' ' || KEYWORD2 || ' ' || CONDINAME AS to_all
from (

select
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    CASE WHEN service_gubun='2' AND store_flag='1' AND ca_dept_code IS NOT NULL THEN RTRIM(category || ' '  || ca_dept_code) ELSE category END AS category,
    ca_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),3,8)='000000' OR SUBSTR(RTRIM(ca_dept_code),3,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,4) END AS ca_dept_mcode,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),5,8)='0000' OR SUBSTR(RTRIM(ca_dept_code),5,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,6) END AS ca_dept_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),7,8)='00' OR SUBSTR(RTRIM(ca_dept_code),7,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,8) END AS ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,    
    shop_name,    
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    model_factory,
    minprice,
    maxprice,
    replace(minprices, ' ', '    ') as minprices,
    C_DATE,
    mallcnt,
    replace(replace(spec,',',' '),'/',' ') spec,
    openexpectflag,
    replace(condiname, ' ', '    ') as condiname,    
    CASE WHEN socialprice=0 THEN keyword ELSE keyword || ' ' || UDF_SOCIAL_GOODSNM(modelno_group,modelno) END AS KEYWORD,    
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag
FROM tmp_es_goods_data_01    
WHERE mod_no = '4'

)

[2018-05-30T09:22:03,642][INFO ][logstash.outputs.elasticsearch] Elasticsearch pool URLs updated {:changes=>{:removed=>[], :added=>[http://100.100.100.111:9200/, http://100.100.100.112:9200/, http://100.100.100.113:9200/]}}
[2018-05-30T09:22:03,648][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://100.100.100.111:9200/, :path=>"/"}
[2018-05-30T09:22:03,942][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://100.100.100.111:9200/"}
[2018-05-30T09:22:04,194][INFO ][logstash.outputs.elasticsearch] ES Output version determined {:es_version=>6}
[2018-05-30T09:22:04,194][WARN ][logstash.outputs.elasticsearch] Detected a 6.x and above cluster: the `type` event field won't be used to determine the document _type {:es_version=>6}
[2018-05-30T09:22:04,195][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://100.100.100.112:9200/, :path=>"/"}
[2018-05-30T09:22:04,347][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://100.100.100.112:9200/"}
[2018-05-30T09:22:04,363][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://100.100.100.113:9200/, :path=>"/"}
[2018-05-30T09:22:04,394][INFO ][logstash.inputs.jdbc     ] (2.893901s) select
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    DECODE(NVL(MODELNO_GROUP,0),0,0,1) AS MODELNO_GROUP_FLAG,
    category,
    '' as cg,
    '' as cat1,
    '' as cat2,
    '' as cat3,
    '' as cat4,
    ca_code,
    ca_dept_mcode,
    ca_dept_code,
    ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,
    shop_name,
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    '' as model_factory,
    minprice,
    maxprice,
    minprices,
    C_DATE,
    mallcnt,
    DECODE(NVL(MALLCNT,0),0,0,1) AS MALLCNT_FLAG,
    spec,
    openexpectflag,
    condiname,
    KEYWORD,
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    MODELNM || ' ' || FACTORY || ' ' || SPEC || ' ' || KEYWORD || ' ' || KEYWORD2 || ' ' || CONDINAME AS to_all
from (

select
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    CASE WHEN service_gubun='2' AND store_flag='1' AND ca_dept_code IS NOT NULL THEN RTRIM(category || ' '  || ca_dept_code) ELSE category END AS category,
    ca_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),3,8)='000000' OR SUBSTR(RTRIM(ca_dept_code),3,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,4) END AS ca_dept_mcode,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),5,8)='0000' OR SUBSTR(RTRIM(ca_dept_code),5,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,6) END AS ca_dept_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),7,8)='00' OR SUBSTR(RTRIM(ca_dept_code),7,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,8) END AS ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,    
    shop_name,    
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    model_factory,
    minprice,
    maxprice,
    replace(minprices, ' ', '    ') as minprices,
    C_DATE,
    mallcnt,
    replace(replace(spec,',',' '),'/',' ') spec,
    openexpectflag,
    replace(condiname, ' ', '    ') as condiname,    
    CASE WHEN socialprice=0 THEN keyword ELSE keyword || ' ' || UDF_SOCIAL_GOODSNM(modelno_group,modelno) END AS KEYWORD,    
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag
FROM tmp_es_price_data_01
WHERE mod_no = '1'

)

[2018-05-30T09:22:04,397][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://100.100.100.113:9200/"}
[2018-05-30T09:22:04,494][INFO ][logstash.outputs.elasticsearch] Using mapping template from {:path=>nil}
[2018-05-30T09:22:04,498][INFO ][logstash.outputs.elasticsearch] Attempting to install template {:manage_template=>{"template"=>"logstash-*", "version"=>60001, "settings"=>{"index.refresh_interval"=>"5s"}, "mappings"=>{"_default_"=>{"dynamic_templates"=>[{"message_field"=>{"path_match"=>"message", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false}}}, {"string_fields"=>{"match"=>"*", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false, "fields"=>{"keyword"=>{"type"=>"keyword", "ignore_above"=>256}}}}}], "properties"=>{"@timestamp"=>{"type"=>"date"}, "@version"=>{"type"=>"keyword"}, "geoip"=>{"dynamic"=>true, "properties"=>{"ip"=>{"type"=>"ip"}, "location"=>{"type"=>"geo_point"}, "latitude"=>{"type"=>"half_float"}, "longitude"=>{"type"=>"half_float"}}}}}}}}
[2018-05-30T09:22:04,502][INFO ][logstash.inputs.jdbc     ] (3.006333s) select 
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    DECODE(NVL(MODELNO_GROUP,0),0,0,1) AS MODELNO_GROUP_FLAG,
    category,
    '' as cg,
    '' as cat1,
    '' as cat2,
    '' as cat3,
    '' as cat4,
    ca_code,
    ca_dept_mcode,
    ca_dept_code,
    ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,
    shop_name,
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    MODELNM || ' ' || FACTORY as model_factory,
    minprice,
    maxprice,
    minprices,
    C_DATE,
    mallcnt,
    DECODE(NVL(MALLCNT,0),0,0,1) AS MALLCNT_FLAG,
    spec,
    openexpectflag,
    condiname,
    KEYWORD,
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    MODELNM || ' ' || FACTORY || ' ' || SPEC || ' ' || KEYWORD || ' ' || KEYWORD2 || ' ' || CONDINAME AS to_all
from (

select
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    CASE WHEN service_gubun='2' AND store_flag='1' AND ca_dept_code IS NOT NULL THEN RTRIM(category || ' '  || ca_dept_code) ELSE category END AS category,
    ca_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),3,8)='000000' OR SUBSTR(RTRIM(ca_dept_code),3,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,4) END AS ca_dept_mcode,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),5,8)='0000' OR SUBSTR(RTRIM(ca_dept_code),5,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,6) END AS ca_dept_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),7,8)='00' OR SUBSTR(RTRIM(ca_dept_code),7,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,8) END AS ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,    
    shop_name,    
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    model_factory,
    minprice,
    maxprice,
    replace(minprices, ' ', '    ') as minprices,
    C_DATE,
    mallcnt,
    replace(replace(spec,',',' '),'/',' ') spec,
    openexpectflag,
    replace(condiname, ' ', '    ') as condiname,    
    CASE WHEN socialprice=0 THEN keyword ELSE keyword || ' ' || UDF_SOCIAL_GOODSNM(modelno_group,modelno) END AS KEYWORD,    
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag
FROM tmp_es_goods_data_01    
WHERE mod_no = '1'

)

[2018-05-30T09:22:04,517][INFO ][logstash.outputs.elasticsearch] New Elasticsearch output {:class=>"LogStash::Outputs::ElasticSearch", :hosts=>["//100.100.100.111:9200", "//100.100.100.112:9200", "//100.100.100.113:9200"]}
[2018-05-30T09:22:04,924][INFO ][logstash.inputs.jdbc     ] (2.214066s) select
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    DECODE(NVL(MODELNO_GROUP,0),0,0,1) AS MODELNO_GROUP_FLAG,
    category,
    '' as cg,
    '' as cat1,
    '' as cat2,
    '' as cat3,
    '' as cat4,
    ca_code,
    ca_dept_mcode,
    ca_dept_code,
    ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,
    shop_name,
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    '' as model_factory,
    minprice,
    maxprice,
    minprices,
    C_DATE,
    mallcnt,
    DECODE(NVL(MALLCNT,0),0,0,1) AS MALLCNT_FLAG,
    spec,
    openexpectflag,
    condiname,
    KEYWORD,
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    MODELNM || ' ' || FACTORY || ' ' || SPEC || ' ' || KEYWORD || ' ' || KEYWORD2 || ' ' || CONDINAME AS to_all
from (

select
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    CASE WHEN service_gubun='2' AND store_flag='1' AND ca_dept_code IS NOT NULL THEN RTRIM(category || ' '  || ca_dept_code) ELSE category END AS category,
    ca_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),3,8)='000000' OR SUBSTR(RTRIM(ca_dept_code),3,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,4) END AS ca_dept_mcode,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),5,8)='0000' OR SUBSTR(RTRIM(ca_dept_code),5,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,6) END AS ca_dept_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),7,8)='00' OR SUBSTR(RTRIM(ca_dept_code),7,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,8) END AS ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,    
    shop_name,    
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    model_factory,
    minprice,
    maxprice,
    replace(minprices, ' ', '    ') as minprices,
    C_DATE,
    mallcnt,
    replace(replace(spec,',',' '),'/',' ') spec,
    openexpectflag,
    replace(condiname, ' ', '    ') as condiname,    
    CASE WHEN socialprice=0 THEN keyword ELSE keyword || ' ' || UDF_SOCIAL_GOODSNM(modelno_group,modelno) END AS KEYWORD,    
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag
FROM tmp_es_price_data_01
WHERE mod_no = '3'

)

[2018-05-30T09:22:04,935][INFO ][logstash.inputs.jdbc     ] (2.243159s) select 
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    DECODE(NVL(MODELNO_GROUP,0),0,0,1) AS MODELNO_GROUP_FLAG,
    category,
    '' as cg,
    '' as cat1,
    '' as cat2,
    '' as cat3,
    '' as cat4,
    ca_code,
    ca_dept_mcode,
    ca_dept_code,
    ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,
    shop_name,
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    MODELNM || ' ' || FACTORY as model_factory,
    minprice,
    maxprice,
    minprices,
    C_DATE,
    mallcnt,
    DECODE(NVL(MALLCNT,0),0,0,1) AS MALLCNT_FLAG,
    spec,
    openexpectflag,
    condiname,
    KEYWORD,
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    MODELNM || ' ' || FACTORY || ' ' || SPEC || ' ' || KEYWORD || ' ' || KEYWORD2 || ' ' || CONDINAME AS to_all
from (

select
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    CASE WHEN service_gubun='2' AND store_flag='1' AND ca_dept_code IS NOT NULL THEN RTRIM(category || ' '  || ca_dept_code) ELSE category END AS category,
    ca_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),3,8)='000000' OR SUBSTR(RTRIM(ca_dept_code),3,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,4) END AS ca_dept_mcode,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),5,8)='0000' OR SUBSTR(RTRIM(ca_dept_code),5,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,6) END AS ca_dept_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),7,8)='00' OR SUBSTR(RTRIM(ca_dept_code),7,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,8) END AS ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,    
    shop_name,    
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    model_factory,
    minprice,
    maxprice,
    replace(minprices, ' ', '    ') as minprices,
    C_DATE,
    mallcnt,
    replace(replace(spec,',',' '),'/',' ') spec,
    openexpectflag,
    replace(condiname, ' ', '    ') as condiname,    
    CASE WHEN socialprice=0 THEN keyword ELSE keyword || ' ' || UDF_SOCIAL_GOODSNM(modelno_group,modelno) END AS KEYWORD,    
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag
FROM tmp_es_goods_data_01    
WHERE mod_no = '3'

)

[2018-05-30T09:22:04,966][INFO ][logstash.inputs.jdbc     ] (2.175203s) select
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    DECODE(NVL(MODELNO_GROUP,0),0,0,1) AS MODELNO_GROUP_FLAG,
    category,
    '' as cg,
    '' as cat1,
    '' as cat2,
    '' as cat3,
    '' as cat4,
    ca_code,
    ca_dept_mcode,
    ca_dept_code,
    ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,
    shop_name,
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    '' as model_factory,
    minprice,
    maxprice,
    minprices,
    C_DATE,
    mallcnt,
    DECODE(NVL(MALLCNT,0),0,0,1) AS MALLCNT_FLAG,
    spec,
    openexpectflag,
    condiname,
    KEYWORD,
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    MODELNM || ' ' || FACTORY || ' ' || SPEC || ' ' || KEYWORD || ' ' || KEYWORD2 || ' ' || CONDINAME AS to_all
from (

select
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    CASE WHEN service_gubun='2' AND store_flag='1' AND ca_dept_code IS NOT NULL THEN RTRIM(category || ' '  || ca_dept_code) ELSE category END AS category,
    ca_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),3,8)='000000' OR SUBSTR(RTRIM(ca_dept_code),3,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,4) END AS ca_dept_mcode,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),5,8)='0000' OR SUBSTR(RTRIM(ca_dept_code),5,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,6) END AS ca_dept_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),7,8)='00' OR SUBSTR(RTRIM(ca_dept_code),7,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,8) END AS ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,    
    shop_name,    
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    model_factory,
    minprice,
    maxprice,
    replace(minprices, ' ', '    ') as minprices,
    C_DATE,
    mallcnt,
    replace(replace(spec,',',' '),'/',' ') spec,
    openexpectflag,
    replace(condiname, ' ', '    ') as condiname,    
    CASE WHEN socialprice=0 THEN keyword ELSE keyword || ' ' || UDF_SOCIAL_GOODSNM(modelno_group,modelno) END AS KEYWORD,    
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag
FROM tmp_es_price_data_01
WHERE mod_no = '5'

)

[2018-05-30T09:22:04,975][INFO ][logstash.inputs.jdbc     ] (2.191604s) select 
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    DECODE(NVL(MODELNO_GROUP,0),0,0,1) AS MODELNO_GROUP_FLAG,
    category,
    '' as cg,
    '' as cat1,
    '' as cat2,
    '' as cat3,
    '' as cat4,
    ca_code,
    ca_dept_mcode,
    ca_dept_code,
    ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,
    shop_name,
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    MODELNM || ' ' || FACTORY as model_factory,
    minprice,
    maxprice,
    minprices,
    C_DATE,
    mallcnt,
    DECODE(NVL(MALLCNT,0),0,0,1) AS MALLCNT_FLAG,
    spec,
    openexpectflag,
    condiname,
    KEYWORD,
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    MODELNM || ' ' || FACTORY || ' ' || SPEC || ' ' || KEYWORD || ' ' || KEYWORD2 || ' ' || CONDINAME AS to_all
from (

select
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    CASE WHEN service_gubun='2' AND store_flag='1' AND ca_dept_code IS NOT NULL THEN RTRIM(category || ' '  || ca_dept_code) ELSE category END AS category,
    ca_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),3,8)='000000' OR SUBSTR(RTRIM(ca_dept_code),3,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,4) END AS ca_dept_mcode,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),5,8)='0000' OR SUBSTR(RTRIM(ca_dept_code),5,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,6) END AS ca_dept_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),7,8)='00' OR SUBSTR(RTRIM(ca_dept_code),7,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,8) END AS ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,    
    shop_name,    
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    model_factory,
    minprice,
    maxprice,
    replace(minprices, ' ', '    ') as minprices,
    C_DATE,
    mallcnt,
    replace(replace(spec,',',' '),'/',' ') spec,
    openexpectflag,
    replace(condiname, ' ', '    ') as condiname,    
    CASE WHEN socialprice=0 THEN keyword ELSE keyword || ' ' || UDF_SOCIAL_GOODSNM(modelno_group,modelno) END AS KEYWORD,    
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag
FROM tmp_es_goods_data_01    
WHERE mod_no = '5'

)

[2018-05-30T09:22:05,452][INFO ][logstash.pipeline        ] Pipeline started succesfully {:pipeline_id=>"main", :thread=>"#<Thread:0x215860d8@/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:246 run>"}
[2018-05-30T09:22:05,499][INFO ][logstash.agent           ] Pipelines running {:count=>1, :pipelines=>["main"]}
[2018-05-30T09:22:05,503][INFO ][logstash.inputs.jdbc     ] (2.329071s) select 
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    DECODE(NVL(MODELNO_GROUP,0),0,0,1) AS MODELNO_GROUP_FLAG,
    category,
    '' as cg,
    '' as cat1,
    '' as cat2,
    '' as cat3,
    '' as cat4,
    ca_code,
    ca_dept_mcode,
    ca_dept_code,
    ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,
    shop_name,
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    MODELNM || ' ' || FACTORY as model_factory,
    minprice,
    maxprice,
    minprices,
    C_DATE,
    mallcnt,
    DECODE(NVL(MALLCNT,0),0,0,1) AS MALLCNT_FLAG,
    spec,
    openexpectflag,
    condiname,
    KEYWORD,
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    MODELNM || ' ' || FACTORY || ' ' || SPEC || ' ' || KEYWORD || ' ' || KEYWORD2 || ' ' || CONDINAME AS to_all
from (

select
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    CASE WHEN service_gubun='2' AND store_flag='1' AND ca_dept_code IS NOT NULL THEN RTRIM(category || ' '  || ca_dept_code) ELSE category END AS category,
    ca_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),3,8)='000000' OR SUBSTR(RTRIM(ca_dept_code),3,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,4) END AS ca_dept_mcode,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),5,8)='0000' OR SUBSTR(RTRIM(ca_dept_code),5,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,6) END AS ca_dept_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),7,8)='00' OR SUBSTR(RTRIM(ca_dept_code),7,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,8) END AS ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,    
    shop_name,    
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    model_factory,
    minprice,
    maxprice,
    replace(minprices, ' ', '    ') as minprices,
    C_DATE,
    mallcnt,
    replace(replace(spec,',',' '),'/',' ') spec,
    openexpectflag,
    replace(condiname, ' ', '    ') as condiname,    
    CASE WHEN socialprice=0 THEN keyword ELSE keyword || ' ' || UDF_SOCIAL_GOODSNM(modelno_group,modelno) END AS KEYWORD,    
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag
FROM tmp_es_goods_data_01    
WHERE mod_no = '2'

)

[2018-05-30T09:22:05,527][INFO ][logstash.inputs.jdbc     ] (2.325166s) select
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    DECODE(NVL(MODELNO_GROUP,0),0,0,1) AS MODELNO_GROUP_FLAG,
    category,
    '' as cg,
    '' as cat1,
    '' as cat2,
    '' as cat3,
    '' as cat4,
    ca_code,
    ca_dept_mcode,
    ca_dept_code,
    ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,
    shop_name,
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    '' as model_factory,
    minprice,
    maxprice,
    minprices,
    C_DATE,
    mallcnt,
    DECODE(NVL(MALLCNT,0),0,0,1) AS MALLCNT_FLAG,
    spec,
    openexpectflag,
    condiname,
    KEYWORD,
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    MODELNM || ' ' || FACTORY || ' ' || SPEC || ' ' || KEYWORD || ' ' || KEYWORD2 || ' ' || CONDINAME AS to_all
from (

select
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    CASE WHEN service_gubun='2' AND store_flag='1' AND ca_dept_code IS NOT NULL THEN RTRIM(category || ' '  || ca_dept_code) ELSE category END AS category,
    ca_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),3,8)='000000' OR SUBSTR(RTRIM(ca_dept_code),3,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,4) END AS ca_dept_mcode,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),5,8)='0000' OR SUBSTR(RTRIM(ca_dept_code),5,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,6) END AS ca_dept_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),7,8)='00' OR SUBSTR(RTRIM(ca_dept_code),7,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,8) END AS ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,    
    shop_name,    
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    model_factory,
    minprice,
    maxprice,
    replace(minprices, ' ', '    ') as minprices,
    C_DATE,
    mallcnt,
    replace(replace(spec,',',' '),'/',' ') spec,
    openexpectflag,
    replace(condiname, ' ', '    ') as condiname,    
    CASE WHEN socialprice=0 THEN keyword ELSE keyword || ' ' || UDF_SOCIAL_GOODSNM(modelno_group,modelno) END AS KEYWORD,    
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag
FROM tmp_es_price_data_01
WHERE mod_no = '2'

)

[2018-05-30T09:22:08,260][INFO ][logstash.inputs.jdbc     ] (0.859205s) select
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    DECODE(NVL(MODELNO_GROUP,0),0,0,1) AS MODELNO_GROUP_FLAG,
    category,
    '' as cg,
    '' as cat1,
    '' as cat2,
    '' as cat3,
    '' as cat4,
    ca_code,
    ca_dept_mcode,
    ca_dept_code,
    ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,
    shop_name,
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    '' as model_factory,
    minprice,
    maxprice,
    minprices,
    C_DATE,
    mallcnt,
    DECODE(NVL(MALLCNT,0),0,0,1) AS MALLCNT_FLAG,
    spec,
    openexpectflag,
    condiname,
    KEYWORD,
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    MODELNM || ' ' || FACTORY || ' ' || SPEC || ' ' || KEYWORD || ' ' || KEYWORD2 || ' ' || CONDINAME AS to_all
from (

select
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    CASE WHEN service_gubun='2' AND store_flag='1' AND ca_dept_code IS NOT NULL THEN RTRIM(category || ' '  || ca_dept_code) ELSE category END AS category,
    ca_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),3,8)='000000' OR SUBSTR(RTRIM(ca_dept_code),3,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,4) END AS ca_dept_mcode,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),5,8)='0000' OR SUBSTR(RTRIM(ca_dept_code),5,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,6) END AS ca_dept_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),7,8)='00' OR SUBSTR(RTRIM(ca_dept_code),7,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,8) END AS ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,    
    shop_name,    
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    model_factory,
    minprice,
    maxprice,
    replace(minprices, ' ', '    ') as minprices,
    C_DATE,
    mallcnt,
    replace(replace(spec,',',' '),'/',' ') spec,
    openexpectflag,
    replace(condiname, ' ', '    ') as condiname,    
    CASE WHEN socialprice=0 THEN keyword ELSE keyword || ' ' || UDF_SOCIAL_GOODSNM(modelno_group,modelno) END AS KEYWORD,    
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag
FROM tmp_es_price_data_01
WHERE mod_no = '0'

)

[2018-05-30T09:22:08,261][INFO ][logstash.inputs.jdbc     ] (0.856831s) select 
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    DECODE(NVL(MODELNO_GROUP,0),0,0,1) AS MODELNO_GROUP_FLAG,
    category,
    '' as cg,
    '' as cat1,
    '' as cat2,
    '' as cat3,
    '' as cat4,
    ca_code,
    ca_dept_mcode,
    ca_dept_code,
    ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,
    shop_name,
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    MODELNM || ' ' || FACTORY as model_factory,
    minprice,
    maxprice,
    minprices,
    C_DATE,
    mallcnt,
    DECODE(NVL(MALLCNT,0),0,0,1) AS MALLCNT_FLAG,
    spec,
    openexpectflag,
    condiname,
    KEYWORD,
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    MODELNM || ' ' || FACTORY || ' ' || SPEC || ' ' || KEYWORD || ' ' || KEYWORD2 || ' ' || CONDINAME AS to_all
from (

select
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    CASE WHEN service_gubun='2' AND store_flag='1' AND ca_dept_code IS NOT NULL THEN RTRIM(category || ' '  || ca_dept_code) ELSE category END AS category,
    ca_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),3,8)='000000' OR SUBSTR(RTRIM(ca_dept_code),3,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,4) END AS ca_dept_mcode,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),5,8)='0000' OR SUBSTR(RTRIM(ca_dept_code),5,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,6) END AS ca_dept_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),7,8)='00' OR SUBSTR(RTRIM(ca_dept_code),7,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,8) END AS ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,    
    shop_name,    
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    model_factory,
    minprice,
    maxprice,
    replace(minprices, ' ', '    ') as minprices,
    C_DATE,
    mallcnt,
    replace(replace(spec,',',' '),'/',' ') spec,
    openexpectflag,
    replace(condiname, ' ', '    ') as condiname,    
    CASE WHEN socialprice=0 THEN keyword ELSE keyword || ' ' || UDF_SOCIAL_GOODSNM(modelno_group,modelno) END AS KEYWORD,    
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag
FROM tmp_es_goods_data_01    
WHERE mod_no = '0'

)

[2018-05-30T10:38:32,401][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"fb_apache", :directory=>"/usr/share/logstash/modules/fb_apache/configuration"}
[2018-05-30T10:38:32,478][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"netflow", :directory=>"/usr/share/logstash/modules/netflow/configuration"}
[2018-05-30T10:38:33,469][WARN ][logstash.config.source.multilocal] Ignoring the 'pipelines.yml' file because modules or command line options are specified
[2018-05-30T10:38:34,106][INFO ][logstash.runner          ] Starting Logstash {"logstash.version"=>"6.2.3"}
[2018-05-30T10:38:34,932][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=>9606}
[2018-05-30T10:38:37,248][INFO ][logstash.filters.ruby.script] Test run complete {:script_path=>"rubyfilter.rb", :results=>{:passed=>0, :failed=>0, :errored=>0}}
[2018-05-30T10:38:37,544][WARN ][logstash.outputs.elasticsearch] You are using a deprecated config setting "document_type" set in elasticsearch. Deprecated settings will continue to work, but are scheduled for removal from logstash in the future. Document types are being deprecated in Elasticsearch 6.0, and removed entirely in 7.0. You should avoid this feature If you have any questions about this, please visit the #logstash channel on freenode irc. {:name=>"document_type", :plugin=><LogStash::Outputs::ElasticSearch hosts=>[//100.100.100.111:9200, //100.100.100.112:9200, //100.100.100.113:9200], index=>"qa-enuri-main", document_type=>"_doc", document_id=>"%{id}", action=>"%{[@metadata][action]}", id=>"3b16bdd1680600ee9156ace46ed76a90d56bc1644736e9c91a7e57c052ab5c69", enable_metric=>true, codec=><LogStash::Codecs::Plain id=>"plain_3eeed0c8-c28f-4fee-a53b-f0333ef3b115", enable_metric=>true, charset=>"UTF-8">, workers=>1, manage_template=>true, template_name=>"logstash", template_overwrite=>false, doc_as_upsert=>false, script_type=>"inline", script_lang=>"painless", script_var_name=>"event", scripted_upsert=>false, retry_initial_interval=>2, retry_max_interval=>64, retry_on_conflict=>1, ssl_certificate_verification=>true, sniffing=>false, sniffing_delay=>5, timeout=>60, pool_max=>1000, pool_max_per_route=>100, resurrect_delay=>5, validate_after_inactivity=>10000, http_compression=>false>}
[2018-05-30T10:38:37,613][INFO ][logstash.pipeline        ] Starting pipeline {:pipeline_id=>"main", "pipeline.workers"=>8, "pipeline.batch.size"=>125, "pipeline.batch.delay"=>50}
[2018-05-30T10:38:38,410][INFO ][logstash.outputs.elasticsearch] Elasticsearch pool URLs updated {:changes=>{:removed=>[], :added=>[http://100.100.100.111:9200/, http://100.100.100.112:9200/, http://100.100.100.113:9200/]}}
[2018-05-30T10:38:38,422][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://100.100.100.111:9200/, :path=>"/"}
[2018-05-30T10:38:38,585][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://100.100.100.111:9200/"}
[2018-05-30T10:38:38,653][INFO ][logstash.outputs.elasticsearch] ES Output version determined {:es_version=>6}
[2018-05-30T10:38:38,653][WARN ][logstash.outputs.elasticsearch] Detected a 6.x and above cluster: the `type` event field won't be used to determine the document _type {:es_version=>6}
[2018-05-30T10:38:38,654][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://100.100.100.112:9200/, :path=>"/"}
[2018-05-30T10:38:38,702][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://100.100.100.112:9200/"}
[2018-05-30T10:38:38,751][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://100.100.100.113:9200/, :path=>"/"}
[2018-05-30T10:38:38,761][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://100.100.100.113:9200/"}
[2018-05-30T10:38:38,809][INFO ][logstash.outputs.elasticsearch] Using mapping template from {:path=>nil}
[2018-05-30T10:38:38,821][INFO ][logstash.outputs.elasticsearch] Attempting to install template {:manage_template=>{"template"=>"logstash-*", "version"=>60001, "settings"=>{"index.refresh_interval"=>"5s"}, "mappings"=>{"_default_"=>{"dynamic_templates"=>[{"message_field"=>{"path_match"=>"message", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false}}}, {"string_fields"=>{"match"=>"*", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false, "fields"=>{"keyword"=>{"type"=>"keyword", "ignore_above"=>256}}}}}], "properties"=>{"@timestamp"=>{"type"=>"date"}, "@version"=>{"type"=>"keyword"}, "geoip"=>{"dynamic"=>true, "properties"=>{"ip"=>{"type"=>"ip"}, "location"=>{"type"=>"geo_point"}, "latitude"=>{"type"=>"half_float"}, "longitude"=>{"type"=>"half_float"}}}}}}}}
[2018-05-30T10:38:38,833][INFO ][logstash.outputs.elasticsearch] New Elasticsearch output {:class=>"LogStash::Outputs::ElasticSearch", :hosts=>["//100.100.100.111:9200", "//100.100.100.112:9200", "//100.100.100.113:9200"]}
[2018-05-30T10:38:39,519][INFO ][logstash.pipeline        ] Pipeline started succesfully {:pipeline_id=>"main", :thread=>"#<Thread:0x25f84423@/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:246 run>"}
[2018-05-30T10:38:39,634][INFO ][logstash.agent           ] Pipelines running {:count=>1, :pipelines=>["main"]}
[2018-05-30T10:38:58,649][ERROR][logstash.inputs.jdbc     ] Unable to connect to database. Tried 1 times {:error_message=>"Java::JavaSql::SQLRecoverableException: IO Error: The Network Adapter could not establish the connection"}
[2018-05-30T10:38:58,658][ERROR][logstash.pipeline        ] A plugin had an unrecoverable error. Will restart this plugin.
  Pipeline_id:main
  Plugin: <LogStash::Inputs::Jdbc jdbc_driver_library=>"/etc/logstash/ojdbc6.jar", jdbc_driver_class=>"Java::oracle.jdbc.driver.OracleDriver", jdbc_connection_string=>"jdbc:oracle:thin:@100.100.100.225:1521:tenuri", jdbc_user=>"es_app", jdbc_password=><password>, jdbc_fetch_size=>10000, statement_filepath=>"as-is_search-log.sql", id=>"5bd7533661d97dbb4a1d2a6189513af0c10219fd73809280818346be344afa9b", enable_metric=>true, codec=><LogStash::Codecs::Plain id=>"plain_1a6af198-39fa-4265-9c68-c91258b113dc", enable_metric=>true, charset=>"UTF-8">, jdbc_paging_enabled=>false, jdbc_page_size=>100000, jdbc_validate_connection=>false, jdbc_validation_timeout=>3600, jdbc_pool_timeout=>5, sql_log_level=>"info", connection_retry_attempts=>1, connection_retry_attempts_wait_time=>0.5, parameters=>{"sql_last_value"=>2018-05-30 09:22:02 +0900}, last_run_metadata_path=>"/home/elastic/.logstash_jdbc_last_run", use_column_value=>false, tracking_column_type=>"numeric", clean_run=>false, record_last_run=>true, lowercase_column_names=>true>
  Error: Java::JavaSql::SQLRecoverableException: IO Error: The Network Adapter could not establish the connection
  Exception: Sequel::DatabaseConnectionError
  Stack: oracle.jdbc.driver.T4CConnection.logon(oracle/jdbc/driver/T4CConnection.java:489)
oracle.jdbc.driver.PhysicalConnection.<init>(oracle/jdbc/driver/PhysicalConnection.java:553)
oracle.jdbc.driver.T4CConnection.<init>(oracle/jdbc/driver/T4CConnection.java:254)
oracle.jdbc.driver.T4CDriverExtension.getConnection(oracle/jdbc/driver/T4CDriverExtension.java:32)
oracle.jdbc.driver.OracleDriver.connect(oracle/jdbc/driver/OracleDriver.java:528)
java.lang.reflect.Method.invoke(java/lang/reflect/Method.java:498)
org.jruby.javasupport.JavaMethod.invokeDirectWithExceptionHandling(org/jruby/javasupport/JavaMethod.java:468)
org.jruby.javasupport.JavaMethod.invokeDirect(org/jruby/javasupport/JavaMethod.java:326)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/adapters/jdbc.rb:203)
RUBY.make_new(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool.rb:126)
RUBY.assign_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:192)
RUBY.acquire(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:133)
RUBY.hold(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:90)
RUBY.synchronize(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:269)
RUBY.test_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:279)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:58)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/core.rb:116)
RUBY.block in jdbc_connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:114)
org.jruby.RubyKernel.loop(org/jruby/RubyKernel.java:1292)
org.jruby.RubyKernel$INVOKER$s$0$0$loop.call(org/jruby/RubyKernel$INVOKER$s$0$0$loop.gen)
RUBY.jdbc_connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:111)
RUBY.open_jdbc_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:163)
RUBY.execute_statement(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:219)
RUBY.execute_query(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/inputs/jdbc.rb:264)
RUBY.run(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/inputs/jdbc.rb:250)
RUBY.inputworker(/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:516)
RUBY.block in start_input(/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:509)
org.jruby.RubyProc.call(org/jruby/RubyProc.java:289)
org.jruby.RubyProc.call(org/jruby/RubyProc.java:246)
java.lang.Thread.run(java/lang/Thread.java:748)
[2018-05-30T10:39:02,672][ERROR][logstash.inputs.jdbc     ] Unable to connect to database. Tried 1 times {:error_message=>"Java::JavaSql::SQLRecoverableException: IO Error: The Network Adapter could not establish the connection"}
[2018-05-30T10:39:02,676][ERROR][logstash.pipeline        ] A plugin had an unrecoverable error. Will restart this plugin.
  Pipeline_id:main
  Plugin: <LogStash::Inputs::Jdbc jdbc_driver_library=>"/etc/logstash/ojdbc6.jar", jdbc_driver_class=>"Java::oracle.jdbc.driver.OracleDriver", jdbc_connection_string=>"jdbc:oracle:thin:@100.100.100.225:1521:tenuri", jdbc_user=>"es_app", jdbc_password=><password>, jdbc_fetch_size=>10000, statement_filepath=>"as-is_search-log.sql", id=>"5bd7533661d97dbb4a1d2a6189513af0c10219fd73809280818346be344afa9b", enable_metric=>true, codec=><LogStash::Codecs::Plain id=>"plain_1a6af198-39fa-4265-9c68-c91258b113dc", enable_metric=>true, charset=>"UTF-8">, jdbc_paging_enabled=>false, jdbc_page_size=>100000, jdbc_validate_connection=>false, jdbc_validation_timeout=>3600, jdbc_pool_timeout=>5, sql_log_level=>"info", connection_retry_attempts=>1, connection_retry_attempts_wait_time=>0.5, parameters=>{"sql_last_value"=>2018-05-30 09:22:02 +0900}, last_run_metadata_path=>"/home/elastic/.logstash_jdbc_last_run", use_column_value=>false, tracking_column_type=>"numeric", clean_run=>false, record_last_run=>true, lowercase_column_names=>true>
  Error: Java::JavaSql::SQLRecoverableException: IO Error: The Network Adapter could not establish the connection
  Exception: Sequel::DatabaseConnectionError
  Stack: oracle.jdbc.driver.T4CConnection.logon(oracle/jdbc/driver/T4CConnection.java:489)
oracle.jdbc.driver.PhysicalConnection.<init>(oracle/jdbc/driver/PhysicalConnection.java:553)
oracle.jdbc.driver.T4CConnection.<init>(oracle/jdbc/driver/T4CConnection.java:254)
oracle.jdbc.driver.T4CDriverExtension.getConnection(oracle/jdbc/driver/T4CDriverExtension.java:32)
oracle.jdbc.driver.OracleDriver.connect(oracle/jdbc/driver/OracleDriver.java:528)
java.lang.reflect.Method.invoke(java/lang/reflect/Method.java:498)
org.jruby.javasupport.JavaMethod.invokeDirectWithExceptionHandling(org/jruby/javasupport/JavaMethod.java:468)
org.jruby.javasupport.JavaMethod.invokeDirect(org/jruby/javasupport/JavaMethod.java:326)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/adapters/jdbc.rb:203)
RUBY.make_new(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool.rb:126)
RUBY.assign_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:192)
RUBY.acquire(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:133)
RUBY.hold(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:90)
RUBY.synchronize(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:269)
RUBY.test_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:279)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:58)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/core.rb:116)
RUBY.block in jdbc_connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:114)
org.jruby.RubyKernel.loop(org/jruby/RubyKernel.java:1292)
org.jruby.RubyKernel$INVOKER$s$0$0$loop.call(org/jruby/RubyKernel$INVOKER$s$0$0$loop.gen)
RUBY.jdbc_connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:111)
RUBY.open_jdbc_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:163)
RUBY.execute_statement(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:219)
RUBY.execute_query(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/inputs/jdbc.rb:264)
RUBY.run(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/inputs/jdbc.rb:250)
RUBY.inputworker(/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:516)
RUBY.block in start_input(/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:509)
org.jruby.RubyProc.call(org/jruby/RubyProc.java:289)
org.jruby.RubyProc.call(org/jruby/RubyProc.java:246)
java.lang.Thread.run(java/lang/Thread.java:748)
[2018-05-30T10:39:05,680][ERROR][logstash.inputs.jdbc     ] Unable to connect to database. Tried 1 times {:error_message=>"Java::JavaSql::SQLRecoverableException: IO Error: The Network Adapter could not establish the connection"}
[2018-05-30T10:39:05,682][ERROR][logstash.pipeline        ] A plugin had an unrecoverable error. Will restart this plugin.
  Pipeline_id:main
  Plugin: <LogStash::Inputs::Jdbc jdbc_driver_library=>"/etc/logstash/ojdbc6.jar", jdbc_driver_class=>"Java::oracle.jdbc.driver.OracleDriver", jdbc_connection_string=>"jdbc:oracle:thin:@100.100.100.225:1521:tenuri", jdbc_user=>"es_app", jdbc_password=><password>, jdbc_fetch_size=>10000, statement_filepath=>"as-is_search-log.sql", id=>"5bd7533661d97dbb4a1d2a6189513af0c10219fd73809280818346be344afa9b", enable_metric=>true, codec=><LogStash::Codecs::Plain id=>"plain_1a6af198-39fa-4265-9c68-c91258b113dc", enable_metric=>true, charset=>"UTF-8">, jdbc_paging_enabled=>false, jdbc_page_size=>100000, jdbc_validate_connection=>false, jdbc_validation_timeout=>3600, jdbc_pool_timeout=>5, sql_log_level=>"info", connection_retry_attempts=>1, connection_retry_attempts_wait_time=>0.5, parameters=>{"sql_last_value"=>2018-05-30 09:22:02 +0900}, last_run_metadata_path=>"/home/elastic/.logstash_jdbc_last_run", use_column_value=>false, tracking_column_type=>"numeric", clean_run=>false, record_last_run=>true, lowercase_column_names=>true>
  Error: Java::JavaSql::SQLRecoverableException: IO Error: The Network Adapter could not establish the connection
  Exception: Sequel::DatabaseConnectionError
  Stack: oracle.jdbc.driver.T4CConnection.logon(oracle/jdbc/driver/T4CConnection.java:489)
oracle.jdbc.driver.PhysicalConnection.<init>(oracle/jdbc/driver/PhysicalConnection.java:553)
oracle.jdbc.driver.T4CConnection.<init>(oracle/jdbc/driver/T4CConnection.java:254)
oracle.jdbc.driver.T4CDriverExtension.getConnection(oracle/jdbc/driver/T4CDriverExtension.java:32)
oracle.jdbc.driver.OracleDriver.connect(oracle/jdbc/driver/OracleDriver.java:528)
java.lang.reflect.Method.invoke(java/lang/reflect/Method.java:498)
org.jruby.javasupport.JavaMethod.invokeDirectWithExceptionHandling(org/jruby/javasupport/JavaMethod.java:468)
org.jruby.javasupport.JavaMethod.invokeDirect(org/jruby/javasupport/JavaMethod.java:326)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/adapters/jdbc.rb:203)
RUBY.make_new(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool.rb:126)
RUBY.assign_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:192)
RUBY.acquire(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:133)
RUBY.hold(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:90)
RUBY.synchronize(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:269)
RUBY.test_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:279)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:58)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/core.rb:116)
RUBY.block in jdbc_connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:114)
org.jruby.RubyKernel.loop(org/jruby/RubyKernel.java:1292)
org.jruby.RubyKernel$INVOKER$s$0$0$loop.call(org/jruby/RubyKernel$INVOKER$s$0$0$loop.gen)
RUBY.jdbc_connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:111)
RUBY.open_jdbc_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:163)
RUBY.execute_statement(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:219)
RUBY.execute_query(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/inputs/jdbc.rb:264)
RUBY.run(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/inputs/jdbc.rb:250)
RUBY.inputworker(/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:516)
RUBY.block in start_input(/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:509)
org.jruby.RubyProc.call(org/jruby/RubyProc.java:289)
org.jruby.RubyProc.call(org/jruby/RubyProc.java:246)
java.lang.Thread.run(java/lang/Thread.java:748)
[2018-05-30T10:39:08,690][ERROR][logstash.inputs.jdbc     ] Unable to connect to database. Tried 1 times {:error_message=>"Java::JavaSql::SQLRecoverableException: IO Error: The Network Adapter could not establish the connection"}
[2018-05-30T10:39:08,692][ERROR][logstash.pipeline        ] A plugin had an unrecoverable error. Will restart this plugin.
  Pipeline_id:main
  Plugin: <LogStash::Inputs::Jdbc jdbc_driver_library=>"/etc/logstash/ojdbc6.jar", jdbc_driver_class=>"Java::oracle.jdbc.driver.OracleDriver", jdbc_connection_string=>"jdbc:oracle:thin:@100.100.100.225:1521:tenuri", jdbc_user=>"es_app", jdbc_password=><password>, jdbc_fetch_size=>10000, statement_filepath=>"as-is_search-log.sql", id=>"5bd7533661d97dbb4a1d2a6189513af0c10219fd73809280818346be344afa9b", enable_metric=>true, codec=><LogStash::Codecs::Plain id=>"plain_1a6af198-39fa-4265-9c68-c91258b113dc", enable_metric=>true, charset=>"UTF-8">, jdbc_paging_enabled=>false, jdbc_page_size=>100000, jdbc_validate_connection=>false, jdbc_validation_timeout=>3600, jdbc_pool_timeout=>5, sql_log_level=>"info", connection_retry_attempts=>1, connection_retry_attempts_wait_time=>0.5, parameters=>{"sql_last_value"=>2018-05-30 09:22:02 +0900}, last_run_metadata_path=>"/home/elastic/.logstash_jdbc_last_run", use_column_value=>false, tracking_column_type=>"numeric", clean_run=>false, record_last_run=>true, lowercase_column_names=>true>
  Error: Java::JavaSql::SQLRecoverableException: IO Error: The Network Adapter could not establish the connection
  Exception: Sequel::DatabaseConnectionError
  Stack: oracle.jdbc.driver.T4CConnection.logon(oracle/jdbc/driver/T4CConnection.java:489)
oracle.jdbc.driver.PhysicalConnection.<init>(oracle/jdbc/driver/PhysicalConnection.java:553)
oracle.jdbc.driver.T4CConnection.<init>(oracle/jdbc/driver/T4CConnection.java:254)
oracle.jdbc.driver.T4CDriverExtension.getConnection(oracle/jdbc/driver/T4CDriverExtension.java:32)
oracle.jdbc.driver.OracleDriver.connect(oracle/jdbc/driver/OracleDriver.java:528)
java.lang.reflect.Method.invoke(java/lang/reflect/Method.java:498)
org.jruby.javasupport.JavaMethod.invokeDirectWithExceptionHandling(org/jruby/javasupport/JavaMethod.java:468)
org.jruby.javasupport.JavaMethod.invokeDirect(org/jruby/javasupport/JavaMethod.java:326)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/adapters/jdbc.rb:203)
RUBY.make_new(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool.rb:126)
RUBY.assign_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:192)
RUBY.acquire(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:133)
RUBY.hold(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:90)
RUBY.synchronize(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:269)
RUBY.test_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:279)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:58)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/core.rb:116)
RUBY.block in jdbc_connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:114)
org.jruby.RubyKernel.loop(org/jruby/RubyKernel.java:1292)
org.jruby.RubyKernel$INVOKER$s$0$0$loop.call(org/jruby/RubyKernel$INVOKER$s$0$0$loop.gen)
RUBY.jdbc_connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:111)
RUBY.open_jdbc_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:163)
RUBY.execute_statement(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:219)
RUBY.execute_query(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/inputs/jdbc.rb:264)
RUBY.run(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/inputs/jdbc.rb:250)
RUBY.inputworker(/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:516)
RUBY.block in start_input(/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:509)
org.jruby.RubyProc.call(org/jruby/RubyProc.java:289)
org.jruby.RubyProc.call(org/jruby/RubyProc.java:246)
java.lang.Thread.run(java/lang/Thread.java:748)
[2018-05-30T10:39:11,690][ERROR][logstash.inputs.jdbc     ] Unable to connect to database. Tried 1 times {:error_message=>"Java::JavaSql::SQLRecoverableException: IO Error: The Network Adapter could not establish the connection"}
[2018-05-30T10:39:11,699][ERROR][logstash.pipeline        ] A plugin had an unrecoverable error. Will restart this plugin.
  Pipeline_id:main
  Plugin: <LogStash::Inputs::Jdbc jdbc_driver_library=>"/etc/logstash/ojdbc6.jar", jdbc_driver_class=>"Java::oracle.jdbc.driver.OracleDriver", jdbc_connection_string=>"jdbc:oracle:thin:@100.100.100.225:1521:tenuri", jdbc_user=>"es_app", jdbc_password=><password>, jdbc_fetch_size=>10000, statement_filepath=>"as-is_search-log.sql", id=>"5bd7533661d97dbb4a1d2a6189513af0c10219fd73809280818346be344afa9b", enable_metric=>true, codec=><LogStash::Codecs::Plain id=>"plain_1a6af198-39fa-4265-9c68-c91258b113dc", enable_metric=>true, charset=>"UTF-8">, jdbc_paging_enabled=>false, jdbc_page_size=>100000, jdbc_validate_connection=>false, jdbc_validation_timeout=>3600, jdbc_pool_timeout=>5, sql_log_level=>"info", connection_retry_attempts=>1, connection_retry_attempts_wait_time=>0.5, parameters=>{"sql_last_value"=>2018-05-30 09:22:02 +0900}, last_run_metadata_path=>"/home/elastic/.logstash_jdbc_last_run", use_column_value=>false, tracking_column_type=>"numeric", clean_run=>false, record_last_run=>true, lowercase_column_names=>true>
  Error: Java::JavaSql::SQLRecoverableException: IO Error: The Network Adapter could not establish the connection
  Exception: Sequel::DatabaseConnectionError
  Stack: oracle.jdbc.driver.T4CConnection.logon(oracle/jdbc/driver/T4CConnection.java:489)
oracle.jdbc.driver.PhysicalConnection.<init>(oracle/jdbc/driver/PhysicalConnection.java:553)
oracle.jdbc.driver.T4CConnection.<init>(oracle/jdbc/driver/T4CConnection.java:254)
oracle.jdbc.driver.T4CDriverExtension.getConnection(oracle/jdbc/driver/T4CDriverExtension.java:32)
oracle.jdbc.driver.OracleDriver.connect(oracle/jdbc/driver/OracleDriver.java:528)
java.lang.reflect.Method.invoke(java/lang/reflect/Method.java:498)
org.jruby.javasupport.JavaMethod.invokeDirectWithExceptionHandling(org/jruby/javasupport/JavaMethod.java:468)
org.jruby.javasupport.JavaMethod.invokeDirect(org/jruby/javasupport/JavaMethod.java:326)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/adapters/jdbc.rb:203)
RUBY.make_new(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool.rb:126)
RUBY.assign_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:192)
RUBY.acquire(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:133)
RUBY.hold(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:90)
RUBY.synchronize(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:269)
RUBY.test_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:279)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:58)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/core.rb:116)
RUBY.block in jdbc_connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:114)
org.jruby.RubyKernel.loop(org/jruby/RubyKernel.java:1292)
org.jruby.RubyKernel$INVOKER$s$0$0$loop.call(org/jruby/RubyKernel$INVOKER$s$0$0$loop.gen)
RUBY.jdbc_connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:111)
RUBY.open_jdbc_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:163)
RUBY.execute_statement(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:219)
RUBY.execute_query(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/inputs/jdbc.rb:264)
RUBY.run(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/inputs/jdbc.rb:250)
RUBY.inputworker(/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:516)
RUBY.block in start_input(/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:509)
org.jruby.RubyProc.call(org/jruby/RubyProc.java:289)
org.jruby.RubyProc.call(org/jruby/RubyProc.java:246)
java.lang.Thread.run(java/lang/Thread.java:748)
[2018-05-30T10:39:14,698][ERROR][logstash.inputs.jdbc     ] Unable to connect to database. Tried 1 times {:error_message=>"Java::JavaSql::SQLRecoverableException: IO Error: The Network Adapter could not establish the connection"}
[2018-05-30T10:39:14,701][ERROR][logstash.pipeline        ] A plugin had an unrecoverable error. Will restart this plugin.
  Pipeline_id:main
  Plugin: <LogStash::Inputs::Jdbc jdbc_driver_library=>"/etc/logstash/ojdbc6.jar", jdbc_driver_class=>"Java::oracle.jdbc.driver.OracleDriver", jdbc_connection_string=>"jdbc:oracle:thin:@100.100.100.225:1521:tenuri", jdbc_user=>"es_app", jdbc_password=><password>, jdbc_fetch_size=>10000, statement_filepath=>"as-is_search-log.sql", id=>"5bd7533661d97dbb4a1d2a6189513af0c10219fd73809280818346be344afa9b", enable_metric=>true, codec=><LogStash::Codecs::Plain id=>"plain_1a6af198-39fa-4265-9c68-c91258b113dc", enable_metric=>true, charset=>"UTF-8">, jdbc_paging_enabled=>false, jdbc_page_size=>100000, jdbc_validate_connection=>false, jdbc_validation_timeout=>3600, jdbc_pool_timeout=>5, sql_log_level=>"info", connection_retry_attempts=>1, connection_retry_attempts_wait_time=>0.5, parameters=>{"sql_last_value"=>2018-05-30 09:22:02 +0900}, last_run_metadata_path=>"/home/elastic/.logstash_jdbc_last_run", use_column_value=>false, tracking_column_type=>"numeric", clean_run=>false, record_last_run=>true, lowercase_column_names=>true>
  Error: Java::JavaSql::SQLRecoverableException: IO Error: The Network Adapter could not establish the connection
  Exception: Sequel::DatabaseConnectionError
  Stack: oracle.jdbc.driver.T4CConnection.logon(oracle/jdbc/driver/T4CConnection.java:489)
oracle.jdbc.driver.PhysicalConnection.<init>(oracle/jdbc/driver/PhysicalConnection.java:553)
oracle.jdbc.driver.T4CConnection.<init>(oracle/jdbc/driver/T4CConnection.java:254)
oracle.jdbc.driver.T4CDriverExtension.getConnection(oracle/jdbc/driver/T4CDriverExtension.java:32)
oracle.jdbc.driver.OracleDriver.connect(oracle/jdbc/driver/OracleDriver.java:528)
java.lang.reflect.Method.invoke(java/lang/reflect/Method.java:498)
org.jruby.javasupport.JavaMethod.invokeDirectWithExceptionHandling(org/jruby/javasupport/JavaMethod.java:468)
org.jruby.javasupport.JavaMethod.invokeDirect(org/jruby/javasupport/JavaMethod.java:326)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/adapters/jdbc.rb:203)
RUBY.make_new(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool.rb:126)
RUBY.assign_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:192)
RUBY.acquire(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:133)
RUBY.hold(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:90)
RUBY.synchronize(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:269)
RUBY.test_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:279)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:58)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/core.rb:116)
RUBY.block in jdbc_connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:114)
org.jruby.RubyKernel.loop(org/jruby/RubyKernel.java:1292)
org.jruby.RubyKernel$INVOKER$s$0$0$loop.call(org/jruby/RubyKernel$INVOKER$s$0$0$loop.gen)
RUBY.jdbc_connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:111)
RUBY.open_jdbc_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:163)
RUBY.execute_statement(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:219)
RUBY.execute_query(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/inputs/jdbc.rb:264)
RUBY.run(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/inputs/jdbc.rb:250)
RUBY.inputworker(/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:516)
RUBY.block in start_input(/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:509)
org.jruby.RubyProc.call(org/jruby/RubyProc.java:289)
org.jruby.RubyProc.call(org/jruby/RubyProc.java:246)
java.lang.Thread.run(java/lang/Thread.java:748)
[2018-05-30T10:39:17,703][ERROR][logstash.inputs.jdbc     ] Unable to connect to database. Tried 1 times {:error_message=>"Java::JavaSql::SQLRecoverableException: IO Error: The Network Adapter could not establish the connection"}
[2018-05-30T10:39:17,706][ERROR][logstash.pipeline        ] A plugin had an unrecoverable error. Will restart this plugin.
  Pipeline_id:main
  Plugin: <LogStash::Inputs::Jdbc jdbc_driver_library=>"/etc/logstash/ojdbc6.jar", jdbc_driver_class=>"Java::oracle.jdbc.driver.OracleDriver", jdbc_connection_string=>"jdbc:oracle:thin:@100.100.100.225:1521:tenuri", jdbc_user=>"es_app", jdbc_password=><password>, jdbc_fetch_size=>10000, statement_filepath=>"as-is_search-log.sql", id=>"5bd7533661d97dbb4a1d2a6189513af0c10219fd73809280818346be344afa9b", enable_metric=>true, codec=><LogStash::Codecs::Plain id=>"plain_1a6af198-39fa-4265-9c68-c91258b113dc", enable_metric=>true, charset=>"UTF-8">, jdbc_paging_enabled=>false, jdbc_page_size=>100000, jdbc_validate_connection=>false, jdbc_validation_timeout=>3600, jdbc_pool_timeout=>5, sql_log_level=>"info", connection_retry_attempts=>1, connection_retry_attempts_wait_time=>0.5, parameters=>{"sql_last_value"=>2018-05-30 09:22:02 +0900}, last_run_metadata_path=>"/home/elastic/.logstash_jdbc_last_run", use_column_value=>false, tracking_column_type=>"numeric", clean_run=>false, record_last_run=>true, lowercase_column_names=>true>
  Error: Java::JavaSql::SQLRecoverableException: IO Error: The Network Adapter could not establish the connection
  Exception: Sequel::DatabaseConnectionError
  Stack: oracle.jdbc.driver.T4CConnection.logon(oracle/jdbc/driver/T4CConnection.java:489)
oracle.jdbc.driver.PhysicalConnection.<init>(oracle/jdbc/driver/PhysicalConnection.java:553)
oracle.jdbc.driver.T4CConnection.<init>(oracle/jdbc/driver/T4CConnection.java:254)
oracle.jdbc.driver.T4CDriverExtension.getConnection(oracle/jdbc/driver/T4CDriverExtension.java:32)
oracle.jdbc.driver.OracleDriver.connect(oracle/jdbc/driver/OracleDriver.java:528)
java.lang.reflect.Method.invoke(java/lang/reflect/Method.java:498)
org.jruby.javasupport.JavaMethod.invokeDirectWithExceptionHandling(org/jruby/javasupport/JavaMethod.java:468)
org.jruby.javasupport.JavaMethod.invokeDirect(org/jruby/javasupport/JavaMethod.java:326)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/adapters/jdbc.rb:203)
RUBY.make_new(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool.rb:126)
RUBY.assign_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:192)
RUBY.acquire(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:133)
RUBY.hold(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:90)
RUBY.synchronize(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:269)
RUBY.test_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:279)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:58)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/core.rb:116)
RUBY.block in jdbc_connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:114)
org.jruby.RubyKernel.loop(org/jruby/RubyKernel.java:1292)
org.jruby.RubyKernel$INVOKER$s$0$0$loop.call(org/jruby/RubyKernel$INVOKER$s$0$0$loop.gen)
RUBY.jdbc_connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:111)
RUBY.open_jdbc_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:163)
RUBY.execute_statement(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:219)
RUBY.execute_query(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/inputs/jdbc.rb:264)
RUBY.run(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/inputs/jdbc.rb:250)
RUBY.inputworker(/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:516)
RUBY.block in start_input(/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:509)
org.jruby.RubyProc.call(org/jruby/RubyProc.java:289)
org.jruby.RubyProc.call(org/jruby/RubyProc.java:246)
java.lang.Thread.run(java/lang/Thread.java:748)
[2018-05-30T10:39:20,709][ERROR][logstash.inputs.jdbc     ] Unable to connect to database. Tried 1 times {:error_message=>"Java::JavaSql::SQLRecoverableException: IO Error: The Network Adapter could not establish the connection"}
[2018-05-30T10:39:20,711][ERROR][logstash.pipeline        ] A plugin had an unrecoverable error. Will restart this plugin.
  Pipeline_id:main
  Plugin: <LogStash::Inputs::Jdbc jdbc_driver_library=>"/etc/logstash/ojdbc6.jar", jdbc_driver_class=>"Java::oracle.jdbc.driver.OracleDriver", jdbc_connection_string=>"jdbc:oracle:thin:@100.100.100.225:1521:tenuri", jdbc_user=>"es_app", jdbc_password=><password>, jdbc_fetch_size=>10000, statement_filepath=>"as-is_search-log.sql", id=>"5bd7533661d97dbb4a1d2a6189513af0c10219fd73809280818346be344afa9b", enable_metric=>true, codec=><LogStash::Codecs::Plain id=>"plain_1a6af198-39fa-4265-9c68-c91258b113dc", enable_metric=>true, charset=>"UTF-8">, jdbc_paging_enabled=>false, jdbc_page_size=>100000, jdbc_validate_connection=>false, jdbc_validation_timeout=>3600, jdbc_pool_timeout=>5, sql_log_level=>"info", connection_retry_attempts=>1, connection_retry_attempts_wait_time=>0.5, parameters=>{"sql_last_value"=>2018-05-30 09:22:02 +0900}, last_run_metadata_path=>"/home/elastic/.logstash_jdbc_last_run", use_column_value=>false, tracking_column_type=>"numeric", clean_run=>false, record_last_run=>true, lowercase_column_names=>true>
  Error: Java::JavaSql::SQLRecoverableException: IO Error: The Network Adapter could not establish the connection
  Exception: Sequel::DatabaseConnectionError
  Stack: oracle.jdbc.driver.T4CConnection.logon(oracle/jdbc/driver/T4CConnection.java:489)
oracle.jdbc.driver.PhysicalConnection.<init>(oracle/jdbc/driver/PhysicalConnection.java:553)
oracle.jdbc.driver.T4CConnection.<init>(oracle/jdbc/driver/T4CConnection.java:254)
oracle.jdbc.driver.T4CDriverExtension.getConnection(oracle/jdbc/driver/T4CDriverExtension.java:32)
oracle.jdbc.driver.OracleDriver.connect(oracle/jdbc/driver/OracleDriver.java:528)
java.lang.reflect.Method.invoke(java/lang/reflect/Method.java:498)
org.jruby.javasupport.JavaMethod.invokeDirectWithExceptionHandling(org/jruby/javasupport/JavaMethod.java:468)
org.jruby.javasupport.JavaMethod.invokeDirect(org/jruby/javasupport/JavaMethod.java:326)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/adapters/jdbc.rb:203)
RUBY.make_new(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool.rb:126)
RUBY.assign_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:192)
RUBY.acquire(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:133)
RUBY.hold(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:90)
RUBY.synchronize(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:269)
RUBY.test_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:279)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:58)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/core.rb:116)
RUBY.block in jdbc_connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:114)
org.jruby.RubyKernel.loop(org/jruby/RubyKernel.java:1292)
org.jruby.RubyKernel$INVOKER$s$0$0$loop.call(org/jruby/RubyKernel$INVOKER$s$0$0$loop.gen)
RUBY.jdbc_connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:111)
RUBY.open_jdbc_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:163)
RUBY.execute_statement(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:219)
RUBY.execute_query(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/inputs/jdbc.rb:264)
RUBY.run(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/inputs/jdbc.rb:250)
RUBY.inputworker(/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:516)
RUBY.block in start_input(/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:509)
org.jruby.RubyProc.call(org/jruby/RubyProc.java:289)
org.jruby.RubyProc.call(org/jruby/RubyProc.java:246)
java.lang.Thread.run(java/lang/Thread.java:748)
[2018-05-30T10:39:23,716][ERROR][logstash.inputs.jdbc     ] Unable to connect to database. Tried 1 times {:error_message=>"Java::JavaSql::SQLRecoverableException: IO Error: The Network Adapter could not establish the connection"}
[2018-05-30T10:39:23,720][ERROR][logstash.pipeline        ] A plugin had an unrecoverable error. Will restart this plugin.
  Pipeline_id:main
  Plugin: <LogStash::Inputs::Jdbc jdbc_driver_library=>"/etc/logstash/ojdbc6.jar", jdbc_driver_class=>"Java::oracle.jdbc.driver.OracleDriver", jdbc_connection_string=>"jdbc:oracle:thin:@100.100.100.225:1521:tenuri", jdbc_user=>"es_app", jdbc_password=><password>, jdbc_fetch_size=>10000, statement_filepath=>"as-is_search-log.sql", id=>"5bd7533661d97dbb4a1d2a6189513af0c10219fd73809280818346be344afa9b", enable_metric=>true, codec=><LogStash::Codecs::Plain id=>"plain_1a6af198-39fa-4265-9c68-c91258b113dc", enable_metric=>true, charset=>"UTF-8">, jdbc_paging_enabled=>false, jdbc_page_size=>100000, jdbc_validate_connection=>false, jdbc_validation_timeout=>3600, jdbc_pool_timeout=>5, sql_log_level=>"info", connection_retry_attempts=>1, connection_retry_attempts_wait_time=>0.5, parameters=>{"sql_last_value"=>2018-05-30 09:22:02 +0900}, last_run_metadata_path=>"/home/elastic/.logstash_jdbc_last_run", use_column_value=>false, tracking_column_type=>"numeric", clean_run=>false, record_last_run=>true, lowercase_column_names=>true>
  Error: Java::JavaSql::SQLRecoverableException: IO Error: The Network Adapter could not establish the connection
  Exception: Sequel::DatabaseConnectionError
  Stack: oracle.jdbc.driver.T4CConnection.logon(oracle/jdbc/driver/T4CConnection.java:489)
oracle.jdbc.driver.PhysicalConnection.<init>(oracle/jdbc/driver/PhysicalConnection.java:553)
oracle.jdbc.driver.T4CConnection.<init>(oracle/jdbc/driver/T4CConnection.java:254)
oracle.jdbc.driver.T4CDriverExtension.getConnection(oracle/jdbc/driver/T4CDriverExtension.java:32)
oracle.jdbc.driver.OracleDriver.connect(oracle/jdbc/driver/OracleDriver.java:528)
java.lang.reflect.Method.invoke(java/lang/reflect/Method.java:498)
org.jruby.javasupport.JavaMethod.invokeDirectWithExceptionHandling(org/jruby/javasupport/JavaMethod.java:468)
org.jruby.javasupport.JavaMethod.invokeDirect(org/jruby/javasupport/JavaMethod.java:326)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/adapters/jdbc.rb:203)
RUBY.make_new(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool.rb:126)
RUBY.assign_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:192)
RUBY.acquire(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:133)
RUBY.hold(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:90)
RUBY.synchronize(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:269)
RUBY.test_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:279)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:58)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/core.rb:116)
RUBY.block in jdbc_connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:114)
org.jruby.RubyKernel.loop(org/jruby/RubyKernel.java:1292)
org.jruby.RubyKernel$INVOKER$s$0$0$loop.call(org/jruby/RubyKernel$INVOKER$s$0$0$loop.gen)
RUBY.jdbc_connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:111)
RUBY.open_jdbc_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:163)
RUBY.execute_statement(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:219)
RUBY.execute_query(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/inputs/jdbc.rb:264)
RUBY.run(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/inputs/jdbc.rb:250)
RUBY.inputworker(/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:516)
RUBY.block in start_input(/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:509)
org.jruby.RubyProc.call(org/jruby/RubyProc.java:289)
org.jruby.RubyProc.call(org/jruby/RubyProc.java:246)
java.lang.Thread.run(java/lang/Thread.java:748)
[2018-05-30T10:39:26,721][ERROR][logstash.inputs.jdbc     ] Unable to connect to database. Tried 1 times {:error_message=>"Java::JavaSql::SQLRecoverableException: IO Error: The Network Adapter could not establish the connection"}
[2018-05-30T10:39:26,725][ERROR][logstash.pipeline        ] A plugin had an unrecoverable error. Will restart this plugin.
  Pipeline_id:main
  Plugin: <LogStash::Inputs::Jdbc jdbc_driver_library=>"/etc/logstash/ojdbc6.jar", jdbc_driver_class=>"Java::oracle.jdbc.driver.OracleDriver", jdbc_connection_string=>"jdbc:oracle:thin:@100.100.100.225:1521:tenuri", jdbc_user=>"es_app", jdbc_password=><password>, jdbc_fetch_size=>10000, statement_filepath=>"as-is_search-log.sql", id=>"5bd7533661d97dbb4a1d2a6189513af0c10219fd73809280818346be344afa9b", enable_metric=>true, codec=><LogStash::Codecs::Plain id=>"plain_1a6af198-39fa-4265-9c68-c91258b113dc", enable_metric=>true, charset=>"UTF-8">, jdbc_paging_enabled=>false, jdbc_page_size=>100000, jdbc_validate_connection=>false, jdbc_validation_timeout=>3600, jdbc_pool_timeout=>5, sql_log_level=>"info", connection_retry_attempts=>1, connection_retry_attempts_wait_time=>0.5, parameters=>{"sql_last_value"=>2018-05-30 09:22:02 +0900}, last_run_metadata_path=>"/home/elastic/.logstash_jdbc_last_run", use_column_value=>false, tracking_column_type=>"numeric", clean_run=>false, record_last_run=>true, lowercase_column_names=>true>
  Error: Java::JavaSql::SQLRecoverableException: IO Error: The Network Adapter could not establish the connection
  Exception: Sequel::DatabaseConnectionError
  Stack: oracle.jdbc.driver.T4CConnection.logon(oracle/jdbc/driver/T4CConnection.java:489)
oracle.jdbc.driver.PhysicalConnection.<init>(oracle/jdbc/driver/PhysicalConnection.java:553)
oracle.jdbc.driver.T4CConnection.<init>(oracle/jdbc/driver/T4CConnection.java:254)
oracle.jdbc.driver.T4CDriverExtension.getConnection(oracle/jdbc/driver/T4CDriverExtension.java:32)
oracle.jdbc.driver.OracleDriver.connect(oracle/jdbc/driver/OracleDriver.java:528)
java.lang.reflect.Method.invoke(java/lang/reflect/Method.java:498)
org.jruby.javasupport.JavaMethod.invokeDirectWithExceptionHandling(org/jruby/javasupport/JavaMethod.java:468)
org.jruby.javasupport.JavaMethod.invokeDirect(org/jruby/javasupport/JavaMethod.java:326)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/adapters/jdbc.rb:203)
RUBY.make_new(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool.rb:126)
RUBY.assign_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:192)
RUBY.acquire(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:133)
RUBY.hold(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:90)
RUBY.synchronize(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:269)
RUBY.test_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:279)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:58)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/core.rb:116)
RUBY.block in jdbc_connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:114)
org.jruby.RubyKernel.loop(org/jruby/RubyKernel.java:1292)
org.jruby.RubyKernel$INVOKER$s$0$0$loop.call(org/jruby/RubyKernel$INVOKER$s$0$0$loop.gen)
RUBY.jdbc_connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:111)
RUBY.open_jdbc_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:163)
RUBY.execute_statement(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:219)
RUBY.execute_query(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/inputs/jdbc.rb:264)
RUBY.run(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/inputs/jdbc.rb:250)
RUBY.inputworker(/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:516)
RUBY.block in start_input(/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:509)
org.jruby.RubyProc.call(org/jruby/RubyProc.java:289)
org.jruby.RubyProc.call(org/jruby/RubyProc.java:246)
java.lang.Thread.run(java/lang/Thread.java:748)
[2018-05-30T10:39:29,729][ERROR][logstash.inputs.jdbc     ] Unable to connect to database. Tried 1 times {:error_message=>"Java::JavaSql::SQLRecoverableException: IO Error: The Network Adapter could not establish the connection"}
[2018-05-30T10:39:29,731][ERROR][logstash.pipeline        ] A plugin had an unrecoverable error. Will restart this plugin.
  Pipeline_id:main
  Plugin: <LogStash::Inputs::Jdbc jdbc_driver_library=>"/etc/logstash/ojdbc6.jar", jdbc_driver_class=>"Java::oracle.jdbc.driver.OracleDriver", jdbc_connection_string=>"jdbc:oracle:thin:@100.100.100.225:1521:tenuri", jdbc_user=>"es_app", jdbc_password=><password>, jdbc_fetch_size=>10000, statement_filepath=>"as-is_search-log.sql", id=>"5bd7533661d97dbb4a1d2a6189513af0c10219fd73809280818346be344afa9b", enable_metric=>true, codec=><LogStash::Codecs::Plain id=>"plain_1a6af198-39fa-4265-9c68-c91258b113dc", enable_metric=>true, charset=>"UTF-8">, jdbc_paging_enabled=>false, jdbc_page_size=>100000, jdbc_validate_connection=>false, jdbc_validation_timeout=>3600, jdbc_pool_timeout=>5, sql_log_level=>"info", connection_retry_attempts=>1, connection_retry_attempts_wait_time=>0.5, parameters=>{"sql_last_value"=>2018-05-30 09:22:02 +0900}, last_run_metadata_path=>"/home/elastic/.logstash_jdbc_last_run", use_column_value=>false, tracking_column_type=>"numeric", clean_run=>false, record_last_run=>true, lowercase_column_names=>true>
  Error: Java::JavaSql::SQLRecoverableException: IO Error: The Network Adapter could not establish the connection
  Exception: Sequel::DatabaseConnectionError
  Stack: oracle.jdbc.driver.T4CConnection.logon(oracle/jdbc/driver/T4CConnection.java:489)
oracle.jdbc.driver.PhysicalConnection.<init>(oracle/jdbc/driver/PhysicalConnection.java:553)
oracle.jdbc.driver.T4CConnection.<init>(oracle/jdbc/driver/T4CConnection.java:254)
oracle.jdbc.driver.T4CDriverExtension.getConnection(oracle/jdbc/driver/T4CDriverExtension.java:32)
oracle.jdbc.driver.OracleDriver.connect(oracle/jdbc/driver/OracleDriver.java:528)
java.lang.reflect.Method.invoke(java/lang/reflect/Method.java:498)
org.jruby.javasupport.JavaMethod.invokeDirectWithExceptionHandling(org/jruby/javasupport/JavaMethod.java:468)
org.jruby.javasupport.JavaMethod.invokeDirect(org/jruby/javasupport/JavaMethod.java:326)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/adapters/jdbc.rb:203)
RUBY.make_new(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool.rb:126)
RUBY.assign_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:192)
RUBY.acquire(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:133)
RUBY.hold(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:90)
RUBY.synchronize(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:269)
RUBY.test_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:279)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:58)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/core.rb:116)
RUBY.block in jdbc_connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:114)
org.jruby.RubyKernel.loop(org/jruby/RubyKernel.java:1292)
org.jruby.RubyKernel$INVOKER$s$0$0$loop.call(org/jruby/RubyKernel$INVOKER$s$0$0$loop.gen)
RUBY.jdbc_connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:111)
RUBY.open_jdbc_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:163)
RUBY.execute_statement(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:219)
RUBY.execute_query(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/inputs/jdbc.rb:264)
RUBY.run(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/inputs/jdbc.rb:250)
RUBY.inputworker(/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:516)
RUBY.block in start_input(/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:509)
org.jruby.RubyProc.call(org/jruby/RubyProc.java:289)
org.jruby.RubyProc.call(org/jruby/RubyProc.java:246)
java.lang.Thread.run(java/lang/Thread.java:748)
[2018-05-30T10:39:32,736][ERROR][logstash.inputs.jdbc     ] Unable to connect to database. Tried 1 times {:error_message=>"Java::JavaSql::SQLRecoverableException: IO Error: The Network Adapter could not establish the connection"}
[2018-05-30T10:39:32,738][ERROR][logstash.pipeline        ] A plugin had an unrecoverable error. Will restart this plugin.
  Pipeline_id:main
  Plugin: <LogStash::Inputs::Jdbc jdbc_driver_library=>"/etc/logstash/ojdbc6.jar", jdbc_driver_class=>"Java::oracle.jdbc.driver.OracleDriver", jdbc_connection_string=>"jdbc:oracle:thin:@100.100.100.225:1521:tenuri", jdbc_user=>"es_app", jdbc_password=><password>, jdbc_fetch_size=>10000, statement_filepath=>"as-is_search-log.sql", id=>"5bd7533661d97dbb4a1d2a6189513af0c10219fd73809280818346be344afa9b", enable_metric=>true, codec=><LogStash::Codecs::Plain id=>"plain_1a6af198-39fa-4265-9c68-c91258b113dc", enable_metric=>true, charset=>"UTF-8">, jdbc_paging_enabled=>false, jdbc_page_size=>100000, jdbc_validate_connection=>false, jdbc_validation_timeout=>3600, jdbc_pool_timeout=>5, sql_log_level=>"info", connection_retry_attempts=>1, connection_retry_attempts_wait_time=>0.5, parameters=>{"sql_last_value"=>2018-05-30 09:22:02 +0900}, last_run_metadata_path=>"/home/elastic/.logstash_jdbc_last_run", use_column_value=>false, tracking_column_type=>"numeric", clean_run=>false, record_last_run=>true, lowercase_column_names=>true>
  Error: Java::JavaSql::SQLRecoverableException: IO Error: The Network Adapter could not establish the connection
  Exception: Sequel::DatabaseConnectionError
  Stack: oracle.jdbc.driver.T4CConnection.logon(oracle/jdbc/driver/T4CConnection.java:489)
oracle.jdbc.driver.PhysicalConnection.<init>(oracle/jdbc/driver/PhysicalConnection.java:553)
oracle.jdbc.driver.T4CConnection.<init>(oracle/jdbc/driver/T4CConnection.java:254)
oracle.jdbc.driver.T4CDriverExtension.getConnection(oracle/jdbc/driver/T4CDriverExtension.java:32)
oracle.jdbc.driver.OracleDriver.connect(oracle/jdbc/driver/OracleDriver.java:528)
java.lang.reflect.Method.invoke(java/lang/reflect/Method.java:498)
org.jruby.javasupport.JavaMethod.invokeDirectWithExceptionHandling(org/jruby/javasupport/JavaMethod.java:468)
org.jruby.javasupport.JavaMethod.invokeDirect(org/jruby/javasupport/JavaMethod.java:326)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/adapters/jdbc.rb:203)
RUBY.make_new(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool.rb:126)
RUBY.assign_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:192)
RUBY.acquire(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:133)
RUBY.hold(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:90)
RUBY.synchronize(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:269)
RUBY.test_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:279)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:58)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/core.rb:116)
RUBY.block in jdbc_connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:114)
org.jruby.RubyKernel.loop(org/jruby/RubyKernel.java:1292)
org.jruby.RubyKernel$INVOKER$s$0$0$loop.call(org/jruby/RubyKernel$INVOKER$s$0$0$loop.gen)
RUBY.jdbc_connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:111)
RUBY.open_jdbc_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:163)
RUBY.execute_statement(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:219)
RUBY.execute_query(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/inputs/jdbc.rb:264)
RUBY.run(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/inputs/jdbc.rb:250)
RUBY.inputworker(/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:516)
RUBY.block in start_input(/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:509)
org.jruby.RubyProc.call(org/jruby/RubyProc.java:289)
org.jruby.RubyProc.call(org/jruby/RubyProc.java:246)
java.lang.Thread.run(java/lang/Thread.java:748)
[2018-05-30T10:39:35,745][ERROR][logstash.inputs.jdbc     ] Unable to connect to database. Tried 1 times {:error_message=>"Java::JavaSql::SQLRecoverableException: IO Error: The Network Adapter could not establish the connection"}
[2018-05-30T10:39:35,748][ERROR][logstash.pipeline        ] A plugin had an unrecoverable error. Will restart this plugin.
  Pipeline_id:main
  Plugin: <LogStash::Inputs::Jdbc jdbc_driver_library=>"/etc/logstash/ojdbc6.jar", jdbc_driver_class=>"Java::oracle.jdbc.driver.OracleDriver", jdbc_connection_string=>"jdbc:oracle:thin:@100.100.100.225:1521:tenuri", jdbc_user=>"es_app", jdbc_password=><password>, jdbc_fetch_size=>10000, statement_filepath=>"as-is_search-log.sql", id=>"5bd7533661d97dbb4a1d2a6189513af0c10219fd73809280818346be344afa9b", enable_metric=>true, codec=><LogStash::Codecs::Plain id=>"plain_1a6af198-39fa-4265-9c68-c91258b113dc", enable_metric=>true, charset=>"UTF-8">, jdbc_paging_enabled=>false, jdbc_page_size=>100000, jdbc_validate_connection=>false, jdbc_validation_timeout=>3600, jdbc_pool_timeout=>5, sql_log_level=>"info", connection_retry_attempts=>1, connection_retry_attempts_wait_time=>0.5, parameters=>{"sql_last_value"=>2018-05-30 09:22:02 +0900}, last_run_metadata_path=>"/home/elastic/.logstash_jdbc_last_run", use_column_value=>false, tracking_column_type=>"numeric", clean_run=>false, record_last_run=>true, lowercase_column_names=>true>
  Error: Java::JavaSql::SQLRecoverableException: IO Error: The Network Adapter could not establish the connection
  Exception: Sequel::DatabaseConnectionError
  Stack: oracle.jdbc.driver.T4CConnection.logon(oracle/jdbc/driver/T4CConnection.java:489)
oracle.jdbc.driver.PhysicalConnection.<init>(oracle/jdbc/driver/PhysicalConnection.java:553)
oracle.jdbc.driver.T4CConnection.<init>(oracle/jdbc/driver/T4CConnection.java:254)
oracle.jdbc.driver.T4CDriverExtension.getConnection(oracle/jdbc/driver/T4CDriverExtension.java:32)
oracle.jdbc.driver.OracleDriver.connect(oracle/jdbc/driver/OracleDriver.java:528)
java.lang.reflect.Method.invoke(java/lang/reflect/Method.java:498)
org.jruby.javasupport.JavaMethod.invokeDirectWithExceptionHandling(org/jruby/javasupport/JavaMethod.java:468)
org.jruby.javasupport.JavaMethod.invokeDirect(org/jruby/javasupport/JavaMethod.java:326)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/adapters/jdbc.rb:203)
RUBY.make_new(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool.rb:126)
RUBY.assign_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:192)
RUBY.acquire(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:133)
RUBY.hold(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:90)
RUBY.synchronize(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:269)
RUBY.test_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:279)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:58)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/core.rb:116)
RUBY.block in jdbc_connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:114)
org.jruby.RubyKernel.loop(org/jruby/RubyKernel.java:1292)
org.jruby.RubyKernel$INVOKER$s$0$0$loop.call(org/jruby/RubyKernel$INVOKER$s$0$0$loop.gen)
RUBY.jdbc_connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:111)
RUBY.open_jdbc_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:163)
RUBY.execute_statement(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:219)
RUBY.execute_query(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/inputs/jdbc.rb:264)
RUBY.run(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/inputs/jdbc.rb:250)
RUBY.inputworker(/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:516)
RUBY.block in start_input(/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:509)
org.jruby.RubyProc.call(org/jruby/RubyProc.java:289)
org.jruby.RubyProc.call(org/jruby/RubyProc.java:246)
java.lang.Thread.run(java/lang/Thread.java:748)
[2018-05-30T10:39:38,747][ERROR][logstash.inputs.jdbc     ] Unable to connect to database. Tried 1 times {:error_message=>"Java::JavaSql::SQLRecoverableException: IO Error: The Network Adapter could not establish the connection"}
[2018-05-30T10:39:38,754][ERROR][logstash.pipeline        ] A plugin had an unrecoverable error. Will restart this plugin.
  Pipeline_id:main
  Plugin: <LogStash::Inputs::Jdbc jdbc_driver_library=>"/etc/logstash/ojdbc6.jar", jdbc_driver_class=>"Java::oracle.jdbc.driver.OracleDriver", jdbc_connection_string=>"jdbc:oracle:thin:@100.100.100.225:1521:tenuri", jdbc_user=>"es_app", jdbc_password=><password>, jdbc_fetch_size=>10000, statement_filepath=>"as-is_search-log.sql", id=>"5bd7533661d97dbb4a1d2a6189513af0c10219fd73809280818346be344afa9b", enable_metric=>true, codec=><LogStash::Codecs::Plain id=>"plain_1a6af198-39fa-4265-9c68-c91258b113dc", enable_metric=>true, charset=>"UTF-8">, jdbc_paging_enabled=>false, jdbc_page_size=>100000, jdbc_validate_connection=>false, jdbc_validation_timeout=>3600, jdbc_pool_timeout=>5, sql_log_level=>"info", connection_retry_attempts=>1, connection_retry_attempts_wait_time=>0.5, parameters=>{"sql_last_value"=>2018-05-30 09:22:02 +0900}, last_run_metadata_path=>"/home/elastic/.logstash_jdbc_last_run", use_column_value=>false, tracking_column_type=>"numeric", clean_run=>false, record_last_run=>true, lowercase_column_names=>true>
  Error: Java::JavaSql::SQLRecoverableException: IO Error: The Network Adapter could not establish the connection
  Exception: Sequel::DatabaseConnectionError
  Stack: oracle.jdbc.driver.T4CConnection.logon(oracle/jdbc/driver/T4CConnection.java:489)
oracle.jdbc.driver.PhysicalConnection.<init>(oracle/jdbc/driver/PhysicalConnection.java:553)
oracle.jdbc.driver.T4CConnection.<init>(oracle/jdbc/driver/T4CConnection.java:254)
oracle.jdbc.driver.T4CDriverExtension.getConnection(oracle/jdbc/driver/T4CDriverExtension.java:32)
oracle.jdbc.driver.OracleDriver.connect(oracle/jdbc/driver/OracleDriver.java:528)
java.lang.reflect.Method.invoke(java/lang/reflect/Method.java:498)
org.jruby.javasupport.JavaMethod.invokeDirectWithExceptionHandling(org/jruby/javasupport/JavaMethod.java:468)
org.jruby.javasupport.JavaMethod.invokeDirect(org/jruby/javasupport/JavaMethod.java:326)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/adapters/jdbc.rb:203)
RUBY.make_new(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool.rb:126)
RUBY.assign_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:192)
RUBY.acquire(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:133)
RUBY.hold(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:90)
RUBY.synchronize(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:269)
RUBY.test_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:279)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:58)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/core.rb:116)
RUBY.block in jdbc_connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:114)
org.jruby.RubyKernel.loop(org/jruby/RubyKernel.java:1292)
org.jruby.RubyKernel$INVOKER$s$0$0$loop.call(org/jruby/RubyKernel$INVOKER$s$0$0$loop.gen)
RUBY.jdbc_connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:111)
RUBY.open_jdbc_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:163)
RUBY.execute_statement(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:219)
RUBY.execute_query(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/inputs/jdbc.rb:264)
RUBY.run(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/inputs/jdbc.rb:250)
RUBY.inputworker(/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:516)
RUBY.block in start_input(/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:509)
org.jruby.RubyProc.call(org/jruby/RubyProc.java:289)
org.jruby.RubyProc.call(org/jruby/RubyProc.java:246)
java.lang.Thread.run(java/lang/Thread.java:748)
[2018-05-30T10:39:41,754][ERROR][logstash.inputs.jdbc     ] Unable to connect to database. Tried 1 times {:error_message=>"Java::JavaSql::SQLRecoverableException: IO Error: The Network Adapter could not establish the connection"}
[2018-05-30T10:39:41,757][ERROR][logstash.pipeline        ] A plugin had an unrecoverable error. Will restart this plugin.
  Pipeline_id:main
  Plugin: <LogStash::Inputs::Jdbc jdbc_driver_library=>"/etc/logstash/ojdbc6.jar", jdbc_driver_class=>"Java::oracle.jdbc.driver.OracleDriver", jdbc_connection_string=>"jdbc:oracle:thin:@100.100.100.225:1521:tenuri", jdbc_user=>"es_app", jdbc_password=><password>, jdbc_fetch_size=>10000, statement_filepath=>"as-is_search-log.sql", id=>"5bd7533661d97dbb4a1d2a6189513af0c10219fd73809280818346be344afa9b", enable_metric=>true, codec=><LogStash::Codecs::Plain id=>"plain_1a6af198-39fa-4265-9c68-c91258b113dc", enable_metric=>true, charset=>"UTF-8">, jdbc_paging_enabled=>false, jdbc_page_size=>100000, jdbc_validate_connection=>false, jdbc_validation_timeout=>3600, jdbc_pool_timeout=>5, sql_log_level=>"info", connection_retry_attempts=>1, connection_retry_attempts_wait_time=>0.5, parameters=>{"sql_last_value"=>2018-05-30 09:22:02 +0900}, last_run_metadata_path=>"/home/elastic/.logstash_jdbc_last_run", use_column_value=>false, tracking_column_type=>"numeric", clean_run=>false, record_last_run=>true, lowercase_column_names=>true>
  Error: Java::JavaSql::SQLRecoverableException: IO Error: The Network Adapter could not establish the connection
  Exception: Sequel::DatabaseConnectionError
  Stack: oracle.jdbc.driver.T4CConnection.logon(oracle/jdbc/driver/T4CConnection.java:489)
oracle.jdbc.driver.PhysicalConnection.<init>(oracle/jdbc/driver/PhysicalConnection.java:553)
oracle.jdbc.driver.T4CConnection.<init>(oracle/jdbc/driver/T4CConnection.java:254)
oracle.jdbc.driver.T4CDriverExtension.getConnection(oracle/jdbc/driver/T4CDriverExtension.java:32)
oracle.jdbc.driver.OracleDriver.connect(oracle/jdbc/driver/OracleDriver.java:528)
java.lang.reflect.Method.invoke(java/lang/reflect/Method.java:498)
org.jruby.javasupport.JavaMethod.invokeDirectWithExceptionHandling(org/jruby/javasupport/JavaMethod.java:468)
org.jruby.javasupport.JavaMethod.invokeDirect(org/jruby/javasupport/JavaMethod.java:326)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/adapters/jdbc.rb:203)
RUBY.make_new(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool.rb:126)
RUBY.assign_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:192)
RUBY.acquire(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:133)
RUBY.hold(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:90)
RUBY.synchronize(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:269)
RUBY.test_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:279)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:58)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/core.rb:116)
RUBY.block in jdbc_connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:114)
org.jruby.RubyKernel.loop(org/jruby/RubyKernel.java:1292)
org.jruby.RubyKernel$INVOKER$s$0$0$loop.call(org/jruby/RubyKernel$INVOKER$s$0$0$loop.gen)
RUBY.jdbc_connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:111)
RUBY.open_jdbc_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:163)
RUBY.execute_statement(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:219)
RUBY.execute_query(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/inputs/jdbc.rb:264)
RUBY.run(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/inputs/jdbc.rb:250)
RUBY.inputworker(/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:516)
RUBY.block in start_input(/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:509)
org.jruby.RubyProc.call(org/jruby/RubyProc.java:289)
org.jruby.RubyProc.call(org/jruby/RubyProc.java:246)
java.lang.Thread.run(java/lang/Thread.java:748)
[2018-05-30T10:39:44,770][ERROR][logstash.inputs.jdbc     ] Unable to connect to database. Tried 1 times {:error_message=>"Java::JavaSql::SQLRecoverableException: IO Error: The Network Adapter could not establish the connection"}
[2018-05-30T10:39:44,772][ERROR][logstash.pipeline        ] A plugin had an unrecoverable error. Will restart this plugin.
  Pipeline_id:main
  Plugin: <LogStash::Inputs::Jdbc jdbc_driver_library=>"/etc/logstash/ojdbc6.jar", jdbc_driver_class=>"Java::oracle.jdbc.driver.OracleDriver", jdbc_connection_string=>"jdbc:oracle:thin:@100.100.100.225:1521:tenuri", jdbc_user=>"es_app", jdbc_password=><password>, jdbc_fetch_size=>10000, statement_filepath=>"as-is_search-log.sql", id=>"5bd7533661d97dbb4a1d2a6189513af0c10219fd73809280818346be344afa9b", enable_metric=>true, codec=><LogStash::Codecs::Plain id=>"plain_1a6af198-39fa-4265-9c68-c91258b113dc", enable_metric=>true, charset=>"UTF-8">, jdbc_paging_enabled=>false, jdbc_page_size=>100000, jdbc_validate_connection=>false, jdbc_validation_timeout=>3600, jdbc_pool_timeout=>5, sql_log_level=>"info", connection_retry_attempts=>1, connection_retry_attempts_wait_time=>0.5, parameters=>{"sql_last_value"=>2018-05-30 09:22:02 +0900}, last_run_metadata_path=>"/home/elastic/.logstash_jdbc_last_run", use_column_value=>false, tracking_column_type=>"numeric", clean_run=>false, record_last_run=>true, lowercase_column_names=>true>
  Error: Java::JavaSql::SQLRecoverableException: IO Error: The Network Adapter could not establish the connection
  Exception: Sequel::DatabaseConnectionError
  Stack: oracle.jdbc.driver.T4CConnection.logon(oracle/jdbc/driver/T4CConnection.java:489)
oracle.jdbc.driver.PhysicalConnection.<init>(oracle/jdbc/driver/PhysicalConnection.java:553)
oracle.jdbc.driver.T4CConnection.<init>(oracle/jdbc/driver/T4CConnection.java:254)
oracle.jdbc.driver.T4CDriverExtension.getConnection(oracle/jdbc/driver/T4CDriverExtension.java:32)
oracle.jdbc.driver.OracleDriver.connect(oracle/jdbc/driver/OracleDriver.java:528)
java.lang.reflect.Method.invoke(java/lang/reflect/Method.java:498)
org.jruby.javasupport.JavaMethod.invokeDirectWithExceptionHandling(org/jruby/javasupport/JavaMethod.java:468)
org.jruby.javasupport.JavaMethod.invokeDirect(org/jruby/javasupport/JavaMethod.java:326)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/adapters/jdbc.rb:203)
RUBY.make_new(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool.rb:126)
RUBY.assign_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:192)
RUBY.acquire(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:133)
RUBY.hold(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:90)
RUBY.synchronize(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:269)
RUBY.test_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:279)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:58)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/core.rb:116)
RUBY.block in jdbc_connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:114)
org.jruby.RubyKernel.loop(org/jruby/RubyKernel.java:1292)
org.jruby.RubyKernel$INVOKER$s$0$0$loop.call(org/jruby/RubyKernel$INVOKER$s$0$0$loop.gen)
RUBY.jdbc_connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:111)
RUBY.open_jdbc_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:163)
RUBY.execute_statement(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:219)
RUBY.execute_query(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/inputs/jdbc.rb:264)
RUBY.run(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/inputs/jdbc.rb:250)
RUBY.inputworker(/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:516)
RUBY.block in start_input(/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:509)
org.jruby.RubyProc.call(org/jruby/RubyProc.java:289)
org.jruby.RubyProc.call(org/jruby/RubyProc.java:246)
java.lang.Thread.run(java/lang/Thread.java:748)
[2018-05-30T10:39:47,772][ERROR][logstash.inputs.jdbc     ] Unable to connect to database. Tried 1 times {:error_message=>"Java::JavaSql::SQLRecoverableException: IO Error: The Network Adapter could not establish the connection"}
[2018-05-30T10:39:47,773][ERROR][logstash.pipeline        ] A plugin had an unrecoverable error. Will restart this plugin.
  Pipeline_id:main
  Plugin: <LogStash::Inputs::Jdbc jdbc_driver_library=>"/etc/logstash/ojdbc6.jar", jdbc_driver_class=>"Java::oracle.jdbc.driver.OracleDriver", jdbc_connection_string=>"jdbc:oracle:thin:@100.100.100.225:1521:tenuri", jdbc_user=>"es_app", jdbc_password=><password>, jdbc_fetch_size=>10000, statement_filepath=>"as-is_search-log.sql", id=>"5bd7533661d97dbb4a1d2a6189513af0c10219fd73809280818346be344afa9b", enable_metric=>true, codec=><LogStash::Codecs::Plain id=>"plain_1a6af198-39fa-4265-9c68-c91258b113dc", enable_metric=>true, charset=>"UTF-8">, jdbc_paging_enabled=>false, jdbc_page_size=>100000, jdbc_validate_connection=>false, jdbc_validation_timeout=>3600, jdbc_pool_timeout=>5, sql_log_level=>"info", connection_retry_attempts=>1, connection_retry_attempts_wait_time=>0.5, parameters=>{"sql_last_value"=>2018-05-30 09:22:02 +0900}, last_run_metadata_path=>"/home/elastic/.logstash_jdbc_last_run", use_column_value=>false, tracking_column_type=>"numeric", clean_run=>false, record_last_run=>true, lowercase_column_names=>true>
  Error: Java::JavaSql::SQLRecoverableException: IO Error: The Network Adapter could not establish the connection
  Exception: Sequel::DatabaseConnectionError
  Stack: oracle.jdbc.driver.T4CConnection.logon(oracle/jdbc/driver/T4CConnection.java:489)
oracle.jdbc.driver.PhysicalConnection.<init>(oracle/jdbc/driver/PhysicalConnection.java:553)
oracle.jdbc.driver.T4CConnection.<init>(oracle/jdbc/driver/T4CConnection.java:254)
oracle.jdbc.driver.T4CDriverExtension.getConnection(oracle/jdbc/driver/T4CDriverExtension.java:32)
oracle.jdbc.driver.OracleDriver.connect(oracle/jdbc/driver/OracleDriver.java:528)
java.lang.reflect.Method.invoke(java/lang/reflect/Method.java:498)
org.jruby.javasupport.JavaMethod.invokeDirectWithExceptionHandling(org/jruby/javasupport/JavaMethod.java:468)
org.jruby.javasupport.JavaMethod.invokeDirect(org/jruby/javasupport/JavaMethod.java:326)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/adapters/jdbc.rb:203)
RUBY.make_new(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool.rb:126)
RUBY.assign_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:192)
RUBY.acquire(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:133)
RUBY.hold(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:90)
RUBY.synchronize(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:269)
RUBY.test_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:279)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:58)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/core.rb:116)
RUBY.block in jdbc_connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:114)
org.jruby.RubyKernel.loop(org/jruby/RubyKernel.java:1292)
org.jruby.RubyKernel$INVOKER$s$0$0$loop.call(org/jruby/RubyKernel$INVOKER$s$0$0$loop.gen)
RUBY.jdbc_connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:111)
RUBY.open_jdbc_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:163)
RUBY.execute_statement(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:219)
RUBY.execute_query(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/inputs/jdbc.rb:264)
RUBY.run(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/inputs/jdbc.rb:250)
RUBY.inputworker(/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:516)
RUBY.block in start_input(/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:509)
org.jruby.RubyProc.call(org/jruby/RubyProc.java:289)
org.jruby.RubyProc.call(org/jruby/RubyProc.java:246)
java.lang.Thread.run(java/lang/Thread.java:748)
[2018-05-30T10:39:50,770][ERROR][logstash.inputs.jdbc     ] Unable to connect to database. Tried 1 times {:error_message=>"Java::JavaSql::SQLRecoverableException: IO Error: The Network Adapter could not establish the connection"}
[2018-05-30T10:39:50,773][ERROR][logstash.pipeline        ] A plugin had an unrecoverable error. Will restart this plugin.
  Pipeline_id:main
  Plugin: <LogStash::Inputs::Jdbc jdbc_driver_library=>"/etc/logstash/ojdbc6.jar", jdbc_driver_class=>"Java::oracle.jdbc.driver.OracleDriver", jdbc_connection_string=>"jdbc:oracle:thin:@100.100.100.225:1521:tenuri", jdbc_user=>"es_app", jdbc_password=><password>, jdbc_fetch_size=>10000, statement_filepath=>"as-is_search-log.sql", id=>"5bd7533661d97dbb4a1d2a6189513af0c10219fd73809280818346be344afa9b", enable_metric=>true, codec=><LogStash::Codecs::Plain id=>"plain_1a6af198-39fa-4265-9c68-c91258b113dc", enable_metric=>true, charset=>"UTF-8">, jdbc_paging_enabled=>false, jdbc_page_size=>100000, jdbc_validate_connection=>false, jdbc_validation_timeout=>3600, jdbc_pool_timeout=>5, sql_log_level=>"info", connection_retry_attempts=>1, connection_retry_attempts_wait_time=>0.5, parameters=>{"sql_last_value"=>2018-05-30 09:22:02 +0900}, last_run_metadata_path=>"/home/elastic/.logstash_jdbc_last_run", use_column_value=>false, tracking_column_type=>"numeric", clean_run=>false, record_last_run=>true, lowercase_column_names=>true>
  Error: Java::JavaSql::SQLRecoverableException: IO Error: The Network Adapter could not establish the connection
  Exception: Sequel::DatabaseConnectionError
  Stack: oracle.jdbc.driver.T4CConnection.logon(oracle/jdbc/driver/T4CConnection.java:489)
oracle.jdbc.driver.PhysicalConnection.<init>(oracle/jdbc/driver/PhysicalConnection.java:553)
oracle.jdbc.driver.T4CConnection.<init>(oracle/jdbc/driver/T4CConnection.java:254)
oracle.jdbc.driver.T4CDriverExtension.getConnection(oracle/jdbc/driver/T4CDriverExtension.java:32)
oracle.jdbc.driver.OracleDriver.connect(oracle/jdbc/driver/OracleDriver.java:528)
java.lang.reflect.Method.invoke(java/lang/reflect/Method.java:498)
org.jruby.javasupport.JavaMethod.invokeDirectWithExceptionHandling(org/jruby/javasupport/JavaMethod.java:468)
org.jruby.javasupport.JavaMethod.invokeDirect(org/jruby/javasupport/JavaMethod.java:326)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/adapters/jdbc.rb:203)
RUBY.make_new(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool.rb:126)
RUBY.assign_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:192)
RUBY.acquire(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:133)
RUBY.hold(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:90)
RUBY.synchronize(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:269)
RUBY.test_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:279)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:58)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/core.rb:116)
RUBY.block in jdbc_connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:114)
org.jruby.RubyKernel.loop(org/jruby/RubyKernel.java:1292)
org.jruby.RubyKernel$INVOKER$s$0$0$loop.call(org/jruby/RubyKernel$INVOKER$s$0$0$loop.gen)
RUBY.jdbc_connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:111)
RUBY.open_jdbc_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:163)
RUBY.execute_statement(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:219)
RUBY.execute_query(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/inputs/jdbc.rb:264)
RUBY.run(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/inputs/jdbc.rb:250)
RUBY.inputworker(/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:516)
RUBY.block in start_input(/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:509)
org.jruby.RubyProc.call(org/jruby/RubyProc.java:289)
org.jruby.RubyProc.call(org/jruby/RubyProc.java:246)
java.lang.Thread.run(java/lang/Thread.java:748)
[2018-05-30T10:39:53,777][ERROR][logstash.inputs.jdbc     ] Unable to connect to database. Tried 1 times {:error_message=>"Java::JavaSql::SQLRecoverableException: IO Error: The Network Adapter could not establish the connection"}
[2018-05-30T10:39:53,780][ERROR][logstash.pipeline        ] A plugin had an unrecoverable error. Will restart this plugin.
  Pipeline_id:main
  Plugin: <LogStash::Inputs::Jdbc jdbc_driver_library=>"/etc/logstash/ojdbc6.jar", jdbc_driver_class=>"Java::oracle.jdbc.driver.OracleDriver", jdbc_connection_string=>"jdbc:oracle:thin:@100.100.100.225:1521:tenuri", jdbc_user=>"es_app", jdbc_password=><password>, jdbc_fetch_size=>10000, statement_filepath=>"as-is_search-log.sql", id=>"5bd7533661d97dbb4a1d2a6189513af0c10219fd73809280818346be344afa9b", enable_metric=>true, codec=><LogStash::Codecs::Plain id=>"plain_1a6af198-39fa-4265-9c68-c91258b113dc", enable_metric=>true, charset=>"UTF-8">, jdbc_paging_enabled=>false, jdbc_page_size=>100000, jdbc_validate_connection=>false, jdbc_validation_timeout=>3600, jdbc_pool_timeout=>5, sql_log_level=>"info", connection_retry_attempts=>1, connection_retry_attempts_wait_time=>0.5, parameters=>{"sql_last_value"=>2018-05-30 09:22:02 +0900}, last_run_metadata_path=>"/home/elastic/.logstash_jdbc_last_run", use_column_value=>false, tracking_column_type=>"numeric", clean_run=>false, record_last_run=>true, lowercase_column_names=>true>
  Error: Java::JavaSql::SQLRecoverableException: IO Error: The Network Adapter could not establish the connection
  Exception: Sequel::DatabaseConnectionError
  Stack: oracle.jdbc.driver.T4CConnection.logon(oracle/jdbc/driver/T4CConnection.java:489)
oracle.jdbc.driver.PhysicalConnection.<init>(oracle/jdbc/driver/PhysicalConnection.java:553)
oracle.jdbc.driver.T4CConnection.<init>(oracle/jdbc/driver/T4CConnection.java:254)
oracle.jdbc.driver.T4CDriverExtension.getConnection(oracle/jdbc/driver/T4CDriverExtension.java:32)
oracle.jdbc.driver.OracleDriver.connect(oracle/jdbc/driver/OracleDriver.java:528)
java.lang.reflect.Method.invoke(java/lang/reflect/Method.java:498)
org.jruby.javasupport.JavaMethod.invokeDirectWithExceptionHandling(org/jruby/javasupport/JavaMethod.java:468)
org.jruby.javasupport.JavaMethod.invokeDirect(org/jruby/javasupport/JavaMethod.java:326)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/adapters/jdbc.rb:203)
RUBY.make_new(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool.rb:126)
RUBY.assign_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:192)
RUBY.acquire(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:133)
RUBY.hold(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:90)
RUBY.synchronize(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:269)
RUBY.test_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:279)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:58)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/core.rb:116)
RUBY.block in jdbc_connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:114)
org.jruby.RubyKernel.loop(org/jruby/RubyKernel.java:1292)
org.jruby.RubyKernel$INVOKER$s$0$0$loop.call(org/jruby/RubyKernel$INVOKER$s$0$0$loop.gen)
RUBY.jdbc_connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:111)
RUBY.open_jdbc_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:163)
RUBY.execute_statement(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:219)
RUBY.execute_query(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/inputs/jdbc.rb:264)
RUBY.run(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/inputs/jdbc.rb:250)
RUBY.inputworker(/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:516)
RUBY.block in start_input(/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:509)
org.jruby.RubyProc.call(org/jruby/RubyProc.java:289)
org.jruby.RubyProc.call(org/jruby/RubyProc.java:246)
java.lang.Thread.run(java/lang/Thread.java:748)
[2018-05-30T10:39:56,782][ERROR][logstash.inputs.jdbc     ] Unable to connect to database. Tried 1 times {:error_message=>"Java::JavaSql::SQLRecoverableException: IO Error: The Network Adapter could not establish the connection"}
[2018-05-30T10:39:56,784][ERROR][logstash.pipeline        ] A plugin had an unrecoverable error. Will restart this plugin.
  Pipeline_id:main
  Plugin: <LogStash::Inputs::Jdbc jdbc_driver_library=>"/etc/logstash/ojdbc6.jar", jdbc_driver_class=>"Java::oracle.jdbc.driver.OracleDriver", jdbc_connection_string=>"jdbc:oracle:thin:@100.100.100.225:1521:tenuri", jdbc_user=>"es_app", jdbc_password=><password>, jdbc_fetch_size=>10000, statement_filepath=>"as-is_search-log.sql", id=>"5bd7533661d97dbb4a1d2a6189513af0c10219fd73809280818346be344afa9b", enable_metric=>true, codec=><LogStash::Codecs::Plain id=>"plain_1a6af198-39fa-4265-9c68-c91258b113dc", enable_metric=>true, charset=>"UTF-8">, jdbc_paging_enabled=>false, jdbc_page_size=>100000, jdbc_validate_connection=>false, jdbc_validation_timeout=>3600, jdbc_pool_timeout=>5, sql_log_level=>"info", connection_retry_attempts=>1, connection_retry_attempts_wait_time=>0.5, parameters=>{"sql_last_value"=>2018-05-30 09:22:02 +0900}, last_run_metadata_path=>"/home/elastic/.logstash_jdbc_last_run", use_column_value=>false, tracking_column_type=>"numeric", clean_run=>false, record_last_run=>true, lowercase_column_names=>true>
  Error: Java::JavaSql::SQLRecoverableException: IO Error: The Network Adapter could not establish the connection
  Exception: Sequel::DatabaseConnectionError
  Stack: oracle.jdbc.driver.T4CConnection.logon(oracle/jdbc/driver/T4CConnection.java:489)
oracle.jdbc.driver.PhysicalConnection.<init>(oracle/jdbc/driver/PhysicalConnection.java:553)
oracle.jdbc.driver.T4CConnection.<init>(oracle/jdbc/driver/T4CConnection.java:254)
oracle.jdbc.driver.T4CDriverExtension.getConnection(oracle/jdbc/driver/T4CDriverExtension.java:32)
oracle.jdbc.driver.OracleDriver.connect(oracle/jdbc/driver/OracleDriver.java:528)
java.lang.reflect.Method.invoke(java/lang/reflect/Method.java:498)
org.jruby.javasupport.JavaMethod.invokeDirectWithExceptionHandling(org/jruby/javasupport/JavaMethod.java:468)
org.jruby.javasupport.JavaMethod.invokeDirect(org/jruby/javasupport/JavaMethod.java:326)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/adapters/jdbc.rb:203)
RUBY.make_new(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool.rb:126)
RUBY.assign_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:192)
RUBY.acquire(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:133)
RUBY.hold(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:90)
RUBY.synchronize(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:269)
RUBY.test_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:279)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:58)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/core.rb:116)
RUBY.block in jdbc_connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:114)
org.jruby.RubyKernel.loop(org/jruby/RubyKernel.java:1292)
org.jruby.RubyKernel$INVOKER$s$0$0$loop.call(org/jruby/RubyKernel$INVOKER$s$0$0$loop.gen)
RUBY.jdbc_connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:111)
RUBY.open_jdbc_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:163)
RUBY.execute_statement(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:219)
RUBY.execute_query(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/inputs/jdbc.rb:264)
RUBY.run(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/inputs/jdbc.rb:250)
RUBY.inputworker(/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:516)
RUBY.block in start_input(/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:509)
org.jruby.RubyProc.call(org/jruby/RubyProc.java:289)
org.jruby.RubyProc.call(org/jruby/RubyProc.java:246)
java.lang.Thread.run(java/lang/Thread.java:748)
[2018-05-30T10:39:59,789][ERROR][logstash.inputs.jdbc     ] Unable to connect to database. Tried 1 times {:error_message=>"Java::JavaSql::SQLRecoverableException: IO Error: The Network Adapter could not establish the connection"}
[2018-05-30T10:39:59,841][ERROR][logstash.pipeline        ] A plugin had an unrecoverable error. Will restart this plugin.
  Pipeline_id:main
  Plugin: <LogStash::Inputs::Jdbc jdbc_driver_library=>"/etc/logstash/ojdbc6.jar", jdbc_driver_class=>"Java::oracle.jdbc.driver.OracleDriver", jdbc_connection_string=>"jdbc:oracle:thin:@100.100.100.225:1521:tenuri", jdbc_user=>"es_app", jdbc_password=><password>, jdbc_fetch_size=>10000, statement_filepath=>"as-is_search-log.sql", id=>"5bd7533661d97dbb4a1d2a6189513af0c10219fd73809280818346be344afa9b", enable_metric=>true, codec=><LogStash::Codecs::Plain id=>"plain_1a6af198-39fa-4265-9c68-c91258b113dc", enable_metric=>true, charset=>"UTF-8">, jdbc_paging_enabled=>false, jdbc_page_size=>100000, jdbc_validate_connection=>false, jdbc_validation_timeout=>3600, jdbc_pool_timeout=>5, sql_log_level=>"info", connection_retry_attempts=>1, connection_retry_attempts_wait_time=>0.5, parameters=>{"sql_last_value"=>2018-05-30 09:22:02 +0900}, last_run_metadata_path=>"/home/elastic/.logstash_jdbc_last_run", use_column_value=>false, tracking_column_type=>"numeric", clean_run=>false, record_last_run=>true, lowercase_column_names=>true>
  Error: Java::JavaSql::SQLRecoverableException: IO Error: The Network Adapter could not establish the connection
  Exception: Sequel::DatabaseConnectionError
  Stack: oracle.jdbc.driver.T4CConnection.logon(oracle/jdbc/driver/T4CConnection.java:489)
oracle.jdbc.driver.PhysicalConnection.<init>(oracle/jdbc/driver/PhysicalConnection.java:553)
oracle.jdbc.driver.T4CConnection.<init>(oracle/jdbc/driver/T4CConnection.java:254)
oracle.jdbc.driver.T4CDriverExtension.getConnection(oracle/jdbc/driver/T4CDriverExtension.java:32)
oracle.jdbc.driver.OracleDriver.connect(oracle/jdbc/driver/OracleDriver.java:528)
java.lang.reflect.Method.invoke(java/lang/reflect/Method.java:498)
org.jruby.javasupport.JavaMethod.invokeDirectWithExceptionHandling(org/jruby/javasupport/JavaMethod.java:468)
org.jruby.javasupport.JavaMethod.invokeDirect(org/jruby/javasupport/JavaMethod.java:326)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/adapters/jdbc.rb:203)
RUBY.make_new(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool.rb:126)
RUBY.assign_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:192)
RUBY.acquire(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:133)
RUBY.hold(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:90)
RUBY.synchronize(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:269)
RUBY.test_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:279)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:58)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/core.rb:116)
RUBY.block in jdbc_connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:114)
org.jruby.RubyKernel.loop(org/jruby/RubyKernel.java:1292)
org.jruby.RubyKernel$INVOKER$s$0$0$loop.call(org/jruby/RubyKernel$INVOKER$s$0$0$loop.gen)
RUBY.jdbc_connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:111)
RUBY.open_jdbc_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:163)
RUBY.execute_statement(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:219)
RUBY.execute_query(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/inputs/jdbc.rb:264)
RUBY.run(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/inputs/jdbc.rb:250)
RUBY.inputworker(/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:516)
RUBY.block in start_input(/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:509)
org.jruby.RubyProc.call(org/jruby/RubyProc.java:289)
org.jruby.RubyProc.call(org/jruby/RubyProc.java:246)
java.lang.Thread.run(java/lang/Thread.java:748)
[2018-05-30T10:40:02,796][ERROR][logstash.inputs.jdbc     ] Unable to connect to database. Tried 1 times {:error_message=>"Java::JavaSql::SQLRecoverableException: IO Error: The Network Adapter could not establish the connection"}
[2018-05-30T10:40:02,801][ERROR][logstash.pipeline        ] A plugin had an unrecoverable error. Will restart this plugin.
  Pipeline_id:main
  Plugin: <LogStash::Inputs::Jdbc jdbc_driver_library=>"/etc/logstash/ojdbc6.jar", jdbc_driver_class=>"Java::oracle.jdbc.driver.OracleDriver", jdbc_connection_string=>"jdbc:oracle:thin:@100.100.100.225:1521:tenuri", jdbc_user=>"es_app", jdbc_password=><password>, jdbc_fetch_size=>10000, statement_filepath=>"as-is_search-log.sql", id=>"5bd7533661d97dbb4a1d2a6189513af0c10219fd73809280818346be344afa9b", enable_metric=>true, codec=><LogStash::Codecs::Plain id=>"plain_1a6af198-39fa-4265-9c68-c91258b113dc", enable_metric=>true, charset=>"UTF-8">, jdbc_paging_enabled=>false, jdbc_page_size=>100000, jdbc_validate_connection=>false, jdbc_validation_timeout=>3600, jdbc_pool_timeout=>5, sql_log_level=>"info", connection_retry_attempts=>1, connection_retry_attempts_wait_time=>0.5, parameters=>{"sql_last_value"=>2018-05-30 09:22:02 +0900}, last_run_metadata_path=>"/home/elastic/.logstash_jdbc_last_run", use_column_value=>false, tracking_column_type=>"numeric", clean_run=>false, record_last_run=>true, lowercase_column_names=>true>
  Error: Java::JavaSql::SQLRecoverableException: IO Error: The Network Adapter could not establish the connection
  Exception: Sequel::DatabaseConnectionError
  Stack: oracle.jdbc.driver.T4CConnection.logon(oracle/jdbc/driver/T4CConnection.java:489)
oracle.jdbc.driver.PhysicalConnection.<init>(oracle/jdbc/driver/PhysicalConnection.java:553)
oracle.jdbc.driver.T4CConnection.<init>(oracle/jdbc/driver/T4CConnection.java:254)
oracle.jdbc.driver.T4CDriverExtension.getConnection(oracle/jdbc/driver/T4CDriverExtension.java:32)
oracle.jdbc.driver.OracleDriver.connect(oracle/jdbc/driver/OracleDriver.java:528)
java.lang.reflect.Method.invoke(java/lang/reflect/Method.java:498)
org.jruby.javasupport.JavaMethod.invokeDirectWithExceptionHandling(org/jruby/javasupport/JavaMethod.java:468)
org.jruby.javasupport.JavaMethod.invokeDirect(org/jruby/javasupport/JavaMethod.java:326)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/adapters/jdbc.rb:203)
RUBY.make_new(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool.rb:126)
RUBY.assign_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:192)
RUBY.acquire(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:133)
RUBY.hold(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:90)
RUBY.synchronize(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:269)
RUBY.test_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:279)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:58)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/core.rb:116)
RUBY.block in jdbc_connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:114)
org.jruby.RubyKernel.loop(org/jruby/RubyKernel.java:1292)
org.jruby.RubyKernel$INVOKER$s$0$0$loop.call(org/jruby/RubyKernel$INVOKER$s$0$0$loop.gen)
RUBY.jdbc_connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:111)
RUBY.open_jdbc_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:163)
RUBY.execute_statement(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:219)
RUBY.execute_query(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/inputs/jdbc.rb:264)
RUBY.run(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/inputs/jdbc.rb:250)
RUBY.inputworker(/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:516)
RUBY.block in start_input(/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:509)
org.jruby.RubyProc.call(org/jruby/RubyProc.java:289)
org.jruby.RubyProc.call(org/jruby/RubyProc.java:246)
java.lang.Thread.run(java/lang/Thread.java:748)
[2018-05-30T10:40:05,800][ERROR][logstash.inputs.jdbc     ] Unable to connect to database. Tried 1 times {:error_message=>"Java::JavaSql::SQLRecoverableException: IO Error: The Network Adapter could not establish the connection"}
[2018-05-30T10:40:05,802][ERROR][logstash.pipeline        ] A plugin had an unrecoverable error. Will restart this plugin.
  Pipeline_id:main
  Plugin: <LogStash::Inputs::Jdbc jdbc_driver_library=>"/etc/logstash/ojdbc6.jar", jdbc_driver_class=>"Java::oracle.jdbc.driver.OracleDriver", jdbc_connection_string=>"jdbc:oracle:thin:@100.100.100.225:1521:tenuri", jdbc_user=>"es_app", jdbc_password=><password>, jdbc_fetch_size=>10000, statement_filepath=>"as-is_search-log.sql", id=>"5bd7533661d97dbb4a1d2a6189513af0c10219fd73809280818346be344afa9b", enable_metric=>true, codec=><LogStash::Codecs::Plain id=>"plain_1a6af198-39fa-4265-9c68-c91258b113dc", enable_metric=>true, charset=>"UTF-8">, jdbc_paging_enabled=>false, jdbc_page_size=>100000, jdbc_validate_connection=>false, jdbc_validation_timeout=>3600, jdbc_pool_timeout=>5, sql_log_level=>"info", connection_retry_attempts=>1, connection_retry_attempts_wait_time=>0.5, parameters=>{"sql_last_value"=>2018-05-30 09:22:02 +0900}, last_run_metadata_path=>"/home/elastic/.logstash_jdbc_last_run", use_column_value=>false, tracking_column_type=>"numeric", clean_run=>false, record_last_run=>true, lowercase_column_names=>true>
  Error: Java::JavaSql::SQLRecoverableException: IO Error: The Network Adapter could not establish the connection
  Exception: Sequel::DatabaseConnectionError
  Stack: oracle.jdbc.driver.T4CConnection.logon(oracle/jdbc/driver/T4CConnection.java:489)
oracle.jdbc.driver.PhysicalConnection.<init>(oracle/jdbc/driver/PhysicalConnection.java:553)
oracle.jdbc.driver.T4CConnection.<init>(oracle/jdbc/driver/T4CConnection.java:254)
oracle.jdbc.driver.T4CDriverExtension.getConnection(oracle/jdbc/driver/T4CDriverExtension.java:32)
oracle.jdbc.driver.OracleDriver.connect(oracle/jdbc/driver/OracleDriver.java:528)
java.lang.reflect.Method.invoke(java/lang/reflect/Method.java:498)
org.jruby.javasupport.JavaMethod.invokeDirectWithExceptionHandling(org/jruby/javasupport/JavaMethod.java:468)
org.jruby.javasupport.JavaMethod.invokeDirect(org/jruby/javasupport/JavaMethod.java:326)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/adapters/jdbc.rb:203)
RUBY.make_new(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool.rb:126)
RUBY.assign_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:192)
RUBY.acquire(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:133)
RUBY.hold(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:90)
RUBY.synchronize(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:269)
RUBY.test_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:279)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:58)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/core.rb:116)
RUBY.block in jdbc_connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:114)
org.jruby.RubyKernel.loop(org/jruby/RubyKernel.java:1292)
org.jruby.RubyKernel$INVOKER$s$0$0$loop.call(org/jruby/RubyKernel$INVOKER$s$0$0$loop.gen)
RUBY.jdbc_connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:111)
RUBY.open_jdbc_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:163)
RUBY.execute_statement(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:219)
RUBY.execute_query(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/inputs/jdbc.rb:264)
RUBY.run(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/inputs/jdbc.rb:250)
RUBY.inputworker(/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:516)
RUBY.block in start_input(/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:509)
org.jruby.RubyProc.call(org/jruby/RubyProc.java:289)
org.jruby.RubyProc.call(org/jruby/RubyProc.java:246)
java.lang.Thread.run(java/lang/Thread.java:748)
[2018-05-30T10:40:08,806][ERROR][logstash.inputs.jdbc     ] Unable to connect to database. Tried 1 times {:error_message=>"Java::JavaSql::SQLRecoverableException: IO Error: The Network Adapter could not establish the connection"}
[2018-05-30T10:40:08,808][ERROR][logstash.pipeline        ] A plugin had an unrecoverable error. Will restart this plugin.
  Pipeline_id:main
  Plugin: <LogStash::Inputs::Jdbc jdbc_driver_library=>"/etc/logstash/ojdbc6.jar", jdbc_driver_class=>"Java::oracle.jdbc.driver.OracleDriver", jdbc_connection_string=>"jdbc:oracle:thin:@100.100.100.225:1521:tenuri", jdbc_user=>"es_app", jdbc_password=><password>, jdbc_fetch_size=>10000, statement_filepath=>"as-is_search-log.sql", id=>"5bd7533661d97dbb4a1d2a6189513af0c10219fd73809280818346be344afa9b", enable_metric=>true, codec=><LogStash::Codecs::Plain id=>"plain_1a6af198-39fa-4265-9c68-c91258b113dc", enable_metric=>true, charset=>"UTF-8">, jdbc_paging_enabled=>false, jdbc_page_size=>100000, jdbc_validate_connection=>false, jdbc_validation_timeout=>3600, jdbc_pool_timeout=>5, sql_log_level=>"info", connection_retry_attempts=>1, connection_retry_attempts_wait_time=>0.5, parameters=>{"sql_last_value"=>2018-05-30 09:22:02 +0900}, last_run_metadata_path=>"/home/elastic/.logstash_jdbc_last_run", use_column_value=>false, tracking_column_type=>"numeric", clean_run=>false, record_last_run=>true, lowercase_column_names=>true>
  Error: Java::JavaSql::SQLRecoverableException: IO Error: The Network Adapter could not establish the connection
  Exception: Sequel::DatabaseConnectionError
  Stack: oracle.jdbc.driver.T4CConnection.logon(oracle/jdbc/driver/T4CConnection.java:489)
oracle.jdbc.driver.PhysicalConnection.<init>(oracle/jdbc/driver/PhysicalConnection.java:553)
oracle.jdbc.driver.T4CConnection.<init>(oracle/jdbc/driver/T4CConnection.java:254)
oracle.jdbc.driver.T4CDriverExtension.getConnection(oracle/jdbc/driver/T4CDriverExtension.java:32)
oracle.jdbc.driver.OracleDriver.connect(oracle/jdbc/driver/OracleDriver.java:528)
java.lang.reflect.Method.invoke(java/lang/reflect/Method.java:498)
org.jruby.javasupport.JavaMethod.invokeDirectWithExceptionHandling(org/jruby/javasupport/JavaMethod.java:468)
org.jruby.javasupport.JavaMethod.invokeDirect(org/jruby/javasupport/JavaMethod.java:326)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/adapters/jdbc.rb:203)
RUBY.make_new(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool.rb:126)
RUBY.assign_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:192)
RUBY.acquire(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:133)
RUBY.hold(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:90)
RUBY.synchronize(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:269)
RUBY.test_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:279)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:58)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/core.rb:116)
RUBY.block in jdbc_connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:114)
org.jruby.RubyKernel.loop(org/jruby/RubyKernel.java:1292)
org.jruby.RubyKernel$INVOKER$s$0$0$loop.call(org/jruby/RubyKernel$INVOKER$s$0$0$loop.gen)
RUBY.jdbc_connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:111)
RUBY.open_jdbc_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:163)
RUBY.execute_statement(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:219)
RUBY.execute_query(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/inputs/jdbc.rb:264)
RUBY.run(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/inputs/jdbc.rb:250)
RUBY.inputworker(/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:516)
RUBY.block in start_input(/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:509)
org.jruby.RubyProc.call(org/jruby/RubyProc.java:289)
org.jruby.RubyProc.call(org/jruby/RubyProc.java:246)
java.lang.Thread.run(java/lang/Thread.java:748)
[2018-05-30T10:40:11,814][ERROR][logstash.inputs.jdbc     ] Unable to connect to database. Tried 1 times {:error_message=>"Java::JavaSql::SQLRecoverableException: IO Error: The Network Adapter could not establish the connection"}
[2018-05-30T10:40:11,830][ERROR][logstash.pipeline        ] A plugin had an unrecoverable error. Will restart this plugin.
  Pipeline_id:main
  Plugin: <LogStash::Inputs::Jdbc jdbc_driver_library=>"/etc/logstash/ojdbc6.jar", jdbc_driver_class=>"Java::oracle.jdbc.driver.OracleDriver", jdbc_connection_string=>"jdbc:oracle:thin:@100.100.100.225:1521:tenuri", jdbc_user=>"es_app", jdbc_password=><password>, jdbc_fetch_size=>10000, statement_filepath=>"as-is_search-log.sql", id=>"5bd7533661d97dbb4a1d2a6189513af0c10219fd73809280818346be344afa9b", enable_metric=>true, codec=><LogStash::Codecs::Plain id=>"plain_1a6af198-39fa-4265-9c68-c91258b113dc", enable_metric=>true, charset=>"UTF-8">, jdbc_paging_enabled=>false, jdbc_page_size=>100000, jdbc_validate_connection=>false, jdbc_validation_timeout=>3600, jdbc_pool_timeout=>5, sql_log_level=>"info", connection_retry_attempts=>1, connection_retry_attempts_wait_time=>0.5, parameters=>{"sql_last_value"=>2018-05-30 09:22:02 +0900}, last_run_metadata_path=>"/home/elastic/.logstash_jdbc_last_run", use_column_value=>false, tracking_column_type=>"numeric", clean_run=>false, record_last_run=>true, lowercase_column_names=>true>
  Error: Java::JavaSql::SQLRecoverableException: IO Error: The Network Adapter could not establish the connection
  Exception: Sequel::DatabaseConnectionError
  Stack: oracle.jdbc.driver.T4CConnection.logon(oracle/jdbc/driver/T4CConnection.java:489)
oracle.jdbc.driver.PhysicalConnection.<init>(oracle/jdbc/driver/PhysicalConnection.java:553)
oracle.jdbc.driver.T4CConnection.<init>(oracle/jdbc/driver/T4CConnection.java:254)
oracle.jdbc.driver.T4CDriverExtension.getConnection(oracle/jdbc/driver/T4CDriverExtension.java:32)
oracle.jdbc.driver.OracleDriver.connect(oracle/jdbc/driver/OracleDriver.java:528)
java.lang.reflect.Method.invoke(java/lang/reflect/Method.java:498)
org.jruby.javasupport.JavaMethod.invokeDirectWithExceptionHandling(org/jruby/javasupport/JavaMethod.java:468)
org.jruby.javasupport.JavaMethod.invokeDirect(org/jruby/javasupport/JavaMethod.java:326)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/adapters/jdbc.rb:203)
RUBY.make_new(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool.rb:126)
RUBY.assign_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:192)
RUBY.acquire(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:133)
RUBY.hold(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:90)
RUBY.synchronize(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:269)
RUBY.test_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:279)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:58)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/core.rb:116)
RUBY.block in jdbc_connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:114)
org.jruby.RubyKernel.loop(org/jruby/RubyKernel.java:1292)
org.jruby.RubyKernel$INVOKER$s$0$0$loop.call(org/jruby/RubyKernel$INVOKER$s$0$0$loop.gen)
RUBY.jdbc_connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:111)
RUBY.open_jdbc_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:163)
RUBY.execute_statement(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:219)
RUBY.execute_query(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/inputs/jdbc.rb:264)
RUBY.run(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/inputs/jdbc.rb:250)
RUBY.inputworker(/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:516)
RUBY.block in start_input(/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:509)
org.jruby.RubyProc.call(org/jruby/RubyProc.java:289)
org.jruby.RubyProc.call(org/jruby/RubyProc.java:246)
java.lang.Thread.run(java/lang/Thread.java:748)
[2018-05-30T10:40:14,818][ERROR][logstash.inputs.jdbc     ] Unable to connect to database. Tried 1 times {:error_message=>"Java::JavaSql::SQLRecoverableException: IO Error: The Network Adapter could not establish the connection"}
[2018-05-30T10:40:14,820][ERROR][logstash.pipeline        ] A plugin had an unrecoverable error. Will restart this plugin.
  Pipeline_id:main
  Plugin: <LogStash::Inputs::Jdbc jdbc_driver_library=>"/etc/logstash/ojdbc6.jar", jdbc_driver_class=>"Java::oracle.jdbc.driver.OracleDriver", jdbc_connection_string=>"jdbc:oracle:thin:@100.100.100.225:1521:tenuri", jdbc_user=>"es_app", jdbc_password=><password>, jdbc_fetch_size=>10000, statement_filepath=>"as-is_search-log.sql", id=>"5bd7533661d97dbb4a1d2a6189513af0c10219fd73809280818346be344afa9b", enable_metric=>true, codec=><LogStash::Codecs::Plain id=>"plain_1a6af198-39fa-4265-9c68-c91258b113dc", enable_metric=>true, charset=>"UTF-8">, jdbc_paging_enabled=>false, jdbc_page_size=>100000, jdbc_validate_connection=>false, jdbc_validation_timeout=>3600, jdbc_pool_timeout=>5, sql_log_level=>"info", connection_retry_attempts=>1, connection_retry_attempts_wait_time=>0.5, parameters=>{"sql_last_value"=>2018-05-30 09:22:02 +0900}, last_run_metadata_path=>"/home/elastic/.logstash_jdbc_last_run", use_column_value=>false, tracking_column_type=>"numeric", clean_run=>false, record_last_run=>true, lowercase_column_names=>true>
  Error: Java::JavaSql::SQLRecoverableException: IO Error: The Network Adapter could not establish the connection
  Exception: Sequel::DatabaseConnectionError
  Stack: oracle.jdbc.driver.T4CConnection.logon(oracle/jdbc/driver/T4CConnection.java:489)
oracle.jdbc.driver.PhysicalConnection.<init>(oracle/jdbc/driver/PhysicalConnection.java:553)
oracle.jdbc.driver.T4CConnection.<init>(oracle/jdbc/driver/T4CConnection.java:254)
oracle.jdbc.driver.T4CDriverExtension.getConnection(oracle/jdbc/driver/T4CDriverExtension.java:32)
oracle.jdbc.driver.OracleDriver.connect(oracle/jdbc/driver/OracleDriver.java:528)
java.lang.reflect.Method.invoke(java/lang/reflect/Method.java:498)
org.jruby.javasupport.JavaMethod.invokeDirectWithExceptionHandling(org/jruby/javasupport/JavaMethod.java:468)
org.jruby.javasupport.JavaMethod.invokeDirect(org/jruby/javasupport/JavaMethod.java:326)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/adapters/jdbc.rb:203)
RUBY.make_new(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool.rb:126)
RUBY.assign_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:192)
RUBY.acquire(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:133)
RUBY.hold(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:90)
RUBY.synchronize(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:269)
RUBY.test_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:279)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:58)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/core.rb:116)
RUBY.block in jdbc_connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:114)
org.jruby.RubyKernel.loop(org/jruby/RubyKernel.java:1292)
org.jruby.RubyKernel$INVOKER$s$0$0$loop.call(org/jruby/RubyKernel$INVOKER$s$0$0$loop.gen)
RUBY.jdbc_connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:111)
RUBY.open_jdbc_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:163)
RUBY.execute_statement(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:219)
RUBY.execute_query(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/inputs/jdbc.rb:264)
RUBY.run(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/inputs/jdbc.rb:250)
RUBY.inputworker(/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:516)
RUBY.block in start_input(/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:509)
org.jruby.RubyProc.call(org/jruby/RubyProc.java:289)
org.jruby.RubyProc.call(org/jruby/RubyProc.java:246)
java.lang.Thread.run(java/lang/Thread.java:748)
[2018-05-30T10:40:17,825][ERROR][logstash.inputs.jdbc     ] Unable to connect to database. Tried 1 times {:error_message=>"Java::JavaSql::SQLRecoverableException: IO Error: The Network Adapter could not establish the connection"}
[2018-05-30T10:40:17,826][ERROR][logstash.pipeline        ] A plugin had an unrecoverable error. Will restart this plugin.
  Pipeline_id:main
  Plugin: <LogStash::Inputs::Jdbc jdbc_driver_library=>"/etc/logstash/ojdbc6.jar", jdbc_driver_class=>"Java::oracle.jdbc.driver.OracleDriver", jdbc_connection_string=>"jdbc:oracle:thin:@100.100.100.225:1521:tenuri", jdbc_user=>"es_app", jdbc_password=><password>, jdbc_fetch_size=>10000, statement_filepath=>"as-is_search-log.sql", id=>"5bd7533661d97dbb4a1d2a6189513af0c10219fd73809280818346be344afa9b", enable_metric=>true, codec=><LogStash::Codecs::Plain id=>"plain_1a6af198-39fa-4265-9c68-c91258b113dc", enable_metric=>true, charset=>"UTF-8">, jdbc_paging_enabled=>false, jdbc_page_size=>100000, jdbc_validate_connection=>false, jdbc_validation_timeout=>3600, jdbc_pool_timeout=>5, sql_log_level=>"info", connection_retry_attempts=>1, connection_retry_attempts_wait_time=>0.5, parameters=>{"sql_last_value"=>2018-05-30 09:22:02 +0900}, last_run_metadata_path=>"/home/elastic/.logstash_jdbc_last_run", use_column_value=>false, tracking_column_type=>"numeric", clean_run=>false, record_last_run=>true, lowercase_column_names=>true>
  Error: Java::JavaSql::SQLRecoverableException: IO Error: The Network Adapter could not establish the connection
  Exception: Sequel::DatabaseConnectionError
  Stack: oracle.jdbc.driver.T4CConnection.logon(oracle/jdbc/driver/T4CConnection.java:489)
oracle.jdbc.driver.PhysicalConnection.<init>(oracle/jdbc/driver/PhysicalConnection.java:553)
oracle.jdbc.driver.T4CConnection.<init>(oracle/jdbc/driver/T4CConnection.java:254)
oracle.jdbc.driver.T4CDriverExtension.getConnection(oracle/jdbc/driver/T4CDriverExtension.java:32)
oracle.jdbc.driver.OracleDriver.connect(oracle/jdbc/driver/OracleDriver.java:528)
java.lang.reflect.Method.invoke(java/lang/reflect/Method.java:498)
org.jruby.javasupport.JavaMethod.invokeDirectWithExceptionHandling(org/jruby/javasupport/JavaMethod.java:468)
org.jruby.javasupport.JavaMethod.invokeDirect(org/jruby/javasupport/JavaMethod.java:326)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/adapters/jdbc.rb:203)
RUBY.make_new(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool.rb:126)
RUBY.assign_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:192)
RUBY.acquire(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:133)
RUBY.hold(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:90)
RUBY.synchronize(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:269)
RUBY.test_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:279)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:58)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/core.rb:116)
RUBY.block in jdbc_connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:114)
org.jruby.RubyKernel.loop(org/jruby/RubyKernel.java:1292)
org.jruby.RubyKernel$INVOKER$s$0$0$loop.call(org/jruby/RubyKernel$INVOKER$s$0$0$loop.gen)
RUBY.jdbc_connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:111)
RUBY.open_jdbc_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:163)
RUBY.execute_statement(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:219)
RUBY.execute_query(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/inputs/jdbc.rb:264)
RUBY.run(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/inputs/jdbc.rb:250)
RUBY.inputworker(/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:516)
RUBY.block in start_input(/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:509)
org.jruby.RubyProc.call(org/jruby/RubyProc.java:289)
org.jruby.RubyProc.call(org/jruby/RubyProc.java:246)
java.lang.Thread.run(java/lang/Thread.java:748)
[2018-05-30T10:40:20,830][ERROR][logstash.inputs.jdbc     ] Unable to connect to database. Tried 1 times {:error_message=>"Java::JavaSql::SQLRecoverableException: IO Error: The Network Adapter could not establish the connection"}
[2018-05-30T10:40:20,832][ERROR][logstash.pipeline        ] A plugin had an unrecoverable error. Will restart this plugin.
  Pipeline_id:main
  Plugin: <LogStash::Inputs::Jdbc jdbc_driver_library=>"/etc/logstash/ojdbc6.jar", jdbc_driver_class=>"Java::oracle.jdbc.driver.OracleDriver", jdbc_connection_string=>"jdbc:oracle:thin:@100.100.100.225:1521:tenuri", jdbc_user=>"es_app", jdbc_password=><password>, jdbc_fetch_size=>10000, statement_filepath=>"as-is_search-log.sql", id=>"5bd7533661d97dbb4a1d2a6189513af0c10219fd73809280818346be344afa9b", enable_metric=>true, codec=><LogStash::Codecs::Plain id=>"plain_1a6af198-39fa-4265-9c68-c91258b113dc", enable_metric=>true, charset=>"UTF-8">, jdbc_paging_enabled=>false, jdbc_page_size=>100000, jdbc_validate_connection=>false, jdbc_validation_timeout=>3600, jdbc_pool_timeout=>5, sql_log_level=>"info", connection_retry_attempts=>1, connection_retry_attempts_wait_time=>0.5, parameters=>{"sql_last_value"=>2018-05-30 09:22:02 +0900}, last_run_metadata_path=>"/home/elastic/.logstash_jdbc_last_run", use_column_value=>false, tracking_column_type=>"numeric", clean_run=>false, record_last_run=>true, lowercase_column_names=>true>
  Error: Java::JavaSql::SQLRecoverableException: IO Error: The Network Adapter could not establish the connection
  Exception: Sequel::DatabaseConnectionError
  Stack: oracle.jdbc.driver.T4CConnection.logon(oracle/jdbc/driver/T4CConnection.java:489)
oracle.jdbc.driver.PhysicalConnection.<init>(oracle/jdbc/driver/PhysicalConnection.java:553)
oracle.jdbc.driver.T4CConnection.<init>(oracle/jdbc/driver/T4CConnection.java:254)
oracle.jdbc.driver.T4CDriverExtension.getConnection(oracle/jdbc/driver/T4CDriverExtension.java:32)
oracle.jdbc.driver.OracleDriver.connect(oracle/jdbc/driver/OracleDriver.java:528)
java.lang.reflect.Method.invoke(java/lang/reflect/Method.java:498)
org.jruby.javasupport.JavaMethod.invokeDirectWithExceptionHandling(org/jruby/javasupport/JavaMethod.java:468)
org.jruby.javasupport.JavaMethod.invokeDirect(org/jruby/javasupport/JavaMethod.java:326)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/adapters/jdbc.rb:203)
RUBY.make_new(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool.rb:126)
RUBY.assign_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:192)
RUBY.acquire(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:133)
RUBY.hold(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:90)
RUBY.synchronize(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:269)
RUBY.test_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:279)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:58)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/core.rb:116)
RUBY.block in jdbc_connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:114)
org.jruby.RubyKernel.loop(org/jruby/RubyKernel.java:1292)
org.jruby.RubyKernel$INVOKER$s$0$0$loop.call(org/jruby/RubyKernel$INVOKER$s$0$0$loop.gen)
RUBY.jdbc_connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:111)
RUBY.open_jdbc_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:163)
RUBY.execute_statement(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:219)
RUBY.execute_query(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/inputs/jdbc.rb:264)
RUBY.run(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/inputs/jdbc.rb:250)
RUBY.inputworker(/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:516)
RUBY.block in start_input(/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:509)
org.jruby.RubyProc.call(org/jruby/RubyProc.java:289)
org.jruby.RubyProc.call(org/jruby/RubyProc.java:246)
java.lang.Thread.run(java/lang/Thread.java:748)
[2018-05-30T10:40:23,838][ERROR][logstash.inputs.jdbc     ] Unable to connect to database. Tried 1 times {:error_message=>"Java::JavaSql::SQLRecoverableException: IO Error: The Network Adapter could not establish the connection"}
[2018-05-30T10:40:23,841][ERROR][logstash.pipeline        ] A plugin had an unrecoverable error. Will restart this plugin.
  Pipeline_id:main
  Plugin: <LogStash::Inputs::Jdbc jdbc_driver_library=>"/etc/logstash/ojdbc6.jar", jdbc_driver_class=>"Java::oracle.jdbc.driver.OracleDriver", jdbc_connection_string=>"jdbc:oracle:thin:@100.100.100.225:1521:tenuri", jdbc_user=>"es_app", jdbc_password=><password>, jdbc_fetch_size=>10000, statement_filepath=>"as-is_search-log.sql", id=>"5bd7533661d97dbb4a1d2a6189513af0c10219fd73809280818346be344afa9b", enable_metric=>true, codec=><LogStash::Codecs::Plain id=>"plain_1a6af198-39fa-4265-9c68-c91258b113dc", enable_metric=>true, charset=>"UTF-8">, jdbc_paging_enabled=>false, jdbc_page_size=>100000, jdbc_validate_connection=>false, jdbc_validation_timeout=>3600, jdbc_pool_timeout=>5, sql_log_level=>"info", connection_retry_attempts=>1, connection_retry_attempts_wait_time=>0.5, parameters=>{"sql_last_value"=>2018-05-30 09:22:02 +0900}, last_run_metadata_path=>"/home/elastic/.logstash_jdbc_last_run", use_column_value=>false, tracking_column_type=>"numeric", clean_run=>false, record_last_run=>true, lowercase_column_names=>true>
  Error: Java::JavaSql::SQLRecoverableException: IO Error: The Network Adapter could not establish the connection
  Exception: Sequel::DatabaseConnectionError
  Stack: oracle.jdbc.driver.T4CConnection.logon(oracle/jdbc/driver/T4CConnection.java:489)
oracle.jdbc.driver.PhysicalConnection.<init>(oracle/jdbc/driver/PhysicalConnection.java:553)
oracle.jdbc.driver.T4CConnection.<init>(oracle/jdbc/driver/T4CConnection.java:254)
oracle.jdbc.driver.T4CDriverExtension.getConnection(oracle/jdbc/driver/T4CDriverExtension.java:32)
oracle.jdbc.driver.OracleDriver.connect(oracle/jdbc/driver/OracleDriver.java:528)
java.lang.reflect.Method.invoke(java/lang/reflect/Method.java:498)
org.jruby.javasupport.JavaMethod.invokeDirectWithExceptionHandling(org/jruby/javasupport/JavaMethod.java:468)
org.jruby.javasupport.JavaMethod.invokeDirect(org/jruby/javasupport/JavaMethod.java:326)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/adapters/jdbc.rb:203)
RUBY.make_new(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool.rb:126)
RUBY.assign_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:192)
RUBY.acquire(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:133)
RUBY.hold(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:90)
RUBY.synchronize(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:269)
RUBY.test_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:279)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:58)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/core.rb:116)
RUBY.block in jdbc_connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:114)
org.jruby.RubyKernel.loop(org/jruby/RubyKernel.java:1292)
org.jruby.RubyKernel$INVOKER$s$0$0$loop.call(org/jruby/RubyKernel$INVOKER$s$0$0$loop.gen)
RUBY.jdbc_connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:111)
RUBY.open_jdbc_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:163)
RUBY.execute_statement(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:219)
RUBY.execute_query(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/inputs/jdbc.rb:264)
RUBY.run(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/inputs/jdbc.rb:250)
RUBY.inputworker(/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:516)
RUBY.block in start_input(/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:509)
org.jruby.RubyProc.call(org/jruby/RubyProc.java:289)
org.jruby.RubyProc.call(org/jruby/RubyProc.java:246)
java.lang.Thread.run(java/lang/Thread.java:748)
[2018-05-30T10:40:26,842][ERROR][logstash.inputs.jdbc     ] Unable to connect to database. Tried 1 times {:error_message=>"Java::JavaSql::SQLRecoverableException: IO Error: The Network Adapter could not establish the connection"}
[2018-05-30T10:40:26,845][ERROR][logstash.pipeline        ] A plugin had an unrecoverable error. Will restart this plugin.
  Pipeline_id:main
  Plugin: <LogStash::Inputs::Jdbc jdbc_driver_library=>"/etc/logstash/ojdbc6.jar", jdbc_driver_class=>"Java::oracle.jdbc.driver.OracleDriver", jdbc_connection_string=>"jdbc:oracle:thin:@100.100.100.225:1521:tenuri", jdbc_user=>"es_app", jdbc_password=><password>, jdbc_fetch_size=>10000, statement_filepath=>"as-is_search-log.sql", id=>"5bd7533661d97dbb4a1d2a6189513af0c10219fd73809280818346be344afa9b", enable_metric=>true, codec=><LogStash::Codecs::Plain id=>"plain_1a6af198-39fa-4265-9c68-c91258b113dc", enable_metric=>true, charset=>"UTF-8">, jdbc_paging_enabled=>false, jdbc_page_size=>100000, jdbc_validate_connection=>false, jdbc_validation_timeout=>3600, jdbc_pool_timeout=>5, sql_log_level=>"info", connection_retry_attempts=>1, connection_retry_attempts_wait_time=>0.5, parameters=>{"sql_last_value"=>2018-05-30 09:22:02 +0900}, last_run_metadata_path=>"/home/elastic/.logstash_jdbc_last_run", use_column_value=>false, tracking_column_type=>"numeric", clean_run=>false, record_last_run=>true, lowercase_column_names=>true>
  Error: Java::JavaSql::SQLRecoverableException: IO Error: The Network Adapter could not establish the connection
  Exception: Sequel::DatabaseConnectionError
  Stack: oracle.jdbc.driver.T4CConnection.logon(oracle/jdbc/driver/T4CConnection.java:489)
oracle.jdbc.driver.PhysicalConnection.<init>(oracle/jdbc/driver/PhysicalConnection.java:553)
oracle.jdbc.driver.T4CConnection.<init>(oracle/jdbc/driver/T4CConnection.java:254)
oracle.jdbc.driver.T4CDriverExtension.getConnection(oracle/jdbc/driver/T4CDriverExtension.java:32)
oracle.jdbc.driver.OracleDriver.connect(oracle/jdbc/driver/OracleDriver.java:528)
java.lang.reflect.Method.invoke(java/lang/reflect/Method.java:498)
org.jruby.javasupport.JavaMethod.invokeDirectWithExceptionHandling(org/jruby/javasupport/JavaMethod.java:468)
org.jruby.javasupport.JavaMethod.invokeDirect(org/jruby/javasupport/JavaMethod.java:326)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/adapters/jdbc.rb:203)
RUBY.make_new(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool.rb:126)
RUBY.assign_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:192)
RUBY.acquire(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:133)
RUBY.hold(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:90)
RUBY.synchronize(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:269)
RUBY.test_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:279)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:58)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/core.rb:116)
RUBY.block in jdbc_connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:114)
org.jruby.RubyKernel.loop(org/jruby/RubyKernel.java:1292)
org.jruby.RubyKernel$INVOKER$s$0$0$loop.call(org/jruby/RubyKernel$INVOKER$s$0$0$loop.gen)
RUBY.jdbc_connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:111)
RUBY.open_jdbc_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:163)
RUBY.execute_statement(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:219)
RUBY.execute_query(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/inputs/jdbc.rb:264)
RUBY.run(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/inputs/jdbc.rb:250)
RUBY.inputworker(/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:516)
RUBY.block in start_input(/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:509)
org.jruby.RubyProc.call(org/jruby/RubyProc.java:289)
org.jruby.RubyProc.call(org/jruby/RubyProc.java:246)
java.lang.Thread.run(java/lang/Thread.java:748)
[2018-05-30T10:40:29,850][ERROR][logstash.inputs.jdbc     ] Unable to connect to database. Tried 1 times {:error_message=>"Java::JavaSql::SQLRecoverableException: IO Error: The Network Adapter could not establish the connection"}
[2018-05-30T10:40:29,853][ERROR][logstash.pipeline        ] A plugin had an unrecoverable error. Will restart this plugin.
  Pipeline_id:main
  Plugin: <LogStash::Inputs::Jdbc jdbc_driver_library=>"/etc/logstash/ojdbc6.jar", jdbc_driver_class=>"Java::oracle.jdbc.driver.OracleDriver", jdbc_connection_string=>"jdbc:oracle:thin:@100.100.100.225:1521:tenuri", jdbc_user=>"es_app", jdbc_password=><password>, jdbc_fetch_size=>10000, statement_filepath=>"as-is_search-log.sql", id=>"5bd7533661d97dbb4a1d2a6189513af0c10219fd73809280818346be344afa9b", enable_metric=>true, codec=><LogStash::Codecs::Plain id=>"plain_1a6af198-39fa-4265-9c68-c91258b113dc", enable_metric=>true, charset=>"UTF-8">, jdbc_paging_enabled=>false, jdbc_page_size=>100000, jdbc_validate_connection=>false, jdbc_validation_timeout=>3600, jdbc_pool_timeout=>5, sql_log_level=>"info", connection_retry_attempts=>1, connection_retry_attempts_wait_time=>0.5, parameters=>{"sql_last_value"=>2018-05-30 09:22:02 +0900}, last_run_metadata_path=>"/home/elastic/.logstash_jdbc_last_run", use_column_value=>false, tracking_column_type=>"numeric", clean_run=>false, record_last_run=>true, lowercase_column_names=>true>
  Error: Java::JavaSql::SQLRecoverableException: IO Error: The Network Adapter could not establish the connection
  Exception: Sequel::DatabaseConnectionError
  Stack: oracle.jdbc.driver.T4CConnection.logon(oracle/jdbc/driver/T4CConnection.java:489)
oracle.jdbc.driver.PhysicalConnection.<init>(oracle/jdbc/driver/PhysicalConnection.java:553)
oracle.jdbc.driver.T4CConnection.<init>(oracle/jdbc/driver/T4CConnection.java:254)
oracle.jdbc.driver.T4CDriverExtension.getConnection(oracle/jdbc/driver/T4CDriverExtension.java:32)
oracle.jdbc.driver.OracleDriver.connect(oracle/jdbc/driver/OracleDriver.java:528)
java.lang.reflect.Method.invoke(java/lang/reflect/Method.java:498)
org.jruby.javasupport.JavaMethod.invokeDirectWithExceptionHandling(org/jruby/javasupport/JavaMethod.java:468)
org.jruby.javasupport.JavaMethod.invokeDirect(org/jruby/javasupport/JavaMethod.java:326)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/adapters/jdbc.rb:203)
RUBY.make_new(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool.rb:126)
RUBY.assign_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:192)
RUBY.acquire(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:133)
RUBY.hold(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:90)
RUBY.synchronize(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:269)
RUBY.test_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:279)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:58)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/core.rb:116)
RUBY.block in jdbc_connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:114)
org.jruby.RubyKernel.loop(org/jruby/RubyKernel.java:1292)
org.jruby.RubyKernel$INVOKER$s$0$0$loop.call(org/jruby/RubyKernel$INVOKER$s$0$0$loop.gen)
RUBY.jdbc_connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:111)
RUBY.open_jdbc_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:163)
RUBY.execute_statement(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:219)
RUBY.execute_query(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/inputs/jdbc.rb:264)
RUBY.run(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/inputs/jdbc.rb:250)
RUBY.inputworker(/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:516)
RUBY.block in start_input(/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:509)
org.jruby.RubyProc.call(org/jruby/RubyProc.java:289)
org.jruby.RubyProc.call(org/jruby/RubyProc.java:246)
java.lang.Thread.run(java/lang/Thread.java:748)
[2018-05-30T10:40:32,856][ERROR][logstash.inputs.jdbc     ] Unable to connect to database. Tried 1 times {:error_message=>"Java::JavaSql::SQLRecoverableException: IO Error: The Network Adapter could not establish the connection"}
[2018-05-30T10:40:32,858][ERROR][logstash.pipeline        ] A plugin had an unrecoverable error. Will restart this plugin.
  Pipeline_id:main
  Plugin: <LogStash::Inputs::Jdbc jdbc_driver_library=>"/etc/logstash/ojdbc6.jar", jdbc_driver_class=>"Java::oracle.jdbc.driver.OracleDriver", jdbc_connection_string=>"jdbc:oracle:thin:@100.100.100.225:1521:tenuri", jdbc_user=>"es_app", jdbc_password=><password>, jdbc_fetch_size=>10000, statement_filepath=>"as-is_search-log.sql", id=>"5bd7533661d97dbb4a1d2a6189513af0c10219fd73809280818346be344afa9b", enable_metric=>true, codec=><LogStash::Codecs::Plain id=>"plain_1a6af198-39fa-4265-9c68-c91258b113dc", enable_metric=>true, charset=>"UTF-8">, jdbc_paging_enabled=>false, jdbc_page_size=>100000, jdbc_validate_connection=>false, jdbc_validation_timeout=>3600, jdbc_pool_timeout=>5, sql_log_level=>"info", connection_retry_attempts=>1, connection_retry_attempts_wait_time=>0.5, parameters=>{"sql_last_value"=>2018-05-30 09:22:02 +0900}, last_run_metadata_path=>"/home/elastic/.logstash_jdbc_last_run", use_column_value=>false, tracking_column_type=>"numeric", clean_run=>false, record_last_run=>true, lowercase_column_names=>true>
  Error: Java::JavaSql::SQLRecoverableException: IO Error: The Network Adapter could not establish the connection
  Exception: Sequel::DatabaseConnectionError
  Stack: oracle.jdbc.driver.T4CConnection.logon(oracle/jdbc/driver/T4CConnection.java:489)
oracle.jdbc.driver.PhysicalConnection.<init>(oracle/jdbc/driver/PhysicalConnection.java:553)
oracle.jdbc.driver.T4CConnection.<init>(oracle/jdbc/driver/T4CConnection.java:254)
oracle.jdbc.driver.T4CDriverExtension.getConnection(oracle/jdbc/driver/T4CDriverExtension.java:32)
oracle.jdbc.driver.OracleDriver.connect(oracle/jdbc/driver/OracleDriver.java:528)
java.lang.reflect.Method.invoke(java/lang/reflect/Method.java:498)
org.jruby.javasupport.JavaMethod.invokeDirectWithExceptionHandling(org/jruby/javasupport/JavaMethod.java:468)
org.jruby.javasupport.JavaMethod.invokeDirect(org/jruby/javasupport/JavaMethod.java:326)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/adapters/jdbc.rb:203)
RUBY.make_new(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool.rb:126)
RUBY.assign_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:192)
RUBY.acquire(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:133)
RUBY.hold(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:90)
RUBY.synchronize(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:269)
RUBY.test_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:279)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:58)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/core.rb:116)
RUBY.block in jdbc_connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:114)
org.jruby.RubyKernel.loop(org/jruby/RubyKernel.java:1292)
org.jruby.RubyKernel$INVOKER$s$0$0$loop.call(org/jruby/RubyKernel$INVOKER$s$0$0$loop.gen)
RUBY.jdbc_connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:111)
RUBY.open_jdbc_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:163)
RUBY.execute_statement(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:219)
RUBY.execute_query(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/inputs/jdbc.rb:264)
RUBY.run(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/inputs/jdbc.rb:250)
RUBY.inputworker(/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:516)
RUBY.block in start_input(/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:509)
org.jruby.RubyProc.call(org/jruby/RubyProc.java:289)
org.jruby.RubyProc.call(org/jruby/RubyProc.java:246)
java.lang.Thread.run(java/lang/Thread.java:748)
[2018-05-30T10:40:35,860][ERROR][logstash.inputs.jdbc     ] Unable to connect to database. Tried 1 times {:error_message=>"Java::JavaSql::SQLRecoverableException: IO Error: The Network Adapter could not establish the connection"}
[2018-05-30T10:40:35,864][ERROR][logstash.pipeline        ] A plugin had an unrecoverable error. Will restart this plugin.
  Pipeline_id:main
  Plugin: <LogStash::Inputs::Jdbc jdbc_driver_library=>"/etc/logstash/ojdbc6.jar", jdbc_driver_class=>"Java::oracle.jdbc.driver.OracleDriver", jdbc_connection_string=>"jdbc:oracle:thin:@100.100.100.225:1521:tenuri", jdbc_user=>"es_app", jdbc_password=><password>, jdbc_fetch_size=>10000, statement_filepath=>"as-is_search-log.sql", id=>"5bd7533661d97dbb4a1d2a6189513af0c10219fd73809280818346be344afa9b", enable_metric=>true, codec=><LogStash::Codecs::Plain id=>"plain_1a6af198-39fa-4265-9c68-c91258b113dc", enable_metric=>true, charset=>"UTF-8">, jdbc_paging_enabled=>false, jdbc_page_size=>100000, jdbc_validate_connection=>false, jdbc_validation_timeout=>3600, jdbc_pool_timeout=>5, sql_log_level=>"info", connection_retry_attempts=>1, connection_retry_attempts_wait_time=>0.5, parameters=>{"sql_last_value"=>2018-05-30 09:22:02 +0900}, last_run_metadata_path=>"/home/elastic/.logstash_jdbc_last_run", use_column_value=>false, tracking_column_type=>"numeric", clean_run=>false, record_last_run=>true, lowercase_column_names=>true>
  Error: Java::JavaSql::SQLRecoverableException: IO Error: The Network Adapter could not establish the connection
  Exception: Sequel::DatabaseConnectionError
  Stack: oracle.jdbc.driver.T4CConnection.logon(oracle/jdbc/driver/T4CConnection.java:489)
oracle.jdbc.driver.PhysicalConnection.<init>(oracle/jdbc/driver/PhysicalConnection.java:553)
oracle.jdbc.driver.T4CConnection.<init>(oracle/jdbc/driver/T4CConnection.java:254)
oracle.jdbc.driver.T4CDriverExtension.getConnection(oracle/jdbc/driver/T4CDriverExtension.java:32)
oracle.jdbc.driver.OracleDriver.connect(oracle/jdbc/driver/OracleDriver.java:528)
java.lang.reflect.Method.invoke(java/lang/reflect/Method.java:498)
org.jruby.javasupport.JavaMethod.invokeDirectWithExceptionHandling(org/jruby/javasupport/JavaMethod.java:468)
org.jruby.javasupport.JavaMethod.invokeDirect(org/jruby/javasupport/JavaMethod.java:326)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/adapters/jdbc.rb:203)
RUBY.make_new(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool.rb:126)
RUBY.assign_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:192)
RUBY.acquire(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:133)
RUBY.hold(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:90)
RUBY.synchronize(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:269)
RUBY.test_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:279)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:58)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/core.rb:116)
RUBY.block in jdbc_connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:114)
org.jruby.RubyKernel.loop(org/jruby/RubyKernel.java:1292)
org.jruby.RubyKernel$INVOKER$s$0$0$loop.call(org/jruby/RubyKernel$INVOKER$s$0$0$loop.gen)
RUBY.jdbc_connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:111)
RUBY.open_jdbc_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:163)
RUBY.execute_statement(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:219)
RUBY.execute_query(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/inputs/jdbc.rb:264)
RUBY.run(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/inputs/jdbc.rb:250)
RUBY.inputworker(/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:516)
RUBY.block in start_input(/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:509)
org.jruby.RubyProc.call(org/jruby/RubyProc.java:289)
org.jruby.RubyProc.call(org/jruby/RubyProc.java:246)
java.lang.Thread.run(java/lang/Thread.java:748)
[2018-05-30T10:40:38,873][ERROR][logstash.inputs.jdbc     ] Unable to connect to database. Tried 1 times {:error_message=>"Java::JavaSql::SQLRecoverableException: IO Error: The Network Adapter could not establish the connection"}
[2018-05-30T10:40:38,875][ERROR][logstash.pipeline        ] A plugin had an unrecoverable error. Will restart this plugin.
  Pipeline_id:main
  Plugin: <LogStash::Inputs::Jdbc jdbc_driver_library=>"/etc/logstash/ojdbc6.jar", jdbc_driver_class=>"Java::oracle.jdbc.driver.OracleDriver", jdbc_connection_string=>"jdbc:oracle:thin:@100.100.100.225:1521:tenuri", jdbc_user=>"es_app", jdbc_password=><password>, jdbc_fetch_size=>10000, statement_filepath=>"as-is_search-log.sql", id=>"5bd7533661d97dbb4a1d2a6189513af0c10219fd73809280818346be344afa9b", enable_metric=>true, codec=><LogStash::Codecs::Plain id=>"plain_1a6af198-39fa-4265-9c68-c91258b113dc", enable_metric=>true, charset=>"UTF-8">, jdbc_paging_enabled=>false, jdbc_page_size=>100000, jdbc_validate_connection=>false, jdbc_validation_timeout=>3600, jdbc_pool_timeout=>5, sql_log_level=>"info", connection_retry_attempts=>1, connection_retry_attempts_wait_time=>0.5, parameters=>{"sql_last_value"=>2018-05-30 09:22:02 +0900}, last_run_metadata_path=>"/home/elastic/.logstash_jdbc_last_run", use_column_value=>false, tracking_column_type=>"numeric", clean_run=>false, record_last_run=>true, lowercase_column_names=>true>
  Error: Java::JavaSql::SQLRecoverableException: IO Error: The Network Adapter could not establish the connection
  Exception: Sequel::DatabaseConnectionError
  Stack: oracle.jdbc.driver.T4CConnection.logon(oracle/jdbc/driver/T4CConnection.java:489)
oracle.jdbc.driver.PhysicalConnection.<init>(oracle/jdbc/driver/PhysicalConnection.java:553)
oracle.jdbc.driver.T4CConnection.<init>(oracle/jdbc/driver/T4CConnection.java:254)
oracle.jdbc.driver.T4CDriverExtension.getConnection(oracle/jdbc/driver/T4CDriverExtension.java:32)
oracle.jdbc.driver.OracleDriver.connect(oracle/jdbc/driver/OracleDriver.java:528)
java.lang.reflect.Method.invoke(java/lang/reflect/Method.java:498)
org.jruby.javasupport.JavaMethod.invokeDirectWithExceptionHandling(org/jruby/javasupport/JavaMethod.java:468)
org.jruby.javasupport.JavaMethod.invokeDirect(org/jruby/javasupport/JavaMethod.java:326)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/adapters/jdbc.rb:203)
RUBY.make_new(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool.rb:126)
RUBY.assign_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:192)
RUBY.acquire(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:133)
RUBY.hold(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:90)
RUBY.synchronize(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:269)
RUBY.test_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:279)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:58)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/core.rb:116)
RUBY.block in jdbc_connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:114)
org.jruby.RubyKernel.loop(org/jruby/RubyKernel.java:1292)
org.jruby.RubyKernel$INVOKER$s$0$0$loop.call(org/jruby/RubyKernel$INVOKER$s$0$0$loop.gen)
RUBY.jdbc_connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:111)
RUBY.open_jdbc_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:163)
RUBY.execute_statement(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:219)
RUBY.execute_query(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/inputs/jdbc.rb:264)
RUBY.run(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/inputs/jdbc.rb:250)
RUBY.inputworker(/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:516)
RUBY.block in start_input(/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:509)
org.jruby.RubyProc.call(org/jruby/RubyProc.java:289)
org.jruby.RubyProc.call(org/jruby/RubyProc.java:246)
java.lang.Thread.run(java/lang/Thread.java:748)
[2018-05-30T10:42:06,556][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"fb_apache", :directory=>"/usr/share/logstash/modules/fb_apache/configuration"}
[2018-05-30T10:42:06,566][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"netflow", :directory=>"/usr/share/logstash/modules/netflow/configuration"}
[2018-05-30T10:42:07,427][WARN ][logstash.config.source.multilocal] Ignoring the 'pipelines.yml' file because modules or command line options are specified
[2018-05-30T10:42:08,032][INFO ][logstash.runner          ] Starting Logstash {"logstash.version"=>"6.2.3"}
[2018-05-30T10:42:08,973][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=>9606}
[2018-05-30T10:42:11,495][INFO ][logstash.filters.ruby.script] Test run complete {:script_path=>"rubyfilter.rb", :results=>{:passed=>0, :failed=>0, :errored=>0}}
[2018-05-30T10:42:11,822][WARN ][logstash.outputs.elasticsearch] You are using a deprecated config setting "document_type" set in elasticsearch. Deprecated settings will continue to work, but are scheduled for removal from logstash in the future. Document types are being deprecated in Elasticsearch 6.0, and removed entirely in 7.0. You should avoid this feature If you have any questions about this, please visit the #logstash channel on freenode irc. {:name=>"document_type", :plugin=><LogStash::Outputs::ElasticSearch hosts=>[//100.100.100.111:9200, //100.100.100.112:9200, //100.100.100.113:9200], index=>"qa-enuri-main", document_type=>"_doc", document_id=>"%{id}", action=>"%{[@metadata][action]}", id=>"3b16bdd1680600ee9156ace46ed76a90d56bc1644736e9c91a7e57c052ab5c69", enable_metric=>true, codec=><LogStash::Codecs::Plain id=>"plain_07f6d7c8-bb36-4390-ac1b-c64b29887402", enable_metric=>true, charset=>"UTF-8">, workers=>1, manage_template=>true, template_name=>"logstash", template_overwrite=>false, doc_as_upsert=>false, script_type=>"inline", script_lang=>"painless", script_var_name=>"event", scripted_upsert=>false, retry_initial_interval=>2, retry_max_interval=>64, retry_on_conflict=>1, ssl_certificate_verification=>true, sniffing=>false, sniffing_delay=>5, timeout=>60, pool_max=>1000, pool_max_per_route=>100, resurrect_delay=>5, validate_after_inactivity=>10000, http_compression=>false>}
[2018-05-30T10:42:11,878][INFO ][logstash.pipeline        ] Starting pipeline {:pipeline_id=>"main", "pipeline.workers"=>8, "pipeline.batch.size"=>125, "pipeline.batch.delay"=>50}
[2018-05-30T10:42:12,594][INFO ][logstash.outputs.elasticsearch] Elasticsearch pool URLs updated {:changes=>{:removed=>[], :added=>[http://100.100.100.111:9200/, http://100.100.100.112:9200/, http://100.100.100.113:9200/]}}
[2018-05-30T10:42:12,598][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://100.100.100.111:9200/, :path=>"/"}
[2018-05-30T10:42:13,394][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://100.100.100.111:9200/"}
[2018-05-30T10:42:13,739][INFO ][logstash.outputs.elasticsearch] ES Output version determined {:es_version=>6}
[2018-05-30T10:42:13,740][WARN ][logstash.outputs.elasticsearch] Detected a 6.x and above cluster: the `type` event field won't be used to determine the document _type {:es_version=>6}
[2018-05-30T10:42:13,740][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://100.100.100.112:9200/, :path=>"/"}
[2018-05-30T10:42:13,753][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://100.100.100.112:9200/"}
[2018-05-30T10:42:13,762][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://100.100.100.113:9200/, :path=>"/"}
[2018-05-30T10:42:13,773][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://100.100.100.113:9200/"}
[2018-05-30T10:42:13,793][INFO ][logstash.outputs.elasticsearch] Using mapping template from {:path=>nil}
[2018-05-30T10:42:13,800][INFO ][logstash.outputs.elasticsearch] Attempting to install template {:manage_template=>{"template"=>"logstash-*", "version"=>60001, "settings"=>{"index.refresh_interval"=>"5s"}, "mappings"=>{"_default_"=>{"dynamic_templates"=>[{"message_field"=>{"path_match"=>"message", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false}}}, {"string_fields"=>{"match"=>"*", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false, "fields"=>{"keyword"=>{"type"=>"keyword", "ignore_above"=>256}}}}}], "properties"=>{"@timestamp"=>{"type"=>"date"}, "@version"=>{"type"=>"keyword"}, "geoip"=>{"dynamic"=>true, "properties"=>{"ip"=>{"type"=>"ip"}, "location"=>{"type"=>"geo_point"}, "latitude"=>{"type"=>"half_float"}, "longitude"=>{"type"=>"half_float"}}}}}}}}
[2018-05-30T10:42:13,810][INFO ][logstash.outputs.elasticsearch] New Elasticsearch output {:class=>"LogStash::Outputs::ElasticSearch", :hosts=>["//100.100.100.111:9200", "//100.100.100.112:9200", "//100.100.100.113:9200"]}
[2018-05-30T10:42:14,454][INFO ][logstash.pipeline        ] Pipeline started succesfully {:pipeline_id=>"main", :thread=>"#<Thread:0x2486662c@/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:246 run>"}
[2018-05-30T10:42:14,504][INFO ][logstash.agent           ] Pipelines running {:count=>1, :pipelines=>["main"]}
[2018-05-30T10:42:18,579][ERROR][logstash.inputs.jdbc     ] Unable to connect to database. Tried 1 times {:error_message=>"Java::JavaSql::SQLRecoverableException: IO Error: The Network Adapter could not establish the connection"}
[2018-05-30T10:42:18,593][ERROR][logstash.pipeline        ] A plugin had an unrecoverable error. Will restart this plugin.
  Pipeline_id:main
  Plugin: <LogStash::Inputs::Jdbc jdbc_driver_library=>"/etc/logstash/ojdbc6.jar", jdbc_driver_class=>"Java::oracle.jdbc.driver.OracleDriver", jdbc_connection_string=>"jdbc:oracle:thin:@100.100.100.225:1521:tenuri", jdbc_user=>"es_app", jdbc_password=><password>, jdbc_fetch_size=>10000, statement_filepath=>"as-is_search-log.sql", id=>"5bd7533661d97dbb4a1d2a6189513af0c10219fd73809280818346be344afa9b", enable_metric=>true, codec=><LogStash::Codecs::Plain id=>"plain_31f27a90-fe38-4e91-86c8-da800a67c5b1", enable_metric=>true, charset=>"UTF-8">, jdbc_paging_enabled=>false, jdbc_page_size=>100000, jdbc_validate_connection=>false, jdbc_validation_timeout=>3600, jdbc_pool_timeout=>5, sql_log_level=>"info", connection_retry_attempts=>1, connection_retry_attempts_wait_time=>0.5, parameters=>{"sql_last_value"=>2018-05-30 09:22:02 +0900}, last_run_metadata_path=>"/home/elastic/.logstash_jdbc_last_run", use_column_value=>false, tracking_column_type=>"numeric", clean_run=>false, record_last_run=>true, lowercase_column_names=>true>
  Error: Java::JavaSql::SQLRecoverableException: IO Error: The Network Adapter could not establish the connection
  Exception: Sequel::DatabaseConnectionError
  Stack: oracle.jdbc.driver.T4CConnection.logon(oracle/jdbc/driver/T4CConnection.java:489)
oracle.jdbc.driver.PhysicalConnection.<init>(oracle/jdbc/driver/PhysicalConnection.java:553)
oracle.jdbc.driver.T4CConnection.<init>(oracle/jdbc/driver/T4CConnection.java:254)
oracle.jdbc.driver.T4CDriverExtension.getConnection(oracle/jdbc/driver/T4CDriverExtension.java:32)
oracle.jdbc.driver.OracleDriver.connect(oracle/jdbc/driver/OracleDriver.java:528)
java.lang.reflect.Method.invoke(java/lang/reflect/Method.java:498)
org.jruby.javasupport.JavaMethod.invokeDirectWithExceptionHandling(org/jruby/javasupport/JavaMethod.java:468)
org.jruby.javasupport.JavaMethod.invokeDirect(org/jruby/javasupport/JavaMethod.java:326)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/adapters/jdbc.rb:203)
RUBY.make_new(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool.rb:126)
RUBY.assign_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:192)
RUBY.acquire(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:133)
RUBY.hold(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:90)
RUBY.synchronize(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:269)
RUBY.test_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:279)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:58)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/core.rb:116)
RUBY.block in jdbc_connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:114)
org.jruby.RubyKernel.loop(org/jruby/RubyKernel.java:1292)
org.jruby.RubyKernel$INVOKER$s$0$0$loop.call(org/jruby/RubyKernel$INVOKER$s$0$0$loop.gen)
RUBY.jdbc_connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:111)
RUBY.open_jdbc_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:163)
RUBY.execute_statement(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:219)
RUBY.execute_query(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/inputs/jdbc.rb:264)
RUBY.run(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/inputs/jdbc.rb:250)
RUBY.inputworker(/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:516)
RUBY.block in start_input(/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:509)
org.jruby.RubyProc.call(org/jruby/RubyProc.java:289)
org.jruby.RubyProc.call(org/jruby/RubyProc.java:246)
java.lang.Thread.run(java/lang/Thread.java:748)
[2018-05-30T10:42:21,578][ERROR][logstash.inputs.jdbc     ] Unable to connect to database. Tried 1 times {:error_message=>"Java::JavaSql::SQLRecoverableException: IO Error: The Network Adapter could not establish the connection"}
[2018-05-30T10:42:21,580][ERROR][logstash.pipeline        ] A plugin had an unrecoverable error. Will restart this plugin.
  Pipeline_id:main
  Plugin: <LogStash::Inputs::Jdbc jdbc_driver_library=>"/etc/logstash/ojdbc6.jar", jdbc_driver_class=>"Java::oracle.jdbc.driver.OracleDriver", jdbc_connection_string=>"jdbc:oracle:thin:@100.100.100.225:1521:tenuri", jdbc_user=>"es_app", jdbc_password=><password>, jdbc_fetch_size=>10000, statement_filepath=>"as-is_search-log.sql", id=>"5bd7533661d97dbb4a1d2a6189513af0c10219fd73809280818346be344afa9b", enable_metric=>true, codec=><LogStash::Codecs::Plain id=>"plain_31f27a90-fe38-4e91-86c8-da800a67c5b1", enable_metric=>true, charset=>"UTF-8">, jdbc_paging_enabled=>false, jdbc_page_size=>100000, jdbc_validate_connection=>false, jdbc_validation_timeout=>3600, jdbc_pool_timeout=>5, sql_log_level=>"info", connection_retry_attempts=>1, connection_retry_attempts_wait_time=>0.5, parameters=>{"sql_last_value"=>2018-05-30 09:22:02 +0900}, last_run_metadata_path=>"/home/elastic/.logstash_jdbc_last_run", use_column_value=>false, tracking_column_type=>"numeric", clean_run=>false, record_last_run=>true, lowercase_column_names=>true>
  Error: Java::JavaSql::SQLRecoverableException: IO Error: The Network Adapter could not establish the connection
  Exception: Sequel::DatabaseConnectionError
  Stack: oracle.jdbc.driver.T4CConnection.logon(oracle/jdbc/driver/T4CConnection.java:489)
oracle.jdbc.driver.PhysicalConnection.<init>(oracle/jdbc/driver/PhysicalConnection.java:553)
oracle.jdbc.driver.T4CConnection.<init>(oracle/jdbc/driver/T4CConnection.java:254)
oracle.jdbc.driver.T4CDriverExtension.getConnection(oracle/jdbc/driver/T4CDriverExtension.java:32)
oracle.jdbc.driver.OracleDriver.connect(oracle/jdbc/driver/OracleDriver.java:528)
java.lang.reflect.Method.invoke(java/lang/reflect/Method.java:498)
org.jruby.javasupport.JavaMethod.invokeDirectWithExceptionHandling(org/jruby/javasupport/JavaMethod.java:468)
org.jruby.javasupport.JavaMethod.invokeDirect(org/jruby/javasupport/JavaMethod.java:326)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/adapters/jdbc.rb:203)
RUBY.make_new(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool.rb:126)
RUBY.assign_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:192)
RUBY.acquire(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:133)
RUBY.hold(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:90)
RUBY.synchronize(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:269)
RUBY.test_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:279)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:58)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/core.rb:116)
RUBY.block in jdbc_connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:114)
org.jruby.RubyKernel.loop(org/jruby/RubyKernel.java:1292)
org.jruby.RubyKernel$INVOKER$s$0$0$loop.call(org/jruby/RubyKernel$INVOKER$s$0$0$loop.gen)
RUBY.jdbc_connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:111)
RUBY.open_jdbc_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:163)
RUBY.execute_statement(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:219)
RUBY.execute_query(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/inputs/jdbc.rb:264)
RUBY.run(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/inputs/jdbc.rb:250)
RUBY.inputworker(/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:516)
RUBY.block in start_input(/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:509)
org.jruby.RubyProc.call(org/jruby/RubyProc.java:289)
org.jruby.RubyProc.call(org/jruby/RubyProc.java:246)
java.lang.Thread.run(java/lang/Thread.java:748)
[2018-05-30T10:42:24,586][ERROR][logstash.inputs.jdbc     ] Unable to connect to database. Tried 1 times {:error_message=>"Java::JavaSql::SQLRecoverableException: IO Error: The Network Adapter could not establish the connection"}
[2018-05-30T10:42:24,588][ERROR][logstash.pipeline        ] A plugin had an unrecoverable error. Will restart this plugin.
  Pipeline_id:main
  Plugin: <LogStash::Inputs::Jdbc jdbc_driver_library=>"/etc/logstash/ojdbc6.jar", jdbc_driver_class=>"Java::oracle.jdbc.driver.OracleDriver", jdbc_connection_string=>"jdbc:oracle:thin:@100.100.100.225:1521:tenuri", jdbc_user=>"es_app", jdbc_password=><password>, jdbc_fetch_size=>10000, statement_filepath=>"as-is_search-log.sql", id=>"5bd7533661d97dbb4a1d2a6189513af0c10219fd73809280818346be344afa9b", enable_metric=>true, codec=><LogStash::Codecs::Plain id=>"plain_31f27a90-fe38-4e91-86c8-da800a67c5b1", enable_metric=>true, charset=>"UTF-8">, jdbc_paging_enabled=>false, jdbc_page_size=>100000, jdbc_validate_connection=>false, jdbc_validation_timeout=>3600, jdbc_pool_timeout=>5, sql_log_level=>"info", connection_retry_attempts=>1, connection_retry_attempts_wait_time=>0.5, parameters=>{"sql_last_value"=>2018-05-30 09:22:02 +0900}, last_run_metadata_path=>"/home/elastic/.logstash_jdbc_last_run", use_column_value=>false, tracking_column_type=>"numeric", clean_run=>false, record_last_run=>true, lowercase_column_names=>true>
  Error: Java::JavaSql::SQLRecoverableException: IO Error: The Network Adapter could not establish the connection
  Exception: Sequel::DatabaseConnectionError
  Stack: oracle.jdbc.driver.T4CConnection.logon(oracle/jdbc/driver/T4CConnection.java:489)
oracle.jdbc.driver.PhysicalConnection.<init>(oracle/jdbc/driver/PhysicalConnection.java:553)
oracle.jdbc.driver.T4CConnection.<init>(oracle/jdbc/driver/T4CConnection.java:254)
oracle.jdbc.driver.T4CDriverExtension.getConnection(oracle/jdbc/driver/T4CDriverExtension.java:32)
oracle.jdbc.driver.OracleDriver.connect(oracle/jdbc/driver/OracleDriver.java:528)
java.lang.reflect.Method.invoke(java/lang/reflect/Method.java:498)
org.jruby.javasupport.JavaMethod.invokeDirectWithExceptionHandling(org/jruby/javasupport/JavaMethod.java:468)
org.jruby.javasupport.JavaMethod.invokeDirect(org/jruby/javasupport/JavaMethod.java:326)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/adapters/jdbc.rb:203)
RUBY.make_new(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool.rb:126)
RUBY.assign_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:192)
RUBY.acquire(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:133)
RUBY.hold(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:90)
RUBY.synchronize(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:269)
RUBY.test_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:279)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:58)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/core.rb:116)
RUBY.block in jdbc_connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:114)
org.jruby.RubyKernel.loop(org/jruby/RubyKernel.java:1292)
org.jruby.RubyKernel$INVOKER$s$0$0$loop.call(org/jruby/RubyKernel$INVOKER$s$0$0$loop.gen)
RUBY.jdbc_connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:111)
RUBY.open_jdbc_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:163)
RUBY.execute_statement(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:219)
RUBY.execute_query(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/inputs/jdbc.rb:264)
RUBY.run(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/inputs/jdbc.rb:250)
RUBY.inputworker(/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:516)
RUBY.block in start_input(/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:509)
org.jruby.RubyProc.call(org/jruby/RubyProc.java:289)
org.jruby.RubyProc.call(org/jruby/RubyProc.java:246)
java.lang.Thread.run(java/lang/Thread.java:748)
[2018-05-30T12:51:12,279][INFO ][logstash.pipeline        ] Pipeline has terminated {:pipeline_id=>"main", :thread=>"#<Thread:0x42edf71@/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:246 run>"}
[2018-05-30T12:54:09,343][INFO ][logstash.pipeline        ] Pipeline has terminated {:pipeline_id=>"main", :thread=>"#<Thread:0x121d8d1b@/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:246 run>"}
[2018-05-30T12:54:57,586][INFO ][logstash.pipeline        ] Pipeline has terminated {:pipeline_id=>"main", :thread=>"#<Thread:0x70120a18@/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:246 run>"}
[2018-05-30T12:55:55,575][INFO ][logstash.pipeline        ] Pipeline has terminated {:pipeline_id=>"main", :thread=>"#<Thread:0x3322c7d9@/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:246 run>"}
[2018-05-30T12:58:30,803][INFO ][logstash.pipeline        ] Pipeline has terminated {:pipeline_id=>"main", :thread=>"#<Thread:0x215860d8@/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:246 run>"}
[2018-05-30T12:59:29,541][INFO ][logstash.pipeline        ] Pipeline has terminated {:pipeline_id=>"main", :thread=>"#<Thread:0x19adf0cd@/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:246 run>"}
[2018-05-30T13:38:49,065][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"fb_apache", :directory=>"/usr/share/logstash/modules/fb_apache/configuration"}
[2018-05-30T13:38:49,073][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"netflow", :directory=>"/usr/share/logstash/modules/netflow/configuration"}
[2018-05-30T13:38:49,428][WARN ][logstash.config.source.multilocal] Ignoring the 'pipelines.yml' file because modules or command line options are specified
[2018-05-30T13:38:49,585][INFO ][logstash.runner          ] Starting Logstash {"logstash.version"=>"6.2.3"}
[2018-05-30T13:38:49,682][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=>9600}
[2018-05-30T13:38:50,175][DEBUG][org.logstash.secret.store.SecretStoreFactory] Attempting to exists or secret store with implementation: org.logstash.secret.store.backend.JavaKeyStore
[2018-05-30T13:38:50,229][WARN ][logstash.outputs.elasticsearch] You are using a deprecated config setting "document_type" set in elasticsearch. Deprecated settings will continue to work, but are scheduled for removal from logstash in the future. Document types are being deprecated in Elasticsearch 6.0, and removed entirely in 7.0. You should avoid this feature If you have any questions about this, please visit the #logstash channel on freenode irc. {:name=>"document_type", :plugin=><LogStash::Outputs::ElasticSearch hosts=>[//100.100.100.111:9200, //100.100.100.112:9200, //100.100.100.113:9200], index=>"qa-enuri-main-as-is-1", document_type=>"_doc", document_id=>"%{id}", action=>"index", id=>"a0af62a40de9ecd4006a0804aadc52ea9bc343aba81f230b001c3233272567d1", enable_metric=>true, codec=><LogStash::Codecs::Plain id=>"plain_b82a413e-a6d9-4e3d-a836-8f845fed7578", enable_metric=>true, charset=>"UTF-8">, workers=>1, manage_template=>true, template_name=>"logstash", template_overwrite=>false, doc_as_upsert=>false, script_type=>"inline", script_lang=>"painless", script_var_name=>"event", scripted_upsert=>false, retry_initial_interval=>2, retry_max_interval=>64, retry_on_conflict=>1, ssl_certificate_verification=>true, sniffing=>false, sniffing_delay=>5, timeout=>60, pool_max=>1000, pool_max_per_route=>100, resurrect_delay=>5, validate_after_inactivity=>10000, http_compression=>false>}
[2018-05-30T13:38:50,243][INFO ][logstash.pipeline        ] Starting pipeline {:pipeline_id=>"main", "pipeline.workers"=>8, "pipeline.batch.size"=>125, "pipeline.batch.delay"=>50}
[2018-05-30T13:38:50,541][INFO ][logstash.outputs.elasticsearch] Elasticsearch pool URLs updated {:changes=>{:removed=>[], :added=>[http://100.100.100.111:9200/, http://100.100.100.112:9200/, http://100.100.100.113:9200/]}}
[2018-05-30T13:38:50,546][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://100.100.100.111:9200/, :path=>"/"}
[2018-05-30T13:38:50,758][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://100.100.100.111:9200/"}
[2018-05-30T13:38:50,826][INFO ][logstash.outputs.elasticsearch] ES Output version determined {:es_version=>6}
[2018-05-30T13:38:50,827][WARN ][logstash.outputs.elasticsearch] Detected a 6.x and above cluster: the `type` event field won't be used to determine the document _type {:es_version=>6}
[2018-05-30T13:38:50,827][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://100.100.100.112:9200/, :path=>"/"}
[2018-05-30T13:38:50,833][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://100.100.100.112:9200/"}
[2018-05-30T13:38:50,840][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://100.100.100.113:9200/, :path=>"/"}
[2018-05-30T13:38:50,845][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://100.100.100.113:9200/"}
[2018-05-30T13:38:50,855][INFO ][logstash.outputs.elasticsearch] Using mapping template from {:path=>nil}
[2018-05-30T13:38:50,862][INFO ][logstash.outputs.elasticsearch] Attempting to install template {:manage_template=>{"template"=>"logstash-*", "version"=>60001, "settings"=>{"index.refresh_interval"=>"5s"}, "mappings"=>{"_default_"=>{"dynamic_templates"=>[{"message_field"=>{"path_match"=>"message", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false}}}, {"string_fields"=>{"match"=>"*", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false, "fields"=>{"keyword"=>{"type"=>"keyword", "ignore_above"=>256}}}}}], "properties"=>{"@timestamp"=>{"type"=>"date"}, "@version"=>{"type"=>"keyword"}, "geoip"=>{"dynamic"=>true, "properties"=>{"ip"=>{"type"=>"ip"}, "location"=>{"type"=>"geo_point"}, "latitude"=>{"type"=>"half_float"}, "longitude"=>{"type"=>"half_float"}}}}}}}}
[2018-05-30T13:38:50,874][INFO ][logstash.outputs.elasticsearch] New Elasticsearch output {:class=>"LogStash::Outputs::ElasticSearch", :hosts=>["//100.100.100.111:9200", "//100.100.100.112:9200", "//100.100.100.113:9200"]}
[2018-05-30T13:38:51,061][INFO ][logstash.pipeline        ] Pipeline started succesfully {:pipeline_id=>"main", :thread=>"#<Thread:0x1a2fd6e6@/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:246 sleep>"}
[2018-05-30T13:38:51,085][INFO ][logstash.agent           ] Pipelines running {:count=>1, :pipelines=>["main"]}
[2018-05-30T13:50:55,848][WARN ][logstash.runner          ] SIGINT received. Shutting down.
[2018-05-30T13:51:00,851][WARN ][logstash.runner          ] Received shutdown signal, but pipeline is still waiting for in-flight events
to be processed. Sending another ^C will force quit Logstash, but this may cause
data loss.
[2018-05-30T13:51:00,878][WARN ][logstash.shutdownwatcher ] {"inflight_count"=>0, "stalling_thread_info"=>{"other"=>[{"thread_id"=>31, "name"=>nil, "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:90:in `read_batch'"}]}}
[2018-05-30T15:12:19,057][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"fb_apache", :directory=>"/usr/share/logstash/modules/fb_apache/configuration"}
[2018-05-30T15:12:19,065][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"netflow", :directory=>"/usr/share/logstash/modules/netflow/configuration"}
[2018-05-30T15:12:19,410][WARN ][logstash.config.source.multilocal] Ignoring the 'pipelines.yml' file because modules or command line options are specified
[2018-05-30T15:12:19,551][INFO ][logstash.runner          ] Starting Logstash {"logstash.version"=>"6.2.3"}
[2018-05-30T15:12:19,648][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=>9600}
[2018-05-30T15:12:20,534][INFO ][logstash.filters.ruby.script] Test run complete {:script_path=>"rubyfilter.rb", :results=>{:passed=>0, :failed=>0, :errored=>0}}
[2018-05-30T15:12:20,668][WARN ][logstash.outputs.elasticsearch] You are using a deprecated config setting "document_type" set in elasticsearch. Deprecated settings will continue to work, but are scheduled for removal from logstash in the future. Document types are being deprecated in Elasticsearch 6.0, and removed entirely in 7.0. You should avoid this feature If you have any questions about this, please visit the #logstash channel on freenode irc. {:name=>"document_type", :plugin=><LogStash::Outputs::ElasticSearch hosts=>[//100.100.100.111:9200, //100.100.100.112:9200, //100.100.100.113:9200], index=>"qa-enuri-main", document_type=>"_doc", document_id=>"%{id}", action=>"%{[@metadata][action]}", id=>"3b16bdd1680600ee9156ace46ed76a90d56bc1644736e9c91a7e57c052ab5c69", enable_metric=>true, codec=><LogStash::Codecs::Plain id=>"plain_c0bb3e9d-13c6-40b5-97f7-405a34d2bc6a", enable_metric=>true, charset=>"UTF-8">, workers=>1, manage_template=>true, template_name=>"logstash", template_overwrite=>false, doc_as_upsert=>false, script_type=>"inline", script_lang=>"painless", script_var_name=>"event", scripted_upsert=>false, retry_initial_interval=>2, retry_max_interval=>64, retry_on_conflict=>1, ssl_certificate_verification=>true, sniffing=>false, sniffing_delay=>5, timeout=>60, pool_max=>1000, pool_max_per_route=>100, resurrect_delay=>5, validate_after_inactivity=>10000, http_compression=>false>}
[2018-05-30T15:12:20,686][INFO ][logstash.pipeline        ] Starting pipeline {:pipeline_id=>"main", "pipeline.workers"=>8, "pipeline.batch.size"=>125, "pipeline.batch.delay"=>50}
[2018-05-30T15:12:20,950][INFO ][logstash.outputs.elasticsearch] Elasticsearch pool URLs updated {:changes=>{:removed=>[], :added=>[http://100.100.100.111:9200/, http://100.100.100.112:9200/, http://100.100.100.113:9200/]}}
[2018-05-30T15:12:20,954][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://100.100.100.111:9200/, :path=>"/"}
[2018-05-30T15:12:21,067][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://100.100.100.111:9200/"}
[2018-05-30T15:12:21,116][INFO ][logstash.outputs.elasticsearch] ES Output version determined {:es_version=>6}
[2018-05-30T15:12:21,116][WARN ][logstash.outputs.elasticsearch] Detected a 6.x and above cluster: the `type` event field won't be used to determine the document _type {:es_version=>6}
[2018-05-30T15:12:21,117][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://100.100.100.112:9200/, :path=>"/"}
[2018-05-30T15:12:21,123][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://100.100.100.112:9200/"}
[2018-05-30T15:12:21,128][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://100.100.100.113:9200/, :path=>"/"}
[2018-05-30T15:12:21,133][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://100.100.100.113:9200/"}
[2018-05-30T15:12:21,140][INFO ][logstash.outputs.elasticsearch] Using mapping template from {:path=>nil}
[2018-05-30T15:12:21,147][INFO ][logstash.outputs.elasticsearch] Attempting to install template {:manage_template=>{"template"=>"logstash-*", "version"=>60001, "settings"=>{"index.refresh_interval"=>"5s"}, "mappings"=>{"_default_"=>{"dynamic_templates"=>[{"message_field"=>{"path_match"=>"message", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false}}}, {"string_fields"=>{"match"=>"*", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false, "fields"=>{"keyword"=>{"type"=>"keyword", "ignore_above"=>256}}}}}], "properties"=>{"@timestamp"=>{"type"=>"date"}, "@version"=>{"type"=>"keyword"}, "geoip"=>{"dynamic"=>true, "properties"=>{"ip"=>{"type"=>"ip"}, "location"=>{"type"=>"geo_point"}, "latitude"=>{"type"=>"half_float"}, "longitude"=>{"type"=>"half_float"}}}}}}}}
[2018-05-30T15:12:21,155][INFO ][logstash.outputs.elasticsearch] New Elasticsearch output {:class=>"LogStash::Outputs::ElasticSearch", :hosts=>["//100.100.100.111:9200", "//100.100.100.112:9200", "//100.100.100.113:9200"]}
[2018-05-30T15:12:21,303][INFO ][logstash.pipeline        ] Pipeline started succesfully {:pipeline_id=>"main", :thread=>"#<Thread:0x61d59849@/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:246 sleep>"}
[2018-05-30T15:12:21,326][INFO ][logstash.agent           ] Pipelines running {:count=>1, :pipelines=>["main"]}
[2018-05-30T15:12:24,759][ERROR][logstash.inputs.jdbc     ] Unable to connect to database. Tried 1 times {:error_message=>"Java::JavaSql::SQLRecoverableException: IO Error: The Network Adapter could not establish the connection"}
[2018-05-30T15:12:24,766][ERROR][logstash.pipeline        ] A plugin had an unrecoverable error. Will restart this plugin.
  Pipeline_id:main
  Plugin: <LogStash::Inputs::Jdbc jdbc_driver_library=>"/etc/logstash/ojdbc6.jar", jdbc_driver_class=>"Java::oracle.jdbc.driver.OracleDriver", jdbc_connection_string=>"jdbc:oracle:thin:@100.100.100.225:1521:tenuri", jdbc_user=>"es_app", jdbc_password=><password>, jdbc_fetch_size=>10000, statement_filepath=>"as-is_search-log.sql", id=>"5bd7533661d97dbb4a1d2a6189513af0c10219fd73809280818346be344afa9b", enable_metric=>true, codec=><LogStash::Codecs::Plain id=>"plain_f3ac762d-4e2c-43ec-bdfd-dc1a40002f14", enable_metric=>true, charset=>"UTF-8">, jdbc_paging_enabled=>false, jdbc_page_size=>100000, jdbc_validate_connection=>false, jdbc_validation_timeout=>3600, jdbc_pool_timeout=>5, sql_log_level=>"info", connection_retry_attempts=>1, connection_retry_attempts_wait_time=>0.5, parameters=>{"sql_last_value"=>2018-05-30 09:22:03 +0900}, last_run_metadata_path=>"/home/elastic/.logstash_jdbc_last_run", use_column_value=>false, tracking_column_type=>"numeric", clean_run=>false, record_last_run=>true, lowercase_column_names=>true>
  Error: Java::JavaSql::SQLRecoverableException: IO Error: The Network Adapter could not establish the connection
  Exception: Sequel::DatabaseConnectionError
  Stack: oracle.jdbc.driver.T4CConnection.logon(oracle/jdbc/driver/T4CConnection.java:489)
oracle.jdbc.driver.PhysicalConnection.<init>(oracle/jdbc/driver/PhysicalConnection.java:553)
oracle.jdbc.driver.T4CConnection.<init>(oracle/jdbc/driver/T4CConnection.java:254)
oracle.jdbc.driver.T4CDriverExtension.getConnection(oracle/jdbc/driver/T4CDriverExtension.java:32)
oracle.jdbc.driver.OracleDriver.connect(oracle/jdbc/driver/OracleDriver.java:528)
java.lang.reflect.Method.invoke(java/lang/reflect/Method.java:498)
org.jruby.javasupport.JavaMethod.invokeDirectWithExceptionHandling(org/jruby/javasupport/JavaMethod.java:468)
org.jruby.javasupport.JavaMethod.invokeDirect(org/jruby/javasupport/JavaMethod.java:326)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/adapters/jdbc.rb:203)
RUBY.make_new(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool.rb:126)
RUBY.assign_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:192)
RUBY.acquire(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:133)
RUBY.hold(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:90)
RUBY.synchronize(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:269)
RUBY.test_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:279)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:58)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/core.rb:116)
RUBY.block in jdbc_connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:114)
org.jruby.RubyKernel.loop(org/jruby/RubyKernel.java:1292)
org.jruby.RubyKernel$INVOKER$s$0$0$loop.call(org/jruby/RubyKernel$INVOKER$s$0$0$loop.gen)
RUBY.jdbc_connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:111)
RUBY.open_jdbc_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:163)
RUBY.execute_statement(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:219)
RUBY.execute_query(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/inputs/jdbc.rb:264)
RUBY.run(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/inputs/jdbc.rb:250)
RUBY.inputworker(/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:516)
RUBY.block in start_input(/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:509)
org.jruby.RubyProc.call(org/jruby/RubyProc.java:289)
org.jruby.RubyProc.call(org/jruby/RubyProc.java:246)
java.lang.Thread.run(java/lang/Thread.java:748)
[2018-05-30T15:12:27,760][ERROR][logstash.inputs.jdbc     ] Unable to connect to database. Tried 1 times {:error_message=>"Java::JavaSql::SQLRecoverableException: IO Error: The Network Adapter could not establish the connection"}
[2018-05-30T15:12:27,767][ERROR][logstash.pipeline        ] A plugin had an unrecoverable error. Will restart this plugin.
  Pipeline_id:main
  Plugin: <LogStash::Inputs::Jdbc jdbc_driver_library=>"/etc/logstash/ojdbc6.jar", jdbc_driver_class=>"Java::oracle.jdbc.driver.OracleDriver", jdbc_connection_string=>"jdbc:oracle:thin:@100.100.100.225:1521:tenuri", jdbc_user=>"es_app", jdbc_password=><password>, jdbc_fetch_size=>10000, statement_filepath=>"as-is_search-log.sql", id=>"5bd7533661d97dbb4a1d2a6189513af0c10219fd73809280818346be344afa9b", enable_metric=>true, codec=><LogStash::Codecs::Plain id=>"plain_f3ac762d-4e2c-43ec-bdfd-dc1a40002f14", enable_metric=>true, charset=>"UTF-8">, jdbc_paging_enabled=>false, jdbc_page_size=>100000, jdbc_validate_connection=>false, jdbc_validation_timeout=>3600, jdbc_pool_timeout=>5, sql_log_level=>"info", connection_retry_attempts=>1, connection_retry_attempts_wait_time=>0.5, parameters=>{"sql_last_value"=>2018-05-30 09:22:03 +0900}, last_run_metadata_path=>"/home/elastic/.logstash_jdbc_last_run", use_column_value=>false, tracking_column_type=>"numeric", clean_run=>false, record_last_run=>true, lowercase_column_names=>true>
  Error: Java::JavaSql::SQLRecoverableException: IO Error: The Network Adapter could not establish the connection
  Exception: Sequel::DatabaseConnectionError
  Stack: oracle.jdbc.driver.T4CConnection.logon(oracle/jdbc/driver/T4CConnection.java:489)
oracle.jdbc.driver.PhysicalConnection.<init>(oracle/jdbc/driver/PhysicalConnection.java:553)
oracle.jdbc.driver.T4CConnection.<init>(oracle/jdbc/driver/T4CConnection.java:254)
oracle.jdbc.driver.T4CDriverExtension.getConnection(oracle/jdbc/driver/T4CDriverExtension.java:32)
oracle.jdbc.driver.OracleDriver.connect(oracle/jdbc/driver/OracleDriver.java:528)
java.lang.reflect.Method.invoke(java/lang/reflect/Method.java:498)
org.jruby.javasupport.JavaMethod.invokeDirectWithExceptionHandling(org/jruby/javasupport/JavaMethod.java:468)
org.jruby.javasupport.JavaMethod.invokeDirect(org/jruby/javasupport/JavaMethod.java:326)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/adapters/jdbc.rb:203)
RUBY.make_new(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool.rb:126)
RUBY.assign_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:192)
RUBY.acquire(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:133)
RUBY.hold(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:90)
RUBY.synchronize(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:269)
RUBY.test_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:279)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:58)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/core.rb:116)
RUBY.block in jdbc_connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:114)
org.jruby.RubyKernel.loop(org/jruby/RubyKernel.java:1292)
org.jruby.RubyKernel$INVOKER$s$0$0$loop.call(org/jruby/RubyKernel$INVOKER$s$0$0$loop.gen)
RUBY.jdbc_connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:111)
RUBY.open_jdbc_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:163)
RUBY.execute_statement(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:219)
RUBY.execute_query(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/inputs/jdbc.rb:264)
RUBY.run(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/inputs/jdbc.rb:250)
RUBY.inputworker(/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:516)
RUBY.block in start_input(/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:509)
org.jruby.RubyProc.call(org/jruby/RubyProc.java:289)
org.jruby.RubyProc.call(org/jruby/RubyProc.java:246)
java.lang.Thread.run(java/lang/Thread.java:748)
[2018-05-30T15:12:30,765][ERROR][logstash.inputs.jdbc     ] Unable to connect to database. Tried 1 times {:error_message=>"Java::JavaSql::SQLRecoverableException: IO Error: The Network Adapter could not establish the connection"}
[2018-05-30T15:12:30,769][ERROR][logstash.pipeline        ] A plugin had an unrecoverable error. Will restart this plugin.
  Pipeline_id:main
  Plugin: <LogStash::Inputs::Jdbc jdbc_driver_library=>"/etc/logstash/ojdbc6.jar", jdbc_driver_class=>"Java::oracle.jdbc.driver.OracleDriver", jdbc_connection_string=>"jdbc:oracle:thin:@100.100.100.225:1521:tenuri", jdbc_user=>"es_app", jdbc_password=><password>, jdbc_fetch_size=>10000, statement_filepath=>"as-is_search-log.sql", id=>"5bd7533661d97dbb4a1d2a6189513af0c10219fd73809280818346be344afa9b", enable_metric=>true, codec=><LogStash::Codecs::Plain id=>"plain_f3ac762d-4e2c-43ec-bdfd-dc1a40002f14", enable_metric=>true, charset=>"UTF-8">, jdbc_paging_enabled=>false, jdbc_page_size=>100000, jdbc_validate_connection=>false, jdbc_validation_timeout=>3600, jdbc_pool_timeout=>5, sql_log_level=>"info", connection_retry_attempts=>1, connection_retry_attempts_wait_time=>0.5, parameters=>{"sql_last_value"=>2018-05-30 09:22:03 +0900}, last_run_metadata_path=>"/home/elastic/.logstash_jdbc_last_run", use_column_value=>false, tracking_column_type=>"numeric", clean_run=>false, record_last_run=>true, lowercase_column_names=>true>
  Error: Java::JavaSql::SQLRecoverableException: IO Error: The Network Adapter could not establish the connection
  Exception: Sequel::DatabaseConnectionError
  Stack: oracle.jdbc.driver.T4CConnection.logon(oracle/jdbc/driver/T4CConnection.java:489)
oracle.jdbc.driver.PhysicalConnection.<init>(oracle/jdbc/driver/PhysicalConnection.java:553)
oracle.jdbc.driver.T4CConnection.<init>(oracle/jdbc/driver/T4CConnection.java:254)
oracle.jdbc.driver.T4CDriverExtension.getConnection(oracle/jdbc/driver/T4CDriverExtension.java:32)
oracle.jdbc.driver.OracleDriver.connect(oracle/jdbc/driver/OracleDriver.java:528)
java.lang.reflect.Method.invoke(java/lang/reflect/Method.java:498)
org.jruby.javasupport.JavaMethod.invokeDirectWithExceptionHandling(org/jruby/javasupport/JavaMethod.java:468)
org.jruby.javasupport.JavaMethod.invokeDirect(org/jruby/javasupport/JavaMethod.java:326)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/adapters/jdbc.rb:203)
RUBY.make_new(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool.rb:126)
RUBY.assign_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:192)
RUBY.acquire(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:133)
RUBY.hold(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:90)
RUBY.synchronize(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:269)
RUBY.test_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:279)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:58)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/core.rb:116)
RUBY.block in jdbc_connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:114)
org.jruby.RubyKernel.loop(org/jruby/RubyKernel.java:1292)
org.jruby.RubyKernel$INVOKER$s$0$0$loop.call(org/jruby/RubyKernel$INVOKER$s$0$0$loop.gen)
RUBY.jdbc_connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:111)
RUBY.open_jdbc_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:163)
RUBY.execute_statement(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:219)
RUBY.execute_query(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/inputs/jdbc.rb:264)
RUBY.run(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/inputs/jdbc.rb:250)
RUBY.inputworker(/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:516)
RUBY.block in start_input(/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:509)
org.jruby.RubyProc.call(org/jruby/RubyProc.java:289)
org.jruby.RubyProc.call(org/jruby/RubyProc.java:246)
java.lang.Thread.run(java/lang/Thread.java:748)
[2018-05-30T15:12:33,772][ERROR][logstash.inputs.jdbc     ] Unable to connect to database. Tried 1 times {:error_message=>"Java::JavaSql::SQLRecoverableException: IO Error: The Network Adapter could not establish the connection"}
[2018-05-30T15:12:33,776][ERROR][logstash.pipeline        ] A plugin had an unrecoverable error. Will restart this plugin.
  Pipeline_id:main
  Plugin: <LogStash::Inputs::Jdbc jdbc_driver_library=>"/etc/logstash/ojdbc6.jar", jdbc_driver_class=>"Java::oracle.jdbc.driver.OracleDriver", jdbc_connection_string=>"jdbc:oracle:thin:@100.100.100.225:1521:tenuri", jdbc_user=>"es_app", jdbc_password=><password>, jdbc_fetch_size=>10000, statement_filepath=>"as-is_search-log.sql", id=>"5bd7533661d97dbb4a1d2a6189513af0c10219fd73809280818346be344afa9b", enable_metric=>true, codec=><LogStash::Codecs::Plain id=>"plain_f3ac762d-4e2c-43ec-bdfd-dc1a40002f14", enable_metric=>true, charset=>"UTF-8">, jdbc_paging_enabled=>false, jdbc_page_size=>100000, jdbc_validate_connection=>false, jdbc_validation_timeout=>3600, jdbc_pool_timeout=>5, sql_log_level=>"info", connection_retry_attempts=>1, connection_retry_attempts_wait_time=>0.5, parameters=>{"sql_last_value"=>2018-05-30 09:22:03 +0900}, last_run_metadata_path=>"/home/elastic/.logstash_jdbc_last_run", use_column_value=>false, tracking_column_type=>"numeric", clean_run=>false, record_last_run=>true, lowercase_column_names=>true>
  Error: Java::JavaSql::SQLRecoverableException: IO Error: The Network Adapter could not establish the connection
  Exception: Sequel::DatabaseConnectionError
  Stack: oracle.jdbc.driver.T4CConnection.logon(oracle/jdbc/driver/T4CConnection.java:489)
oracle.jdbc.driver.PhysicalConnection.<init>(oracle/jdbc/driver/PhysicalConnection.java:553)
oracle.jdbc.driver.T4CConnection.<init>(oracle/jdbc/driver/T4CConnection.java:254)
oracle.jdbc.driver.T4CDriverExtension.getConnection(oracle/jdbc/driver/T4CDriverExtension.java:32)
oracle.jdbc.driver.OracleDriver.connect(oracle/jdbc/driver/OracleDriver.java:528)
java.lang.reflect.Method.invoke(java/lang/reflect/Method.java:498)
org.jruby.javasupport.JavaMethod.invokeDirectWithExceptionHandling(org/jruby/javasupport/JavaMethod.java:468)
org.jruby.javasupport.JavaMethod.invokeDirect(org/jruby/javasupport/JavaMethod.java:326)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/adapters/jdbc.rb:203)
RUBY.make_new(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool.rb:126)
RUBY.assign_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:192)
RUBY.acquire(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:133)
RUBY.hold(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:90)
RUBY.synchronize(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:269)
RUBY.test_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:279)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:58)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/core.rb:116)
RUBY.block in jdbc_connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:114)
org.jruby.RubyKernel.loop(org/jruby/RubyKernel.java:1292)
org.jruby.RubyKernel$INVOKER$s$0$0$loop.call(org/jruby/RubyKernel$INVOKER$s$0$0$loop.gen)
RUBY.jdbc_connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:111)
RUBY.open_jdbc_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:163)
RUBY.execute_statement(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:219)
RUBY.execute_query(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/inputs/jdbc.rb:264)
RUBY.run(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/inputs/jdbc.rb:250)
RUBY.inputworker(/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:516)
RUBY.block in start_input(/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:509)
org.jruby.RubyProc.call(org/jruby/RubyProc.java:289)
org.jruby.RubyProc.call(org/jruby/RubyProc.java:246)
java.lang.Thread.run(java/lang/Thread.java:748)
[2018-05-30T15:12:36,779][ERROR][logstash.inputs.jdbc     ] Unable to connect to database. Tried 1 times {:error_message=>"Java::JavaSql::SQLRecoverableException: IO Error: The Network Adapter could not establish the connection"}
[2018-05-30T15:12:36,782][ERROR][logstash.pipeline        ] A plugin had an unrecoverable error. Will restart this plugin.
  Pipeline_id:main
  Plugin: <LogStash::Inputs::Jdbc jdbc_driver_library=>"/etc/logstash/ojdbc6.jar", jdbc_driver_class=>"Java::oracle.jdbc.driver.OracleDriver", jdbc_connection_string=>"jdbc:oracle:thin:@100.100.100.225:1521:tenuri", jdbc_user=>"es_app", jdbc_password=><password>, jdbc_fetch_size=>10000, statement_filepath=>"as-is_search-log.sql", id=>"5bd7533661d97dbb4a1d2a6189513af0c10219fd73809280818346be344afa9b", enable_metric=>true, codec=><LogStash::Codecs::Plain id=>"plain_f3ac762d-4e2c-43ec-bdfd-dc1a40002f14", enable_metric=>true, charset=>"UTF-8">, jdbc_paging_enabled=>false, jdbc_page_size=>100000, jdbc_validate_connection=>false, jdbc_validation_timeout=>3600, jdbc_pool_timeout=>5, sql_log_level=>"info", connection_retry_attempts=>1, connection_retry_attempts_wait_time=>0.5, parameters=>{"sql_last_value"=>2018-05-30 09:22:03 +0900}, last_run_metadata_path=>"/home/elastic/.logstash_jdbc_last_run", use_column_value=>false, tracking_column_type=>"numeric", clean_run=>false, record_last_run=>true, lowercase_column_names=>true>
  Error: Java::JavaSql::SQLRecoverableException: IO Error: The Network Adapter could not establish the connection
  Exception: Sequel::DatabaseConnectionError
  Stack: oracle.jdbc.driver.T4CConnection.logon(oracle/jdbc/driver/T4CConnection.java:489)
oracle.jdbc.driver.PhysicalConnection.<init>(oracle/jdbc/driver/PhysicalConnection.java:553)
oracle.jdbc.driver.T4CConnection.<init>(oracle/jdbc/driver/T4CConnection.java:254)
oracle.jdbc.driver.T4CDriverExtension.getConnection(oracle/jdbc/driver/T4CDriverExtension.java:32)
oracle.jdbc.driver.OracleDriver.connect(oracle/jdbc/driver/OracleDriver.java:528)
java.lang.reflect.Method.invoke(java/lang/reflect/Method.java:498)
org.jruby.javasupport.JavaMethod.invokeDirectWithExceptionHandling(org/jruby/javasupport/JavaMethod.java:468)
org.jruby.javasupport.JavaMethod.invokeDirect(org/jruby/javasupport/JavaMethod.java:326)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/adapters/jdbc.rb:203)
RUBY.make_new(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool.rb:126)
RUBY.assign_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:192)
RUBY.acquire(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:133)
RUBY.hold(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:90)
RUBY.synchronize(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:269)
RUBY.test_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:279)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:58)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/core.rb:116)
RUBY.block in jdbc_connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:114)
org.jruby.RubyKernel.loop(org/jruby/RubyKernel.java:1292)
org.jruby.RubyKernel$INVOKER$s$0$0$loop.call(org/jruby/RubyKernel$INVOKER$s$0$0$loop.gen)
RUBY.jdbc_connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:111)
RUBY.open_jdbc_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:163)
RUBY.execute_statement(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:219)
RUBY.execute_query(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/inputs/jdbc.rb:264)
RUBY.run(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/inputs/jdbc.rb:250)
RUBY.inputworker(/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:516)
RUBY.block in start_input(/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:509)
org.jruby.RubyProc.call(org/jruby/RubyProc.java:289)
org.jruby.RubyProc.call(org/jruby/RubyProc.java:246)
java.lang.Thread.run(java/lang/Thread.java:748)
[2018-05-30T15:12:39,783][ERROR][logstash.inputs.jdbc     ] Unable to connect to database. Tried 1 times {:error_message=>"Java::JavaSql::SQLRecoverableException: IO Error: The Network Adapter could not establish the connection"}
[2018-05-30T15:12:39,786][ERROR][logstash.pipeline        ] A plugin had an unrecoverable error. Will restart this plugin.
  Pipeline_id:main
  Plugin: <LogStash::Inputs::Jdbc jdbc_driver_library=>"/etc/logstash/ojdbc6.jar", jdbc_driver_class=>"Java::oracle.jdbc.driver.OracleDriver", jdbc_connection_string=>"jdbc:oracle:thin:@100.100.100.225:1521:tenuri", jdbc_user=>"es_app", jdbc_password=><password>, jdbc_fetch_size=>10000, statement_filepath=>"as-is_search-log.sql", id=>"5bd7533661d97dbb4a1d2a6189513af0c10219fd73809280818346be344afa9b", enable_metric=>true, codec=><LogStash::Codecs::Plain id=>"plain_f3ac762d-4e2c-43ec-bdfd-dc1a40002f14", enable_metric=>true, charset=>"UTF-8">, jdbc_paging_enabled=>false, jdbc_page_size=>100000, jdbc_validate_connection=>false, jdbc_validation_timeout=>3600, jdbc_pool_timeout=>5, sql_log_level=>"info", connection_retry_attempts=>1, connection_retry_attempts_wait_time=>0.5, parameters=>{"sql_last_value"=>2018-05-30 09:22:03 +0900}, last_run_metadata_path=>"/home/elastic/.logstash_jdbc_last_run", use_column_value=>false, tracking_column_type=>"numeric", clean_run=>false, record_last_run=>true, lowercase_column_names=>true>
  Error: Java::JavaSql::SQLRecoverableException: IO Error: The Network Adapter could not establish the connection
  Exception: Sequel::DatabaseConnectionError
  Stack: oracle.jdbc.driver.T4CConnection.logon(oracle/jdbc/driver/T4CConnection.java:489)
oracle.jdbc.driver.PhysicalConnection.<init>(oracle/jdbc/driver/PhysicalConnection.java:553)
oracle.jdbc.driver.T4CConnection.<init>(oracle/jdbc/driver/T4CConnection.java:254)
oracle.jdbc.driver.T4CDriverExtension.getConnection(oracle/jdbc/driver/T4CDriverExtension.java:32)
oracle.jdbc.driver.OracleDriver.connect(oracle/jdbc/driver/OracleDriver.java:528)
java.lang.reflect.Method.invoke(java/lang/reflect/Method.java:498)
org.jruby.javasupport.JavaMethod.invokeDirectWithExceptionHandling(org/jruby/javasupport/JavaMethod.java:468)
org.jruby.javasupport.JavaMethod.invokeDirect(org/jruby/javasupport/JavaMethod.java:326)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/adapters/jdbc.rb:203)
RUBY.make_new(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool.rb:126)
RUBY.assign_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:192)
RUBY.acquire(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:133)
RUBY.hold(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:90)
RUBY.synchronize(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:269)
RUBY.test_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:279)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:58)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/core.rb:116)
RUBY.block in jdbc_connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:114)
org.jruby.RubyKernel.loop(org/jruby/RubyKernel.java:1292)
org.jruby.RubyKernel$INVOKER$s$0$0$loop.call(org/jruby/RubyKernel$INVOKER$s$0$0$loop.gen)
RUBY.jdbc_connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:111)
RUBY.open_jdbc_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:163)
RUBY.execute_statement(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:219)
RUBY.execute_query(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/inputs/jdbc.rb:264)
RUBY.run(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/inputs/jdbc.rb:250)
RUBY.inputworker(/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:516)
RUBY.block in start_input(/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:509)
org.jruby.RubyProc.call(org/jruby/RubyProc.java:289)
org.jruby.RubyProc.call(org/jruby/RubyProc.java:246)
java.lang.Thread.run(java/lang/Thread.java:748)
[2018-05-30T15:12:42,789][ERROR][logstash.inputs.jdbc     ] Unable to connect to database. Tried 1 times {:error_message=>"Java::JavaSql::SQLRecoverableException: IO Error: The Network Adapter could not establish the connection"}
[2018-05-30T15:12:42,793][ERROR][logstash.pipeline        ] A plugin had an unrecoverable error. Will restart this plugin.
  Pipeline_id:main
  Plugin: <LogStash::Inputs::Jdbc jdbc_driver_library=>"/etc/logstash/ojdbc6.jar", jdbc_driver_class=>"Java::oracle.jdbc.driver.OracleDriver", jdbc_connection_string=>"jdbc:oracle:thin:@100.100.100.225:1521:tenuri", jdbc_user=>"es_app", jdbc_password=><password>, jdbc_fetch_size=>10000, statement_filepath=>"as-is_search-log.sql", id=>"5bd7533661d97dbb4a1d2a6189513af0c10219fd73809280818346be344afa9b", enable_metric=>true, codec=><LogStash::Codecs::Plain id=>"plain_f3ac762d-4e2c-43ec-bdfd-dc1a40002f14", enable_metric=>true, charset=>"UTF-8">, jdbc_paging_enabled=>false, jdbc_page_size=>100000, jdbc_validate_connection=>false, jdbc_validation_timeout=>3600, jdbc_pool_timeout=>5, sql_log_level=>"info", connection_retry_attempts=>1, connection_retry_attempts_wait_time=>0.5, parameters=>{"sql_last_value"=>2018-05-30 09:22:03 +0900}, last_run_metadata_path=>"/home/elastic/.logstash_jdbc_last_run", use_column_value=>false, tracking_column_type=>"numeric", clean_run=>false, record_last_run=>true, lowercase_column_names=>true>
  Error: Java::JavaSql::SQLRecoverableException: IO Error: The Network Adapter could not establish the connection
  Exception: Sequel::DatabaseConnectionError
  Stack: oracle.jdbc.driver.T4CConnection.logon(oracle/jdbc/driver/T4CConnection.java:489)
oracle.jdbc.driver.PhysicalConnection.<init>(oracle/jdbc/driver/PhysicalConnection.java:553)
oracle.jdbc.driver.T4CConnection.<init>(oracle/jdbc/driver/T4CConnection.java:254)
oracle.jdbc.driver.T4CDriverExtension.getConnection(oracle/jdbc/driver/T4CDriverExtension.java:32)
oracle.jdbc.driver.OracleDriver.connect(oracle/jdbc/driver/OracleDriver.java:528)
java.lang.reflect.Method.invoke(java/lang/reflect/Method.java:498)
org.jruby.javasupport.JavaMethod.invokeDirectWithExceptionHandling(org/jruby/javasupport/JavaMethod.java:468)
org.jruby.javasupport.JavaMethod.invokeDirect(org/jruby/javasupport/JavaMethod.java:326)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/adapters/jdbc.rb:203)
RUBY.make_new(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool.rb:126)
RUBY.assign_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:192)
RUBY.acquire(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:133)
RUBY.hold(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:90)
RUBY.synchronize(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:269)
RUBY.test_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:279)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:58)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/core.rb:116)
RUBY.block in jdbc_connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:114)
org.jruby.RubyKernel.loop(org/jruby/RubyKernel.java:1292)
org.jruby.RubyKernel$INVOKER$s$0$0$loop.call(org/jruby/RubyKernel$INVOKER$s$0$0$loop.gen)
RUBY.jdbc_connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:111)
RUBY.open_jdbc_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:163)
RUBY.execute_statement(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:219)
RUBY.execute_query(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/inputs/jdbc.rb:264)
RUBY.run(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/inputs/jdbc.rb:250)
RUBY.inputworker(/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:516)
RUBY.block in start_input(/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:509)
org.jruby.RubyProc.call(org/jruby/RubyProc.java:289)
org.jruby.RubyProc.call(org/jruby/RubyProc.java:246)
java.lang.Thread.run(java/lang/Thread.java:748)
[2018-05-30T15:12:45,795][ERROR][logstash.inputs.jdbc     ] Unable to connect to database. Tried 1 times {:error_message=>"Java::JavaSql::SQLRecoverableException: IO Error: The Network Adapter could not establish the connection"}
[2018-05-30T15:12:45,798][ERROR][logstash.pipeline        ] A plugin had an unrecoverable error. Will restart this plugin.
  Pipeline_id:main
  Plugin: <LogStash::Inputs::Jdbc jdbc_driver_library=>"/etc/logstash/ojdbc6.jar", jdbc_driver_class=>"Java::oracle.jdbc.driver.OracleDriver", jdbc_connection_string=>"jdbc:oracle:thin:@100.100.100.225:1521:tenuri", jdbc_user=>"es_app", jdbc_password=><password>, jdbc_fetch_size=>10000, statement_filepath=>"as-is_search-log.sql", id=>"5bd7533661d97dbb4a1d2a6189513af0c10219fd73809280818346be344afa9b", enable_metric=>true, codec=><LogStash::Codecs::Plain id=>"plain_f3ac762d-4e2c-43ec-bdfd-dc1a40002f14", enable_metric=>true, charset=>"UTF-8">, jdbc_paging_enabled=>false, jdbc_page_size=>100000, jdbc_validate_connection=>false, jdbc_validation_timeout=>3600, jdbc_pool_timeout=>5, sql_log_level=>"info", connection_retry_attempts=>1, connection_retry_attempts_wait_time=>0.5, parameters=>{"sql_last_value"=>2018-05-30 09:22:03 +0900}, last_run_metadata_path=>"/home/elastic/.logstash_jdbc_last_run", use_column_value=>false, tracking_column_type=>"numeric", clean_run=>false, record_last_run=>true, lowercase_column_names=>true>
  Error: Java::JavaSql::SQLRecoverableException: IO Error: The Network Adapter could not establish the connection
  Exception: Sequel::DatabaseConnectionError
  Stack: oracle.jdbc.driver.T4CConnection.logon(oracle/jdbc/driver/T4CConnection.java:489)
oracle.jdbc.driver.PhysicalConnection.<init>(oracle/jdbc/driver/PhysicalConnection.java:553)
oracle.jdbc.driver.T4CConnection.<init>(oracle/jdbc/driver/T4CConnection.java:254)
oracle.jdbc.driver.T4CDriverExtension.getConnection(oracle/jdbc/driver/T4CDriverExtension.java:32)
oracle.jdbc.driver.OracleDriver.connect(oracle/jdbc/driver/OracleDriver.java:528)
java.lang.reflect.Method.invoke(java/lang/reflect/Method.java:498)
org.jruby.javasupport.JavaMethod.invokeDirectWithExceptionHandling(org/jruby/javasupport/JavaMethod.java:468)
org.jruby.javasupport.JavaMethod.invokeDirect(org/jruby/javasupport/JavaMethod.java:326)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/adapters/jdbc.rb:203)
RUBY.make_new(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool.rb:126)
RUBY.assign_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:192)
RUBY.acquire(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:133)
RUBY.hold(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:90)
RUBY.synchronize(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:269)
RUBY.test_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:279)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:58)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/core.rb:116)
RUBY.block in jdbc_connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:114)
org.jruby.RubyKernel.loop(org/jruby/RubyKernel.java:1292)
org.jruby.RubyKernel$INVOKER$s$0$0$loop.call(org/jruby/RubyKernel$INVOKER$s$0$0$loop.gen)
RUBY.jdbc_connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:111)
RUBY.open_jdbc_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:163)
RUBY.execute_statement(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:219)
RUBY.execute_query(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/inputs/jdbc.rb:264)
RUBY.run(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/inputs/jdbc.rb:250)
RUBY.inputworker(/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:516)
RUBY.block in start_input(/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:509)
org.jruby.RubyProc.call(org/jruby/RubyProc.java:289)
org.jruby.RubyProc.call(org/jruby/RubyProc.java:246)
java.lang.Thread.run(java/lang/Thread.java:748)
[2018-05-30T15:12:48,801][ERROR][logstash.inputs.jdbc     ] Unable to connect to database. Tried 1 times {:error_message=>"Java::JavaSql::SQLRecoverableException: IO Error: The Network Adapter could not establish the connection"}
[2018-05-30T15:12:48,804][ERROR][logstash.pipeline        ] A plugin had an unrecoverable error. Will restart this plugin.
  Pipeline_id:main
  Plugin: <LogStash::Inputs::Jdbc jdbc_driver_library=>"/etc/logstash/ojdbc6.jar", jdbc_driver_class=>"Java::oracle.jdbc.driver.OracleDriver", jdbc_connection_string=>"jdbc:oracle:thin:@100.100.100.225:1521:tenuri", jdbc_user=>"es_app", jdbc_password=><password>, jdbc_fetch_size=>10000, statement_filepath=>"as-is_search-log.sql", id=>"5bd7533661d97dbb4a1d2a6189513af0c10219fd73809280818346be344afa9b", enable_metric=>true, codec=><LogStash::Codecs::Plain id=>"plain_f3ac762d-4e2c-43ec-bdfd-dc1a40002f14", enable_metric=>true, charset=>"UTF-8">, jdbc_paging_enabled=>false, jdbc_page_size=>100000, jdbc_validate_connection=>false, jdbc_validation_timeout=>3600, jdbc_pool_timeout=>5, sql_log_level=>"info", connection_retry_attempts=>1, connection_retry_attempts_wait_time=>0.5, parameters=>{"sql_last_value"=>2018-05-30 09:22:03 +0900}, last_run_metadata_path=>"/home/elastic/.logstash_jdbc_last_run", use_column_value=>false, tracking_column_type=>"numeric", clean_run=>false, record_last_run=>true, lowercase_column_names=>true>
  Error: Java::JavaSql::SQLRecoverableException: IO Error: The Network Adapter could not establish the connection
  Exception: Sequel::DatabaseConnectionError
  Stack: oracle.jdbc.driver.T4CConnection.logon(oracle/jdbc/driver/T4CConnection.java:489)
oracle.jdbc.driver.PhysicalConnection.<init>(oracle/jdbc/driver/PhysicalConnection.java:553)
oracle.jdbc.driver.T4CConnection.<init>(oracle/jdbc/driver/T4CConnection.java:254)
oracle.jdbc.driver.T4CDriverExtension.getConnection(oracle/jdbc/driver/T4CDriverExtension.java:32)
oracle.jdbc.driver.OracleDriver.connect(oracle/jdbc/driver/OracleDriver.java:528)
java.lang.reflect.Method.invoke(java/lang/reflect/Method.java:498)
org.jruby.javasupport.JavaMethod.invokeDirectWithExceptionHandling(org/jruby/javasupport/JavaMethod.java:468)
org.jruby.javasupport.JavaMethod.invokeDirect(org/jruby/javasupport/JavaMethod.java:326)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/adapters/jdbc.rb:203)
RUBY.make_new(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool.rb:126)
RUBY.assign_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:192)
RUBY.acquire(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:133)
RUBY.hold(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:90)
RUBY.synchronize(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:269)
RUBY.test_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:279)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:58)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/core.rb:116)
RUBY.block in jdbc_connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:114)
org.jruby.RubyKernel.loop(org/jruby/RubyKernel.java:1292)
org.jruby.RubyKernel$INVOKER$s$0$0$loop.call(org/jruby/RubyKernel$INVOKER$s$0$0$loop.gen)
RUBY.jdbc_connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:111)
RUBY.open_jdbc_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:163)
RUBY.execute_statement(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:219)
RUBY.execute_query(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/inputs/jdbc.rb:264)
RUBY.run(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/inputs/jdbc.rb:250)
RUBY.inputworker(/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:516)
RUBY.block in start_input(/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:509)
org.jruby.RubyProc.call(org/jruby/RubyProc.java:289)
org.jruby.RubyProc.call(org/jruby/RubyProc.java:246)
java.lang.Thread.run(java/lang/Thread.java:748)
[2018-05-30T15:12:51,807][ERROR][logstash.inputs.jdbc     ] Unable to connect to database. Tried 1 times {:error_message=>"Java::JavaSql::SQLRecoverableException: IO Error: The Network Adapter could not establish the connection"}
[2018-05-30T15:12:51,813][ERROR][logstash.pipeline        ] A plugin had an unrecoverable error. Will restart this plugin.
  Pipeline_id:main
  Plugin: <LogStash::Inputs::Jdbc jdbc_driver_library=>"/etc/logstash/ojdbc6.jar", jdbc_driver_class=>"Java::oracle.jdbc.driver.OracleDriver", jdbc_connection_string=>"jdbc:oracle:thin:@100.100.100.225:1521:tenuri", jdbc_user=>"es_app", jdbc_password=><password>, jdbc_fetch_size=>10000, statement_filepath=>"as-is_search-log.sql", id=>"5bd7533661d97dbb4a1d2a6189513af0c10219fd73809280818346be344afa9b", enable_metric=>true, codec=><LogStash::Codecs::Plain id=>"plain_f3ac762d-4e2c-43ec-bdfd-dc1a40002f14", enable_metric=>true, charset=>"UTF-8">, jdbc_paging_enabled=>false, jdbc_page_size=>100000, jdbc_validate_connection=>false, jdbc_validation_timeout=>3600, jdbc_pool_timeout=>5, sql_log_level=>"info", connection_retry_attempts=>1, connection_retry_attempts_wait_time=>0.5, parameters=>{"sql_last_value"=>2018-05-30 09:22:03 +0900}, last_run_metadata_path=>"/home/elastic/.logstash_jdbc_last_run", use_column_value=>false, tracking_column_type=>"numeric", clean_run=>false, record_last_run=>true, lowercase_column_names=>true>
  Error: Java::JavaSql::SQLRecoverableException: IO Error: The Network Adapter could not establish the connection
  Exception: Sequel::DatabaseConnectionError
  Stack: oracle.jdbc.driver.T4CConnection.logon(oracle/jdbc/driver/T4CConnection.java:489)
oracle.jdbc.driver.PhysicalConnection.<init>(oracle/jdbc/driver/PhysicalConnection.java:553)
oracle.jdbc.driver.T4CConnection.<init>(oracle/jdbc/driver/T4CConnection.java:254)
oracle.jdbc.driver.T4CDriverExtension.getConnection(oracle/jdbc/driver/T4CDriverExtension.java:32)
oracle.jdbc.driver.OracleDriver.connect(oracle/jdbc/driver/OracleDriver.java:528)
java.lang.reflect.Method.invoke(java/lang/reflect/Method.java:498)
org.jruby.javasupport.JavaMethod.invokeDirectWithExceptionHandling(org/jruby/javasupport/JavaMethod.java:468)
org.jruby.javasupport.JavaMethod.invokeDirect(org/jruby/javasupport/JavaMethod.java:326)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/adapters/jdbc.rb:203)
RUBY.make_new(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool.rb:126)
RUBY.assign_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:192)
RUBY.acquire(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:133)
RUBY.hold(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:90)
RUBY.synchronize(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:269)
RUBY.test_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:279)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:58)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/core.rb:116)
RUBY.block in jdbc_connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:114)
org.jruby.RubyKernel.loop(org/jruby/RubyKernel.java:1292)
org.jruby.RubyKernel$INVOKER$s$0$0$loop.call(org/jruby/RubyKernel$INVOKER$s$0$0$loop.gen)
RUBY.jdbc_connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:111)
RUBY.open_jdbc_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:163)
RUBY.execute_statement(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:219)
RUBY.execute_query(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/inputs/jdbc.rb:264)
RUBY.run(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/inputs/jdbc.rb:250)
RUBY.inputworker(/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:516)
RUBY.block in start_input(/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:509)
org.jruby.RubyProc.call(org/jruby/RubyProc.java:289)
org.jruby.RubyProc.call(org/jruby/RubyProc.java:246)
java.lang.Thread.run(java/lang/Thread.java:748)
[2018-05-30T15:12:54,812][ERROR][logstash.inputs.jdbc     ] Unable to connect to database. Tried 1 times {:error_message=>"Java::JavaSql::SQLRecoverableException: IO Error: The Network Adapter could not establish the connection"}
[2018-05-30T15:12:54,815][ERROR][logstash.pipeline        ] A plugin had an unrecoverable error. Will restart this plugin.
  Pipeline_id:main
  Plugin: <LogStash::Inputs::Jdbc jdbc_driver_library=>"/etc/logstash/ojdbc6.jar", jdbc_driver_class=>"Java::oracle.jdbc.driver.OracleDriver", jdbc_connection_string=>"jdbc:oracle:thin:@100.100.100.225:1521:tenuri", jdbc_user=>"es_app", jdbc_password=><password>, jdbc_fetch_size=>10000, statement_filepath=>"as-is_search-log.sql", id=>"5bd7533661d97dbb4a1d2a6189513af0c10219fd73809280818346be344afa9b", enable_metric=>true, codec=><LogStash::Codecs::Plain id=>"plain_f3ac762d-4e2c-43ec-bdfd-dc1a40002f14", enable_metric=>true, charset=>"UTF-8">, jdbc_paging_enabled=>false, jdbc_page_size=>100000, jdbc_validate_connection=>false, jdbc_validation_timeout=>3600, jdbc_pool_timeout=>5, sql_log_level=>"info", connection_retry_attempts=>1, connection_retry_attempts_wait_time=>0.5, parameters=>{"sql_last_value"=>2018-05-30 09:22:03 +0900}, last_run_metadata_path=>"/home/elastic/.logstash_jdbc_last_run", use_column_value=>false, tracking_column_type=>"numeric", clean_run=>false, record_last_run=>true, lowercase_column_names=>true>
  Error: Java::JavaSql::SQLRecoverableException: IO Error: The Network Adapter could not establish the connection
  Exception: Sequel::DatabaseConnectionError
  Stack: oracle.jdbc.driver.T4CConnection.logon(oracle/jdbc/driver/T4CConnection.java:489)
oracle.jdbc.driver.PhysicalConnection.<init>(oracle/jdbc/driver/PhysicalConnection.java:553)
oracle.jdbc.driver.T4CConnection.<init>(oracle/jdbc/driver/T4CConnection.java:254)
oracle.jdbc.driver.T4CDriverExtension.getConnection(oracle/jdbc/driver/T4CDriverExtension.java:32)
oracle.jdbc.driver.OracleDriver.connect(oracle/jdbc/driver/OracleDriver.java:528)
java.lang.reflect.Method.invoke(java/lang/reflect/Method.java:498)
org.jruby.javasupport.JavaMethod.invokeDirectWithExceptionHandling(org/jruby/javasupport/JavaMethod.java:468)
org.jruby.javasupport.JavaMethod.invokeDirect(org/jruby/javasupport/JavaMethod.java:326)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/adapters/jdbc.rb:203)
RUBY.make_new(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool.rb:126)
RUBY.assign_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:192)
RUBY.acquire(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:133)
RUBY.hold(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:90)
RUBY.synchronize(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:269)
RUBY.test_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:279)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:58)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/core.rb:116)
RUBY.block in jdbc_connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:114)
org.jruby.RubyKernel.loop(org/jruby/RubyKernel.java:1292)
org.jruby.RubyKernel$INVOKER$s$0$0$loop.call(org/jruby/RubyKernel$INVOKER$s$0$0$loop.gen)
RUBY.jdbc_connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:111)
RUBY.open_jdbc_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:163)
RUBY.execute_statement(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:219)
RUBY.execute_query(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/inputs/jdbc.rb:264)
RUBY.run(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/inputs/jdbc.rb:250)
RUBY.inputworker(/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:516)
RUBY.block in start_input(/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:509)
org.jruby.RubyProc.call(org/jruby/RubyProc.java:289)
org.jruby.RubyProc.call(org/jruby/RubyProc.java:246)
java.lang.Thread.run(java/lang/Thread.java:748)
[2018-05-30T15:12:57,818][ERROR][logstash.inputs.jdbc     ] Unable to connect to database. Tried 1 times {:error_message=>"Java::JavaSql::SQLRecoverableException: IO Error: The Network Adapter could not establish the connection"}
[2018-05-30T15:12:57,820][ERROR][logstash.pipeline        ] A plugin had an unrecoverable error. Will restart this plugin.
  Pipeline_id:main
  Plugin: <LogStash::Inputs::Jdbc jdbc_driver_library=>"/etc/logstash/ojdbc6.jar", jdbc_driver_class=>"Java::oracle.jdbc.driver.OracleDriver", jdbc_connection_string=>"jdbc:oracle:thin:@100.100.100.225:1521:tenuri", jdbc_user=>"es_app", jdbc_password=><password>, jdbc_fetch_size=>10000, statement_filepath=>"as-is_search-log.sql", id=>"5bd7533661d97dbb4a1d2a6189513af0c10219fd73809280818346be344afa9b", enable_metric=>true, codec=><LogStash::Codecs::Plain id=>"plain_f3ac762d-4e2c-43ec-bdfd-dc1a40002f14", enable_metric=>true, charset=>"UTF-8">, jdbc_paging_enabled=>false, jdbc_page_size=>100000, jdbc_validate_connection=>false, jdbc_validation_timeout=>3600, jdbc_pool_timeout=>5, sql_log_level=>"info", connection_retry_attempts=>1, connection_retry_attempts_wait_time=>0.5, parameters=>{"sql_last_value"=>2018-05-30 09:22:03 +0900}, last_run_metadata_path=>"/home/elastic/.logstash_jdbc_last_run", use_column_value=>false, tracking_column_type=>"numeric", clean_run=>false, record_last_run=>true, lowercase_column_names=>true>
  Error: Java::JavaSql::SQLRecoverableException: IO Error: The Network Adapter could not establish the connection
  Exception: Sequel::DatabaseConnectionError
  Stack: oracle.jdbc.driver.T4CConnection.logon(oracle/jdbc/driver/T4CConnection.java:489)
oracle.jdbc.driver.PhysicalConnection.<init>(oracle/jdbc/driver/PhysicalConnection.java:553)
oracle.jdbc.driver.T4CConnection.<init>(oracle/jdbc/driver/T4CConnection.java:254)
oracle.jdbc.driver.T4CDriverExtension.getConnection(oracle/jdbc/driver/T4CDriverExtension.java:32)
oracle.jdbc.driver.OracleDriver.connect(oracle/jdbc/driver/OracleDriver.java:528)
java.lang.reflect.Method.invoke(java/lang/reflect/Method.java:498)
org.jruby.javasupport.JavaMethod.invokeDirectWithExceptionHandling(org/jruby/javasupport/JavaMethod.java:468)
org.jruby.javasupport.JavaMethod.invokeDirect(org/jruby/javasupport/JavaMethod.java:326)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/adapters/jdbc.rb:203)
RUBY.make_new(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool.rb:126)
RUBY.assign_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:192)
RUBY.acquire(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:133)
RUBY.hold(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:90)
RUBY.synchronize(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:269)
RUBY.test_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:279)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:58)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/core.rb:116)
RUBY.block in jdbc_connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:114)
org.jruby.RubyKernel.loop(org/jruby/RubyKernel.java:1292)
org.jruby.RubyKernel$INVOKER$s$0$0$loop.call(org/jruby/RubyKernel$INVOKER$s$0$0$loop.gen)
RUBY.jdbc_connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:111)
RUBY.open_jdbc_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:163)
RUBY.execute_statement(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:219)
RUBY.execute_query(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/inputs/jdbc.rb:264)
RUBY.run(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/inputs/jdbc.rb:250)
RUBY.inputworker(/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:516)
RUBY.block in start_input(/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:509)
org.jruby.RubyProc.call(org/jruby/RubyProc.java:289)
org.jruby.RubyProc.call(org/jruby/RubyProc.java:246)
java.lang.Thread.run(java/lang/Thread.java:748)
[2018-05-30T15:13:00,825][ERROR][logstash.inputs.jdbc     ] Unable to connect to database. Tried 1 times {:error_message=>"Java::JavaSql::SQLRecoverableException: IO Error: The Network Adapter could not establish the connection"}
[2018-05-30T15:13:00,829][ERROR][logstash.pipeline        ] A plugin had an unrecoverable error. Will restart this plugin.
  Pipeline_id:main
  Plugin: <LogStash::Inputs::Jdbc jdbc_driver_library=>"/etc/logstash/ojdbc6.jar", jdbc_driver_class=>"Java::oracle.jdbc.driver.OracleDriver", jdbc_connection_string=>"jdbc:oracle:thin:@100.100.100.225:1521:tenuri", jdbc_user=>"es_app", jdbc_password=><password>, jdbc_fetch_size=>10000, statement_filepath=>"as-is_search-log.sql", id=>"5bd7533661d97dbb4a1d2a6189513af0c10219fd73809280818346be344afa9b", enable_metric=>true, codec=><LogStash::Codecs::Plain id=>"plain_f3ac762d-4e2c-43ec-bdfd-dc1a40002f14", enable_metric=>true, charset=>"UTF-8">, jdbc_paging_enabled=>false, jdbc_page_size=>100000, jdbc_validate_connection=>false, jdbc_validation_timeout=>3600, jdbc_pool_timeout=>5, sql_log_level=>"info", connection_retry_attempts=>1, connection_retry_attempts_wait_time=>0.5, parameters=>{"sql_last_value"=>2018-05-30 09:22:03 +0900}, last_run_metadata_path=>"/home/elastic/.logstash_jdbc_last_run", use_column_value=>false, tracking_column_type=>"numeric", clean_run=>false, record_last_run=>true, lowercase_column_names=>true>
  Error: Java::JavaSql::SQLRecoverableException: IO Error: The Network Adapter could not establish the connection
  Exception: Sequel::DatabaseConnectionError
  Stack: oracle.jdbc.driver.T4CConnection.logon(oracle/jdbc/driver/T4CConnection.java:489)
oracle.jdbc.driver.PhysicalConnection.<init>(oracle/jdbc/driver/PhysicalConnection.java:553)
oracle.jdbc.driver.T4CConnection.<init>(oracle/jdbc/driver/T4CConnection.java:254)
oracle.jdbc.driver.T4CDriverExtension.getConnection(oracle/jdbc/driver/T4CDriverExtension.java:32)
oracle.jdbc.driver.OracleDriver.connect(oracle/jdbc/driver/OracleDriver.java:528)
java.lang.reflect.Method.invoke(java/lang/reflect/Method.java:498)
org.jruby.javasupport.JavaMethod.invokeDirectWithExceptionHandling(org/jruby/javasupport/JavaMethod.java:468)
org.jruby.javasupport.JavaMethod.invokeDirect(org/jruby/javasupport/JavaMethod.java:326)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/adapters/jdbc.rb:203)
RUBY.make_new(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool.rb:126)
RUBY.assign_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:192)
RUBY.acquire(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:133)
RUBY.hold(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:90)
RUBY.synchronize(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:269)
RUBY.test_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:279)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:58)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/core.rb:116)
RUBY.block in jdbc_connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:114)
org.jruby.RubyKernel.loop(org/jruby/RubyKernel.java:1292)
org.jruby.RubyKernel$INVOKER$s$0$0$loop.call(org/jruby/RubyKernel$INVOKER$s$0$0$loop.gen)
RUBY.jdbc_connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:111)
RUBY.open_jdbc_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:163)
RUBY.execute_statement(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:219)
RUBY.execute_query(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/inputs/jdbc.rb:264)
RUBY.run(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/inputs/jdbc.rb:250)
RUBY.inputworker(/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:516)
RUBY.block in start_input(/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:509)
org.jruby.RubyProc.call(org/jruby/RubyProc.java:289)
org.jruby.RubyProc.call(org/jruby/RubyProc.java:246)
java.lang.Thread.run(java/lang/Thread.java:748)
[2018-05-30T15:13:03,832][ERROR][logstash.inputs.jdbc     ] Unable to connect to database. Tried 1 times {:error_message=>"Java::JavaSql::SQLRecoverableException: IO Error: The Network Adapter could not establish the connection"}
[2018-05-30T15:13:03,835][ERROR][logstash.pipeline        ] A plugin had an unrecoverable error. Will restart this plugin.
  Pipeline_id:main
  Plugin: <LogStash::Inputs::Jdbc jdbc_driver_library=>"/etc/logstash/ojdbc6.jar", jdbc_driver_class=>"Java::oracle.jdbc.driver.OracleDriver", jdbc_connection_string=>"jdbc:oracle:thin:@100.100.100.225:1521:tenuri", jdbc_user=>"es_app", jdbc_password=><password>, jdbc_fetch_size=>10000, statement_filepath=>"as-is_search-log.sql", id=>"5bd7533661d97dbb4a1d2a6189513af0c10219fd73809280818346be344afa9b", enable_metric=>true, codec=><LogStash::Codecs::Plain id=>"plain_f3ac762d-4e2c-43ec-bdfd-dc1a40002f14", enable_metric=>true, charset=>"UTF-8">, jdbc_paging_enabled=>false, jdbc_page_size=>100000, jdbc_validate_connection=>false, jdbc_validation_timeout=>3600, jdbc_pool_timeout=>5, sql_log_level=>"info", connection_retry_attempts=>1, connection_retry_attempts_wait_time=>0.5, parameters=>{"sql_last_value"=>2018-05-30 09:22:03 +0900}, last_run_metadata_path=>"/home/elastic/.logstash_jdbc_last_run", use_column_value=>false, tracking_column_type=>"numeric", clean_run=>false, record_last_run=>true, lowercase_column_names=>true>
  Error: Java::JavaSql::SQLRecoverableException: IO Error: The Network Adapter could not establish the connection
  Exception: Sequel::DatabaseConnectionError
  Stack: oracle.jdbc.driver.T4CConnection.logon(oracle/jdbc/driver/T4CConnection.java:489)
oracle.jdbc.driver.PhysicalConnection.<init>(oracle/jdbc/driver/PhysicalConnection.java:553)
oracle.jdbc.driver.T4CConnection.<init>(oracle/jdbc/driver/T4CConnection.java:254)
oracle.jdbc.driver.T4CDriverExtension.getConnection(oracle/jdbc/driver/T4CDriverExtension.java:32)
oracle.jdbc.driver.OracleDriver.connect(oracle/jdbc/driver/OracleDriver.java:528)
java.lang.reflect.Method.invoke(java/lang/reflect/Method.java:498)
org.jruby.javasupport.JavaMethod.invokeDirectWithExceptionHandling(org/jruby/javasupport/JavaMethod.java:468)
org.jruby.javasupport.JavaMethod.invokeDirect(org/jruby/javasupport/JavaMethod.java:326)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/adapters/jdbc.rb:203)
RUBY.make_new(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool.rb:126)
RUBY.assign_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:192)
RUBY.acquire(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:133)
RUBY.hold(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:90)
RUBY.synchronize(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:269)
RUBY.test_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:279)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:58)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/core.rb:116)
RUBY.block in jdbc_connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:114)
org.jruby.RubyKernel.loop(org/jruby/RubyKernel.java:1292)
org.jruby.RubyKernel$INVOKER$s$0$0$loop.call(org/jruby/RubyKernel$INVOKER$s$0$0$loop.gen)
RUBY.jdbc_connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:111)
RUBY.open_jdbc_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:163)
RUBY.execute_statement(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:219)
RUBY.execute_query(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/inputs/jdbc.rb:264)
RUBY.run(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/inputs/jdbc.rb:250)
RUBY.inputworker(/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:516)
RUBY.block in start_input(/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:509)
org.jruby.RubyProc.call(org/jruby/RubyProc.java:289)
org.jruby.RubyProc.call(org/jruby/RubyProc.java:246)
java.lang.Thread.run(java/lang/Thread.java:748)
[2018-05-30T15:13:06,838][ERROR][logstash.inputs.jdbc     ] Unable to connect to database. Tried 1 times {:error_message=>"Java::JavaSql::SQLRecoverableException: IO Error: The Network Adapter could not establish the connection"}
[2018-05-30T15:13:06,841][ERROR][logstash.pipeline        ] A plugin had an unrecoverable error. Will restart this plugin.
  Pipeline_id:main
  Plugin: <LogStash::Inputs::Jdbc jdbc_driver_library=>"/etc/logstash/ojdbc6.jar", jdbc_driver_class=>"Java::oracle.jdbc.driver.OracleDriver", jdbc_connection_string=>"jdbc:oracle:thin:@100.100.100.225:1521:tenuri", jdbc_user=>"es_app", jdbc_password=><password>, jdbc_fetch_size=>10000, statement_filepath=>"as-is_search-log.sql", id=>"5bd7533661d97dbb4a1d2a6189513af0c10219fd73809280818346be344afa9b", enable_metric=>true, codec=><LogStash::Codecs::Plain id=>"plain_f3ac762d-4e2c-43ec-bdfd-dc1a40002f14", enable_metric=>true, charset=>"UTF-8">, jdbc_paging_enabled=>false, jdbc_page_size=>100000, jdbc_validate_connection=>false, jdbc_validation_timeout=>3600, jdbc_pool_timeout=>5, sql_log_level=>"info", connection_retry_attempts=>1, connection_retry_attempts_wait_time=>0.5, parameters=>{"sql_last_value"=>2018-05-30 09:22:03 +0900}, last_run_metadata_path=>"/home/elastic/.logstash_jdbc_last_run", use_column_value=>false, tracking_column_type=>"numeric", clean_run=>false, record_last_run=>true, lowercase_column_names=>true>
  Error: Java::JavaSql::SQLRecoverableException: IO Error: The Network Adapter could not establish the connection
  Exception: Sequel::DatabaseConnectionError
  Stack: oracle.jdbc.driver.T4CConnection.logon(oracle/jdbc/driver/T4CConnection.java:489)
oracle.jdbc.driver.PhysicalConnection.<init>(oracle/jdbc/driver/PhysicalConnection.java:553)
oracle.jdbc.driver.T4CConnection.<init>(oracle/jdbc/driver/T4CConnection.java:254)
oracle.jdbc.driver.T4CDriverExtension.getConnection(oracle/jdbc/driver/T4CDriverExtension.java:32)
oracle.jdbc.driver.OracleDriver.connect(oracle/jdbc/driver/OracleDriver.java:528)
java.lang.reflect.Method.invoke(java/lang/reflect/Method.java:498)
org.jruby.javasupport.JavaMethod.invokeDirectWithExceptionHandling(org/jruby/javasupport/JavaMethod.java:468)
org.jruby.javasupport.JavaMethod.invokeDirect(org/jruby/javasupport/JavaMethod.java:326)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/adapters/jdbc.rb:203)
RUBY.make_new(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool.rb:126)
RUBY.assign_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:192)
RUBY.acquire(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:133)
RUBY.hold(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:90)
RUBY.synchronize(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:269)
RUBY.test_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:279)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:58)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/core.rb:116)
RUBY.block in jdbc_connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:114)
org.jruby.RubyKernel.loop(org/jruby/RubyKernel.java:1292)
org.jruby.RubyKernel$INVOKER$s$0$0$loop.call(org/jruby/RubyKernel$INVOKER$s$0$0$loop.gen)
RUBY.jdbc_connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:111)
RUBY.open_jdbc_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:163)
RUBY.execute_statement(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:219)
RUBY.execute_query(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/inputs/jdbc.rb:264)
RUBY.run(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/inputs/jdbc.rb:250)
RUBY.inputworker(/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:516)
RUBY.block in start_input(/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:509)
org.jruby.RubyProc.call(org/jruby/RubyProc.java:289)
org.jruby.RubyProc.call(org/jruby/RubyProc.java:246)
java.lang.Thread.run(java/lang/Thread.java:748)
[2018-05-30T15:13:09,842][ERROR][logstash.inputs.jdbc     ] Unable to connect to database. Tried 1 times {:error_message=>"Java::JavaSql::SQLRecoverableException: IO Error: The Network Adapter could not establish the connection"}
[2018-05-30T15:13:09,845][ERROR][logstash.pipeline        ] A plugin had an unrecoverable error. Will restart this plugin.
  Pipeline_id:main
  Plugin: <LogStash::Inputs::Jdbc jdbc_driver_library=>"/etc/logstash/ojdbc6.jar", jdbc_driver_class=>"Java::oracle.jdbc.driver.OracleDriver", jdbc_connection_string=>"jdbc:oracle:thin:@100.100.100.225:1521:tenuri", jdbc_user=>"es_app", jdbc_password=><password>, jdbc_fetch_size=>10000, statement_filepath=>"as-is_search-log.sql", id=>"5bd7533661d97dbb4a1d2a6189513af0c10219fd73809280818346be344afa9b", enable_metric=>true, codec=><LogStash::Codecs::Plain id=>"plain_f3ac762d-4e2c-43ec-bdfd-dc1a40002f14", enable_metric=>true, charset=>"UTF-8">, jdbc_paging_enabled=>false, jdbc_page_size=>100000, jdbc_validate_connection=>false, jdbc_validation_timeout=>3600, jdbc_pool_timeout=>5, sql_log_level=>"info", connection_retry_attempts=>1, connection_retry_attempts_wait_time=>0.5, parameters=>{"sql_last_value"=>2018-05-30 09:22:03 +0900}, last_run_metadata_path=>"/home/elastic/.logstash_jdbc_last_run", use_column_value=>false, tracking_column_type=>"numeric", clean_run=>false, record_last_run=>true, lowercase_column_names=>true>
  Error: Java::JavaSql::SQLRecoverableException: IO Error: The Network Adapter could not establish the connection
  Exception: Sequel::DatabaseConnectionError
  Stack: oracle.jdbc.driver.T4CConnection.logon(oracle/jdbc/driver/T4CConnection.java:489)
oracle.jdbc.driver.PhysicalConnection.<init>(oracle/jdbc/driver/PhysicalConnection.java:553)
oracle.jdbc.driver.T4CConnection.<init>(oracle/jdbc/driver/T4CConnection.java:254)
oracle.jdbc.driver.T4CDriverExtension.getConnection(oracle/jdbc/driver/T4CDriverExtension.java:32)
oracle.jdbc.driver.OracleDriver.connect(oracle/jdbc/driver/OracleDriver.java:528)
java.lang.reflect.Method.invoke(java/lang/reflect/Method.java:498)
org.jruby.javasupport.JavaMethod.invokeDirectWithExceptionHandling(org/jruby/javasupport/JavaMethod.java:468)
org.jruby.javasupport.JavaMethod.invokeDirect(org/jruby/javasupport/JavaMethod.java:326)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/adapters/jdbc.rb:203)
RUBY.make_new(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool.rb:126)
RUBY.assign_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:192)
RUBY.acquire(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:133)
RUBY.hold(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:90)
RUBY.synchronize(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:269)
RUBY.test_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:279)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:58)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/core.rb:116)
RUBY.block in jdbc_connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:114)
org.jruby.RubyKernel.loop(org/jruby/RubyKernel.java:1292)
org.jruby.RubyKernel$INVOKER$s$0$0$loop.call(org/jruby/RubyKernel$INVOKER$s$0$0$loop.gen)
RUBY.jdbc_connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:111)
RUBY.open_jdbc_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:163)
RUBY.execute_statement(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:219)
RUBY.execute_query(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/inputs/jdbc.rb:264)
RUBY.run(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/inputs/jdbc.rb:250)
RUBY.inputworker(/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:516)
RUBY.block in start_input(/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:509)
org.jruby.RubyProc.call(org/jruby/RubyProc.java:289)
org.jruby.RubyProc.call(org/jruby/RubyProc.java:246)
java.lang.Thread.run(java/lang/Thread.java:748)
[2018-05-30T15:13:12,850][ERROR][logstash.inputs.jdbc     ] Unable to connect to database. Tried 1 times {:error_message=>"Java::JavaSql::SQLRecoverableException: IO Error: The Network Adapter could not establish the connection"}
[2018-05-30T15:13:12,853][ERROR][logstash.pipeline        ] A plugin had an unrecoverable error. Will restart this plugin.
  Pipeline_id:main
  Plugin: <LogStash::Inputs::Jdbc jdbc_driver_library=>"/etc/logstash/ojdbc6.jar", jdbc_driver_class=>"Java::oracle.jdbc.driver.OracleDriver", jdbc_connection_string=>"jdbc:oracle:thin:@100.100.100.225:1521:tenuri", jdbc_user=>"es_app", jdbc_password=><password>, jdbc_fetch_size=>10000, statement_filepath=>"as-is_search-log.sql", id=>"5bd7533661d97dbb4a1d2a6189513af0c10219fd73809280818346be344afa9b", enable_metric=>true, codec=><LogStash::Codecs::Plain id=>"plain_f3ac762d-4e2c-43ec-bdfd-dc1a40002f14", enable_metric=>true, charset=>"UTF-8">, jdbc_paging_enabled=>false, jdbc_page_size=>100000, jdbc_validate_connection=>false, jdbc_validation_timeout=>3600, jdbc_pool_timeout=>5, sql_log_level=>"info", connection_retry_attempts=>1, connection_retry_attempts_wait_time=>0.5, parameters=>{"sql_last_value"=>2018-05-30 09:22:03 +0900}, last_run_metadata_path=>"/home/elastic/.logstash_jdbc_last_run", use_column_value=>false, tracking_column_type=>"numeric", clean_run=>false, record_last_run=>true, lowercase_column_names=>true>
  Error: Java::JavaSql::SQLRecoverableException: IO Error: The Network Adapter could not establish the connection
  Exception: Sequel::DatabaseConnectionError
  Stack: oracle.jdbc.driver.T4CConnection.logon(oracle/jdbc/driver/T4CConnection.java:489)
oracle.jdbc.driver.PhysicalConnection.<init>(oracle/jdbc/driver/PhysicalConnection.java:553)
oracle.jdbc.driver.T4CConnection.<init>(oracle/jdbc/driver/T4CConnection.java:254)
oracle.jdbc.driver.T4CDriverExtension.getConnection(oracle/jdbc/driver/T4CDriverExtension.java:32)
oracle.jdbc.driver.OracleDriver.connect(oracle/jdbc/driver/OracleDriver.java:528)
java.lang.reflect.Method.invoke(java/lang/reflect/Method.java:498)
org.jruby.javasupport.JavaMethod.invokeDirectWithExceptionHandling(org/jruby/javasupport/JavaMethod.java:468)
org.jruby.javasupport.JavaMethod.invokeDirect(org/jruby/javasupport/JavaMethod.java:326)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/adapters/jdbc.rb:203)
RUBY.make_new(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool.rb:126)
RUBY.assign_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:192)
RUBY.acquire(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:133)
RUBY.hold(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:90)
RUBY.synchronize(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:269)
RUBY.test_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:279)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:58)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/core.rb:116)
RUBY.block in jdbc_connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:114)
org.jruby.RubyKernel.loop(org/jruby/RubyKernel.java:1292)
org.jruby.RubyKernel$INVOKER$s$0$0$loop.call(org/jruby/RubyKernel$INVOKER$s$0$0$loop.gen)
RUBY.jdbc_connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:111)
RUBY.open_jdbc_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:163)
RUBY.execute_statement(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:219)
RUBY.execute_query(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/inputs/jdbc.rb:264)
RUBY.run(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/inputs/jdbc.rb:250)
RUBY.inputworker(/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:516)
RUBY.block in start_input(/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:509)
org.jruby.RubyProc.call(org/jruby/RubyProc.java:289)
org.jruby.RubyProc.call(org/jruby/RubyProc.java:246)
java.lang.Thread.run(java/lang/Thread.java:748)
[2018-05-30T15:13:15,855][ERROR][logstash.inputs.jdbc     ] Unable to connect to database. Tried 1 times {:error_message=>"Java::JavaSql::SQLRecoverableException: IO Error: The Network Adapter could not establish the connection"}
[2018-05-30T15:13:15,863][ERROR][logstash.pipeline        ] A plugin had an unrecoverable error. Will restart this plugin.
  Pipeline_id:main
  Plugin: <LogStash::Inputs::Jdbc jdbc_driver_library=>"/etc/logstash/ojdbc6.jar", jdbc_driver_class=>"Java::oracle.jdbc.driver.OracleDriver", jdbc_connection_string=>"jdbc:oracle:thin:@100.100.100.225:1521:tenuri", jdbc_user=>"es_app", jdbc_password=><password>, jdbc_fetch_size=>10000, statement_filepath=>"as-is_search-log.sql", id=>"5bd7533661d97dbb4a1d2a6189513af0c10219fd73809280818346be344afa9b", enable_metric=>true, codec=><LogStash::Codecs::Plain id=>"plain_f3ac762d-4e2c-43ec-bdfd-dc1a40002f14", enable_metric=>true, charset=>"UTF-8">, jdbc_paging_enabled=>false, jdbc_page_size=>100000, jdbc_validate_connection=>false, jdbc_validation_timeout=>3600, jdbc_pool_timeout=>5, sql_log_level=>"info", connection_retry_attempts=>1, connection_retry_attempts_wait_time=>0.5, parameters=>{"sql_last_value"=>2018-05-30 09:22:03 +0900}, last_run_metadata_path=>"/home/elastic/.logstash_jdbc_last_run", use_column_value=>false, tracking_column_type=>"numeric", clean_run=>false, record_last_run=>true, lowercase_column_names=>true>
  Error: Java::JavaSql::SQLRecoverableException: IO Error: The Network Adapter could not establish the connection
  Exception: Sequel::DatabaseConnectionError
  Stack: oracle.jdbc.driver.T4CConnection.logon(oracle/jdbc/driver/T4CConnection.java:489)
oracle.jdbc.driver.PhysicalConnection.<init>(oracle/jdbc/driver/PhysicalConnection.java:553)
oracle.jdbc.driver.T4CConnection.<init>(oracle/jdbc/driver/T4CConnection.java:254)
oracle.jdbc.driver.T4CDriverExtension.getConnection(oracle/jdbc/driver/T4CDriverExtension.java:32)
oracle.jdbc.driver.OracleDriver.connect(oracle/jdbc/driver/OracleDriver.java:528)
java.lang.reflect.Method.invoke(java/lang/reflect/Method.java:498)
org.jruby.javasupport.JavaMethod.invokeDirectWithExceptionHandling(org/jruby/javasupport/JavaMethod.java:468)
org.jruby.javasupport.JavaMethod.invokeDirect(org/jruby/javasupport/JavaMethod.java:326)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/adapters/jdbc.rb:203)
RUBY.make_new(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool.rb:126)
RUBY.assign_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:192)
RUBY.acquire(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:133)
RUBY.hold(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:90)
RUBY.synchronize(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:269)
RUBY.test_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:279)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:58)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/core.rb:116)
RUBY.block in jdbc_connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:114)
org.jruby.RubyKernel.loop(org/jruby/RubyKernel.java:1292)
org.jruby.RubyKernel$INVOKER$s$0$0$loop.call(org/jruby/RubyKernel$INVOKER$s$0$0$loop.gen)
RUBY.jdbc_connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:111)
RUBY.open_jdbc_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:163)
RUBY.execute_statement(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:219)
RUBY.execute_query(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/inputs/jdbc.rb:264)
RUBY.run(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/inputs/jdbc.rb:250)
RUBY.inputworker(/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:516)
RUBY.block in start_input(/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:509)
org.jruby.RubyProc.call(org/jruby/RubyProc.java:289)
org.jruby.RubyProc.call(org/jruby/RubyProc.java:246)
java.lang.Thread.run(java/lang/Thread.java:748)
[2018-05-30T15:13:18,861][ERROR][logstash.inputs.jdbc     ] Unable to connect to database. Tried 1 times {:error_message=>"Java::JavaSql::SQLRecoverableException: IO Error: The Network Adapter could not establish the connection"}
[2018-05-30T15:13:18,865][ERROR][logstash.pipeline        ] A plugin had an unrecoverable error. Will restart this plugin.
  Pipeline_id:main
  Plugin: <LogStash::Inputs::Jdbc jdbc_driver_library=>"/etc/logstash/ojdbc6.jar", jdbc_driver_class=>"Java::oracle.jdbc.driver.OracleDriver", jdbc_connection_string=>"jdbc:oracle:thin:@100.100.100.225:1521:tenuri", jdbc_user=>"es_app", jdbc_password=><password>, jdbc_fetch_size=>10000, statement_filepath=>"as-is_search-log.sql", id=>"5bd7533661d97dbb4a1d2a6189513af0c10219fd73809280818346be344afa9b", enable_metric=>true, codec=><LogStash::Codecs::Plain id=>"plain_f3ac762d-4e2c-43ec-bdfd-dc1a40002f14", enable_metric=>true, charset=>"UTF-8">, jdbc_paging_enabled=>false, jdbc_page_size=>100000, jdbc_validate_connection=>false, jdbc_validation_timeout=>3600, jdbc_pool_timeout=>5, sql_log_level=>"info", connection_retry_attempts=>1, connection_retry_attempts_wait_time=>0.5, parameters=>{"sql_last_value"=>2018-05-30 09:22:03 +0900}, last_run_metadata_path=>"/home/elastic/.logstash_jdbc_last_run", use_column_value=>false, tracking_column_type=>"numeric", clean_run=>false, record_last_run=>true, lowercase_column_names=>true>
  Error: Java::JavaSql::SQLRecoverableException: IO Error: The Network Adapter could not establish the connection
  Exception: Sequel::DatabaseConnectionError
  Stack: oracle.jdbc.driver.T4CConnection.logon(oracle/jdbc/driver/T4CConnection.java:489)
oracle.jdbc.driver.PhysicalConnection.<init>(oracle/jdbc/driver/PhysicalConnection.java:553)
oracle.jdbc.driver.T4CConnection.<init>(oracle/jdbc/driver/T4CConnection.java:254)
oracle.jdbc.driver.T4CDriverExtension.getConnection(oracle/jdbc/driver/T4CDriverExtension.java:32)
oracle.jdbc.driver.OracleDriver.connect(oracle/jdbc/driver/OracleDriver.java:528)
java.lang.reflect.Method.invoke(java/lang/reflect/Method.java:498)
org.jruby.javasupport.JavaMethod.invokeDirectWithExceptionHandling(org/jruby/javasupport/JavaMethod.java:468)
org.jruby.javasupport.JavaMethod.invokeDirect(org/jruby/javasupport/JavaMethod.java:326)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/adapters/jdbc.rb:203)
RUBY.make_new(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool.rb:126)
RUBY.assign_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:192)
RUBY.acquire(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:133)
RUBY.hold(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:90)
RUBY.synchronize(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:269)
RUBY.test_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:279)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:58)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/core.rb:116)
RUBY.block in jdbc_connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:114)
org.jruby.RubyKernel.loop(org/jruby/RubyKernel.java:1292)
org.jruby.RubyKernel$INVOKER$s$0$0$loop.call(org/jruby/RubyKernel$INVOKER$s$0$0$loop.gen)
RUBY.jdbc_connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:111)
RUBY.open_jdbc_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:163)
RUBY.execute_statement(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:219)
RUBY.execute_query(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/inputs/jdbc.rb:264)
RUBY.run(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/inputs/jdbc.rb:250)
RUBY.inputworker(/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:516)
RUBY.block in start_input(/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:509)
org.jruby.RubyProc.call(org/jruby/RubyProc.java:289)
org.jruby.RubyProc.call(org/jruby/RubyProc.java:246)
java.lang.Thread.run(java/lang/Thread.java:748)
[2018-05-30T15:13:21,869][ERROR][logstash.inputs.jdbc     ] Unable to connect to database. Tried 1 times {:error_message=>"Java::JavaSql::SQLRecoverableException: IO Error: The Network Adapter could not establish the connection"}
[2018-05-30T15:13:21,872][ERROR][logstash.pipeline        ] A plugin had an unrecoverable error. Will restart this plugin.
  Pipeline_id:main
  Plugin: <LogStash::Inputs::Jdbc jdbc_driver_library=>"/etc/logstash/ojdbc6.jar", jdbc_driver_class=>"Java::oracle.jdbc.driver.OracleDriver", jdbc_connection_string=>"jdbc:oracle:thin:@100.100.100.225:1521:tenuri", jdbc_user=>"es_app", jdbc_password=><password>, jdbc_fetch_size=>10000, statement_filepath=>"as-is_search-log.sql", id=>"5bd7533661d97dbb4a1d2a6189513af0c10219fd73809280818346be344afa9b", enable_metric=>true, codec=><LogStash::Codecs::Plain id=>"plain_f3ac762d-4e2c-43ec-bdfd-dc1a40002f14", enable_metric=>true, charset=>"UTF-8">, jdbc_paging_enabled=>false, jdbc_page_size=>100000, jdbc_validate_connection=>false, jdbc_validation_timeout=>3600, jdbc_pool_timeout=>5, sql_log_level=>"info", connection_retry_attempts=>1, connection_retry_attempts_wait_time=>0.5, parameters=>{"sql_last_value"=>2018-05-30 09:22:03 +0900}, last_run_metadata_path=>"/home/elastic/.logstash_jdbc_last_run", use_column_value=>false, tracking_column_type=>"numeric", clean_run=>false, record_last_run=>true, lowercase_column_names=>true>
  Error: Java::JavaSql::SQLRecoverableException: IO Error: The Network Adapter could not establish the connection
  Exception: Sequel::DatabaseConnectionError
  Stack: oracle.jdbc.driver.T4CConnection.logon(oracle/jdbc/driver/T4CConnection.java:489)
oracle.jdbc.driver.PhysicalConnection.<init>(oracle/jdbc/driver/PhysicalConnection.java:553)
oracle.jdbc.driver.T4CConnection.<init>(oracle/jdbc/driver/T4CConnection.java:254)
oracle.jdbc.driver.T4CDriverExtension.getConnection(oracle/jdbc/driver/T4CDriverExtension.java:32)
oracle.jdbc.driver.OracleDriver.connect(oracle/jdbc/driver/OracleDriver.java:528)
java.lang.reflect.Method.invoke(java/lang/reflect/Method.java:498)
org.jruby.javasupport.JavaMethod.invokeDirectWithExceptionHandling(org/jruby/javasupport/JavaMethod.java:468)
org.jruby.javasupport.JavaMethod.invokeDirect(org/jruby/javasupport/JavaMethod.java:326)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/adapters/jdbc.rb:203)
RUBY.make_new(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool.rb:126)
RUBY.assign_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:192)
RUBY.acquire(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:133)
RUBY.hold(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:90)
RUBY.synchronize(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:269)
RUBY.test_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:279)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:58)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/core.rb:116)
RUBY.block in jdbc_connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:114)
org.jruby.RubyKernel.loop(org/jruby/RubyKernel.java:1292)
org.jruby.RubyKernel$INVOKER$s$0$0$loop.call(org/jruby/RubyKernel$INVOKER$s$0$0$loop.gen)
RUBY.jdbc_connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:111)
RUBY.open_jdbc_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:163)
RUBY.execute_statement(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:219)
RUBY.execute_query(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/inputs/jdbc.rb:264)
RUBY.run(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/inputs/jdbc.rb:250)
RUBY.inputworker(/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:516)
RUBY.block in start_input(/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:509)
org.jruby.RubyProc.call(org/jruby/RubyProc.java:289)
org.jruby.RubyProc.call(org/jruby/RubyProc.java:246)
java.lang.Thread.run(java/lang/Thread.java:748)
[2018-05-30T15:13:24,873][ERROR][logstash.inputs.jdbc     ] Unable to connect to database. Tried 1 times {:error_message=>"Java::JavaSql::SQLRecoverableException: IO Error: The Network Adapter could not establish the connection"}
[2018-05-30T15:13:24,889][ERROR][logstash.pipeline        ] A plugin had an unrecoverable error. Will restart this plugin.
  Pipeline_id:main
  Plugin: <LogStash::Inputs::Jdbc jdbc_driver_library=>"/etc/logstash/ojdbc6.jar", jdbc_driver_class=>"Java::oracle.jdbc.driver.OracleDriver", jdbc_connection_string=>"jdbc:oracle:thin:@100.100.100.225:1521:tenuri", jdbc_user=>"es_app", jdbc_password=><password>, jdbc_fetch_size=>10000, statement_filepath=>"as-is_search-log.sql", id=>"5bd7533661d97dbb4a1d2a6189513af0c10219fd73809280818346be344afa9b", enable_metric=>true, codec=><LogStash::Codecs::Plain id=>"plain_f3ac762d-4e2c-43ec-bdfd-dc1a40002f14", enable_metric=>true, charset=>"UTF-8">, jdbc_paging_enabled=>false, jdbc_page_size=>100000, jdbc_validate_connection=>false, jdbc_validation_timeout=>3600, jdbc_pool_timeout=>5, sql_log_level=>"info", connection_retry_attempts=>1, connection_retry_attempts_wait_time=>0.5, parameters=>{"sql_last_value"=>2018-05-30 09:22:03 +0900}, last_run_metadata_path=>"/home/elastic/.logstash_jdbc_last_run", use_column_value=>false, tracking_column_type=>"numeric", clean_run=>false, record_last_run=>true, lowercase_column_names=>true>
  Error: Java::JavaSql::SQLRecoverableException: IO Error: The Network Adapter could not establish the connection
  Exception: Sequel::DatabaseConnectionError
  Stack: oracle.jdbc.driver.T4CConnection.logon(oracle/jdbc/driver/T4CConnection.java:489)
oracle.jdbc.driver.PhysicalConnection.<init>(oracle/jdbc/driver/PhysicalConnection.java:553)
oracle.jdbc.driver.T4CConnection.<init>(oracle/jdbc/driver/T4CConnection.java:254)
oracle.jdbc.driver.T4CDriverExtension.getConnection(oracle/jdbc/driver/T4CDriverExtension.java:32)
oracle.jdbc.driver.OracleDriver.connect(oracle/jdbc/driver/OracleDriver.java:528)
java.lang.reflect.Method.invoke(java/lang/reflect/Method.java:498)
org.jruby.javasupport.JavaMethod.invokeDirectWithExceptionHandling(org/jruby/javasupport/JavaMethod.java:468)
org.jruby.javasupport.JavaMethod.invokeDirect(org/jruby/javasupport/JavaMethod.java:326)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/adapters/jdbc.rb:203)
RUBY.make_new(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool.rb:126)
RUBY.assign_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:192)
RUBY.acquire(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:133)
RUBY.hold(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:90)
RUBY.synchronize(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:269)
RUBY.test_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:279)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:58)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/core.rb:116)
RUBY.block in jdbc_connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:114)
org.jruby.RubyKernel.loop(org/jruby/RubyKernel.java:1292)
org.jruby.RubyKernel$INVOKER$s$0$0$loop.call(org/jruby/RubyKernel$INVOKER$s$0$0$loop.gen)
RUBY.jdbc_connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:111)
RUBY.open_jdbc_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:163)
RUBY.execute_statement(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:219)
RUBY.execute_query(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/inputs/jdbc.rb:264)
RUBY.run(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/inputs/jdbc.rb:250)
RUBY.inputworker(/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:516)
RUBY.block in start_input(/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:509)
org.jruby.RubyProc.call(org/jruby/RubyProc.java:289)
org.jruby.RubyProc.call(org/jruby/RubyProc.java:246)
java.lang.Thread.run(java/lang/Thread.java:748)
[2018-05-30T15:13:27,880][ERROR][logstash.inputs.jdbc     ] Unable to connect to database. Tried 1 times {:error_message=>"Java::JavaSql::SQLRecoverableException: IO Error: The Network Adapter could not establish the connection"}
[2018-05-30T15:13:27,884][ERROR][logstash.pipeline        ] A plugin had an unrecoverable error. Will restart this plugin.
  Pipeline_id:main
  Plugin: <LogStash::Inputs::Jdbc jdbc_driver_library=>"/etc/logstash/ojdbc6.jar", jdbc_driver_class=>"Java::oracle.jdbc.driver.OracleDriver", jdbc_connection_string=>"jdbc:oracle:thin:@100.100.100.225:1521:tenuri", jdbc_user=>"es_app", jdbc_password=><password>, jdbc_fetch_size=>10000, statement_filepath=>"as-is_search-log.sql", id=>"5bd7533661d97dbb4a1d2a6189513af0c10219fd73809280818346be344afa9b", enable_metric=>true, codec=><LogStash::Codecs::Plain id=>"plain_f3ac762d-4e2c-43ec-bdfd-dc1a40002f14", enable_metric=>true, charset=>"UTF-8">, jdbc_paging_enabled=>false, jdbc_page_size=>100000, jdbc_validate_connection=>false, jdbc_validation_timeout=>3600, jdbc_pool_timeout=>5, sql_log_level=>"info", connection_retry_attempts=>1, connection_retry_attempts_wait_time=>0.5, parameters=>{"sql_last_value"=>2018-05-30 09:22:03 +0900}, last_run_metadata_path=>"/home/elastic/.logstash_jdbc_last_run", use_column_value=>false, tracking_column_type=>"numeric", clean_run=>false, record_last_run=>true, lowercase_column_names=>true>
  Error: Java::JavaSql::SQLRecoverableException: IO Error: The Network Adapter could not establish the connection
  Exception: Sequel::DatabaseConnectionError
  Stack: oracle.jdbc.driver.T4CConnection.logon(oracle/jdbc/driver/T4CConnection.java:489)
oracle.jdbc.driver.PhysicalConnection.<init>(oracle/jdbc/driver/PhysicalConnection.java:553)
oracle.jdbc.driver.T4CConnection.<init>(oracle/jdbc/driver/T4CConnection.java:254)
oracle.jdbc.driver.T4CDriverExtension.getConnection(oracle/jdbc/driver/T4CDriverExtension.java:32)
oracle.jdbc.driver.OracleDriver.connect(oracle/jdbc/driver/OracleDriver.java:528)
java.lang.reflect.Method.invoke(java/lang/reflect/Method.java:498)
org.jruby.javasupport.JavaMethod.invokeDirectWithExceptionHandling(org/jruby/javasupport/JavaMethod.java:468)
org.jruby.javasupport.JavaMethod.invokeDirect(org/jruby/javasupport/JavaMethod.java:326)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/adapters/jdbc.rb:203)
RUBY.make_new(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool.rb:126)
RUBY.assign_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:192)
RUBY.acquire(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:133)
RUBY.hold(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:90)
RUBY.synchronize(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:269)
RUBY.test_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:279)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:58)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/core.rb:116)
RUBY.block in jdbc_connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:114)
org.jruby.RubyKernel.loop(org/jruby/RubyKernel.java:1292)
org.jruby.RubyKernel$INVOKER$s$0$0$loop.call(org/jruby/RubyKernel$INVOKER$s$0$0$loop.gen)
RUBY.jdbc_connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:111)
RUBY.open_jdbc_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:163)
RUBY.execute_statement(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:219)
RUBY.execute_query(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/inputs/jdbc.rb:264)
RUBY.run(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/inputs/jdbc.rb:250)
RUBY.inputworker(/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:516)
RUBY.block in start_input(/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:509)
org.jruby.RubyProc.call(org/jruby/RubyProc.java:289)
org.jruby.RubyProc.call(org/jruby/RubyProc.java:246)
java.lang.Thread.run(java/lang/Thread.java:748)
[2018-05-30T15:13:30,885][ERROR][logstash.inputs.jdbc     ] Unable to connect to database. Tried 1 times {:error_message=>"Java::JavaSql::SQLRecoverableException: IO Error: The Network Adapter could not establish the connection"}
[2018-05-30T15:13:30,889][ERROR][logstash.pipeline        ] A plugin had an unrecoverable error. Will restart this plugin.
  Pipeline_id:main
  Plugin: <LogStash::Inputs::Jdbc jdbc_driver_library=>"/etc/logstash/ojdbc6.jar", jdbc_driver_class=>"Java::oracle.jdbc.driver.OracleDriver", jdbc_connection_string=>"jdbc:oracle:thin:@100.100.100.225:1521:tenuri", jdbc_user=>"es_app", jdbc_password=><password>, jdbc_fetch_size=>10000, statement_filepath=>"as-is_search-log.sql", id=>"5bd7533661d97dbb4a1d2a6189513af0c10219fd73809280818346be344afa9b", enable_metric=>true, codec=><LogStash::Codecs::Plain id=>"plain_f3ac762d-4e2c-43ec-bdfd-dc1a40002f14", enable_metric=>true, charset=>"UTF-8">, jdbc_paging_enabled=>false, jdbc_page_size=>100000, jdbc_validate_connection=>false, jdbc_validation_timeout=>3600, jdbc_pool_timeout=>5, sql_log_level=>"info", connection_retry_attempts=>1, connection_retry_attempts_wait_time=>0.5, parameters=>{"sql_last_value"=>2018-05-30 09:22:03 +0900}, last_run_metadata_path=>"/home/elastic/.logstash_jdbc_last_run", use_column_value=>false, tracking_column_type=>"numeric", clean_run=>false, record_last_run=>true, lowercase_column_names=>true>
  Error: Java::JavaSql::SQLRecoverableException: IO Error: The Network Adapter could not establish the connection
  Exception: Sequel::DatabaseConnectionError
  Stack: oracle.jdbc.driver.T4CConnection.logon(oracle/jdbc/driver/T4CConnection.java:489)
oracle.jdbc.driver.PhysicalConnection.<init>(oracle/jdbc/driver/PhysicalConnection.java:553)
oracle.jdbc.driver.T4CConnection.<init>(oracle/jdbc/driver/T4CConnection.java:254)
oracle.jdbc.driver.T4CDriverExtension.getConnection(oracle/jdbc/driver/T4CDriverExtension.java:32)
oracle.jdbc.driver.OracleDriver.connect(oracle/jdbc/driver/OracleDriver.java:528)
java.lang.reflect.Method.invoke(java/lang/reflect/Method.java:498)
org.jruby.javasupport.JavaMethod.invokeDirectWithExceptionHandling(org/jruby/javasupport/JavaMethod.java:468)
org.jruby.javasupport.JavaMethod.invokeDirect(org/jruby/javasupport/JavaMethod.java:326)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/adapters/jdbc.rb:203)
RUBY.make_new(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool.rb:126)
RUBY.assign_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:192)
RUBY.acquire(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:133)
RUBY.hold(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:90)
RUBY.synchronize(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:269)
RUBY.test_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:279)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:58)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/core.rb:116)
RUBY.block in jdbc_connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:114)
org.jruby.RubyKernel.loop(org/jruby/RubyKernel.java:1292)
org.jruby.RubyKernel$INVOKER$s$0$0$loop.call(org/jruby/RubyKernel$INVOKER$s$0$0$loop.gen)
RUBY.jdbc_connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:111)
RUBY.open_jdbc_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:163)
RUBY.execute_statement(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:219)
RUBY.execute_query(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/inputs/jdbc.rb:264)
RUBY.run(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/inputs/jdbc.rb:250)
RUBY.inputworker(/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:516)
RUBY.block in start_input(/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:509)
org.jruby.RubyProc.call(org/jruby/RubyProc.java:289)
org.jruby.RubyProc.call(org/jruby/RubyProc.java:246)
java.lang.Thread.run(java/lang/Thread.java:748)
[2018-05-30T15:13:33,891][ERROR][logstash.inputs.jdbc     ] Unable to connect to database. Tried 1 times {:error_message=>"Java::JavaSql::SQLRecoverableException: IO Error: The Network Adapter could not establish the connection"}
[2018-05-30T15:13:33,895][ERROR][logstash.pipeline        ] A plugin had an unrecoverable error. Will restart this plugin.
  Pipeline_id:main
  Plugin: <LogStash::Inputs::Jdbc jdbc_driver_library=>"/etc/logstash/ojdbc6.jar", jdbc_driver_class=>"Java::oracle.jdbc.driver.OracleDriver", jdbc_connection_string=>"jdbc:oracle:thin:@100.100.100.225:1521:tenuri", jdbc_user=>"es_app", jdbc_password=><password>, jdbc_fetch_size=>10000, statement_filepath=>"as-is_search-log.sql", id=>"5bd7533661d97dbb4a1d2a6189513af0c10219fd73809280818346be344afa9b", enable_metric=>true, codec=><LogStash::Codecs::Plain id=>"plain_f3ac762d-4e2c-43ec-bdfd-dc1a40002f14", enable_metric=>true, charset=>"UTF-8">, jdbc_paging_enabled=>false, jdbc_page_size=>100000, jdbc_validate_connection=>false, jdbc_validation_timeout=>3600, jdbc_pool_timeout=>5, sql_log_level=>"info", connection_retry_attempts=>1, connection_retry_attempts_wait_time=>0.5, parameters=>{"sql_last_value"=>2018-05-30 09:22:03 +0900}, last_run_metadata_path=>"/home/elastic/.logstash_jdbc_last_run", use_column_value=>false, tracking_column_type=>"numeric", clean_run=>false, record_last_run=>true, lowercase_column_names=>true>
  Error: Java::JavaSql::SQLRecoverableException: IO Error: The Network Adapter could not establish the connection
  Exception: Sequel::DatabaseConnectionError
  Stack: oracle.jdbc.driver.T4CConnection.logon(oracle/jdbc/driver/T4CConnection.java:489)
oracle.jdbc.driver.PhysicalConnection.<init>(oracle/jdbc/driver/PhysicalConnection.java:553)
oracle.jdbc.driver.T4CConnection.<init>(oracle/jdbc/driver/T4CConnection.java:254)
oracle.jdbc.driver.T4CDriverExtension.getConnection(oracle/jdbc/driver/T4CDriverExtension.java:32)
oracle.jdbc.driver.OracleDriver.connect(oracle/jdbc/driver/OracleDriver.java:528)
java.lang.reflect.Method.invoke(java/lang/reflect/Method.java:498)
org.jruby.javasupport.JavaMethod.invokeDirectWithExceptionHandling(org/jruby/javasupport/JavaMethod.java:468)
org.jruby.javasupport.JavaMethod.invokeDirect(org/jruby/javasupport/JavaMethod.java:326)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/adapters/jdbc.rb:203)
RUBY.make_new(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool.rb:126)
RUBY.assign_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:192)
RUBY.acquire(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:133)
RUBY.hold(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:90)
RUBY.synchronize(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:269)
RUBY.test_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:279)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:58)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/core.rb:116)
RUBY.block in jdbc_connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:114)
org.jruby.RubyKernel.loop(org/jruby/RubyKernel.java:1292)
org.jruby.RubyKernel$INVOKER$s$0$0$loop.call(org/jruby/RubyKernel$INVOKER$s$0$0$loop.gen)
RUBY.jdbc_connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:111)
RUBY.open_jdbc_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:163)
RUBY.execute_statement(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:219)
RUBY.execute_query(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/inputs/jdbc.rb:264)
RUBY.run(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/inputs/jdbc.rb:250)
RUBY.inputworker(/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:516)
RUBY.block in start_input(/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:509)
org.jruby.RubyProc.call(org/jruby/RubyProc.java:289)
org.jruby.RubyProc.call(org/jruby/RubyProc.java:246)
java.lang.Thread.run(java/lang/Thread.java:748)
[2018-05-30T15:13:36,898][ERROR][logstash.inputs.jdbc     ] Unable to connect to database. Tried 1 times {:error_message=>"Java::JavaSql::SQLRecoverableException: IO Error: The Network Adapter could not establish the connection"}
[2018-05-30T15:13:36,903][ERROR][logstash.pipeline        ] A plugin had an unrecoverable error. Will restart this plugin.
  Pipeline_id:main
  Plugin: <LogStash::Inputs::Jdbc jdbc_driver_library=>"/etc/logstash/ojdbc6.jar", jdbc_driver_class=>"Java::oracle.jdbc.driver.OracleDriver", jdbc_connection_string=>"jdbc:oracle:thin:@100.100.100.225:1521:tenuri", jdbc_user=>"es_app", jdbc_password=><password>, jdbc_fetch_size=>10000, statement_filepath=>"as-is_search-log.sql", id=>"5bd7533661d97dbb4a1d2a6189513af0c10219fd73809280818346be344afa9b", enable_metric=>true, codec=><LogStash::Codecs::Plain id=>"plain_f3ac762d-4e2c-43ec-bdfd-dc1a40002f14", enable_metric=>true, charset=>"UTF-8">, jdbc_paging_enabled=>false, jdbc_page_size=>100000, jdbc_validate_connection=>false, jdbc_validation_timeout=>3600, jdbc_pool_timeout=>5, sql_log_level=>"info", connection_retry_attempts=>1, connection_retry_attempts_wait_time=>0.5, parameters=>{"sql_last_value"=>2018-05-30 09:22:03 +0900}, last_run_metadata_path=>"/home/elastic/.logstash_jdbc_last_run", use_column_value=>false, tracking_column_type=>"numeric", clean_run=>false, record_last_run=>true, lowercase_column_names=>true>
  Error: Java::JavaSql::SQLRecoverableException: IO Error: The Network Adapter could not establish the connection
  Exception: Sequel::DatabaseConnectionError
  Stack: oracle.jdbc.driver.T4CConnection.logon(oracle/jdbc/driver/T4CConnection.java:489)
oracle.jdbc.driver.PhysicalConnection.<init>(oracle/jdbc/driver/PhysicalConnection.java:553)
oracle.jdbc.driver.T4CConnection.<init>(oracle/jdbc/driver/T4CConnection.java:254)
oracle.jdbc.driver.T4CDriverExtension.getConnection(oracle/jdbc/driver/T4CDriverExtension.java:32)
oracle.jdbc.driver.OracleDriver.connect(oracle/jdbc/driver/OracleDriver.java:528)
java.lang.reflect.Method.invoke(java/lang/reflect/Method.java:498)
org.jruby.javasupport.JavaMethod.invokeDirectWithExceptionHandling(org/jruby/javasupport/JavaMethod.java:468)
org.jruby.javasupport.JavaMethod.invokeDirect(org/jruby/javasupport/JavaMethod.java:326)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/adapters/jdbc.rb:203)
RUBY.make_new(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool.rb:126)
RUBY.assign_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:192)
RUBY.acquire(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:133)
RUBY.hold(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:90)
RUBY.synchronize(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:269)
RUBY.test_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:279)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:58)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/core.rb:116)
RUBY.block in jdbc_connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:114)
org.jruby.RubyKernel.loop(org/jruby/RubyKernel.java:1292)
org.jruby.RubyKernel$INVOKER$s$0$0$loop.call(org/jruby/RubyKernel$INVOKER$s$0$0$loop.gen)
RUBY.jdbc_connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:111)
RUBY.open_jdbc_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:163)
RUBY.execute_statement(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:219)
RUBY.execute_query(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/inputs/jdbc.rb:264)
RUBY.run(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/inputs/jdbc.rb:250)
RUBY.inputworker(/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:516)
RUBY.block in start_input(/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:509)
org.jruby.RubyProc.call(org/jruby/RubyProc.java:289)
org.jruby.RubyProc.call(org/jruby/RubyProc.java:246)
java.lang.Thread.run(java/lang/Thread.java:748)
[2018-05-30T15:13:39,902][ERROR][logstash.inputs.jdbc     ] Unable to connect to database. Tried 1 times {:error_message=>"Java::JavaSql::SQLRecoverableException: IO Error: The Network Adapter could not establish the connection"}
[2018-05-30T15:13:39,905][ERROR][logstash.pipeline        ] A plugin had an unrecoverable error. Will restart this plugin.
  Pipeline_id:main
  Plugin: <LogStash::Inputs::Jdbc jdbc_driver_library=>"/etc/logstash/ojdbc6.jar", jdbc_driver_class=>"Java::oracle.jdbc.driver.OracleDriver", jdbc_connection_string=>"jdbc:oracle:thin:@100.100.100.225:1521:tenuri", jdbc_user=>"es_app", jdbc_password=><password>, jdbc_fetch_size=>10000, statement_filepath=>"as-is_search-log.sql", id=>"5bd7533661d97dbb4a1d2a6189513af0c10219fd73809280818346be344afa9b", enable_metric=>true, codec=><LogStash::Codecs::Plain id=>"plain_f3ac762d-4e2c-43ec-bdfd-dc1a40002f14", enable_metric=>true, charset=>"UTF-8">, jdbc_paging_enabled=>false, jdbc_page_size=>100000, jdbc_validate_connection=>false, jdbc_validation_timeout=>3600, jdbc_pool_timeout=>5, sql_log_level=>"info", connection_retry_attempts=>1, connection_retry_attempts_wait_time=>0.5, parameters=>{"sql_last_value"=>2018-05-30 09:22:03 +0900}, last_run_metadata_path=>"/home/elastic/.logstash_jdbc_last_run", use_column_value=>false, tracking_column_type=>"numeric", clean_run=>false, record_last_run=>true, lowercase_column_names=>true>
  Error: Java::JavaSql::SQLRecoverableException: IO Error: The Network Adapter could not establish the connection
  Exception: Sequel::DatabaseConnectionError
  Stack: oracle.jdbc.driver.T4CConnection.logon(oracle/jdbc/driver/T4CConnection.java:489)
oracle.jdbc.driver.PhysicalConnection.<init>(oracle/jdbc/driver/PhysicalConnection.java:553)
oracle.jdbc.driver.T4CConnection.<init>(oracle/jdbc/driver/T4CConnection.java:254)
oracle.jdbc.driver.T4CDriverExtension.getConnection(oracle/jdbc/driver/T4CDriverExtension.java:32)
oracle.jdbc.driver.OracleDriver.connect(oracle/jdbc/driver/OracleDriver.java:528)
java.lang.reflect.Method.invoke(java/lang/reflect/Method.java:498)
org.jruby.javasupport.JavaMethod.invokeDirectWithExceptionHandling(org/jruby/javasupport/JavaMethod.java:468)
org.jruby.javasupport.JavaMethod.invokeDirect(org/jruby/javasupport/JavaMethod.java:326)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/adapters/jdbc.rb:203)
RUBY.make_new(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool.rb:126)
RUBY.assign_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:192)
RUBY.acquire(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:133)
RUBY.hold(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:90)
RUBY.synchronize(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:269)
RUBY.test_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:279)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:58)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/core.rb:116)
RUBY.block in jdbc_connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:114)
org.jruby.RubyKernel.loop(org/jruby/RubyKernel.java:1292)
org.jruby.RubyKernel$INVOKER$s$0$0$loop.call(org/jruby/RubyKernel$INVOKER$s$0$0$loop.gen)
RUBY.jdbc_connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:111)
RUBY.open_jdbc_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:163)
RUBY.execute_statement(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:219)
RUBY.execute_query(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/inputs/jdbc.rb:264)
RUBY.run(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/inputs/jdbc.rb:250)
RUBY.inputworker(/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:516)
RUBY.block in start_input(/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:509)
org.jruby.RubyProc.call(org/jruby/RubyProc.java:289)
org.jruby.RubyProc.call(org/jruby/RubyProc.java:246)
java.lang.Thread.run(java/lang/Thread.java:748)
[2018-05-30T15:13:42,910][ERROR][logstash.inputs.jdbc     ] Unable to connect to database. Tried 1 times {:error_message=>"Java::JavaSql::SQLRecoverableException: IO Error: The Network Adapter could not establish the connection"}
[2018-05-30T15:13:42,913][ERROR][logstash.pipeline        ] A plugin had an unrecoverable error. Will restart this plugin.
  Pipeline_id:main
  Plugin: <LogStash::Inputs::Jdbc jdbc_driver_library=>"/etc/logstash/ojdbc6.jar", jdbc_driver_class=>"Java::oracle.jdbc.driver.OracleDriver", jdbc_connection_string=>"jdbc:oracle:thin:@100.100.100.225:1521:tenuri", jdbc_user=>"es_app", jdbc_password=><password>, jdbc_fetch_size=>10000, statement_filepath=>"as-is_search-log.sql", id=>"5bd7533661d97dbb4a1d2a6189513af0c10219fd73809280818346be344afa9b", enable_metric=>true, codec=><LogStash::Codecs::Plain id=>"plain_f3ac762d-4e2c-43ec-bdfd-dc1a40002f14", enable_metric=>true, charset=>"UTF-8">, jdbc_paging_enabled=>false, jdbc_page_size=>100000, jdbc_validate_connection=>false, jdbc_validation_timeout=>3600, jdbc_pool_timeout=>5, sql_log_level=>"info", connection_retry_attempts=>1, connection_retry_attempts_wait_time=>0.5, parameters=>{"sql_last_value"=>2018-05-30 09:22:03 +0900}, last_run_metadata_path=>"/home/elastic/.logstash_jdbc_last_run", use_column_value=>false, tracking_column_type=>"numeric", clean_run=>false, record_last_run=>true, lowercase_column_names=>true>
  Error: Java::JavaSql::SQLRecoverableException: IO Error: The Network Adapter could not establish the connection
  Exception: Sequel::DatabaseConnectionError
  Stack: oracle.jdbc.driver.T4CConnection.logon(oracle/jdbc/driver/T4CConnection.java:489)
oracle.jdbc.driver.PhysicalConnection.<init>(oracle/jdbc/driver/PhysicalConnection.java:553)
oracle.jdbc.driver.T4CConnection.<init>(oracle/jdbc/driver/T4CConnection.java:254)
oracle.jdbc.driver.T4CDriverExtension.getConnection(oracle/jdbc/driver/T4CDriverExtension.java:32)
oracle.jdbc.driver.OracleDriver.connect(oracle/jdbc/driver/OracleDriver.java:528)
java.lang.reflect.Method.invoke(java/lang/reflect/Method.java:498)
org.jruby.javasupport.JavaMethod.invokeDirectWithExceptionHandling(org/jruby/javasupport/JavaMethod.java:468)
org.jruby.javasupport.JavaMethod.invokeDirect(org/jruby/javasupport/JavaMethod.java:326)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/adapters/jdbc.rb:203)
RUBY.make_new(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool.rb:126)
RUBY.assign_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:192)
RUBY.acquire(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:133)
RUBY.hold(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:90)
RUBY.synchronize(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:269)
RUBY.test_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:279)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:58)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/core.rb:116)
RUBY.block in jdbc_connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:114)
org.jruby.RubyKernel.loop(org/jruby/RubyKernel.java:1292)
org.jruby.RubyKernel$INVOKER$s$0$0$loop.call(org/jruby/RubyKernel$INVOKER$s$0$0$loop.gen)
RUBY.jdbc_connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:111)
RUBY.open_jdbc_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:163)
RUBY.execute_statement(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:219)
RUBY.execute_query(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/inputs/jdbc.rb:264)
RUBY.run(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/inputs/jdbc.rb:250)
RUBY.inputworker(/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:516)
RUBY.block in start_input(/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:509)
org.jruby.RubyProc.call(org/jruby/RubyProc.java:289)
org.jruby.RubyProc.call(org/jruby/RubyProc.java:246)
java.lang.Thread.run(java/lang/Thread.java:748)
[2018-05-30T15:13:45,915][ERROR][logstash.inputs.jdbc     ] Unable to connect to database. Tried 1 times {:error_message=>"Java::JavaSql::SQLRecoverableException: IO Error: The Network Adapter could not establish the connection"}
[2018-05-30T15:13:45,922][ERROR][logstash.pipeline        ] A plugin had an unrecoverable error. Will restart this plugin.
  Pipeline_id:main
  Plugin: <LogStash::Inputs::Jdbc jdbc_driver_library=>"/etc/logstash/ojdbc6.jar", jdbc_driver_class=>"Java::oracle.jdbc.driver.OracleDriver", jdbc_connection_string=>"jdbc:oracle:thin:@100.100.100.225:1521:tenuri", jdbc_user=>"es_app", jdbc_password=><password>, jdbc_fetch_size=>10000, statement_filepath=>"as-is_search-log.sql", id=>"5bd7533661d97dbb4a1d2a6189513af0c10219fd73809280818346be344afa9b", enable_metric=>true, codec=><LogStash::Codecs::Plain id=>"plain_f3ac762d-4e2c-43ec-bdfd-dc1a40002f14", enable_metric=>true, charset=>"UTF-8">, jdbc_paging_enabled=>false, jdbc_page_size=>100000, jdbc_validate_connection=>false, jdbc_validation_timeout=>3600, jdbc_pool_timeout=>5, sql_log_level=>"info", connection_retry_attempts=>1, connection_retry_attempts_wait_time=>0.5, parameters=>{"sql_last_value"=>2018-05-30 09:22:03 +0900}, last_run_metadata_path=>"/home/elastic/.logstash_jdbc_last_run", use_column_value=>false, tracking_column_type=>"numeric", clean_run=>false, record_last_run=>true, lowercase_column_names=>true>
  Error: Java::JavaSql::SQLRecoverableException: IO Error: The Network Adapter could not establish the connection
  Exception: Sequel::DatabaseConnectionError
  Stack: oracle.jdbc.driver.T4CConnection.logon(oracle/jdbc/driver/T4CConnection.java:489)
oracle.jdbc.driver.PhysicalConnection.<init>(oracle/jdbc/driver/PhysicalConnection.java:553)
oracle.jdbc.driver.T4CConnection.<init>(oracle/jdbc/driver/T4CConnection.java:254)
oracle.jdbc.driver.T4CDriverExtension.getConnection(oracle/jdbc/driver/T4CDriverExtension.java:32)
oracle.jdbc.driver.OracleDriver.connect(oracle/jdbc/driver/OracleDriver.java:528)
java.lang.reflect.Method.invoke(java/lang/reflect/Method.java:498)
org.jruby.javasupport.JavaMethod.invokeDirectWithExceptionHandling(org/jruby/javasupport/JavaMethod.java:468)
org.jruby.javasupport.JavaMethod.invokeDirect(org/jruby/javasupport/JavaMethod.java:326)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/adapters/jdbc.rb:203)
RUBY.make_new(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool.rb:126)
RUBY.assign_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:192)
RUBY.acquire(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:133)
RUBY.hold(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:90)
RUBY.synchronize(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:269)
RUBY.test_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:279)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:58)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/core.rb:116)
RUBY.block in jdbc_connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:114)
org.jruby.RubyKernel.loop(org/jruby/RubyKernel.java:1292)
org.jruby.RubyKernel$INVOKER$s$0$0$loop.call(org/jruby/RubyKernel$INVOKER$s$0$0$loop.gen)
RUBY.jdbc_connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:111)
RUBY.open_jdbc_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:163)
RUBY.execute_statement(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:219)
RUBY.execute_query(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/inputs/jdbc.rb:264)
RUBY.run(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/inputs/jdbc.rb:250)
RUBY.inputworker(/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:516)
RUBY.block in start_input(/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:509)
org.jruby.RubyProc.call(org/jruby/RubyProc.java:289)
org.jruby.RubyProc.call(org/jruby/RubyProc.java:246)
java.lang.Thread.run(java/lang/Thread.java:748)
[2018-05-30T15:13:48,921][ERROR][logstash.inputs.jdbc     ] Unable to connect to database. Tried 1 times {:error_message=>"Java::JavaSql::SQLRecoverableException: IO Error: The Network Adapter could not establish the connection"}
[2018-05-30T15:13:48,926][ERROR][logstash.pipeline        ] A plugin had an unrecoverable error. Will restart this plugin.
  Pipeline_id:main
  Plugin: <LogStash::Inputs::Jdbc jdbc_driver_library=>"/etc/logstash/ojdbc6.jar", jdbc_driver_class=>"Java::oracle.jdbc.driver.OracleDriver", jdbc_connection_string=>"jdbc:oracle:thin:@100.100.100.225:1521:tenuri", jdbc_user=>"es_app", jdbc_password=><password>, jdbc_fetch_size=>10000, statement_filepath=>"as-is_search-log.sql", id=>"5bd7533661d97dbb4a1d2a6189513af0c10219fd73809280818346be344afa9b", enable_metric=>true, codec=><LogStash::Codecs::Plain id=>"plain_f3ac762d-4e2c-43ec-bdfd-dc1a40002f14", enable_metric=>true, charset=>"UTF-8">, jdbc_paging_enabled=>false, jdbc_page_size=>100000, jdbc_validate_connection=>false, jdbc_validation_timeout=>3600, jdbc_pool_timeout=>5, sql_log_level=>"info", connection_retry_attempts=>1, connection_retry_attempts_wait_time=>0.5, parameters=>{"sql_last_value"=>2018-05-30 09:22:03 +0900}, last_run_metadata_path=>"/home/elastic/.logstash_jdbc_last_run", use_column_value=>false, tracking_column_type=>"numeric", clean_run=>false, record_last_run=>true, lowercase_column_names=>true>
  Error: Java::JavaSql::SQLRecoverableException: IO Error: The Network Adapter could not establish the connection
  Exception: Sequel::DatabaseConnectionError
  Stack: oracle.jdbc.driver.T4CConnection.logon(oracle/jdbc/driver/T4CConnection.java:489)
oracle.jdbc.driver.PhysicalConnection.<init>(oracle/jdbc/driver/PhysicalConnection.java:553)
oracle.jdbc.driver.T4CConnection.<init>(oracle/jdbc/driver/T4CConnection.java:254)
oracle.jdbc.driver.T4CDriverExtension.getConnection(oracle/jdbc/driver/T4CDriverExtension.java:32)
oracle.jdbc.driver.OracleDriver.connect(oracle/jdbc/driver/OracleDriver.java:528)
java.lang.reflect.Method.invoke(java/lang/reflect/Method.java:498)
org.jruby.javasupport.JavaMethod.invokeDirectWithExceptionHandling(org/jruby/javasupport/JavaMethod.java:468)
org.jruby.javasupport.JavaMethod.invokeDirect(org/jruby/javasupport/JavaMethod.java:326)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/adapters/jdbc.rb:203)
RUBY.make_new(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool.rb:126)
RUBY.assign_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:192)
RUBY.acquire(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:133)
RUBY.hold(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:90)
RUBY.synchronize(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:269)
RUBY.test_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:279)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:58)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/core.rb:116)
RUBY.block in jdbc_connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:114)
org.jruby.RubyKernel.loop(org/jruby/RubyKernel.java:1292)
org.jruby.RubyKernel$INVOKER$s$0$0$loop.call(org/jruby/RubyKernel$INVOKER$s$0$0$loop.gen)
RUBY.jdbc_connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:111)
RUBY.open_jdbc_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:163)
RUBY.execute_statement(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:219)
RUBY.execute_query(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/inputs/jdbc.rb:264)
RUBY.run(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/inputs/jdbc.rb:250)
RUBY.inputworker(/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:516)
RUBY.block in start_input(/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:509)
org.jruby.RubyProc.call(org/jruby/RubyProc.java:289)
org.jruby.RubyProc.call(org/jruby/RubyProc.java:246)
java.lang.Thread.run(java/lang/Thread.java:748)
[2018-05-30T15:13:51,927][ERROR][logstash.inputs.jdbc     ] Unable to connect to database. Tried 1 times {:error_message=>"Java::JavaSql::SQLRecoverableException: IO Error: The Network Adapter could not establish the connection"}
[2018-05-30T15:13:51,932][ERROR][logstash.pipeline        ] A plugin had an unrecoverable error. Will restart this plugin.
  Pipeline_id:main
  Plugin: <LogStash::Inputs::Jdbc jdbc_driver_library=>"/etc/logstash/ojdbc6.jar", jdbc_driver_class=>"Java::oracle.jdbc.driver.OracleDriver", jdbc_connection_string=>"jdbc:oracle:thin:@100.100.100.225:1521:tenuri", jdbc_user=>"es_app", jdbc_password=><password>, jdbc_fetch_size=>10000, statement_filepath=>"as-is_search-log.sql", id=>"5bd7533661d97dbb4a1d2a6189513af0c10219fd73809280818346be344afa9b", enable_metric=>true, codec=><LogStash::Codecs::Plain id=>"plain_f3ac762d-4e2c-43ec-bdfd-dc1a40002f14", enable_metric=>true, charset=>"UTF-8">, jdbc_paging_enabled=>false, jdbc_page_size=>100000, jdbc_validate_connection=>false, jdbc_validation_timeout=>3600, jdbc_pool_timeout=>5, sql_log_level=>"info", connection_retry_attempts=>1, connection_retry_attempts_wait_time=>0.5, parameters=>{"sql_last_value"=>2018-05-30 09:22:03 +0900}, last_run_metadata_path=>"/home/elastic/.logstash_jdbc_last_run", use_column_value=>false, tracking_column_type=>"numeric", clean_run=>false, record_last_run=>true, lowercase_column_names=>true>
  Error: Java::JavaSql::SQLRecoverableException: IO Error: The Network Adapter could not establish the connection
  Exception: Sequel::DatabaseConnectionError
  Stack: oracle.jdbc.driver.T4CConnection.logon(oracle/jdbc/driver/T4CConnection.java:489)
oracle.jdbc.driver.PhysicalConnection.<init>(oracle/jdbc/driver/PhysicalConnection.java:553)
oracle.jdbc.driver.T4CConnection.<init>(oracle/jdbc/driver/T4CConnection.java:254)
oracle.jdbc.driver.T4CDriverExtension.getConnection(oracle/jdbc/driver/T4CDriverExtension.java:32)
oracle.jdbc.driver.OracleDriver.connect(oracle/jdbc/driver/OracleDriver.java:528)
java.lang.reflect.Method.invoke(java/lang/reflect/Method.java:498)
org.jruby.javasupport.JavaMethod.invokeDirectWithExceptionHandling(org/jruby/javasupport/JavaMethod.java:468)
org.jruby.javasupport.JavaMethod.invokeDirect(org/jruby/javasupport/JavaMethod.java:326)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/adapters/jdbc.rb:203)
RUBY.make_new(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool.rb:126)
RUBY.assign_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:192)
RUBY.acquire(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:133)
RUBY.hold(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:90)
RUBY.synchronize(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:269)
RUBY.test_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:279)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:58)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/core.rb:116)
RUBY.block in jdbc_connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:114)
org.jruby.RubyKernel.loop(org/jruby/RubyKernel.java:1292)
org.jruby.RubyKernel$INVOKER$s$0$0$loop.call(org/jruby/RubyKernel$INVOKER$s$0$0$loop.gen)
RUBY.jdbc_connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:111)
RUBY.open_jdbc_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:163)
RUBY.execute_statement(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:219)
RUBY.execute_query(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/inputs/jdbc.rb:264)
RUBY.run(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/inputs/jdbc.rb:250)
RUBY.inputworker(/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:516)
RUBY.block in start_input(/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:509)
org.jruby.RubyProc.call(org/jruby/RubyProc.java:289)
org.jruby.RubyProc.call(org/jruby/RubyProc.java:246)
java.lang.Thread.run(java/lang/Thread.java:748)
[2018-05-30T15:13:54,933][ERROR][logstash.inputs.jdbc     ] Unable to connect to database. Tried 1 times {:error_message=>"Java::JavaSql::SQLRecoverableException: IO Error: The Network Adapter could not establish the connection"}
[2018-05-30T15:13:54,936][ERROR][logstash.pipeline        ] A plugin had an unrecoverable error. Will restart this plugin.
  Pipeline_id:main
  Plugin: <LogStash::Inputs::Jdbc jdbc_driver_library=>"/etc/logstash/ojdbc6.jar", jdbc_driver_class=>"Java::oracle.jdbc.driver.OracleDriver", jdbc_connection_string=>"jdbc:oracle:thin:@100.100.100.225:1521:tenuri", jdbc_user=>"es_app", jdbc_password=><password>, jdbc_fetch_size=>10000, statement_filepath=>"as-is_search-log.sql", id=>"5bd7533661d97dbb4a1d2a6189513af0c10219fd73809280818346be344afa9b", enable_metric=>true, codec=><LogStash::Codecs::Plain id=>"plain_f3ac762d-4e2c-43ec-bdfd-dc1a40002f14", enable_metric=>true, charset=>"UTF-8">, jdbc_paging_enabled=>false, jdbc_page_size=>100000, jdbc_validate_connection=>false, jdbc_validation_timeout=>3600, jdbc_pool_timeout=>5, sql_log_level=>"info", connection_retry_attempts=>1, connection_retry_attempts_wait_time=>0.5, parameters=>{"sql_last_value"=>2018-05-30 09:22:03 +0900}, last_run_metadata_path=>"/home/elastic/.logstash_jdbc_last_run", use_column_value=>false, tracking_column_type=>"numeric", clean_run=>false, record_last_run=>true, lowercase_column_names=>true>
  Error: Java::JavaSql::SQLRecoverableException: IO Error: The Network Adapter could not establish the connection
  Exception: Sequel::DatabaseConnectionError
  Stack: oracle.jdbc.driver.T4CConnection.logon(oracle/jdbc/driver/T4CConnection.java:489)
oracle.jdbc.driver.PhysicalConnection.<init>(oracle/jdbc/driver/PhysicalConnection.java:553)
oracle.jdbc.driver.T4CConnection.<init>(oracle/jdbc/driver/T4CConnection.java:254)
oracle.jdbc.driver.T4CDriverExtension.getConnection(oracle/jdbc/driver/T4CDriverExtension.java:32)
oracle.jdbc.driver.OracleDriver.connect(oracle/jdbc/driver/OracleDriver.java:528)
java.lang.reflect.Method.invoke(java/lang/reflect/Method.java:498)
org.jruby.javasupport.JavaMethod.invokeDirectWithExceptionHandling(org/jruby/javasupport/JavaMethod.java:468)
org.jruby.javasupport.JavaMethod.invokeDirect(org/jruby/javasupport/JavaMethod.java:326)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/adapters/jdbc.rb:203)
RUBY.make_new(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool.rb:126)
RUBY.assign_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:192)
RUBY.acquire(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:133)
RUBY.hold(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:90)
RUBY.synchronize(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:269)
RUBY.test_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:279)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:58)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/core.rb:116)
RUBY.block in jdbc_connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:114)
org.jruby.RubyKernel.loop(org/jruby/RubyKernel.java:1292)
org.jruby.RubyKernel$INVOKER$s$0$0$loop.call(org/jruby/RubyKernel$INVOKER$s$0$0$loop.gen)
RUBY.jdbc_connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:111)
RUBY.open_jdbc_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:163)
RUBY.execute_statement(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:219)
RUBY.execute_query(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/inputs/jdbc.rb:264)
RUBY.run(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/inputs/jdbc.rb:250)
RUBY.inputworker(/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:516)
RUBY.block in start_input(/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:509)
org.jruby.RubyProc.call(org/jruby/RubyProc.java:289)
org.jruby.RubyProc.call(org/jruby/RubyProc.java:246)
java.lang.Thread.run(java/lang/Thread.java:748)
[2018-05-30T15:13:57,939][ERROR][logstash.inputs.jdbc     ] Unable to connect to database. Tried 1 times {:error_message=>"Java::JavaSql::SQLRecoverableException: IO Error: The Network Adapter could not establish the connection"}
[2018-05-30T15:13:57,945][ERROR][logstash.pipeline        ] A plugin had an unrecoverable error. Will restart this plugin.
  Pipeline_id:main
  Plugin: <LogStash::Inputs::Jdbc jdbc_driver_library=>"/etc/logstash/ojdbc6.jar", jdbc_driver_class=>"Java::oracle.jdbc.driver.OracleDriver", jdbc_connection_string=>"jdbc:oracle:thin:@100.100.100.225:1521:tenuri", jdbc_user=>"es_app", jdbc_password=><password>, jdbc_fetch_size=>10000, statement_filepath=>"as-is_search-log.sql", id=>"5bd7533661d97dbb4a1d2a6189513af0c10219fd73809280818346be344afa9b", enable_metric=>true, codec=><LogStash::Codecs::Plain id=>"plain_f3ac762d-4e2c-43ec-bdfd-dc1a40002f14", enable_metric=>true, charset=>"UTF-8">, jdbc_paging_enabled=>false, jdbc_page_size=>100000, jdbc_validate_connection=>false, jdbc_validation_timeout=>3600, jdbc_pool_timeout=>5, sql_log_level=>"info", connection_retry_attempts=>1, connection_retry_attempts_wait_time=>0.5, parameters=>{"sql_last_value"=>2018-05-30 09:22:03 +0900}, last_run_metadata_path=>"/home/elastic/.logstash_jdbc_last_run", use_column_value=>false, tracking_column_type=>"numeric", clean_run=>false, record_last_run=>true, lowercase_column_names=>true>
  Error: Java::JavaSql::SQLRecoverableException: IO Error: The Network Adapter could not establish the connection
  Exception: Sequel::DatabaseConnectionError
  Stack: oracle.jdbc.driver.T4CConnection.logon(oracle/jdbc/driver/T4CConnection.java:489)
oracle.jdbc.driver.PhysicalConnection.<init>(oracle/jdbc/driver/PhysicalConnection.java:553)
oracle.jdbc.driver.T4CConnection.<init>(oracle/jdbc/driver/T4CConnection.java:254)
oracle.jdbc.driver.T4CDriverExtension.getConnection(oracle/jdbc/driver/T4CDriverExtension.java:32)
oracle.jdbc.driver.OracleDriver.connect(oracle/jdbc/driver/OracleDriver.java:528)
java.lang.reflect.Method.invoke(java/lang/reflect/Method.java:498)
org.jruby.javasupport.JavaMethod.invokeDirectWithExceptionHandling(org/jruby/javasupport/JavaMethod.java:468)
org.jruby.javasupport.JavaMethod.invokeDirect(org/jruby/javasupport/JavaMethod.java:326)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/adapters/jdbc.rb:203)
RUBY.make_new(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool.rb:126)
RUBY.assign_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:192)
RUBY.acquire(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:133)
RUBY.hold(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:90)
RUBY.synchronize(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:269)
RUBY.test_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:279)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:58)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/core.rb:116)
RUBY.block in jdbc_connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:114)
org.jruby.RubyKernel.loop(org/jruby/RubyKernel.java:1292)
org.jruby.RubyKernel$INVOKER$s$0$0$loop.call(org/jruby/RubyKernel$INVOKER$s$0$0$loop.gen)
RUBY.jdbc_connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:111)
RUBY.open_jdbc_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:163)
RUBY.execute_statement(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:219)
RUBY.execute_query(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/inputs/jdbc.rb:264)
RUBY.run(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/inputs/jdbc.rb:250)
RUBY.inputworker(/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:516)
RUBY.block in start_input(/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:509)
org.jruby.RubyProc.call(org/jruby/RubyProc.java:289)
org.jruby.RubyProc.call(org/jruby/RubyProc.java:246)
java.lang.Thread.run(java/lang/Thread.java:748)
[2018-05-30T15:14:00,945][ERROR][logstash.inputs.jdbc     ] Unable to connect to database. Tried 1 times {:error_message=>"Java::JavaSql::SQLRecoverableException: IO Error: The Network Adapter could not establish the connection"}
[2018-05-30T15:14:00,949][ERROR][logstash.pipeline        ] A plugin had an unrecoverable error. Will restart this plugin.
  Pipeline_id:main
  Plugin: <LogStash::Inputs::Jdbc jdbc_driver_library=>"/etc/logstash/ojdbc6.jar", jdbc_driver_class=>"Java::oracle.jdbc.driver.OracleDriver", jdbc_connection_string=>"jdbc:oracle:thin:@100.100.100.225:1521:tenuri", jdbc_user=>"es_app", jdbc_password=><password>, jdbc_fetch_size=>10000, statement_filepath=>"as-is_search-log.sql", id=>"5bd7533661d97dbb4a1d2a6189513af0c10219fd73809280818346be344afa9b", enable_metric=>true, codec=><LogStash::Codecs::Plain id=>"plain_f3ac762d-4e2c-43ec-bdfd-dc1a40002f14", enable_metric=>true, charset=>"UTF-8">, jdbc_paging_enabled=>false, jdbc_page_size=>100000, jdbc_validate_connection=>false, jdbc_validation_timeout=>3600, jdbc_pool_timeout=>5, sql_log_level=>"info", connection_retry_attempts=>1, connection_retry_attempts_wait_time=>0.5, parameters=>{"sql_last_value"=>2018-05-30 09:22:03 +0900}, last_run_metadata_path=>"/home/elastic/.logstash_jdbc_last_run", use_column_value=>false, tracking_column_type=>"numeric", clean_run=>false, record_last_run=>true, lowercase_column_names=>true>
  Error: Java::JavaSql::SQLRecoverableException: IO Error: The Network Adapter could not establish the connection
  Exception: Sequel::DatabaseConnectionError
  Stack: oracle.jdbc.driver.T4CConnection.logon(oracle/jdbc/driver/T4CConnection.java:489)
oracle.jdbc.driver.PhysicalConnection.<init>(oracle/jdbc/driver/PhysicalConnection.java:553)
oracle.jdbc.driver.T4CConnection.<init>(oracle/jdbc/driver/T4CConnection.java:254)
oracle.jdbc.driver.T4CDriverExtension.getConnection(oracle/jdbc/driver/T4CDriverExtension.java:32)
oracle.jdbc.driver.OracleDriver.connect(oracle/jdbc/driver/OracleDriver.java:528)
java.lang.reflect.Method.invoke(java/lang/reflect/Method.java:498)
org.jruby.javasupport.JavaMethod.invokeDirectWithExceptionHandling(org/jruby/javasupport/JavaMethod.java:468)
org.jruby.javasupport.JavaMethod.invokeDirect(org/jruby/javasupport/JavaMethod.java:326)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/adapters/jdbc.rb:203)
RUBY.make_new(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool.rb:126)
RUBY.assign_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:192)
RUBY.acquire(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:133)
RUBY.hold(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:90)
RUBY.synchronize(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:269)
RUBY.test_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:279)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:58)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/core.rb:116)
RUBY.block in jdbc_connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:114)
org.jruby.RubyKernel.loop(org/jruby/RubyKernel.java:1292)
org.jruby.RubyKernel$INVOKER$s$0$0$loop.call(org/jruby/RubyKernel$INVOKER$s$0$0$loop.gen)
RUBY.jdbc_connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:111)
RUBY.open_jdbc_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:163)
RUBY.execute_statement(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:219)
RUBY.execute_query(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/inputs/jdbc.rb:264)
RUBY.run(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/inputs/jdbc.rb:250)
RUBY.inputworker(/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:516)
RUBY.block in start_input(/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:509)
org.jruby.RubyProc.call(org/jruby/RubyProc.java:289)
org.jruby.RubyProc.call(org/jruby/RubyProc.java:246)
java.lang.Thread.run(java/lang/Thread.java:748)
[2018-05-30T15:14:03,951][ERROR][logstash.inputs.jdbc     ] Unable to connect to database. Tried 1 times {:error_message=>"Java::JavaSql::SQLRecoverableException: IO Error: The Network Adapter could not establish the connection"}
[2018-05-30T15:14:03,955][ERROR][logstash.pipeline        ] A plugin had an unrecoverable error. Will restart this plugin.
  Pipeline_id:main
  Plugin: <LogStash::Inputs::Jdbc jdbc_driver_library=>"/etc/logstash/ojdbc6.jar", jdbc_driver_class=>"Java::oracle.jdbc.driver.OracleDriver", jdbc_connection_string=>"jdbc:oracle:thin:@100.100.100.225:1521:tenuri", jdbc_user=>"es_app", jdbc_password=><password>, jdbc_fetch_size=>10000, statement_filepath=>"as-is_search-log.sql", id=>"5bd7533661d97dbb4a1d2a6189513af0c10219fd73809280818346be344afa9b", enable_metric=>true, codec=><LogStash::Codecs::Plain id=>"plain_f3ac762d-4e2c-43ec-bdfd-dc1a40002f14", enable_metric=>true, charset=>"UTF-8">, jdbc_paging_enabled=>false, jdbc_page_size=>100000, jdbc_validate_connection=>false, jdbc_validation_timeout=>3600, jdbc_pool_timeout=>5, sql_log_level=>"info", connection_retry_attempts=>1, connection_retry_attempts_wait_time=>0.5, parameters=>{"sql_last_value"=>2018-05-30 09:22:03 +0900}, last_run_metadata_path=>"/home/elastic/.logstash_jdbc_last_run", use_column_value=>false, tracking_column_type=>"numeric", clean_run=>false, record_last_run=>true, lowercase_column_names=>true>
  Error: Java::JavaSql::SQLRecoverableException: IO Error: The Network Adapter could not establish the connection
  Exception: Sequel::DatabaseConnectionError
  Stack: oracle.jdbc.driver.T4CConnection.logon(oracle/jdbc/driver/T4CConnection.java:489)
oracle.jdbc.driver.PhysicalConnection.<init>(oracle/jdbc/driver/PhysicalConnection.java:553)
oracle.jdbc.driver.T4CConnection.<init>(oracle/jdbc/driver/T4CConnection.java:254)
oracle.jdbc.driver.T4CDriverExtension.getConnection(oracle/jdbc/driver/T4CDriverExtension.java:32)
oracle.jdbc.driver.OracleDriver.connect(oracle/jdbc/driver/OracleDriver.java:528)
java.lang.reflect.Method.invoke(java/lang/reflect/Method.java:498)
org.jruby.javasupport.JavaMethod.invokeDirectWithExceptionHandling(org/jruby/javasupport/JavaMethod.java:468)
org.jruby.javasupport.JavaMethod.invokeDirect(org/jruby/javasupport/JavaMethod.java:326)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/adapters/jdbc.rb:203)
RUBY.make_new(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool.rb:126)
RUBY.assign_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:192)
RUBY.acquire(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:133)
RUBY.hold(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:90)
RUBY.synchronize(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:269)
RUBY.test_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:279)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:58)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/core.rb:116)
RUBY.block in jdbc_connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:114)
org.jruby.RubyKernel.loop(org/jruby/RubyKernel.java:1292)
org.jruby.RubyKernel$INVOKER$s$0$0$loop.call(org/jruby/RubyKernel$INVOKER$s$0$0$loop.gen)
RUBY.jdbc_connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:111)
RUBY.open_jdbc_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:163)
RUBY.execute_statement(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:219)
RUBY.execute_query(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/inputs/jdbc.rb:264)
RUBY.run(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/inputs/jdbc.rb:250)
RUBY.inputworker(/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:516)
RUBY.block in start_input(/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:509)
org.jruby.RubyProc.call(org/jruby/RubyProc.java:289)
org.jruby.RubyProc.call(org/jruby/RubyProc.java:246)
java.lang.Thread.run(java/lang/Thread.java:748)
[2018-05-30T15:14:06,959][ERROR][logstash.inputs.jdbc     ] Unable to connect to database. Tried 1 times {:error_message=>"Java::JavaSql::SQLRecoverableException: IO Error: The Network Adapter could not establish the connection"}
[2018-05-30T15:14:06,962][ERROR][logstash.pipeline        ] A plugin had an unrecoverable error. Will restart this plugin.
  Pipeline_id:main
  Plugin: <LogStash::Inputs::Jdbc jdbc_driver_library=>"/etc/logstash/ojdbc6.jar", jdbc_driver_class=>"Java::oracle.jdbc.driver.OracleDriver", jdbc_connection_string=>"jdbc:oracle:thin:@100.100.100.225:1521:tenuri", jdbc_user=>"es_app", jdbc_password=><password>, jdbc_fetch_size=>10000, statement_filepath=>"as-is_search-log.sql", id=>"5bd7533661d97dbb4a1d2a6189513af0c10219fd73809280818346be344afa9b", enable_metric=>true, codec=><LogStash::Codecs::Plain id=>"plain_f3ac762d-4e2c-43ec-bdfd-dc1a40002f14", enable_metric=>true, charset=>"UTF-8">, jdbc_paging_enabled=>false, jdbc_page_size=>100000, jdbc_validate_connection=>false, jdbc_validation_timeout=>3600, jdbc_pool_timeout=>5, sql_log_level=>"info", connection_retry_attempts=>1, connection_retry_attempts_wait_time=>0.5, parameters=>{"sql_last_value"=>2018-05-30 09:22:03 +0900}, last_run_metadata_path=>"/home/elastic/.logstash_jdbc_last_run", use_column_value=>false, tracking_column_type=>"numeric", clean_run=>false, record_last_run=>true, lowercase_column_names=>true>
  Error: Java::JavaSql::SQLRecoverableException: IO Error: The Network Adapter could not establish the connection
  Exception: Sequel::DatabaseConnectionError
  Stack: oracle.jdbc.driver.T4CConnection.logon(oracle/jdbc/driver/T4CConnection.java:489)
oracle.jdbc.driver.PhysicalConnection.<init>(oracle/jdbc/driver/PhysicalConnection.java:553)
oracle.jdbc.driver.T4CConnection.<init>(oracle/jdbc/driver/T4CConnection.java:254)
oracle.jdbc.driver.T4CDriverExtension.getConnection(oracle/jdbc/driver/T4CDriverExtension.java:32)
oracle.jdbc.driver.OracleDriver.connect(oracle/jdbc/driver/OracleDriver.java:528)
java.lang.reflect.Method.invoke(java/lang/reflect/Method.java:498)
org.jruby.javasupport.JavaMethod.invokeDirectWithExceptionHandling(org/jruby/javasupport/JavaMethod.java:468)
org.jruby.javasupport.JavaMethod.invokeDirect(org/jruby/javasupport/JavaMethod.java:326)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/adapters/jdbc.rb:203)
RUBY.make_new(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool.rb:126)
RUBY.assign_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:192)
RUBY.acquire(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:133)
RUBY.hold(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:90)
RUBY.synchronize(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:269)
RUBY.test_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:279)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:58)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/core.rb:116)
RUBY.block in jdbc_connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:114)
org.jruby.RubyKernel.loop(org/jruby/RubyKernel.java:1292)
org.jruby.RubyKernel$INVOKER$s$0$0$loop.call(org/jruby/RubyKernel$INVOKER$s$0$0$loop.gen)
RUBY.jdbc_connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:111)
RUBY.open_jdbc_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:163)
RUBY.execute_statement(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:219)
RUBY.execute_query(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/inputs/jdbc.rb:264)
RUBY.run(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/inputs/jdbc.rb:250)
RUBY.inputworker(/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:516)
RUBY.block in start_input(/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:509)
org.jruby.RubyProc.call(org/jruby/RubyProc.java:289)
org.jruby.RubyProc.call(org/jruby/RubyProc.java:246)
java.lang.Thread.run(java/lang/Thread.java:748)
[2018-05-30T15:14:09,963][ERROR][logstash.inputs.jdbc     ] Unable to connect to database. Tried 1 times {:error_message=>"Java::JavaSql::SQLRecoverableException: IO Error: The Network Adapter could not establish the connection"}
[2018-05-30T15:14:09,967][ERROR][logstash.pipeline        ] A plugin had an unrecoverable error. Will restart this plugin.
  Pipeline_id:main
  Plugin: <LogStash::Inputs::Jdbc jdbc_driver_library=>"/etc/logstash/ojdbc6.jar", jdbc_driver_class=>"Java::oracle.jdbc.driver.OracleDriver", jdbc_connection_string=>"jdbc:oracle:thin:@100.100.100.225:1521:tenuri", jdbc_user=>"es_app", jdbc_password=><password>, jdbc_fetch_size=>10000, statement_filepath=>"as-is_search-log.sql", id=>"5bd7533661d97dbb4a1d2a6189513af0c10219fd73809280818346be344afa9b", enable_metric=>true, codec=><LogStash::Codecs::Plain id=>"plain_f3ac762d-4e2c-43ec-bdfd-dc1a40002f14", enable_metric=>true, charset=>"UTF-8">, jdbc_paging_enabled=>false, jdbc_page_size=>100000, jdbc_validate_connection=>false, jdbc_validation_timeout=>3600, jdbc_pool_timeout=>5, sql_log_level=>"info", connection_retry_attempts=>1, connection_retry_attempts_wait_time=>0.5, parameters=>{"sql_last_value"=>2018-05-30 09:22:03 +0900}, last_run_metadata_path=>"/home/elastic/.logstash_jdbc_last_run", use_column_value=>false, tracking_column_type=>"numeric", clean_run=>false, record_last_run=>true, lowercase_column_names=>true>
  Error: Java::JavaSql::SQLRecoverableException: IO Error: The Network Adapter could not establish the connection
  Exception: Sequel::DatabaseConnectionError
  Stack: oracle.jdbc.driver.T4CConnection.logon(oracle/jdbc/driver/T4CConnection.java:489)
oracle.jdbc.driver.PhysicalConnection.<init>(oracle/jdbc/driver/PhysicalConnection.java:553)
oracle.jdbc.driver.T4CConnection.<init>(oracle/jdbc/driver/T4CConnection.java:254)
oracle.jdbc.driver.T4CDriverExtension.getConnection(oracle/jdbc/driver/T4CDriverExtension.java:32)
oracle.jdbc.driver.OracleDriver.connect(oracle/jdbc/driver/OracleDriver.java:528)
java.lang.reflect.Method.invoke(java/lang/reflect/Method.java:498)
org.jruby.javasupport.JavaMethod.invokeDirectWithExceptionHandling(org/jruby/javasupport/JavaMethod.java:468)
org.jruby.javasupport.JavaMethod.invokeDirect(org/jruby/javasupport/JavaMethod.java:326)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/adapters/jdbc.rb:203)
RUBY.make_new(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool.rb:126)
RUBY.assign_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:192)
RUBY.acquire(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:133)
RUBY.hold(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/connection_pool/threaded.rb:90)
RUBY.synchronize(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:269)
RUBY.test_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:279)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:58)
RUBY.connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/core.rb:116)
RUBY.block in jdbc_connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:114)
org.jruby.RubyKernel.loop(org/jruby/RubyKernel.java:1292)
org.jruby.RubyKernel$INVOKER$s$0$0$loop.call(org/jruby/RubyKernel$INVOKER$s$0$0$loop.gen)
RUBY.jdbc_connect(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:111)
RUBY.open_jdbc_connection(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:163)
RUBY.execute_statement(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:219)
RUBY.execute_query(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/inputs/jdbc.rb:264)
RUBY.run(/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/inputs/jdbc.rb:250)
RUBY.inputworker(/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:516)
RUBY.block in start_input(/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:509)
org.jruby.RubyProc.call(org/jruby/RubyProc.java:289)
org.jruby.RubyProc.call(org/jruby/RubyProc.java:246)
java.lang.Thread.run(java/lang/Thread.java:748)
[2018-05-30T15:14:38,870][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"fb_apache", :directory=>"/usr/share/logstash/modules/fb_apache/configuration"}
[2018-05-30T15:14:38,878][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"netflow", :directory=>"/usr/share/logstash/modules/netflow/configuration"}
[2018-05-30T15:14:39,230][WARN ][logstash.config.source.multilocal] Ignoring the 'pipelines.yml' file because modules or command line options are specified
[2018-05-30T15:14:39,380][INFO ][logstash.runner          ] Starting Logstash {"logstash.version"=>"6.2.3"}
[2018-05-30T15:14:39,484][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=>9600}
[2018-05-30T15:14:40,334][INFO ][logstash.filters.ruby.script] Test run complete {:script_path=>"rubyfilter.rb", :results=>{:passed=>0, :failed=>0, :errored=>0}}
[2018-05-30T15:14:40,450][WARN ][logstash.outputs.elasticsearch] You are using a deprecated config setting "document_type" set in elasticsearch. Deprecated settings will continue to work, but are scheduled for removal from logstash in the future. Document types are being deprecated in Elasticsearch 6.0, and removed entirely in 7.0. You should avoid this feature If you have any questions about this, please visit the #logstash channel on freenode irc. {:name=>"document_type", :plugin=><LogStash::Outputs::ElasticSearch hosts=>[//100.100.100.111:9200, //100.100.100.112:9200, //100.100.100.113:9200], index=>"qa-enuri-main", document_type=>"_doc", document_id=>"%{id}", action=>"%{[@metadata][action]}", id=>"1e467b65cdb19f8ec490211c54b70c84245eb646e7b738c238df4f2c36495d5d", enable_metric=>true, codec=><LogStash::Codecs::Plain id=>"plain_4e1244a2-d0a3-418a-a9f0-4d3340c0445b", enable_metric=>true, charset=>"UTF-8">, workers=>1, manage_template=>true, template_name=>"logstash", template_overwrite=>false, doc_as_upsert=>false, script_type=>"inline", script_lang=>"painless", script_var_name=>"event", scripted_upsert=>false, retry_initial_interval=>2, retry_max_interval=>64, retry_on_conflict=>1, ssl_certificate_verification=>true, sniffing=>false, sniffing_delay=>5, timeout=>60, pool_max=>1000, pool_max_per_route=>100, resurrect_delay=>5, validate_after_inactivity=>10000, http_compression=>false>}
[2018-05-30T15:14:40,462][INFO ][logstash.pipeline        ] Starting pipeline {:pipeline_id=>"main", "pipeline.workers"=>8, "pipeline.batch.size"=>125, "pipeline.batch.delay"=>50}
[2018-05-30T15:14:40,778][INFO ][logstash.outputs.elasticsearch] Elasticsearch pool URLs updated {:changes=>{:removed=>[], :added=>[http://100.100.100.111:9200/, http://100.100.100.112:9200/, http://100.100.100.113:9200/]}}
[2018-05-30T15:14:40,782][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://100.100.100.111:9200/, :path=>"/"}
[2018-05-30T15:14:40,908][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://100.100.100.111:9200/"}
[2018-05-30T15:14:40,960][INFO ][logstash.outputs.elasticsearch] ES Output version determined {:es_version=>6}
[2018-05-30T15:14:40,961][WARN ][logstash.outputs.elasticsearch] Detected a 6.x and above cluster: the `type` event field won't be used to determine the document _type {:es_version=>6}
[2018-05-30T15:14:40,962][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://100.100.100.112:9200/, :path=>"/"}
[2018-05-30T15:14:40,968][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://100.100.100.112:9200/"}
[2018-05-30T15:14:40,974][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://100.100.100.113:9200/, :path=>"/"}
[2018-05-30T15:14:40,979][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://100.100.100.113:9200/"}
[2018-05-30T15:14:40,988][INFO ][logstash.outputs.elasticsearch] Using mapping template from {:path=>nil}
[2018-05-30T15:14:40,995][INFO ][logstash.outputs.elasticsearch] Attempting to install template {:manage_template=>{"template"=>"logstash-*", "version"=>60001, "settings"=>{"index.refresh_interval"=>"5s"}, "mappings"=>{"_default_"=>{"dynamic_templates"=>[{"message_field"=>{"path_match"=>"message", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false}}}, {"string_fields"=>{"match"=>"*", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false, "fields"=>{"keyword"=>{"type"=>"keyword", "ignore_above"=>256}}}}}], "properties"=>{"@timestamp"=>{"type"=>"date"}, "@version"=>{"type"=>"keyword"}, "geoip"=>{"dynamic"=>true, "properties"=>{"ip"=>{"type"=>"ip"}, "location"=>{"type"=>"geo_point"}, "latitude"=>{"type"=>"half_float"}, "longitude"=>{"type"=>"half_float"}}}}}}}}
[2018-05-30T15:14:41,002][INFO ][logstash.outputs.elasticsearch] New Elasticsearch output {:class=>"LogStash::Outputs::ElasticSearch", :hosts=>["//100.100.100.111:9200", "//100.100.100.112:9200", "//100.100.100.113:9200"]}
[2018-05-30T15:14:41,166][INFO ][logstash.pipeline        ] Pipeline started succesfully {:pipeline_id=>"main", :thread=>"#<Thread:0x6f41a83d@/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:246 sleep>"}
[2018-05-30T15:14:41,185][INFO ][logstash.agent           ] Pipelines running {:count=>1, :pipelines=>["main"]}
[2018-05-30T15:14:43,423][INFO ][logstash.inputs.jdbc     ] (1.578949s) select
    status as action,
    search_key as ID,
    modelno,
    pl_no,
    modelno_group,
    MODELNO_GROUP_FLAG,
    category,
    CG,
    CAT1,
    CAT2,
    CAT3,
    CAT4,
    ca_code,
    ca_dept_mcode,
    ca_dept_code,
    ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,
    shop_name,
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    model_factory,
    minprice,
    maxprice,
    minprices,
    C_DATE,
    mallcnt,
    MALLCNT_FLAG,
    spec,
    openexpectflag,
    condiname,
    KEYWORD,
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    MODELNM || ' ' || FACTORY || ' ' || SPEC || ' ' || KEYWORD || ' ' || KEYWORD2 || ' ' || CONDINAME AS to_all
from dbenuri.TBL_SEARCH_LOG_ES
--where
-- (case when modelno=0 then mod(pl_no, 3) else mod(modelno, 3) end) = 0
-- and regdate < (select stime from DBENURI.ir_inc_index_timestamp where collection_name = 'ENURI_0')

[2018-05-30T15:14:44,400][INFO ][logstash.pipeline        ] Pipeline has terminated {:pipeline_id=>"main", :thread=>"#<Thread:0x6f41a83d@/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:246 run>"}
[2018-05-30T16:29:00,738][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"fb_apache", :directory=>"/usr/share/logstash/modules/fb_apache/configuration"}
[2018-05-30T16:29:00,746][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"netflow", :directory=>"/usr/share/logstash/modules/netflow/configuration"}
[2018-05-30T16:29:01,166][WARN ][logstash.config.source.multilocal] Ignoring the 'pipelines.yml' file because modules or command line options are specified
[2018-05-30T16:29:01,341][INFO ][logstash.runner          ] Starting Logstash {"logstash.version"=>"6.2.3"}
[2018-05-30T16:29:01,444][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=>9600}
[2018-05-30T16:29:02,296][INFO ][logstash.filters.ruby.script] Test run complete {:script_path=>"rubyfilter.rb", :results=>{:passed=>0, :failed=>0, :errored=>0}}
[2018-05-30T16:29:02,412][WARN ][logstash.outputs.elasticsearch] You are using a deprecated config setting "document_type" set in elasticsearch. Deprecated settings will continue to work, but are scheduled for removal from logstash in the future. Document types are being deprecated in Elasticsearch 6.0, and removed entirely in 7.0. You should avoid this feature If you have any questions about this, please visit the #logstash channel on freenode irc. {:name=>"document_type", :plugin=><LogStash::Outputs::ElasticSearch hosts=>[//100.100.100.111:9200, //100.100.100.112:9200, //100.100.100.113:9200], index=>"qa-enuri-main", document_type=>"_doc", document_id=>"%{id}", action=>"%{[@metadata][action]}", id=>"4eb63d99d7ef7654506bf1442576c3d37cf9e23b25a892282b49dbc9d98a8fac", enable_metric=>true, codec=><LogStash::Codecs::Plain id=>"plain_723cfda4-78e5-433a-9b2b-4892992235c3", enable_metric=>true, charset=>"UTF-8">, workers=>1, manage_template=>true, template_name=>"logstash", template_overwrite=>false, doc_as_upsert=>false, script_type=>"inline", script_lang=>"painless", script_var_name=>"event", scripted_upsert=>false, retry_initial_interval=>2, retry_max_interval=>64, retry_on_conflict=>1, ssl_certificate_verification=>true, sniffing=>false, sniffing_delay=>5, timeout=>60, pool_max=>1000, pool_max_per_route=>100, resurrect_delay=>5, validate_after_inactivity=>10000, http_compression=>false>}
[2018-05-30T16:29:02,422][INFO ][logstash.pipeline        ] Starting pipeline {:pipeline_id=>"main", "pipeline.workers"=>8, "pipeline.batch.size"=>125, "pipeline.batch.delay"=>50}
[2018-05-30T16:29:02,710][INFO ][logstash.outputs.elasticsearch] Elasticsearch pool URLs updated {:changes=>{:removed=>[], :added=>[http://100.100.100.111:9200/, http://100.100.100.112:9200/, http://100.100.100.113:9200/]}}
[2018-05-30T16:29:02,713][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://100.100.100.111:9200/, :path=>"/"}
[2018-05-30T16:29:02,827][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://100.100.100.111:9200/"}
[2018-05-30T16:29:02,875][INFO ][logstash.outputs.elasticsearch] ES Output version determined {:es_version=>6}
[2018-05-30T16:29:02,876][WARN ][logstash.outputs.elasticsearch] Detected a 6.x and above cluster: the `type` event field won't be used to determine the document _type {:es_version=>6}
[2018-05-30T16:29:02,877][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://100.100.100.112:9200/, :path=>"/"}
[2018-05-30T16:29:02,885][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://100.100.100.112:9200/"}
[2018-05-30T16:29:02,890][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://100.100.100.113:9200/, :path=>"/"}
[2018-05-30T16:29:02,896][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://100.100.100.113:9200/"}
[2018-05-30T16:29:02,904][INFO ][logstash.outputs.elasticsearch] Using mapping template from {:path=>nil}
[2018-05-30T16:29:02,909][INFO ][logstash.outputs.elasticsearch] Attempting to install template {:manage_template=>{"template"=>"logstash-*", "version"=>60001, "settings"=>{"index.refresh_interval"=>"5s"}, "mappings"=>{"_default_"=>{"dynamic_templates"=>[{"message_field"=>{"path_match"=>"message", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false}}}, {"string_fields"=>{"match"=>"*", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false, "fields"=>{"keyword"=>{"type"=>"keyword", "ignore_above"=>256}}}}}], "properties"=>{"@timestamp"=>{"type"=>"date"}, "@version"=>{"type"=>"keyword"}, "geoip"=>{"dynamic"=>true, "properties"=>{"ip"=>{"type"=>"ip"}, "location"=>{"type"=>"geo_point"}, "latitude"=>{"type"=>"half_float"}, "longitude"=>{"type"=>"half_float"}}}}}}}}
[2018-05-30T16:29:02,918][INFO ][logstash.outputs.elasticsearch] New Elasticsearch output {:class=>"LogStash::Outputs::ElasticSearch", :hosts=>["//100.100.100.111:9200", "//100.100.100.112:9200", "//100.100.100.113:9200"]}
[2018-05-30T16:29:03,056][ERROR][logstash.pipeline        ] Error registering plugin {:pipeline_id=>"main", :plugin=>"<LogStash::Inputs::Jdbc jdbc_driver_library=>\"/etc/logstash/ojdbc6.jar\", jdbc_driver_class=>\"Java::oracle.jdbc.driver.OracleDriver\", jdbc_connection_string=>\"jdbc:oracle:thin:@100.100.100.194:1521:tenuri\", jdbc_user=>\"es_app\", jdbc_password=><password>, jdbc_fetch_size=>10000, statement_filepath=>\"as-is_search-log.sql\", use_column_value=>true, tracking_column=>\"regdate\", tracking_column_type=>\"timestamp\", last_run_metadata_path=>\"search-log_last_run\", id=>\"29c652cdb74b2d95b7a3cb0865f0dc89bb81c748f37540ac018136231fcfe8bd\", enable_metric=>true, codec=><LogStash::Codecs::Plain id=>\"plain_f4679e96-204c-4ab2-831d-489e02726abb\", enable_metric=>true, charset=>\"UTF-8\">, jdbc_paging_enabled=>false, jdbc_page_size=>100000, jdbc_validate_connection=>false, jdbc_validation_timeout=>3600, jdbc_pool_timeout=>5, sql_log_level=>\"info\", connection_retry_attempts=>1, connection_retry_attempts_wait_time=>0.5, clean_run=>false, record_last_run=>true, lowercase_column_names=>true>", :error=>"Is a directory - search-log_last_run", :thread=>"#<Thread:0xd89d35b@/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:246 run>"}
[2018-05-30T16:29:03,909][ERROR][logstash.pipeline        ] Pipeline aborted due to error {:pipeline_id=>"main", :exception=>#<Errno::EISDIR: Is a directory - search-log_last_run>, :backtrace=>["org/jruby/RubyIO.java:3600:in `read'", "/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/value_tracking.rb:102:in `read'", "/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/value_tracking.rb:78:in `get_initial'", "/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/value_tracking.rb:36:in `initialize'", "/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/value_tracking.rb:29:in `build_last_value_tracker'", "/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/inputs/jdbc.rb:216:in `register'", "/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:341:in `register_plugin'", "/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:352:in `block in register_plugins'", "org/jruby/RubyArray.java:1734:in `each'", "/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:352:in `register_plugins'", "/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:502:in `start_inputs'", "/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:393:in `start_workers'", "/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:289:in `run'", "/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:249:in `block in start'"], :thread=>"#<Thread:0xd89d35b@/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:246 run>"}
[2018-05-30T16:29:03,939][ERROR][logstash.agent           ] Failed to execute action {:id=>:main, :action_type=>LogStash::ConvergeResult::FailedAction, :message=>"Could not execute action: LogStash::PipelineAction::Create/pipeline_id:main, action_result: false", :backtrace=>nil}
[2018-05-30T16:31:20,622][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"fb_apache", :directory=>"/usr/share/logstash/modules/fb_apache/configuration"}
[2018-05-30T16:31:20,631][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"netflow", :directory=>"/usr/share/logstash/modules/netflow/configuration"}
[2018-05-30T16:31:20,996][WARN ][logstash.config.source.multilocal] Ignoring the 'pipelines.yml' file because modules or command line options are specified
[2018-05-30T16:31:21,140][INFO ][logstash.runner          ] Starting Logstash {"logstash.version"=>"6.2.3"}
[2018-05-30T16:31:21,269][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=>9600}
[2018-05-30T16:31:22,195][INFO ][logstash.filters.ruby.script] Test run complete {:script_path=>"rubyfilter.rb", :results=>{:passed=>0, :failed=>0, :errored=>0}}
[2018-05-30T16:31:22,302][WARN ][logstash.outputs.elasticsearch] You are using a deprecated config setting "document_type" set in elasticsearch. Deprecated settings will continue to work, but are scheduled for removal from logstash in the future. Document types are being deprecated in Elasticsearch 6.0, and removed entirely in 7.0. You should avoid this feature If you have any questions about this, please visit the #logstash channel on freenode irc. {:name=>"document_type", :plugin=><LogStash::Outputs::ElasticSearch hosts=>[//100.100.100.111:9200, //100.100.100.112:9200, //100.100.100.113:9200], index=>"qa-enuri-main", document_type=>"_doc", document_id=>"%{id}", action=>"%{[@metadata][action]}", id=>"4eb63d99d7ef7654506bf1442576c3d37cf9e23b25a892282b49dbc9d98a8fac", enable_metric=>true, codec=><LogStash::Codecs::Plain id=>"plain_3fa3660d-48a4-4d4a-87a7-3d33e5dc5d45", enable_metric=>true, charset=>"UTF-8">, workers=>1, manage_template=>true, template_name=>"logstash", template_overwrite=>false, doc_as_upsert=>false, script_type=>"inline", script_lang=>"painless", script_var_name=>"event", scripted_upsert=>false, retry_initial_interval=>2, retry_max_interval=>64, retry_on_conflict=>1, ssl_certificate_verification=>true, sniffing=>false, sniffing_delay=>5, timeout=>60, pool_max=>1000, pool_max_per_route=>100, resurrect_delay=>5, validate_after_inactivity=>10000, http_compression=>false>}
[2018-05-30T16:31:22,314][INFO ][logstash.pipeline        ] Starting pipeline {:pipeline_id=>"main", "pipeline.workers"=>8, "pipeline.batch.size"=>125, "pipeline.batch.delay"=>50}
[2018-05-30T16:31:22,562][INFO ][logstash.outputs.elasticsearch] Elasticsearch pool URLs updated {:changes=>{:removed=>[], :added=>[http://100.100.100.111:9200/, http://100.100.100.112:9200/, http://100.100.100.113:9200/]}}
[2018-05-30T16:31:22,565][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://100.100.100.111:9200/, :path=>"/"}
[2018-05-30T16:31:22,674][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://100.100.100.111:9200/"}
[2018-05-30T16:31:22,723][INFO ][logstash.outputs.elasticsearch] ES Output version determined {:es_version=>6}
[2018-05-30T16:31:22,723][WARN ][logstash.outputs.elasticsearch] Detected a 6.x and above cluster: the `type` event field won't be used to determine the document _type {:es_version=>6}
[2018-05-30T16:31:22,724][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://100.100.100.112:9200/, :path=>"/"}
[2018-05-30T16:31:22,730][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://100.100.100.112:9200/"}
[2018-05-30T16:31:22,735][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://100.100.100.113:9200/, :path=>"/"}
[2018-05-30T16:31:22,739][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://100.100.100.113:9200/"}
[2018-05-30T16:31:22,748][INFO ][logstash.outputs.elasticsearch] Using mapping template from {:path=>nil}
[2018-05-30T16:31:22,753][INFO ][logstash.outputs.elasticsearch] Attempting to install template {:manage_template=>{"template"=>"logstash-*", "version"=>60001, "settings"=>{"index.refresh_interval"=>"5s"}, "mappings"=>{"_default_"=>{"dynamic_templates"=>[{"message_field"=>{"path_match"=>"message", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false}}}, {"string_fields"=>{"match"=>"*", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false, "fields"=>{"keyword"=>{"type"=>"keyword", "ignore_above"=>256}}}}}], "properties"=>{"@timestamp"=>{"type"=>"date"}, "@version"=>{"type"=>"keyword"}, "geoip"=>{"dynamic"=>true, "properties"=>{"ip"=>{"type"=>"ip"}, "location"=>{"type"=>"geo_point"}, "latitude"=>{"type"=>"half_float"}, "longitude"=>{"type"=>"half_float"}}}}}}}}
[2018-05-30T16:31:22,760][INFO ][logstash.outputs.elasticsearch] New Elasticsearch output {:class=>"LogStash::Outputs::ElasticSearch", :hosts=>["//100.100.100.111:9200", "//100.100.100.112:9200", "//100.100.100.113:9200"]}
[2018-05-30T16:31:22,909][INFO ][logstash.pipeline        ] Pipeline started succesfully {:pipeline_id=>"main", :thread=>"#<Thread:0x75567adf@/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:246 sleep>"}
[2018-05-30T16:31:22,927][INFO ][logstash.agent           ] Pipelines running {:count=>1, :pipelines=>["main"]}
[2018-05-30T16:31:23,628][ERROR][logstash.inputs.jdbc     ] Java::JavaSql::SQLSyntaxErrorException: ORA-00904: "REGDATA": invalid identifier: select
    status as action,
    search_key as ID,
    modelno,
    pl_no,
    modelno_group,
    MODELNO_GROUP_FLAG,
    category,
    CG,
    CAT1,
    CAT2,
    CAT3,
    CAT4,
    ca_code,
    ca_dept_mcode,
    ca_dept_code,
    ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,
    shop_name,
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    model_factory,
    minprice,
    maxprice,
    minprices,
    C_DATE,
    mallcnt,
    MALLCNT_FLAG,
    spec,
    openexpectflag,
    condiname,
    KEYWORD,
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    MODELNM || ' ' || FACTORY || ' ' || SPEC || ' ' || KEYWORD || ' ' || KEYWORD2 || ' ' || CONDINAME AS to_all
from dbenuri.TBL_SEARCH_LOG_ES
where regdata > TIMESTAMP '1970-01-01 09:00:00.000000 +09:00'
--where
-- (case when modelno=0 then mod(pl_no, 3) else mod(modelno, 3) end) = 0
-- and regdate < (select stime from DBENURI.ir_inc_index_timestamp where collection_name = 'ENURI_0')

[2018-05-30T16:31:23,632][WARN ][logstash.inputs.jdbc     ] Exception when executing JDBC query {:exception=>#<Sequel::DatabaseError: Java::JavaSql::SQLSyntaxErrorException: ORA-00904: "REGDATA": invalid identifier
>}
[2018-05-30T16:31:24,752][INFO ][logstash.pipeline        ] Pipeline has terminated {:pipeline_id=>"main", :thread=>"#<Thread:0x75567adf@/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:246 run>"}
[2018-05-30T16:32:43,199][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"fb_apache", :directory=>"/usr/share/logstash/modules/fb_apache/configuration"}
[2018-05-30T16:32:43,207][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"netflow", :directory=>"/usr/share/logstash/modules/netflow/configuration"}
[2018-05-30T16:32:43,568][WARN ][logstash.config.source.multilocal] Ignoring the 'pipelines.yml' file because modules or command line options are specified
[2018-05-30T16:32:43,720][INFO ][logstash.runner          ] Starting Logstash {"logstash.version"=>"6.2.3"}
[2018-05-30T16:32:43,850][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=>9600}
[2018-05-30T16:32:44,686][INFO ][logstash.filters.ruby.script] Test run complete {:script_path=>"rubyfilter.rb", :results=>{:passed=>0, :failed=>0, :errored=>0}}
[2018-05-30T16:32:44,791][WARN ][logstash.outputs.elasticsearch] You are using a deprecated config setting "document_type" set in elasticsearch. Deprecated settings will continue to work, but are scheduled for removal from logstash in the future. Document types are being deprecated in Elasticsearch 6.0, and removed entirely in 7.0. You should avoid this feature If you have any questions about this, please visit the #logstash channel on freenode irc. {:name=>"document_type", :plugin=><LogStash::Outputs::ElasticSearch hosts=>[//100.100.100.111:9200, //100.100.100.112:9200, //100.100.100.113:9200], index=>"qa-enuri-main", document_type=>"_doc", document_id=>"%{id}", action=>"%{[@metadata][action]}", id=>"4eb63d99d7ef7654506bf1442576c3d37cf9e23b25a892282b49dbc9d98a8fac", enable_metric=>true, codec=><LogStash::Codecs::Plain id=>"plain_9e8b567a-a2b4-4e95-80b3-51af8fa6cf92", enable_metric=>true, charset=>"UTF-8">, workers=>1, manage_template=>true, template_name=>"logstash", template_overwrite=>false, doc_as_upsert=>false, script_type=>"inline", script_lang=>"painless", script_var_name=>"event", scripted_upsert=>false, retry_initial_interval=>2, retry_max_interval=>64, retry_on_conflict=>1, ssl_certificate_verification=>true, sniffing=>false, sniffing_delay=>5, timeout=>60, pool_max=>1000, pool_max_per_route=>100, resurrect_delay=>5, validate_after_inactivity=>10000, http_compression=>false>}
[2018-05-30T16:32:44,803][INFO ][logstash.pipeline        ] Starting pipeline {:pipeline_id=>"main", "pipeline.workers"=>8, "pipeline.batch.size"=>125, "pipeline.batch.delay"=>50}
[2018-05-30T16:32:45,057][INFO ][logstash.outputs.elasticsearch] Elasticsearch pool URLs updated {:changes=>{:removed=>[], :added=>[http://100.100.100.111:9200/, http://100.100.100.112:9200/, http://100.100.100.113:9200/]}}
[2018-05-30T16:32:45,060][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://100.100.100.111:9200/, :path=>"/"}
[2018-05-30T16:32:45,171][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://100.100.100.111:9200/"}
[2018-05-30T16:32:45,219][INFO ][logstash.outputs.elasticsearch] ES Output version determined {:es_version=>6}
[2018-05-30T16:32:45,220][WARN ][logstash.outputs.elasticsearch] Detected a 6.x and above cluster: the `type` event field won't be used to determine the document _type {:es_version=>6}
[2018-05-30T16:32:45,220][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://100.100.100.112:9200/, :path=>"/"}
[2018-05-30T16:32:45,227][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://100.100.100.112:9200/"}
[2018-05-30T16:32:45,232][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://100.100.100.113:9200/, :path=>"/"}
[2018-05-30T16:32:45,237][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://100.100.100.113:9200/"}
[2018-05-30T16:32:45,245][INFO ][logstash.outputs.elasticsearch] Using mapping template from {:path=>nil}
[2018-05-30T16:32:45,251][INFO ][logstash.outputs.elasticsearch] Attempting to install template {:manage_template=>{"template"=>"logstash-*", "version"=>60001, "settings"=>{"index.refresh_interval"=>"5s"}, "mappings"=>{"_default_"=>{"dynamic_templates"=>[{"message_field"=>{"path_match"=>"message", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false}}}, {"string_fields"=>{"match"=>"*", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false, "fields"=>{"keyword"=>{"type"=>"keyword", "ignore_above"=>256}}}}}], "properties"=>{"@timestamp"=>{"type"=>"date"}, "@version"=>{"type"=>"keyword"}, "geoip"=>{"dynamic"=>true, "properties"=>{"ip"=>{"type"=>"ip"}, "location"=>{"type"=>"geo_point"}, "latitude"=>{"type"=>"half_float"}, "longitude"=>{"type"=>"half_float"}}}}}}}}
[2018-05-30T16:32:45,258][INFO ][logstash.outputs.elasticsearch] New Elasticsearch output {:class=>"LogStash::Outputs::ElasticSearch", :hosts=>["//100.100.100.111:9200", "//100.100.100.112:9200", "//100.100.100.113:9200"]}
[2018-05-30T16:32:45,410][INFO ][logstash.pipeline        ] Pipeline started succesfully {:pipeline_id=>"main", :thread=>"#<Thread:0xddd7d69@/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:246 sleep>"}
[2018-05-30T16:32:45,427][INFO ][logstash.agent           ] Pipelines running {:count=>1, :pipelines=>["main"]}
[2018-05-30T16:32:48,661][INFO ][logstash.inputs.jdbc     ] (2.552459s) select
    status as action,
    search_key as ID,
    modelno,
    pl_no,
    modelno_group,
    MODELNO_GROUP_FLAG,
    category,
    CG,
    CAT1,
    CAT2,
    CAT3,
    CAT4,
    ca_code,
    ca_dept_mcode,
    ca_dept_code,
    ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,
    shop_name,
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    model_factory,
    minprice,
    maxprice,
    minprices,
    C_DATE,
    mallcnt,
    MALLCNT_FLAG,
    spec,
    openexpectflag,
    condiname,
    KEYWORD,
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    MODELNM || ' ' || FACTORY || ' ' || SPEC || ' ' || KEYWORD || ' ' || KEYWORD2 || ' ' || CONDINAME AS to_all
from dbenuri.TBL_SEARCH_LOG_ES
where regdate > TIMESTAMP '1970-01-01 09:00:00.000000 +09:00'
--where
-- (case when modelno=0 then mod(pl_no, 3) else mod(modelno, 3) end) = 0
-- and regdate < (select stime from DBENURI.ir_inc_index_timestamp where collection_name = 'ENURI_0')

[2018-05-30T16:32:49,620][INFO ][logstash.pipeline        ] Pipeline has terminated {:pipeline_id=>"main", :thread=>"#<Thread:0xddd7d69@/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:246 run>"}
[2018-05-30T16:34:10,637][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"fb_apache", :directory=>"/usr/share/logstash/modules/fb_apache/configuration"}
[2018-05-30T16:34:10,645][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"netflow", :directory=>"/usr/share/logstash/modules/netflow/configuration"}
[2018-05-30T16:34:10,992][WARN ][logstash.config.source.multilocal] Ignoring the 'pipelines.yml' file because modules or command line options are specified
[2018-05-30T16:34:11,140][INFO ][logstash.runner          ] Starting Logstash {"logstash.version"=>"6.2.3"}
[2018-05-30T16:34:11,246][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=>9600}
[2018-05-30T16:34:12,097][INFO ][logstash.filters.ruby.script] Test run complete {:script_path=>"rubyfilter.rb", :results=>{:passed=>0, :failed=>0, :errored=>0}}
[2018-05-30T16:34:12,216][WARN ][logstash.outputs.elasticsearch] You are using a deprecated config setting "document_type" set in elasticsearch. Deprecated settings will continue to work, but are scheduled for removal from logstash in the future. Document types are being deprecated in Elasticsearch 6.0, and removed entirely in 7.0. You should avoid this feature If you have any questions about this, please visit the #logstash channel on freenode irc. {:name=>"document_type", :plugin=><LogStash::Outputs::ElasticSearch hosts=>[//100.100.100.111:9200, //100.100.100.112:9200, //100.100.100.113:9200], index=>"qa-enuri-main", document_type=>"_doc", document_id=>"%{id}", action=>"%{[@metadata][action]}", id=>"4eb63d99d7ef7654506bf1442576c3d37cf9e23b25a892282b49dbc9d98a8fac", enable_metric=>true, codec=><LogStash::Codecs::Plain id=>"plain_fa6b59dd-f0cf-4433-88ee-0c7198fddb1b", enable_metric=>true, charset=>"UTF-8">, workers=>1, manage_template=>true, template_name=>"logstash", template_overwrite=>false, doc_as_upsert=>false, script_type=>"inline", script_lang=>"painless", script_var_name=>"event", scripted_upsert=>false, retry_initial_interval=>2, retry_max_interval=>64, retry_on_conflict=>1, ssl_certificate_verification=>true, sniffing=>false, sniffing_delay=>5, timeout=>60, pool_max=>1000, pool_max_per_route=>100, resurrect_delay=>5, validate_after_inactivity=>10000, http_compression=>false>}
[2018-05-30T16:34:12,234][INFO ][logstash.pipeline        ] Starting pipeline {:pipeline_id=>"main", "pipeline.workers"=>8, "pipeline.batch.size"=>125, "pipeline.batch.delay"=>50}
[2018-05-30T16:34:12,500][INFO ][logstash.outputs.elasticsearch] Elasticsearch pool URLs updated {:changes=>{:removed=>[], :added=>[http://100.100.100.111:9200/, http://100.100.100.112:9200/, http://100.100.100.113:9200/]}}
[2018-05-30T16:34:12,503][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://100.100.100.111:9200/, :path=>"/"}
[2018-05-30T16:34:12,614][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://100.100.100.111:9200/"}
[2018-05-30T16:34:12,663][INFO ][logstash.outputs.elasticsearch] ES Output version determined {:es_version=>6}
[2018-05-30T16:34:12,663][WARN ][logstash.outputs.elasticsearch] Detected a 6.x and above cluster: the `type` event field won't be used to determine the document _type {:es_version=>6}
[2018-05-30T16:34:12,664][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://100.100.100.112:9200/, :path=>"/"}
[2018-05-30T16:34:12,670][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://100.100.100.112:9200/"}
[2018-05-30T16:34:12,675][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://100.100.100.113:9200/, :path=>"/"}
[2018-05-30T16:34:12,680][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://100.100.100.113:9200/"}
[2018-05-30T16:34:12,687][INFO ][logstash.outputs.elasticsearch] Using mapping template from {:path=>nil}
[2018-05-30T16:34:12,693][INFO ][logstash.outputs.elasticsearch] Attempting to install template {:manage_template=>{"template"=>"logstash-*", "version"=>60001, "settings"=>{"index.refresh_interval"=>"5s"}, "mappings"=>{"_default_"=>{"dynamic_templates"=>[{"message_field"=>{"path_match"=>"message", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false}}}, {"string_fields"=>{"match"=>"*", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false, "fields"=>{"keyword"=>{"type"=>"keyword", "ignore_above"=>256}}}}}], "properties"=>{"@timestamp"=>{"type"=>"date"}, "@version"=>{"type"=>"keyword"}, "geoip"=>{"dynamic"=>true, "properties"=>{"ip"=>{"type"=>"ip"}, "location"=>{"type"=>"geo_point"}, "latitude"=>{"type"=>"half_float"}, "longitude"=>{"type"=>"half_float"}}}}}}}}
[2018-05-30T16:34:12,700][INFO ][logstash.outputs.elasticsearch] New Elasticsearch output {:class=>"LogStash::Outputs::ElasticSearch", :hosts=>["//100.100.100.111:9200", "//100.100.100.112:9200", "//100.100.100.113:9200"]}
[2018-05-30T16:34:12,926][INFO ][logstash.pipeline        ] Pipeline started succesfully {:pipeline_id=>"main", :thread=>"#<Thread:0x6e5b4df7@/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:246 sleep>"}
[2018-05-30T16:34:12,943][INFO ][logstash.agent           ] Pipelines running {:count=>1, :pipelines=>["main"]}
[2018-05-30T16:34:15,231][INFO ][logstash.inputs.jdbc     ] (1.364975s) select
    status as action,
    search_key as ID,
    modelno,
    pl_no,
    modelno_group,
    MODELNO_GROUP_FLAG,
    category,
    CG,
    CAT1,
    CAT2,
    CAT3,
    CAT4,
    ca_code,
    ca_dept_mcode,
    ca_dept_code,
    ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,
    shop_name,
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    model_factory,
    minprice,
    maxprice,
    minprices,
    C_DATE,
    mallcnt,
    MALLCNT_FLAG,
    spec,
    openexpectflag,
    condiname,
    KEYWORD,
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    MODELNM || ' ' || FACTORY || ' ' || SPEC || ' ' || KEYWORD || ' ' || KEYWORD2 || ' ' || CONDINAME AS to_all
from dbenuri.TBL_SEARCH_LOG_ES
where regdate > TIMESTAMP '2018-01-01 09:00:00.000000 +09:00'
--where
-- (case when modelno=0 then mod(pl_no, 3) else mod(modelno, 3) end) = 0
-- and regdate < (select stime from DBENURI.ir_inc_index_timestamp where collection_name = 'ENURI_0')

[2018-05-30T16:34:15,693][INFO ][logstash.pipeline        ] Pipeline has terminated {:pipeline_id=>"main", :thread=>"#<Thread:0x6e5b4df7@/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:246 run>"}

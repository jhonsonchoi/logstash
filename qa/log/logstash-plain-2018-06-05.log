[2018-06-05T09:23:41,506][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"fb_apache", :directory=>"/usr/share/logstash/modules/fb_apache/configuration"}
[2018-06-05T09:23:41,599][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"netflow", :directory=>"/usr/share/logstash/modules/netflow/configuration"}
[2018-06-05T09:23:43,347][WARN ][logstash.config.source.multilocal] Ignoring the 'pipelines.yml' file because modules or command line options are specified
[2018-06-05T09:23:44,070][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"fb_apache", :directory=>"/usr/share/logstash/modules/fb_apache/configuration"}
[2018-06-05T09:23:44,085][INFO ][logstash.runner          ] Starting Logstash {"logstash.version"=>"6.2.3"}
[2018-06-05T09:23:44,103][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"netflow", :directory=>"/usr/share/logstash/modules/netflow/configuration"}
[2018-06-05T09:23:44,113][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"fb_apache", :directory=>"/usr/share/logstash/modules/fb_apache/configuration"}
[2018-06-05T09:23:44,152][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"netflow", :directory=>"/usr/share/logstash/modules/netflow/configuration"}
[2018-06-05T09:23:44,646][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=>9601}
[2018-06-05T09:23:44,826][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"fb_apache", :directory=>"/usr/share/logstash/modules/fb_apache/configuration"}
[2018-06-05T09:23:44,876][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"netflow", :directory=>"/usr/share/logstash/modules/netflow/configuration"}
[2018-06-05T09:23:45,965][WARN ][logstash.config.source.multilocal] Ignoring the 'pipelines.yml' file because modules or command line options are specified
[2018-06-05T09:23:45,987][WARN ][logstash.config.source.multilocal] Ignoring the 'pipelines.yml' file because modules or command line options are specified
[2018-06-05T09:23:46,154][WARN ][logstash.config.source.multilocal] Ignoring the 'pipelines.yml' file because modules or command line options are specified
[2018-06-05T09:23:46,547][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"fb_apache", :directory=>"/usr/share/logstash/modules/fb_apache/configuration"}
[2018-06-05T09:23:46,570][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"netflow", :directory=>"/usr/share/logstash/modules/netflow/configuration"}
[2018-06-05T09:23:46,641][INFO ][logstash.runner          ] Starting Logstash {"logstash.version"=>"6.2.3"}
[2018-06-05T09:23:46,849][INFO ][logstash.runner          ] Starting Logstash {"logstash.version"=>"6.2.3"}
[2018-06-05T09:23:46,928][INFO ][logstash.runner          ] Starting Logstash {"logstash.version"=>"6.2.3"}
[2018-06-05T09:23:47,139][DEBUG][org.logstash.secret.store.SecretStoreFactory] Attempting to exists or secret store with implementation: org.logstash.secret.store.backend.JavaKeyStore
[2018-06-05T09:23:47,237][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=>9602}
[2018-06-05T09:23:47,489][DEBUG][org.logstash.secret.store.SecretStoreFactory] Attempting to exists or secret store with implementation: org.logstash.secret.store.backend.JavaKeyStore
[2018-06-05T09:23:47,631][INFO ][logstash.filters.ruby.script] Test run complete {:script_path=>"rubyfilter.rb", :results=>{:passed=>0, :failed=>0, :errored=>0}}
[2018-06-05T09:23:47,701][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=>9603}
[2018-06-05T09:23:47,738][WARN ][logstash.config.source.multilocal] Ignoring the 'pipelines.yml' file because modules or command line options are specified
[2018-06-05T09:23:47,743][DEBUG][org.logstash.secret.store.SecretStoreFactory] Attempting to exists or secret store with implementation: org.logstash.secret.store.backend.JavaKeyStore
[2018-06-05T09:23:47,743][DEBUG][org.logstash.secret.store.SecretStoreFactory] Attempting to exists or secret store with implementation: org.logstash.secret.store.backend.JavaKeyStore
[2018-06-05T09:23:47,808][INFO ][logstash.pipeline        ] Starting pipeline {:pipeline_id=>"main", "pipeline.workers"=>8, "pipeline.batch.size"=>125, "pipeline.batch.delay"=>50}
[2018-06-05T09:23:48,010][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=>9604}
[2018-06-05T09:23:48,473][INFO ][logstash.runner          ] Starting Logstash {"logstash.version"=>"6.2.3"}
[2018-06-05T09:23:48,884][INFO ][logstash.pipeline        ] Pipeline started succesfully {:pipeline_id=>"main", :thread=>"#<Thread:0x22456651@/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:246 run>"}
[2018-06-05T09:23:49,101][INFO ][logstash.agent           ] Pipelines running {:count=>1, :pipelines=>["main"]}
[2018-06-05T09:23:49,149][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=>9605}
[2018-06-05T09:23:49,910][DEBUG][org.logstash.secret.store.SecretStoreFactory] Attempting to exists or secret store with implementation: org.logstash.secret.store.backend.JavaKeyStore
[2018-06-05T09:23:50,303][DEBUG][org.logstash.secret.store.SecretStoreFactory] Attempting to exists or secret store with implementation: org.logstash.secret.store.backend.JavaKeyStore
[2018-06-05T09:23:50,404][DEBUG][org.logstash.secret.store.SecretStoreFactory] Attempting to exists or secret store with implementation: org.logstash.secret.store.backend.JavaKeyStore
[2018-06-05T09:23:50,466][DEBUG][org.logstash.secret.store.SecretStoreFactory] Attempting to exists or secret store with implementation: org.logstash.secret.store.backend.JavaKeyStore
[2018-06-05T09:23:50,479][DEBUG][org.logstash.secret.store.SecretStoreFactory] Attempting to exists or secret store with implementation: org.logstash.secret.store.backend.JavaKeyStore
[2018-06-05T09:23:50,653][INFO ][logstash.filters.ruby.script] Test run complete {:script_path=>"rubyfilter.rb", :results=>{:passed=>0, :failed=>0, :errored=>0}}
[2018-06-05T09:23:50,719][DEBUG][org.logstash.secret.store.SecretStoreFactory] Attempting to exists or secret store with implementation: org.logstash.secret.store.backend.JavaKeyStore
[2018-06-05T09:23:50,720][DEBUG][org.logstash.secret.store.SecretStoreFactory] Attempting to exists or secret store with implementation: org.logstash.secret.store.backend.JavaKeyStore
[2018-06-05T09:23:50,738][INFO ][logstash.filters.ruby.script] Test run complete {:script_path=>"rubyfilter.rb", :results=>{:passed=>0, :failed=>0, :errored=>0}}
[2018-06-05T09:23:50,802][DEBUG][org.logstash.secret.store.SecretStoreFactory] Attempting to exists or secret store with implementation: org.logstash.secret.store.backend.JavaKeyStore
[2018-06-05T09:23:50,815][INFO ][logstash.pipeline        ] Starting pipeline {:pipeline_id=>"main", "pipeline.workers"=>8, "pipeline.batch.size"=>125, "pipeline.batch.delay"=>50}
[2018-06-05T09:23:50,923][DEBUG][org.logstash.secret.store.SecretStoreFactory] Attempting to exists or secret store with implementation: org.logstash.secret.store.backend.JavaKeyStore
[2018-06-05T09:23:50,924][DEBUG][org.logstash.secret.store.SecretStoreFactory] Attempting to exists or secret store with implementation: org.logstash.secret.store.backend.JavaKeyStore
[2018-06-05T09:23:51,022][INFO ][logstash.pipeline        ] Starting pipeline {:pipeline_id=>"main", "pipeline.workers"=>8, "pipeline.batch.size"=>125, "pipeline.batch.delay"=>50}
[2018-06-05T09:23:51,129][INFO ][logstash.filters.ruby.script] Test run complete {:script_path=>"rubyfilter.rb", :results=>{:passed=>0, :failed=>0, :errored=>0}}
[2018-06-05T09:23:51,237][ERROR][logstash.pipeline        ] A plugin had an unrecoverable error. Will restart this plugin.
  Pipeline_id:main
  Plugin: <LogStash::Inputs::Jdbc jdbc_driver_library=>"/etc/logstash/ojdbc6.jar", jdbc_driver_class=>"Java::oracle.jdbc.driver.OracleDriver", jdbc_connection_string=>"jdbc:oracle:thin:@100.100.100.194:1521:tenuri", jdbc_user=>"es_app", jdbc_password=><password>, jdbc_fetch_size=>1024, parameters=>{"favorite_mod_no"=>"0", "sql_last_value"=>2018-06-01 20:03:43 +0900}, statement_filepath=>"as-is_pricelist.sql", id=>"403c591de49c3f9ff2e58f75b58b1475aa9d54423b1fccb87bc7e4e37afed9b4", enable_metric=>true, codec=><LogStash::Codecs::Plain id=>"plain_e2a2b0ec-a645-4f70-9a08-a6b3187e4a03", enable_metric=>true, charset=>"UTF-8">, jdbc_paging_enabled=>false, jdbc_page_size=>100000, jdbc_validate_connection=>false, jdbc_validation_timeout=>3600, jdbc_pool_timeout=>5, sql_log_level=>"info", connection_retry_attempts=>1, connection_retry_attempts_wait_time=>0.5, last_run_metadata_path=>"/home/elastic/.logstash_jdbc_last_run", use_column_value=>false, tracking_column_type=>"numeric", clean_run=>false, record_last_run=>true, lowercase_column_names=>true>
  Error: uninitialized constant Sequel::JDBC::Oracle::DatabaseMethods
Did you mean?  Sequel::JDBC::Database
  Exception: NameError
  Stack: org/jruby/RubyModule.java:3343:in `const_missing'
/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/adapters/jdbc/oracle.rb:11:in `block in JDBC'
/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/adapters/jdbc.rb:343:in `adapter_initialize'
/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/misc.rb:144:in `initialize'
/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:57:in `connect'
/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/core.rb:116:in `connect'
/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:114:in `block in jdbc_connect'
org/jruby/RubyKernel.java:1292:in `loop'
/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:111:in `jdbc_connect'
/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:163:in `open_jdbc_connection'
/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:219:in `execute_statement'
/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/inputs/jdbc.rb:264:in `execute_query'
/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/inputs/jdbc.rb:250:in `run'
/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:516:in `inputworker'
/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:509:in `block in start_input'
[2018-06-05T09:23:51,252][DEBUG][org.logstash.secret.store.SecretStoreFactory] Attempting to exists or secret store with implementation: org.logstash.secret.store.backend.JavaKeyStore
[2018-06-05T09:23:51,252][DEBUG][org.logstash.secret.store.SecretStoreFactory] Attempting to exists or secret store with implementation: org.logstash.secret.store.backend.JavaKeyStore
[2018-06-05T09:23:51,532][INFO ][logstash.pipeline        ] Starting pipeline {:pipeline_id=>"main", "pipeline.workers"=>8, "pipeline.batch.size"=>125, "pipeline.batch.delay"=>50}
[2018-06-05T09:23:52,035][DEBUG][org.logstash.secret.store.SecretStoreFactory] Attempting to exists or secret store with implementation: org.logstash.secret.store.backend.JavaKeyStore
[2018-06-05T09:23:52,110][INFO ][logstash.pipeline        ] Pipeline started succesfully {:pipeline_id=>"main", :thread=>"#<Thread:0x31860250@/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:246 run>"}
[2018-06-05T09:23:52,226][INFO ][logstash.agent           ] Pipelines running {:count=>1, :pipelines=>["main"]}
[2018-06-05T09:23:52,286][DEBUG][org.logstash.secret.store.SecretStoreFactory] Attempting to exists or secret store with implementation: org.logstash.secret.store.backend.JavaKeyStore
[2018-06-05T09:23:52,468][INFO ][logstash.pipeline        ] Pipeline started succesfully {:pipeline_id=>"main", :thread=>"#<Thread:0x4cca632a@/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:246 run>"}
[2018-06-05T09:23:52,507][INFO ][logstash.agent           ] Pipelines running {:count=>1, :pipelines=>["main"]}
[2018-06-05T09:23:52,565][INFO ][logstash.filters.ruby.script] Test run complete {:script_path=>"rubyfilter.rb", :results=>{:passed=>0, :failed=>0, :errored=>0}}
[2018-06-05T09:23:52,680][DEBUG][org.logstash.secret.store.SecretStoreFactory] Attempting to exists or secret store with implementation: org.logstash.secret.store.backend.JavaKeyStore
[2018-06-05T09:23:52,680][DEBUG][org.logstash.secret.store.SecretStoreFactory] Attempting to exists or secret store with implementation: org.logstash.secret.store.backend.JavaKeyStore
[2018-06-05T09:23:52,831][INFO ][logstash.pipeline        ] Starting pipeline {:pipeline_id=>"main", "pipeline.workers"=>8, "pipeline.batch.size"=>125, "pipeline.batch.delay"=>50}
[2018-06-05T09:23:52,835][INFO ][logstash.pipeline        ] Pipeline started succesfully {:pipeline_id=>"main", :thread=>"#<Thread:0x62be86c9@/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:246 sleep>"}
[2018-06-05T09:23:52,897][INFO ][logstash.agent           ] Pipelines running {:count=>1, :pipelines=>["main"]}
[2018-06-05T09:23:54,216][INFO ][logstash.inputs.jdbc     ] (1.502055s) select 
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    DECODE(NVL(MODELNO_GROUP,0),0,0,1) AS MODELNO_GROUP_FLAG,
    category,
    '' as cg,
    '' as cat1,
    '' as cat2,
    '' as cat3,
    '' as cat4,
    ca_code,
    ca_dept_mcode,
    ca_dept_code,
    ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,
    shop_name,
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    MODELNM || ' ' || FACTORY as model_factory,
    minprice,
    maxprice,
    minprices,
    C_DATE,
    mallcnt,
    DECODE(NVL(MALLCNT,0),0,0,1) AS MALLCNT_FLAG,
    spec,
    openexpectflag,
    condiname,
    KEYWORD,
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    to_all
--    MODELNM || ' ' || FACTORY || ' ' || SPEC || ' ' || KEYWORD || ' ' || KEYWORD2 || ' ' || CONDINAME AS to_all
from (

select
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    CASE WHEN service_gubun='2' AND store_flag='1' AND ca_dept_code IS NOT NULL THEN RTRIM(category || ' '  || ca_dept_code) ELSE category END AS category,
    ca_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),3,8)='000000' OR SUBSTR(RTRIM(ca_dept_code),3,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,4) END AS ca_dept_mcode,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),5,8)='0000' OR SUBSTR(RTRIM(ca_dept_code),5,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,6) END AS ca_dept_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),7,8)='00' OR SUBSTR(RTRIM(ca_dept_code),7,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,8) END AS ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,    
    shop_name,    
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    model_factory,
    minprice,
    maxprice,
    replace(minprices, ' ', '    ') as minprices,
    C_DATE,
    mallcnt,
    replace(replace(spec,',',' '),'/',' ') spec,
    openexpectflag,
    replace(condiname, ' ', '    ') as condiname,    
    CASE WHEN socialprice=0 THEN keyword ELSE keyword || ' ' || UDF_SOCIAL_GOODSNM(modelno_group,modelno) END AS KEYWORD,    
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    to_all
FROM tmp_es_goods_data_01    
WHERE mod_no = '0'

)

[2018-06-05T09:23:54,245][INFO ][logstash.inputs.jdbc     ] (1.549547s) select
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    DECODE(NVL(MODELNO_GROUP,0),0,0,1) AS MODELNO_GROUP_FLAG,
    category,
    '' as cg,
    '' as cat1,
    '' as cat2,
    '' as cat3,
    '' as cat4,
    ca_code,
    ca_dept_mcode,
    ca_dept_code,
    ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,
    shop_name,
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    '' as model_factory,
    minprice,
    maxprice,
    minprices,
    C_DATE,
    mallcnt,
    DECODE(NVL(MALLCNT,0),0,0,1) AS MALLCNT_FLAG,
    spec,
    openexpectflag,
    condiname,
    KEYWORD,
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    to_all
--    MODELNM || ' ' || FACTORY || ' ' || SPEC || ' ' || KEYWORD || ' ' || KEYWORD2 || ' ' || CONDINAME AS to_all
from (

select
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    CASE WHEN service_gubun='2' AND store_flag='1' AND ca_dept_code IS NOT NULL THEN RTRIM(category || ' '  || ca_dept_code) ELSE category END AS category,
    ca_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),3,8)='000000' OR SUBSTR(RTRIM(ca_dept_code),3,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,4) END AS ca_dept_mcode,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),5,8)='0000' OR SUBSTR(RTRIM(ca_dept_code),5,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,6) END AS ca_dept_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),7,8)='00' OR SUBSTR(RTRIM(ca_dept_code),7,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,8) END AS ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,    
    shop_name,    
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    model_factory,
    minprice,
    maxprice,
    replace(minprices, ' ', '    ') as minprices,
    C_DATE,
    mallcnt,
    replace(replace(spec,',',' '),'/',' ') spec,
    openexpectflag,
    replace(condiname, ' ', '    ') as condiname,    
    CASE WHEN socialprice=0 THEN keyword ELSE keyword || ' ' || UDF_SOCIAL_GOODSNM(modelno_group,modelno) END AS KEYWORD,    
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    to_all
FROM tmp_es_price_data_01
WHERE mod_no = '0'

)

[2018-06-05T09:23:54,345][ERROR][logstash.pipeline        ] A plugin had an unrecoverable error. Will restart this plugin.
  Pipeline_id:main
  Plugin: <LogStash::Inputs::Jdbc jdbc_driver_library=>"/etc/logstash/ojdbc6.jar", jdbc_driver_class=>"Java::oracle.jdbc.driver.OracleDriver", jdbc_connection_string=>"jdbc:oracle:thin:@100.100.100.194:1521:tenuri", jdbc_user=>"es_app", jdbc_password=><password>, jdbc_fetch_size=>1024, parameters=>{"favorite_mod_no"=>"1", "sql_last_value"=>2018-06-01 20:03:43 +0900}, statement_filepath=>"as-is_goods.sql", id=>"16fcf07668c18b990fb61743b175fa06b2e876b245d1dd6e6563800ccd584857", enable_metric=>true, codec=><LogStash::Codecs::Plain id=>"plain_1dfcae40-1b02-4795-a47e-6017d3c386be", enable_metric=>true, charset=>"UTF-8">, jdbc_paging_enabled=>false, jdbc_page_size=>100000, jdbc_validate_connection=>false, jdbc_validation_timeout=>3600, jdbc_pool_timeout=>5, sql_log_level=>"info", connection_retry_attempts=>1, connection_retry_attempts_wait_time=>0.5, last_run_metadata_path=>"/home/elastic/.logstash_jdbc_last_run", use_column_value=>false, tracking_column_type=>"numeric", clean_run=>false, record_last_run=>true, lowercase_column_names=>true>
  Error: uninitialized constant Sequel::JDBC::Oracle::DatabaseMethods
Did you mean?  Sequel::JDBC::Database
  Exception: NameError
  Stack: org/jruby/RubyModule.java:3343:in `const_missing'
/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/adapters/jdbc/oracle.rb:11:in `block in JDBC'
/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/adapters/jdbc.rb:343:in `adapter_initialize'
/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/misc.rb:144:in `initialize'
/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:57:in `connect'
/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/core.rb:116:in `connect'
/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:114:in `block in jdbc_connect'
org/jruby/RubyKernel.java:1292:in `loop'
/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:111:in `jdbc_connect'
/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:163:in `open_jdbc_connection'
/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:219:in `execute_statement'
/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/inputs/jdbc.rb:264:in `execute_query'
/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/inputs/jdbc.rb:250:in `run'
/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:516:in `inputworker'
/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:509:in `block in start_input'
[2018-06-05T09:23:54,446][INFO ][logstash.pipeline        ] Pipeline started succesfully {:pipeline_id=>"main", :thread=>"#<Thread:0x4876ed1d@/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:246 run>"}
[2018-06-05T09:23:54,476][INFO ][logstash.agent           ] Pipelines running {:count=>1, :pipelines=>["main"]}
[2018-06-05T09:23:54,745][ERROR][logstash.pipeline        ] A plugin had an unrecoverable error. Will restart this plugin.
  Pipeline_id:main
  Plugin: <LogStash::Inputs::Jdbc jdbc_driver_library=>"/etc/logstash/ojdbc6.jar", jdbc_driver_class=>"Java::oracle.jdbc.driver.OracleDriver", jdbc_connection_string=>"jdbc:oracle:thin:@100.100.100.194:1521:tenuri", jdbc_user=>"es_app", jdbc_password=><password>, jdbc_fetch_size=>1024, parameters=>{"favorite_mod_no"=>"4", "sql_last_value"=>2018-06-01 20:03:43 +0900}, statement_filepath=>"as-is_goods.sql", id=>"16fcf07668c18b990fb61743b175fa06b2e876b245d1dd6e6563800ccd584857", enable_metric=>true, codec=><LogStash::Codecs::Plain id=>"plain_fbd60498-29d1-45ec-b68f-40fba8bd3eda", enable_metric=>true, charset=>"UTF-8">, jdbc_paging_enabled=>false, jdbc_page_size=>100000, jdbc_validate_connection=>false, jdbc_validation_timeout=>3600, jdbc_pool_timeout=>5, sql_log_level=>"info", connection_retry_attempts=>1, connection_retry_attempts_wait_time=>0.5, last_run_metadata_path=>"/home/elastic/.logstash_jdbc_last_run", use_column_value=>false, tracking_column_type=>"numeric", clean_run=>false, record_last_run=>true, lowercase_column_names=>true>
  Error: uninitialized constant Sequel::JDBC::Oracle::DatabaseMethods
Did you mean?  Sequel::JDBC::Database
  Exception: NameError
  Stack: org/jruby/RubyModule.java:3343:in `const_missing'
/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/adapters/jdbc/oracle.rb:11:in `block in JDBC'
/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/adapters/jdbc.rb:343:in `adapter_initialize'
/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/misc.rb:144:in `initialize'
/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:57:in `connect'
/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/core.rb:116:in `connect'
/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:114:in `block in jdbc_connect'
org/jruby/RubyKernel.java:1292:in `loop'
/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:111:in `jdbc_connect'
/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:163:in `open_jdbc_connection'
/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:219:in `execute_statement'
/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/inputs/jdbc.rb:264:in `execute_query'
/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/inputs/jdbc.rb:250:in `run'
/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:516:in `inputworker'
/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:509:in `block in start_input'
[2018-06-05T09:23:55,854][INFO ][logstash.outputs.file    ] Opening file {:path=>"/home/elastic/enuri/logstash/qa/qa-enuri-main-as-is-2018.06.05.00.22-0.txt"}
[2018-06-05T09:23:58,316][INFO ][logstash.inputs.jdbc     ] (2.801888s) select
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    DECODE(NVL(MODELNO_GROUP,0),0,0,1) AS MODELNO_GROUP_FLAG,
    category,
    '' as cg,
    '' as cat1,
    '' as cat2,
    '' as cat3,
    '' as cat4,
    ca_code,
    ca_dept_mcode,
    ca_dept_code,
    ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,
    shop_name,
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    '' as model_factory,
    minprice,
    maxprice,
    minprices,
    C_DATE,
    mallcnt,
    DECODE(NVL(MALLCNT,0),0,0,1) AS MALLCNT_FLAG,
    spec,
    openexpectflag,
    condiname,
    KEYWORD,
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    to_all
--    MODELNM || ' ' || FACTORY || ' ' || SPEC || ' ' || KEYWORD || ' ' || KEYWORD2 || ' ' || CONDINAME AS to_all
from (

select
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    CASE WHEN service_gubun='2' AND store_flag='1' AND ca_dept_code IS NOT NULL THEN RTRIM(category || ' '  || ca_dept_code) ELSE category END AS category,
    ca_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),3,8)='000000' OR SUBSTR(RTRIM(ca_dept_code),3,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,4) END AS ca_dept_mcode,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),5,8)='0000' OR SUBSTR(RTRIM(ca_dept_code),5,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,6) END AS ca_dept_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),7,8)='00' OR SUBSTR(RTRIM(ca_dept_code),7,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,8) END AS ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,    
    shop_name,    
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    model_factory,
    minprice,
    maxprice,
    replace(minprices, ' ', '    ') as minprices,
    C_DATE,
    mallcnt,
    replace(replace(spec,',',' '),'/',' ') spec,
    openexpectflag,
    replace(condiname, ' ', '    ') as condiname,    
    CASE WHEN socialprice=0 THEN keyword ELSE keyword || ' ' || UDF_SOCIAL_GOODSNM(modelno_group,modelno) END AS KEYWORD,    
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    to_all
FROM tmp_es_price_data_01
WHERE mod_no = '1'

)

[2018-06-05T09:23:58,326][INFO ][logstash.inputs.jdbc     ] (2.810336s) select 
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    DECODE(NVL(MODELNO_GROUP,0),0,0,1) AS MODELNO_GROUP_FLAG,
    category,
    '' as cg,
    '' as cat1,
    '' as cat2,
    '' as cat3,
    '' as cat4,
    ca_code,
    ca_dept_mcode,
    ca_dept_code,
    ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,
    shop_name,
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    MODELNM || ' ' || FACTORY as model_factory,
    minprice,
    maxprice,
    minprices,
    C_DATE,
    mallcnt,
    DECODE(NVL(MALLCNT,0),0,0,1) AS MALLCNT_FLAG,
    spec,
    openexpectflag,
    condiname,
    KEYWORD,
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    to_all
--    MODELNM || ' ' || FACTORY || ' ' || SPEC || ' ' || KEYWORD || ' ' || KEYWORD2 || ' ' || CONDINAME AS to_all
from (

select
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    CASE WHEN service_gubun='2' AND store_flag='1' AND ca_dept_code IS NOT NULL THEN RTRIM(category || ' '  || ca_dept_code) ELSE category END AS category,
    ca_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),3,8)='000000' OR SUBSTR(RTRIM(ca_dept_code),3,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,4) END AS ca_dept_mcode,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),5,8)='0000' OR SUBSTR(RTRIM(ca_dept_code),5,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,6) END AS ca_dept_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),7,8)='00' OR SUBSTR(RTRIM(ca_dept_code),7,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,8) END AS ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,    
    shop_name,    
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    model_factory,
    minprice,
    maxprice,
    replace(minprices, ' ', '    ') as minprices,
    C_DATE,
    mallcnt,
    replace(replace(spec,',',' '),'/',' ') spec,
    openexpectflag,
    replace(condiname, ' ', '    ') as condiname,    
    CASE WHEN socialprice=0 THEN keyword ELSE keyword || ' ' || UDF_SOCIAL_GOODSNM(modelno_group,modelno) END AS KEYWORD,    
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    to_all
FROM tmp_es_goods_data_01    
WHERE mod_no = '1'

)

[2018-06-05T09:23:58,998][INFO ][logstash.inputs.jdbc     ] (2.730728s) select
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    DECODE(NVL(MODELNO_GROUP,0),0,0,1) AS MODELNO_GROUP_FLAG,
    category,
    '' as cg,
    '' as cat1,
    '' as cat2,
    '' as cat3,
    '' as cat4,
    ca_code,
    ca_dept_mcode,
    ca_dept_code,
    ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,
    shop_name,
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    '' as model_factory,
    minprice,
    maxprice,
    minprices,
    C_DATE,
    mallcnt,
    DECODE(NVL(MALLCNT,0),0,0,1) AS MALLCNT_FLAG,
    spec,
    openexpectflag,
    condiname,
    KEYWORD,
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    to_all
--    MODELNM || ' ' || FACTORY || ' ' || SPEC || ' ' || KEYWORD || ' ' || KEYWORD2 || ' ' || CONDINAME AS to_all
from (

select
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    CASE WHEN service_gubun='2' AND store_flag='1' AND ca_dept_code IS NOT NULL THEN RTRIM(category || ' '  || ca_dept_code) ELSE category END AS category,
    ca_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),3,8)='000000' OR SUBSTR(RTRIM(ca_dept_code),3,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,4) END AS ca_dept_mcode,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),5,8)='0000' OR SUBSTR(RTRIM(ca_dept_code),5,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,6) END AS ca_dept_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),7,8)='00' OR SUBSTR(RTRIM(ca_dept_code),7,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,8) END AS ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,    
    shop_name,    
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    model_factory,
    minprice,
    maxprice,
    replace(minprices, ' ', '    ') as minprices,
    C_DATE,
    mallcnt,
    replace(replace(spec,',',' '),'/',' ') spec,
    openexpectflag,
    replace(condiname, ' ', '    ') as condiname,    
    CASE WHEN socialprice=0 THEN keyword ELSE keyword || ' ' || UDF_SOCIAL_GOODSNM(modelno_group,modelno) END AS KEYWORD,    
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    to_all
FROM tmp_es_price_data_01
WHERE mod_no = '4'

)

[2018-06-05T09:23:59,006][INFO ][logstash.inputs.jdbc     ] (2.737262s) select 
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    DECODE(NVL(MODELNO_GROUP,0),0,0,1) AS MODELNO_GROUP_FLAG,
    category,
    '' as cg,
    '' as cat1,
    '' as cat2,
    '' as cat3,
    '' as cat4,
    ca_code,
    ca_dept_mcode,
    ca_dept_code,
    ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,
    shop_name,
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    MODELNM || ' ' || FACTORY as model_factory,
    minprice,
    maxprice,
    minprices,
    C_DATE,
    mallcnt,
    DECODE(NVL(MALLCNT,0),0,0,1) AS MALLCNT_FLAG,
    spec,
    openexpectflag,
    condiname,
    KEYWORD,
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    to_all
--    MODELNM || ' ' || FACTORY || ' ' || SPEC || ' ' || KEYWORD || ' ' || KEYWORD2 || ' ' || CONDINAME AS to_all
from (

select
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    CASE WHEN service_gubun='2' AND store_flag='1' AND ca_dept_code IS NOT NULL THEN RTRIM(category || ' '  || ca_dept_code) ELSE category END AS category,
    ca_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),3,8)='000000' OR SUBSTR(RTRIM(ca_dept_code),3,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,4) END AS ca_dept_mcode,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),5,8)='0000' OR SUBSTR(RTRIM(ca_dept_code),5,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,6) END AS ca_dept_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),7,8)='00' OR SUBSTR(RTRIM(ca_dept_code),7,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,8) END AS ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,    
    shop_name,    
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    model_factory,
    minprice,
    maxprice,
    replace(minprices, ' ', '    ') as minprices,
    C_DATE,
    mallcnt,
    replace(replace(spec,',',' '),'/',' ') spec,
    openexpectflag,
    replace(condiname, ' ', '    ') as condiname,    
    CASE WHEN socialprice=0 THEN keyword ELSE keyword || ' ' || UDF_SOCIAL_GOODSNM(modelno_group,modelno) END AS KEYWORD,    
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    to_all
FROM tmp_es_goods_data_01    
WHERE mod_no = '4'

)

[2018-06-05T09:23:59,264][INFO ][logstash.inputs.jdbc     ] (3.869096s) select
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    DECODE(NVL(MODELNO_GROUP,0),0,0,1) AS MODELNO_GROUP_FLAG,
    category,
    '' as cg,
    '' as cat1,
    '' as cat2,
    '' as cat3,
    '' as cat4,
    ca_code,
    ca_dept_mcode,
    ca_dept_code,
    ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,
    shop_name,
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    '' as model_factory,
    minprice,
    maxprice,
    minprices,
    C_DATE,
    mallcnt,
    DECODE(NVL(MALLCNT,0),0,0,1) AS MALLCNT_FLAG,
    spec,
    openexpectflag,
    condiname,
    KEYWORD,
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    to_all
--    MODELNM || ' ' || FACTORY || ' ' || SPEC || ' ' || KEYWORD || ' ' || KEYWORD2 || ' ' || CONDINAME AS to_all
from (

select
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    CASE WHEN service_gubun='2' AND store_flag='1' AND ca_dept_code IS NOT NULL THEN RTRIM(category || ' '  || ca_dept_code) ELSE category END AS category,
    ca_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),3,8)='000000' OR SUBSTR(RTRIM(ca_dept_code),3,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,4) END AS ca_dept_mcode,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),5,8)='0000' OR SUBSTR(RTRIM(ca_dept_code),5,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,6) END AS ca_dept_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),7,8)='00' OR SUBSTR(RTRIM(ca_dept_code),7,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,8) END AS ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,    
    shop_name,    
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    model_factory,
    minprice,
    maxprice,
    replace(minprices, ' ', '    ') as minprices,
    C_DATE,
    mallcnt,
    replace(replace(spec,',',' '),'/',' ') spec,
    openexpectflag,
    replace(condiname, ' ', '    ') as condiname,    
    CASE WHEN socialprice=0 THEN keyword ELSE keyword || ' ' || UDF_SOCIAL_GOODSNM(modelno_group,modelno) END AS KEYWORD,    
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    to_all
FROM tmp_es_price_data_01
WHERE mod_no = '5'

)

[2018-06-05T09:23:59,270][INFO ][logstash.inputs.jdbc     ] (3.038246s) select
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    DECODE(NVL(MODELNO_GROUP,0),0,0,1) AS MODELNO_GROUP_FLAG,
    category,
    '' as cg,
    '' as cat1,
    '' as cat2,
    '' as cat3,
    '' as cat4,
    ca_code,
    ca_dept_mcode,
    ca_dept_code,
    ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,
    shop_name,
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    '' as model_factory,
    minprice,
    maxprice,
    minprices,
    C_DATE,
    mallcnt,
    DECODE(NVL(MALLCNT,0),0,0,1) AS MALLCNT_FLAG,
    spec,
    openexpectflag,
    condiname,
    KEYWORD,
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    to_all
--    MODELNM || ' ' || FACTORY || ' ' || SPEC || ' ' || KEYWORD || ' ' || KEYWORD2 || ' ' || CONDINAME AS to_all
from (

select
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    CASE WHEN service_gubun='2' AND store_flag='1' AND ca_dept_code IS NOT NULL THEN RTRIM(category || ' '  || ca_dept_code) ELSE category END AS category,
    ca_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),3,8)='000000' OR SUBSTR(RTRIM(ca_dept_code),3,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,4) END AS ca_dept_mcode,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),5,8)='0000' OR SUBSTR(RTRIM(ca_dept_code),5,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,6) END AS ca_dept_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),7,8)='00' OR SUBSTR(RTRIM(ca_dept_code),7,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,8) END AS ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,    
    shop_name,    
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    model_factory,
    minprice,
    maxprice,
    replace(minprices, ' ', '    ') as minprices,
    C_DATE,
    mallcnt,
    replace(replace(spec,',',' '),'/',' ') spec,
    openexpectflag,
    replace(condiname, ' ', '    ') as condiname,    
    CASE WHEN socialprice=0 THEN keyword ELSE keyword || ' ' || UDF_SOCIAL_GOODSNM(modelno_group,modelno) END AS KEYWORD,    
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    to_all
FROM tmp_es_price_data_01
WHERE mod_no = '2'

)

[2018-06-05T09:23:59,271][INFO ][logstash.inputs.jdbc     ] (3.034335s) select 
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    DECODE(NVL(MODELNO_GROUP,0),0,0,1) AS MODELNO_GROUP_FLAG,
    category,
    '' as cg,
    '' as cat1,
    '' as cat2,
    '' as cat3,
    '' as cat4,
    ca_code,
    ca_dept_mcode,
    ca_dept_code,
    ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,
    shop_name,
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    MODELNM || ' ' || FACTORY as model_factory,
    minprice,
    maxprice,
    minprices,
    C_DATE,
    mallcnt,
    DECODE(NVL(MALLCNT,0),0,0,1) AS MALLCNT_FLAG,
    spec,
    openexpectflag,
    condiname,
    KEYWORD,
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    to_all
--    MODELNM || ' ' || FACTORY || ' ' || SPEC || ' ' || KEYWORD || ' ' || KEYWORD2 || ' ' || CONDINAME AS to_all
from (

select
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    CASE WHEN service_gubun='2' AND store_flag='1' AND ca_dept_code IS NOT NULL THEN RTRIM(category || ' '  || ca_dept_code) ELSE category END AS category,
    ca_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),3,8)='000000' OR SUBSTR(RTRIM(ca_dept_code),3,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,4) END AS ca_dept_mcode,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),5,8)='0000' OR SUBSTR(RTRIM(ca_dept_code),5,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,6) END AS ca_dept_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),7,8)='00' OR SUBSTR(RTRIM(ca_dept_code),7,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,8) END AS ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,    
    shop_name,    
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    model_factory,
    minprice,
    maxprice,
    replace(minprices, ' ', '    ') as minprices,
    C_DATE,
    mallcnt,
    replace(replace(spec,',',' '),'/',' ') spec,
    openexpectflag,
    replace(condiname, ' ', '    ') as condiname,    
    CASE WHEN socialprice=0 THEN keyword ELSE keyword || ' ' || UDF_SOCIAL_GOODSNM(modelno_group,modelno) END AS KEYWORD,    
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    to_all
FROM tmp_es_goods_data_01    
WHERE mod_no = '2'

)

[2018-06-05T09:23:59,273][INFO ][logstash.inputs.jdbc     ] (3.882941s) select 
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    DECODE(NVL(MODELNO_GROUP,0),0,0,1) AS MODELNO_GROUP_FLAG,
    category,
    '' as cg,
    '' as cat1,
    '' as cat2,
    '' as cat3,
    '' as cat4,
    ca_code,
    ca_dept_mcode,
    ca_dept_code,
    ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,
    shop_name,
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    MODELNM || ' ' || FACTORY as model_factory,
    minprice,
    maxprice,
    minprices,
    C_DATE,
    mallcnt,
    DECODE(NVL(MALLCNT,0),0,0,1) AS MALLCNT_FLAG,
    spec,
    openexpectflag,
    condiname,
    KEYWORD,
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    to_all
--    MODELNM || ' ' || FACTORY || ' ' || SPEC || ' ' || KEYWORD || ' ' || KEYWORD2 || ' ' || CONDINAME AS to_all
from (

select
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    CASE WHEN service_gubun='2' AND store_flag='1' AND ca_dept_code IS NOT NULL THEN RTRIM(category || ' '  || ca_dept_code) ELSE category END AS category,
    ca_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),3,8)='000000' OR SUBSTR(RTRIM(ca_dept_code),3,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,4) END AS ca_dept_mcode,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),5,8)='0000' OR SUBSTR(RTRIM(ca_dept_code),5,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,6) END AS ca_dept_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),7,8)='00' OR SUBSTR(RTRIM(ca_dept_code),7,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,8) END AS ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,    
    shop_name,    
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    model_factory,
    minprice,
    maxprice,
    replace(minprices, ' ', '    ') as minprices,
    C_DATE,
    mallcnt,
    replace(replace(spec,',',' '),'/',' ') spec,
    openexpectflag,
    replace(condiname, ' ', '    ') as condiname,    
    CASE WHEN socialprice=0 THEN keyword ELSE keyword || ' ' || UDF_SOCIAL_GOODSNM(modelno_group,modelno) END AS KEYWORD,    
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    to_all
FROM tmp_es_goods_data_01    
WHERE mod_no = '5'

)

[2018-06-05T09:23:59,630][INFO ][logstash.outputs.file    ] Opening file {:path=>"/home/elastic/enuri/logstash/qa/qa-enuri-main-as-is-2018.06.05.00.22-1.txt"}
[2018-06-05T09:24:00,725][INFO ][logstash.outputs.file    ] Opening file {:path=>"/home/elastic/enuri/logstash/qa/qa-enuri-main-as-is-2018.06.05.00.22-2.txt"}
[2018-06-05T09:24:00,726][INFO ][logstash.outputs.file    ] Opening file {:path=>"/home/elastic/enuri/logstash/qa/qa-enuri-main-as-is-2018.06.05.00.22-4.txt"}
[2018-06-05T09:24:01,070][INFO ][logstash.outputs.file    ] Opening file {:path=>"/home/elastic/enuri/logstash/qa/qa-enuri-main-as-is-2018.06.05.00.22-5.txt"}
[2018-06-05T09:36:43,080][FATAL][logstash.runner          ] An unexpected error occurred! {:error=>#<Errno::ENOSPC: No space left on device - /home/elastic/enuri/logstash/qa/qa-enuri-main-as-is-2018.06.05.00.22-0.txt>, :backtrace=>["org/jruby/RubyIO.java:1457:in `write'", "org/jruby/[2018-06-05T10:39:29,490][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"fb_apache", :directory=>"/usr/share/logstash/modules/fb_apache/configuration"}
[2018-06-05T10:39:29,523][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"netflow", :directory=>"/usr/share/logstash/modules/netflow/configuration"}
[2018-06-05T10:39:30,110][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"fb_apache", :directory=>"/usr/share/logstash/modules/fb_apache/configuration"}
[2018-06-05T10:39:30,190][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"netflow", :directory=>"/usr/share/logstash/modules/netflow/configuration"}
[2018-06-05T10:39:30,723][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"fb_apache", :directory=>"/usr/share/logstash/modules/fb_apache/configuration"}
[2018-06-05T10:39:30,759][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"netflow", :directory=>"/usr/share/logstash/modules/netflow/configuration"}
[2018-06-05T10:39:30,954][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"fb_apache", :directory=>"/usr/share/logstash/modules/fb_apache/configuration"}
[2018-06-05T10:39:30,967][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"netflow", :directory=>"/usr/share/logstash/modules/netflow/configuration"}
[2018-06-05T10:39:31,043][WARN ][logstash.config.source.multilocal] Ignoring the 'pipelines.yml' file because modules or command line options are specified
[2018-06-05T10:39:31,775][INFO ][logstash.runner          ] Starting Logstash {"logstash.version"=>"6.2.3"}
[2018-06-05T10:39:32,025][WARN ][logstash.config.source.multilocal] Ignoring the 'pipelines.yml' file because modules or command line options are specified
[2018-06-05T10:39:32,330][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=>9600}
[2018-06-05T10:39:32,651][WARN ][logstash.config.source.multilocal] Ignoring the 'pipelines.yml' file because modules or command line options are specified
[2018-06-05T10:39:32,780][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"fb_apache", :directory=>"/usr/share/logstash/modules/fb_apache/configuration"}
[2018-06-05T10:39:32,787][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"netflow", :directory=>"/usr/share/logstash/modules/netflow/configuration"}
[2018-06-05T10:39:32,924][INFO ][logstash.runner          ] Starting Logstash {"logstash.version"=>"6.2.3"}
[2018-06-05T10:39:33,130][WARN ][logstash.config.source.multilocal] Ignoring the 'pipelines.yml' file because modules or command line options are specified
[2018-06-05T10:39:33,501][INFO ][logstash.runner          ] Starting Logstash {"logstash.version"=>"6.2.3"}
[2018-06-05T10:39:33,737][INFO ][logstash.runner          ] Starting Logstash {"logstash.version"=>"6.2.3"}
[2018-06-05T10:39:33,551][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=>9601}
[2018-06-05T10:39:33,760][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"fb_apache", :directory=>"/usr/share/logstash/modules/fb_apache/configuration"}
[2018-06-05T10:39:33,785][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"netflow", :directory=>"/usr/share/logstash/modules/netflow/configuration"}
[2018-06-05T10:40:35,329][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"fb_apache", :directory=>"/usr/share/logstash/modules/fb_apache/configuration"}
[2018-06-05T10:40:35,404][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"netflow", :directory=>"/usr/share/logstash/modules/netflow/configuration"}
[2018-06-05T10:40:35,625][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"fb_apache", :directory=>"/usr/share/logstash/modules/fb_apache/configuration"}
[2018-06-05T10:40:35,650][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"netflow", :directory=>"/usr/share/logstash/modules/netflow/configuration"}
[2018-06-05T10:40:36,058][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"fb_apache", :directory=>"/usr/share/logstash/modules/fb_apache/configuration"}
[2018-06-05T10:40:36,115][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"netflow", :directory=>"/usr/share/logstash/modules/netflow/configuration"}
[2018-06-05T10:40:36,203][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"fb_apache", :directory=>"/usr/share/logstash/modules/fb_apache/configuration"}
[2018-06-05T10:40:36,232][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"netflow", :directory=>"/usr/share/logstash/modules/netflow/configuration"}
[2018-06-05T10:40:37,541][WARN ][logstash.config.source.multilocal] Ignoring the 'pipelines.yml' file because modules or command line options are specified
[2018-06-05T10:40:37,603][WARN ][logstash.config.source.multilocal] Ignoring the 'pipelines.yml' file because modules or command line options are specified
[2018-06-05T10:40:37,630][WARN ][logstash.config.source.multilocal] Ignoring the 'pipelines.yml' file because modules or command line options are specified
[2018-06-05T10:40:37,719][WARN ][logstash.config.source.multilocal] Ignoring the 'pipelines.yml' file because modules or command line options are specified
[2018-06-05T10:40:38,240][INFO ][logstash.runner          ] Starting Logstash {"logstash.version"=>"6.2.3"}
[2018-06-05T10:40:38,330][INFO ][logstash.runner          ] Starting Logstash {"logstash.version"=>"6.2.3"}
[2018-06-05T10:40:38,360][INFO ][logstash.runner          ] Starting Logstash {"logstash.version"=>"6.2.3"}
[2018-06-05T10:40:38,482][INFO ][logstash.runner          ] Starting Logstash {"logstash.version"=>"6.2.3"}
[2018-06-05T10:40:38,693][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"fb_apache", :directory=>"/usr/share/logstash/modules/fb_apache/configuration"}
[2018-06-05T10:40:38,728][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"netflow", :directory=>"/usr/share/logstash/modules/netflow/configuration"}
[2018-06-05T10:40:38,793][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=>9600}
[2018-06-05T10:40:38,926][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=>9601}
[2018-06-05T10:40:39,061][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=>9602}
[2018-06-05T10:40:39,214][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=>9603}
[2018-06-05T10:40:39,984][WARN ][logstash.config.source.multilocal] Ignoring the 'pipelines.yml' file because modules or command line options are specified
[2018-06-05T10:40:40,537][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"fb_apache", :directory=>"/usr/share/logstash/modules/fb_apache/configuration"}
[2018-06-05T10:40:40,567][INFO ][logstash.runner          ] Starting Logstash {"logstash.version"=>"6.2.3"}
[2018-06-05T10:40:40,570][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"netflow", :directory=>"/usr/share/logstash/modules/netflow/configuration"}
[2018-06-05T10:40:41,601][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=>9604}
[2018-06-05T10:40:41,946][DEBUG][org.logstash.secret.store.SecretStoreFactory] Attempting to exists or secret store with implementation: org.logstash.secret.store.backend.JavaKeyStore
[2018-06-05T10:40:42,016][DEBUG][org.logstash.secret.store.SecretStoreFactory] Attempting to exists or secret store with implementation: org.logstash.secret.store.backend.JavaKeyStore
[2018-06-05T10:40:42,366][DEBUG][org.logstash.secret.store.SecretStoreFactory] Attempting to exists or secret store with implementation: org.logstash.secret.store.backend.JavaKeyStore
[2018-06-05T10:40:42,563][INFO ][logstash.filters.ruby.script] Test run complete {:script_path=>"rubyfilter.rb", :results=>{:passed=>0, :failed=>0, :errored=>0}}
[2018-06-05T10:40:42,714][DEBUG][org.logstash.secret.store.SecretStoreFactory] Attempting to exists or secret store with implementation: org.logstash.secret.store.backend.JavaKeyStore
[2018-06-05T10:40:42,757][WARN ][logstash.config.source.multilocal] Ignoring the 'pipelines.yml' file because modules or command line options are specified
[2018-06-05T10:40:43,163][DEBUG][org.logstash.secret.store.SecretStoreFactory] Attempting to exists or secret store with implementation: org.logstash.secret.store.backend.JavaKeyStore
[2018-06-05T10:40:43,311][DEBUG][org.logstash.secret.store.SecretStoreFactory] Attempting to exists or secret store with implementation: org.logstash.secret.store.backend.JavaKeyStore
[2018-06-05T10:40:43,419][INFO ][logstash.runner          ] Starting Logstash {"logstash.version"=>"6.2.3"}
[2018-06-05T10:40:43,597][DEBUG][org.logstash.secret.store.SecretStoreFactory] Attempting to exists or secret store with implementation: org.logstash.secret.store.backend.JavaKeyStore
[2018-06-05T10:40:43,710][INFO ][logstash.filters.ruby.script] Test run complete {:script_path=>"rubyfilter.rb", :results=>{:passed=>0, :failed=>0, :errored=>0}}
[2018-06-05T10:40:43,718][INFO ][logstash.filters.ruby.script] Test run complete {:script_path=>"rubyfilter.rb", :results=>{:passed=>0, :failed=>0, :errored=>0}}
[2018-06-05T10:40:43,733][DEBUG][org.logstash.secret.store.SecretStoreFactory] Attempting to exists or secret store with implementation: org.logstash.secret.store.backend.JavaKeyStore
[2018-06-05T10:40:43,839][DEBUG][org.logstash.secret.store.SecretStoreFactory] Attempting to exists or secret store with implementation: org.logstash.secret.store.backend.JavaKeyStore
[2018-06-05T10:40:43,962][DEBUG][org.logstash.secret.store.SecretStoreFactory] Attempting to exists or secret store with implementation: org.logstash.secret.store.backend.JavaKeyStore
[2018-06-05T10:40:43,981][WARN ][logstash.outputs.elasticsearch] You are using a deprecated config setting "document_type" set in elasticsearch. Deprecated settings will continue to work, but are scheduled for removal from logstash in the future. Document types are being deprecated in Elasticsearch 6.0, and removed entirely in 7.0. You should avoid this feature If you have any questions about this, please visit the #logstash channel on freenode irc. {:name=>"document_type", :plugin=><LogStash::Outputs::ElasticSearch hosts=>[//100.100.100.111:9200, //100.100.100.112:9200, //100.100.100.113:9200], index=>"qa-enuri-main-as-is-2018.06.05.01.39", document_type=>"_doc", document_id=>"%{id}", action=>"index", id=>"6ecd11524c84e5de286546b0de40f57503392aeab1548c7913e69855f4645bbc", enable_metric=>true, codec=><LogStash::Codecs::Plain id=>"plain_95edeaa5-eb60-4449-9135-9e53a5588677", enable_metric=>true, charset=>"UTF-8">, workers=>1, manage_template=>true, template_name=>"logstash", template_overwrite=>false, doc_as_upsert=>false, script_type=>"inline", script_lang=>"painless", script_var_name=>"event", scripted_upsert=>false, retry_initial_interval=>2, retry_max_interval=>64, retry_on_conflict=>1, ssl_certificate_verification=>true, sniffing=>false, sniffing_delay=>5, timeout=>60, pool_max=>1000, pool_max_per_route=>100, resurrect_delay=>5, validate_after_inactivity=>10000, http_compression=>false>}
[2018-06-05T10:40:44,073][INFO ][logstash.filters.ruby.script] Test run complete {:script_path=>"rubyfilter.rb", :results=>{:passed=>0, :failed=>0, :errored=>0}}
[2018-06-05T10:40:44,077][INFO ][logstash.pipeline        ] Starting pipeline {:pipeline_id=>"main", "pipeline.workers"=>8, "pipeline.batch.size"=>125, "pipeline.batch.delay"=>50}
[2018-06-05T10:40:44,033][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=>9605}
[2018-06-05T10:40:44,279][DEBUG][org.logstash.secret.store.SecretStoreFactory] Attempting to exists or secret store with implementation: org.logstash.secret.store.backend.JavaKeyStore
[2018-06-05T10:40:44,386][DEBUG][org.logstash.secret.store.SecretStoreFactory] Attempting to exists or secret store with implementation: org.logstash.secret.store.backend.JavaKeyStore
[2018-06-05T10:40:44,394][WARN ][logstash.outputs.elasticsearch] You are using a deprecated config setting "document_type" set in elasticsearch. Deprecated settings will continue to work, but are scheduled for removal from logstash in the future. Document types are being deprecated in Elasticsearch 6.0, and removed entirely in 7.0. You should avoid this feature If you have any questions about this, please visit the #logstash channel on freenode irc. {:name=>"document_type", :plugin=><LogStash::Outputs::ElasticSearch hosts=>[//100.100.100.111:9200, //100.100.100.112:9200, //100.100.100.113:9200], index=>"qa-enuri-main-as-is-2018.06.05.01.39", document_type=>"_doc", document_id=>"%{id}", action=>"index", id=>"6ecd11524c84e5de286546b0de40f57503392aeab1548c7913e69855f4645bbc", enable_metric=>true, codec=><LogStash::Codecs::Plain id=>"plain_d20096ab-92c6-4ed9-9e16-d5fde1a738bf", enable_metric=>true, charset=>"UTF-8">, workers=>1, manage_template=>true, template_name=>"logstash", template_overwrite=>false, doc_as_upsert=>false, script_type=>"inline", script_lang=>"painless", script_var_name=>"event", scripted_upsert=>false, retry_initial_interval=>2, retry_max_interval=>64, retry_on_conflict=>1, ssl_certificate_verification=>true, sniffing=>false, sniffing_delay=>5, timeout=>60, pool_max=>1000, pool_max_per_route=>100, resurrect_delay=>5, validate_after_inactivity=>10000, http_compression=>false>}
[2018-06-05T10:40:44,413][DEBUG][org.logstash.secret.store.SecretStoreFactory] Attempting to exists or secret store with implementation: org.logstash.secret.store.backend.JavaKeyStore
[2018-06-05T10:40:44,423][INFO ][logstash.pipeline        ] Starting pipeline {:pipeline_id=>"main", "pipeline.workers"=>8, "pipeline.batch.size"=>125, "pipeline.batch.delay"=>50}
[2018-06-05T10:40:44,467][WARN ][logstash.outputs.elasticsearch] You are using a deprecated config setting "document_type" set in elasticsearch. Deprecated settings will continue to work, but are scheduled for removal from logstash in the future. Document types are being deprecated in Elasticsearch 6.0, and removed entirely in 7.0. You should avoid this feature If you have any questions about this, please visit the #logstash channel on freenode irc. {:name=>"document_type", :plugin=><LogStash::Outputs::ElasticSearch hosts=>[//100.100.100.111:9200, //100.100.100.112:9200, //100.100.100.113:9200], index=>"qa-enuri-main-as-is-2018.06.05.01.39", document_type=>"_doc", document_id=>"%{id}", action=>"index", id=>"6ecd11524c84e5de286546b0de40f57503392aeab1548c7913e69855f4645bbc", enable_metric=>true, codec=><LogStash::Codecs::Plain id=>"plain_d6f6be4e-f20f-4baf-bf45-373822a3d655", enable_metric=>true, charset=>"UTF-8">, workers=>1, manage_template=>true, template_name=>"logstash", template_overwrite=>false, doc_as_upsert=>false, script_type=>"inline", script_lang=>"painless", script_var_name=>"event", scripted_upsert=>false, retry_initial_interval=>2, retry_max_interval=>64, retry_on_conflict=>1, ssl_certificate_verification=>true, sniffing=>false, sniffing_delay=>5, timeout=>60, pool_max=>1000, pool_max_per_route=>100, resurrect_delay=>5, validate_after_inactivity=>10000, http_compression=>false>}
[2018-06-05T10:40:44,504][INFO ][logstash.pipeline        ] Starting pipeline {:pipeline_id=>"main", "pipeline.workers"=>8, "pipeline.batch.size"=>125, "pipeline.batch.delay"=>50}
[2018-06-05T10:40:44,580][INFO ][logstash.filters.ruby.script] Test run complete {:script_path=>"rubyfilter.rb", :results=>{:passed=>0, :failed=>0, :errored=>0}}
[2018-06-05T10:40:44,648][DEBUG][org.logstash.secret.store.SecretStoreFactory] Attempting to exists or secret store with implementation: org.logstash.secret.store.backend.JavaKeyStore
[2018-06-05T10:40:44,801][WARN ][logstash.outputs.elasticsearch] You are using a deprecated config setting "document_type" set in elasticsearch. Deprecated settings will continue to work, but are scheduled for removal from logstash in the future. Document types are being deprecated in Elasticsearch 6.0, and removed entirely in 7.0. You should avoid this feature If you have any questions about this, please visit the #logstash channel on freenode irc. {:name=>"document_type", :plugin=><LogStash::Outputs::ElasticSearch hosts=>[//100.100.100.111:9200, //100.100.100.112:9200, //100.100.100.113:9200], index=>"qa-enuri-main-as-is-2018.06.05.01.39", document_type=>"_doc", document_id=>"%{id}", action=>"index", id=>"6ecd11524c84e5de286546b0de40f57503392aeab1548c7913e69855f4645bbc", enable_metric=>true, codec=><LogStash::Codecs::Plain id=>"plain_d13da009-8ffb-4c6b-9cf6-89f1380337f8", enable_metric=>true, charset=>"UTF-8">, workers=>1, manage_template=>true, template_name=>"logstash", template_overwrite=>false, doc_as_upsert=>false, script_type=>"inline", script_lang=>"painless", script_var_name=>"event", scripted_upsert=>false, retry_initial_interval=>2, retry_max_interval=>64, retry_on_conflict=>1, ssl_certificate_verification=>true, sniffing=>false, sniffing_delay=>5, timeout=>60, pool_max=>1000, pool_max_per_route=>100, resurrect_delay=>5, validate_after_inactivity=>10000, http_compression=>false>}
[2018-06-05T10:40:44,818][INFO ][logstash.pipeline        ] Starting pipeline {:pipeline_id=>"main", "pipeline.workers"=>8, "pipeline.batch.size"=>125, "pipeline.batch.delay"=>50}
[2018-06-05T10:40:45,135][DEBUG][org.logstash.secret.store.SecretStoreFactory] Attempting to exists or secret store with implementation: org.logstash.secret.store.backend.JavaKeyStore
[2018-06-05T10:40:45,191][WARN ][logstash.outputs.elasticsearch] You are using a deprecated config setting "document_type" set in elasticsearch. Deprecated settings will continue to work, but are scheduled for removal from logstash in the future. Document types are being deprecated in Elasticsearch 6.0, and removed entirely in 7.0. You should avoid this feature If you have any questions about this, please visit the #logstash channel on freenode irc. {:name=>"document_type", :plugin=><LogStash::Outputs::ElasticSearch hosts=>[//100.100.100.111:9200, //100.100.100.112:9200, //100.100.100.113:9200], index=>"qa-enuri-main-as-is-2018.06.05.01.39", document_type=>"_doc", document_id=>"%{id}", action=>"index", id=>"6ecd11524c84e5de286546b0de40f57503392aeab1548c7913e69855f4645bbc", enable_metric=>true, codec=><LogStash::Codecs::Plain id=>"plain_14adf950-0987-493e-8ca7-a3f2e14a15e8", enable_metric=>true, charset=>"UTF-8">, workers=>1, manage_template=>true, template_name=>"logstash", template_overwrite=>false, doc_as_upsert=>false, script_type=>"inline", script_lang=>"painless", script_var_name=>"event", scripted_upsert=>false, retry_initial_interval=>2, retry_max_interval=>64, retry_on_conflict=>1, ssl_certificate_verification=>true, sniffing=>false, sniffing_delay=>5, timeout=>60, pool_max=>1000, pool_max_per_route=>100, resurrect_delay=>5, validate_after_inactivity=>10000, http_compression=>false>}
[2018-06-05T10:40:45,227][INFO ][logstash.pipeline        ] Starting pipeline {:pipeline_id=>"main", "pipeline.workers"=>8, "pipeline.batch.size"=>125, "pipeline.batch.delay"=>50}
[2018-06-05T10:40:45,680][INFO ][logstash.outputs.elasticsearch] Elasticsearch pool URLs updated {:changes=>{:removed=>[], :added=>[http://100.100.100.111:9200/, http://100.100.100.112:9200/, http://100.100.100.113:9200/]}}
[2018-06-05T10:40:45,684][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://100.100.100.111:9200/, :path=>"/"}
[2018-06-05T10:40:45,690][INFO ][logstash.outputs.elasticsearch] Elasticsearch pool URLs updated {:changes=>{:removed=>[], :added=>[http://100.100.100.111:9200/, http://100.100.100.112:9200/, http://100.100.100.113:9200/]}}
[2018-06-05T10:40:45,693][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://100.100.100.111:9200/, :path=>"/"}
[2018-06-05T10:40:45,695][INFO ][logstash.outputs.elasticsearch] Elasticsearch pool URLs updated {:changes=>{:removed=>[], :added=>[http://100.100.100.111:9200/, http://100.100.100.112:9200/, http://100.100.100.113:9200/]}}
[2018-06-05T10:40:45,697][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://100.100.100.111:9200/, :path=>"/"}
[2018-06-05T10:40:45,752][INFO ][logstash.outputs.elasticsearch] Elasticsearch pool URLs updated {:changes=>{:removed=>[], :added=>[http://100.100.100.111:9200/, http://100.100.100.112:9200/, http://100.100.100.113:9200/]}}
[2018-06-05T10:40:45,755][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://100.100.100.111:9200/, :path=>"/"}
[2018-06-05T10:40:45,923][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://100.100.100.111:9200/"}
[2018-06-05T10:40:46,035][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://100.100.100.111:9200/"}
[2018-06-05T10:40:46,123][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://100.100.100.111:9200/"}
[2018-06-05T10:40:46,166][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://100.100.100.111:9200/"}
[2018-06-05T10:40:46,230][INFO ][logstash.outputs.elasticsearch] ES Output version determined {:es_version=>6}
[2018-06-05T10:40:46,230][WARN ][logstash.outputs.elasticsearch] Detected a 6.x and above cluster: the `type` event field won't be used to determine the document _type {:es_version=>6}
[2018-06-05T10:40:46,231][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://100.100.100.112:9200/, :path=>"/"}
[2018-06-05T10:40:46,240][INFO ][logstash.outputs.elasticsearch] ES Output version determined {:es_version=>6}
[2018-06-05T10:40:46,241][WARN ][logstash.outputs.elasticsearch] Detected a 6.x and above cluster: the `type` event field won't be used to determine the document _type {:es_version=>6}
[2018-06-05T10:40:46,242][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://100.100.100.112:9200/, :path=>"/"}
[2018-06-05T10:40:46,281][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://100.100.100.112:9200/"}
[2018-06-05T10:40:46,296][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://100.100.100.112:9200/"}
[2018-06-05T10:40:46,300][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://100.100.100.113:9200/, :path=>"/"}
[2018-06-05T10:40:46,309][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://100.100.100.113:9200/, :path=>"/"}
[2018-06-05T10:40:46,348][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://100.100.100.113:9200/"}
[2018-06-05T10:40:46,348][INFO ][logstash.outputs.elasticsearch] ES Output version determined {:es_version=>6}
[2018-06-05T10:40:46,349][WARN ][logstash.outputs.elasticsearch] Detected a 6.x and above cluster: the `type` event field won't be used to determine the document _type {:es_version=>6}
[2018-06-05T10:40:46,349][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://100.100.100.113:9200/"}
[2018-06-05T10:40:46,349][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://100.100.100.112:9200/, :path=>"/"}
[2018-06-05T10:40:46,361][INFO ][logstash.outputs.elasticsearch] Elasticsearch pool URLs updated {:changes=>{:removed=>[], :added=>[http://100.100.100.111:9200/, http://100.100.100.112:9200/, http://100.100.100.113:9200/]}}
[2018-06-05T10:40:46,363][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://100.100.100.111:9200/, :path=>"/"}
[2018-06-05T10:40:46,375][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://100.100.100.112:9200/"}
[2018-06-05T10:40:46,383][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://100.100.100.113:9200/, :path=>"/"}
[2018-06-05T10:40:46,381][INFO ][logstash.outputs.elasticsearch] Using mapping template from {:path=>nil}
[2018-06-05T10:40:46,387][INFO ][logstash.outputs.elasticsearch] ES Output version determined {:es_version=>6}
[2018-06-05T10:40:46,387][WARN ][logstash.outputs.elasticsearch] Detected a 6.x and above cluster: the `type` event field won't be used to determine the document _type {:es_version=>6}
[2018-06-05T10:40:46,388][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://100.100.100.112:9200/, :path=>"/"}
[2018-06-05T10:40:46,389][INFO ][logstash.outputs.elasticsearch] Using mapping template from {:path=>nil}
[2018-06-05T10:40:46,408][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://100.100.100.113:9200/"}
[2018-06-05T10:40:46,405][INFO ][logstash.outputs.elasticsearch] Attempting to install template {:manage_template=>{"template"=>"logstash-*", "version"=>60001, "settings"=>{"index.refresh_interval"=>"5s"}, "mappings"=>{"_default_"=>{"dynamic_templates"=>[{"message_field"=>{"path_match"=>"message", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false}}}, {"string_fields"=>{"match"=>"*", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false, "fields"=>{"keyword"=>{"type"=>"keyword", "ignore_above"=>256}}}}}], "properties"=>{"@timestamp"=>{"type"=>"date"}, "@version"=>{"type"=>"keyword"}, "geoip"=>{"dynamic"=>true, "properties"=>{"ip"=>{"type"=>"ip"}, "location"=>{"type"=>"geo_point"}, "latitude"=>{"type"=>"half_float"}, "longitude"=>{"type"=>"half_float"}}}}}}}}
[2018-06-05T10:40:46,415][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://100.100.100.112:9200/"}
[2018-06-05T10:40:46,417][INFO ][logstash.outputs.elasticsearch] Attempting to install template {:manage_template=>{"template"=>"logstash-*", "version"=>60001, "settings"=>{"index.refresh_interval"=>"5s"}, "mappings"=>{"_default_"=>{"dynamic_templates"=>[{"message_field"=>{"path_match"=>"message", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false}}}, {"string_fields"=>{"match"=>"*", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false, "fields"=>{"keyword"=>{"type"=>"keyword", "ignore_above"=>256}}}}}], "properties"=>{"@timestamp"=>{"type"=>"date"}, "@version"=>{"type"=>"keyword"}, "geoip"=>{"dynamic"=>true, "properties"=>{"ip"=>{"type"=>"ip"}, "location"=>{"type"=>"geo_point"}, "latitude"=>{"type"=>"half_float"}, "longitude"=>{"type"=>"half_float"}}}}}}}}
[2018-06-05T10:40:46,427][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://100.100.100.113:9200/, :path=>"/"}
[2018-06-05T10:40:46,434][INFO ][logstash.outputs.elasticsearch] New Elasticsearch output {:class=>"LogStash::Outputs::ElasticSearch", :hosts=>["//100.100.100.111:9200", "//100.100.100.112:9200", "//100.100.100.113:9200"]}
[2018-06-05T10:40:46,442][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://100.100.100.113:9200/"}
[2018-06-05T10:40:46,456][INFO ][logstash.outputs.elasticsearch] New Elasticsearch output {:class=>"LogStash::Outputs::ElasticSearch", :hosts=>["//100.100.100.111:9200", "//100.100.100.112:9200", "//100.100.100.113:9200"]}
[2018-06-05T10:40:46,467][INFO ][logstash.outputs.elasticsearch] Using mapping template from {:path=>nil}
[2018-06-05T10:40:46,482][INFO ][logstash.outputs.elasticsearch] Attempting to install template {:manage_template=>{"template"=>"logstash-*", "version"=>60001, "settings"=>{"index.refresh_interval"=>"5s"}, "mappings"=>{"_default_"=>{"dynamic_templates"=>[{"message_field"=>{"path_match"=>"message", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false}}}, {"string_fields"=>{"match"=>"*", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false, "fields"=>{"keyword"=>{"type"=>"keyword", "ignore_above"=>256}}}}}], "properties"=>{"@timestamp"=>{"type"=>"date"}, "@version"=>{"type"=>"keyword"}, "geoip"=>{"dynamic"=>true, "properties"=>{"ip"=>{"type"=>"ip"}, "location"=>{"type"=>"geo_point"}, "latitude"=>{"type"=>"half_float"}, "longitude"=>{"type"=>"half_float"}}}}}}}}
[2018-06-05T10:40:46,484][INFO ][logstash.outputs.elasticsearch] Using mapping template from {:path=>nil}
[2018-06-05T10:40:46,503][INFO ][logstash.outputs.elasticsearch] New Elasticsearch output {:class=>"LogStash::Outputs::ElasticSearch", :hosts=>["//100.100.100.111:9200", "//100.100.100.112:9200", "//100.100.100.113:9200"]}
[2018-06-05T10:40:46,515][INFO ][logstash.outputs.elasticsearch] Attempting to install template {:manage_template=>{"template"=>"logstash-*", "version"=>60001, "settings"=>{"index.refresh_interval"=>"5s"}, "mappings"=>{"_default_"=>{"dynamic_templates"=>[{"message_field"=>{"path_match"=>"message", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false}}}, {"string_fields"=>{"match"=>"*", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false, "fields"=>{"keyword"=>{"type"=>"keyword", "ignore_above"=>256}}}}}], "properties"=>{"@timestamp"=>{"type"=>"date"}, "@version"=>{"type"=>"keyword"}, "geoip"=>{"dynamic"=>true, "properties"=>{"ip"=>{"type"=>"ip"}, "location"=>{"type"=>"geo_point"}, "latitude"=>{"type"=>"half_float"}, "longitude"=>{"type"=>"half_float"}}}}}}}}
[2018-06-05T10:40:46,552][INFO ][logstash.outputs.elasticsearch] New Elasticsearch output {:class=>"LogStash::Outputs::ElasticSearch", :hosts=>["//100.100.100.111:9200", "//100.100.100.112:9200", "//100.100.100.113:9200"]}
[2018-06-05T10:40:46,620][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://100.100.100.111:9200/"}
[2018-06-05T10:40:46,681][DEBUG][org.logstash.secret.store.SecretStoreFactory] Attempting to exists or secret store with implementation: org.logstash.secret.store.backend.JavaKeyStore
[2018-06-05T10:40:46,759][INFO ][logstash.outputs.elasticsearch] ES Output version determined {:es_version=>6}
[2018-06-05T10:40:46,760][WARN ][logstash.outputs.elasticsearch] Detected a 6.x and above cluster: the `type` event field won't be used to determine the document _type {:es_version=>6}
[2018-06-05T10:40:46,760][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://100.100.100.112:9200/, :path=>"/"}
[2018-06-05T10:40:46,784][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://100.100.100.112:9200/"}
[2018-06-05T10:40:46,797][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://100.100.100.113:9200/, :path=>"/"}
[2018-06-05T10:40:46,809][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://100.100.100.113:9200/"}
[2018-06-05T10:40:46,860][INFO ][logstash.outputs.elasticsearch] Using mapping template from {:path=>nil}
[2018-06-05T10:40:46,865][INFO ][logstash.outputs.elasticsearch] Attempting to install template {:manage_template=>{"template"=>"logstash-*", "version"=>60001, "settings"=>{"index.refresh_interval"=>"5s"}, "mappings"=>{"_default_"=>{"dynamic_templates"=>[{"message_field"=>{"path_match"=>"message", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false}}}, {"string_fields"=>{"match"=>"*", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false, "fields"=>{"keyword"=>{"type"=>"keyword", "ignore_above"=>256}}}}}], "properties"=>{"@timestamp"=>{"type"=>"date"}, "@version"=>{"type"=>"keyword"}, "geoip"=>{"dynamic"=>true, "properties"=>{"ip"=>{"type"=>"ip"}, "location"=>{"type"=>"geo_point"}, "latitude"=>{"type"=>"half_float"}, "longitude"=>{"type"=>"half_float"}}}}}}}}
[2018-06-05T10:40:46,892][INFO ][logstash.outputs.elasticsearch] New Elasticsearch output {:class=>"LogStash::Outputs::ElasticSearch", :hosts=>["//100.100.100.111:9200", "//100.100.100.112:9200", "//100.100.100.113:9200"]}
[2018-06-05T10:40:47,039][DEBUG][org.logstash.secret.store.SecretStoreFactory] Attempting to exists or secret store with implementation: org.logstash.secret.store.backend.JavaKeyStore
[2018-06-05T10:40:47,278][INFO ][logstash.pipeline        ] Pipeline started succesfully {:pipeline_id=>"main", :thread=>"#<Thread:0x141a2aa2@/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:246 run>"}
[2018-06-05T10:40:47,303][INFO ][logstash.filters.ruby.script] Test run complete {:script_path=>"rubyfilter.rb", :results=>{:passed=>0, :failed=>0, :errored=>0}}
[2018-06-05T10:40:47,333][INFO ][logstash.pipeline        ] Pipeline started succesfully {:pipeline_id=>"main", :thread=>"#<Thread:0x3045b6b5@/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:246 run>"}
[2018-06-05T10:40:47,348][INFO ][logstash.agent           ] Pipelines running {:count=>1, :pipelines=>["main"]}
[2018-06-05T10:40:47,368][INFO ][logstash.agent           ] Pipelines running {:count=>1, :pipelines=>["main"]}
[2018-06-05T10:40:47,468][INFO ][logstash.pipeline        ] Pipeline started succesfully {:pipeline_id=>"main", :thread=>"#<Thread:0x3cf9966a@/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:246 sleep>"}
[2018-06-05T10:40:47,539][INFO ][logstash.agent           ] Pipelines running {:count=>1, :pipelines=>["main"]}
[2018-06-05T10:40:47,552][INFO ][logstash.pipeline        ] Pipeline started succesfully {:pipeline_id=>"main", :thread=>"#<Thread:0x57857631@/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:246 run>"}
[2018-06-05T10:40:47,615][INFO ][logstash.agent           ] Pipelines running {:count=>1, :pipelines=>["main"]}
[2018-06-05T10:40:47,833][DEBUG][org.logstash.secret.store.SecretStoreFactory] Attempting to exists or secret store with implementation: org.logstash.secret.store.backend.JavaKeyStore
[2018-06-05T10:40:47,847][INFO ][logstash.pipeline        ] Pipeline started succesfully {:pipeline_id=>"main", :thread=>"#<Thread:0xe366ae6@/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:246 run>"}
[2018-06-05T10:40:47,921][INFO ][logstash.agent           ] Pipelines running {:count=>1, :pipelines=>["main"]}
[2018-06-05T10:40:48,003][WARN ][logstash.outputs.elasticsearch] You are using a deprecated config setting "document_type" set in elasticsearch. Deprecated settings will continue to work, but are scheduled for removal from logstash in the future. Document types are being deprecated in Elasticsearch 6.0, and removed entirely in 7.0. You should avoid this feature If you have any questions about this, please visit the #logstash channel on freenode irc. {:name=>"document_type", :plugin=><LogStash::Outputs::ElasticSearch hosts=>[//100.100.100.111:9200, //100.100.100.112:9200, //100.100.100.113:9200], index=>"qa-enuri-main-as-is-2018.06.05.01.39", document_type=>"_doc", document_id=>"%{id}", action=>"index", id=>"6ecd11524c84e5de286546b0de40f57503392aeab1548c7913e69855f4645bbc", enable_metric=>true, codec=><LogStash::Codecs::Plain id=>"plain_4bbeadd1-a2ea-4016-afb8-bba1bfd6edaa", enable_metric=>true, charset=>"UTF-8">, workers=>1, manage_template=>true, template_name=>"logstash", template_overwrite=>false, doc_as_upsert=>false, script_type=>"inline", script_lang=>"painless", script_var_name=>"event", scripted_upsert=>false, retry_initial_interval=>2, retry_max_interval=>64, retry_on_conflict=>1, ssl_certificate_verification=>true, sniffing=>false, sniffing_delay=>5, timeout=>60, pool_max=>1000, pool_max_per_route=>100, resurrect_delay=>5, validate_after_inactivity=>10000, http_compression=>false>}
[2018-06-05T10:40:48,045][INFO ][logstash.pipeline        ] Starting pipeline {:pipeline_id=>"main", "pipeline.workers"=>8, "pipeline.batch.size"=>125, "pipeline.batch.delay"=>50}
[2018-06-05T10:40:49,186][INFO ][logstash.outputs.elasticsearch] Elasticsearch pool URLs updated {:changes=>{:removed=>[], :added=>[http://100.100.100.111:9200/, http://100.100.100.112:9200/, http://100.100.100.113:9200/]}}
[2018-06-05T10:40:49,189][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://100.100.100.111:9200/, :path=>"/"}
[2018-06-05T10:40:49,557][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://100.100.100.111:9200/"}
[2018-06-05T10:40:49,866][INFO ][logstash.outputs.elasticsearch] ES Output version determined {:es_version=>6}
[2018-06-05T10:40:49,866][WARN ][logstash.outputs.elasticsearch] Detected a 6.x and above cluster: the `type` event field won't be used to determine the document _type {:es_version=>6}
[2018-06-05T10:40:49,867][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://100.100.100.112:9200/, :path=>"/"}
[2018-06-05T10:40:49,915][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://100.100.100.112:9200/"}
[2018-06-05T10:40:49,956][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://100.100.100.113:9200/, :path=>"/"}
[2018-06-05T10:40:50,036][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://100.100.100.113:9200/"}
[2018-06-05T10:40:50,073][INFO ][logstash.outputs.elasticsearch] Using mapping template from {:path=>nil}
[2018-06-05T10:40:50,099][INFO ][logstash.outputs.elasticsearch] Attempting to install template {:manage_template=>{"template"=>"logstash-*", "version"=>60001, "settings"=>{"index.refresh_interval"=>"5s"}, "mappings"=>{"_default_"=>{"dynamic_templates"=>[{"message_field"=>{"path_match"=>"message", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false}}}, {"string_fields"=>{"match"=>"*", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false, "fields"=>{"keyword"=>{"type"=>"keyword", "ignore_above"=>256}}}}}], "properties"=>{"@timestamp"=>{"type"=>"date"}, "@version"=>{"type"=>"keyword"}, "geoip"=>{"dynamic"=>true, "properties"=>{"ip"=>{"type"=>"ip"}, "location"=>{"type"=>"geo_point"}, "latitude"=>{"type"=>"half_float"}, "longitude"=>{"type"=>"half_float"}}}}}}}}
[2018-06-05T10:40:50,134][INFO ][logstash.outputs.elasticsearch] New Elasticsearch output {:class=>"LogStash::Outputs::ElasticSearch", :hosts=>["//100.100.100.111:9200", "//100.100.100.112:9200", "//100.100.100.113:9200"]}
[2018-06-05T10:40:51,452][INFO ][logstash.pipeline        ] Pipeline started succesfully {:pipeline_id=>"main", :thread=>"#<Thread:0x4c1d1775@/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:246 run>"}
[2018-06-05T10:40:51,584][INFO ][logstash.agent           ] Pipelines running {:count=>1, :pipelines=>["main"]}
[2018-06-05T10:40:51,929][INFO ][logstash.inputs.jdbc     ] (1.853786s) select 
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    DECODE(NVL(MODELNO_GROUP,0),0,0,1) AS MODELNO_GROUP_FLAG,
    category,
    '' as cg,
    '' as cat1,
    '' as cat2,
    '' as cat3,
    '' as cat4,
    ca_code,
    ca_dept_mcode,
    ca_dept_code,
    ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,
    shop_name,
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    MODELNM || ' ' || FACTORY as model_factory,
    minprice,
    maxprice,
    minprices,
    C_DATE,
    mallcnt,
    DECODE(NVL(MALLCNT,0),0,0,1) AS MALLCNT_FLAG,
    spec,
    openexpectflag,
    condiname,
    KEYWORD,
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    to_all
--    MODELNM || ' ' || FACTORY || ' ' || SPEC || ' ' || KEYWORD || ' ' || KEYWORD2 || ' ' || CONDINAME AS to_all
from (

select
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    CASE WHEN service_gubun='2' AND store_flag='1' AND ca_dept_code IS NOT NULL THEN RTRIM(category || ' '  || ca_dept_code) ELSE category END AS category,
    ca_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),3,8)='000000' OR SUBSTR(RTRIM(ca_dept_code),3,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,4) END AS ca_dept_mcode,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),5,8)='0000' OR SUBSTR(RTRIM(ca_dept_code),5,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,6) END AS ca_dept_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),7,8)='00' OR SUBSTR(RTRIM(ca_dept_code),7,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,8) END AS ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,    
    shop_name,    
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    model_factory,
    minprice,
    maxprice,
    replace(minprices, ' ', '    ') as minprices,
    C_DATE,
    mallcnt,
    replace(replace(spec,',',' '),'/',' ') spec,
    openexpectflag,
    replace(condiname, ' ', '    ') as condiname,    
    CASE WHEN socialprice=0 THEN keyword ELSE keyword || ' ' || UDF_SOCIAL_GOODSNM(modelno_group,modelno) END AS KEYWORD,    
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    to_all
FROM tmp_es_goods_data_01    
WHERE mod_no = '3'

)

[2018-06-05T10:40:51,934][INFO ][logstash.inputs.jdbc     ] (1.856911s) select
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    DECODE(NVL(MODELNO_GROUP,0),0,0,1) AS MODELNO_GROUP_FLAG,
    category,
    '' as cg,
    '' as cat1,
    '' as cat2,
    '' as cat3,
    '' as cat4,
    ca_code,
    ca_dept_mcode,
    ca_dept_code,
    ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,
    shop_name,
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    '' as model_factory,
    minprice,
    maxprice,
    minprices,
    C_DATE,
    mallcnt,
    DECODE(NVL(MALLCNT,0),0,0,1) AS MALLCNT_FLAG,
    spec,
    openexpectflag,
    condiname,
    KEYWORD,
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    to_all
--    MODELNM || ' ' || FACTORY || ' ' || SPEC || ' ' || KEYWORD || ' ' || KEYWORD2 || ' ' || CONDINAME AS to_all
from (

select
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    CASE WHEN service_gubun='2' AND store_flag='1' AND ca_dept_code IS NOT NULL THEN RTRIM(category || ' '  || ca_dept_code) ELSE category END AS category,
    ca_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),3,8)='000000' OR SUBSTR(RTRIM(ca_dept_code),3,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,4) END AS ca_dept_mcode,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),5,8)='0000' OR SUBSTR(RTRIM(ca_dept_code),5,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,6) END AS ca_dept_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),7,8)='00' OR SUBSTR(RTRIM(ca_dept_code),7,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,8) END AS ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,    
    shop_name,    
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    model_factory,
    minprice,
    maxprice,
    replace(minprices, ' ', '    ') as minprices,
    C_DATE,
    mallcnt,
    replace(replace(spec,',',' '),'/',' ') spec,
    openexpectflag,
    replace(condiname, ' ', '    ') as condiname,    
    CASE WHEN socialprice=0 THEN keyword ELSE keyword || ' ' || UDF_SOCIAL_GOODSNM(modelno_group,modelno) END AS KEYWORD,    
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    to_all
FROM tmp_es_price_data_01
WHERE mod_no = '3'

)

[2018-06-05T10:40:52,283][INFO ][logstash.inputs.jdbc     ] (2.114200s) select
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    DECODE(NVL(MODELNO_GROUP,0),0,0,1) AS MODELNO_GROUP_FLAG,
    category,
    '' as cg,
    '' as cat1,
    '' as cat2,
    '' as cat3,
    '' as cat4,
    ca_code,
    ca_dept_mcode,
    ca_dept_code,
    ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,
    shop_name,
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    '' as model_factory,
    minprice,
    maxprice,
    minprices,
    C_DATE,
    mallcnt,
    DECODE(NVL(MALLCNT,0),0,0,1) AS MALLCNT_FLAG,
    spec,
    openexpectflag,
    condiname,
    KEYWORD,
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    to_all
--    MODELNM || ' ' || FACTORY || ' ' || SPEC || ' ' || KEYWORD || ' ' || KEYWORD2 || ' ' || CONDINAME AS to_all
from (

select
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    CASE WHEN service_gubun='2' AND store_flag='1' AND ca_dept_code IS NOT NULL THEN RTRIM(category || ' '  || ca_dept_code) ELSE category END AS category,
    ca_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),3,8)='000000' OR SUBSTR(RTRIM(ca_dept_code),3,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,4) END AS ca_dept_mcode,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),5,8)='0000' OR SUBSTR(RTRIM(ca_dept_code),5,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,6) END AS ca_dept_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),7,8)='00' OR SUBSTR(RTRIM(ca_dept_code),7,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,8) END AS ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,    
    shop_name,    
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    model_factory,
    minprice,
    maxprice,
    replace(minprices, ' ', '    ') as minprices,
    C_DATE,
    mallcnt,
    replace(replace(spec,',',' '),'/',' ') spec,
    openexpectflag,
    replace(condiname, ' ', '    ') as condiname,    
    CASE WHEN socialprice=0 THEN keyword ELSE keyword || ' ' || UDF_SOCIAL_GOODSNM(modelno_group,modelno) END AS KEYWORD,    
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    to_all
FROM tmp_es_price_data_01
WHERE mod_no = '4'

)

[2018-06-05T10:40:52,403][INFO ][logstash.inputs.jdbc     ] (2.172427s) select 
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    DECODE(NVL(MODELNO_GROUP,0),0,0,1) AS MODELNO_GROUP_FLAG,
    category,
    '' as cg,
    '' as cat1,
    '' as cat2,
    '' as cat3,
    '' as cat4,
    ca_code,
    ca_dept_mcode,
    ca_dept_code,
    ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,
    shop_name,
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    MODELNM || ' ' || FACTORY as model_factory,
    minprice,
    maxprice,
    minprices,
    C_DATE,
    mallcnt,
    DECODE(NVL(MALLCNT,0),0,0,1) AS MALLCNT_FLAG,
    spec,
    openexpectflag,
    condiname,
    KEYWORD,
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    to_all
--    MODELNM || ' ' || FACTORY || ' ' || SPEC || ' ' || KEYWORD || ' ' || KEYWORD2 || ' ' || CONDINAME AS to_all
from (

select
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    CASE WHEN service_gubun='2' AND store_flag='1' AND ca_dept_code IS NOT NULL THEN RTRIM(category || ' '  || ca_dept_code) ELSE category END AS category,
    ca_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),3,8)='000000' OR SUBSTR(RTRIM(ca_dept_code),3,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,4) END AS ca_dept_mcode,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),5,8)='0000' OR SUBSTR(RTRIM(ca_dept_code),5,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,6) END AS ca_dept_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),7,8)='00' OR SUBSTR(RTRIM(ca_dept_code),7,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,8) END AS ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,    
    shop_name,    
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    model_factory,
    minprice,
    maxprice,
    replace(minprices, ' ', '    ') as minprices,
    C_DATE,
    mallcnt,
    replace(replace(spec,',',' '),'/',' ') spec,
    openexpectflag,
    replace(condiname, ' ', '    ') as condiname,    
    CASE WHEN socialprice=0 THEN keyword ELSE keyword || ' ' || UDF_SOCIAL_GOODSNM(modelno_group,modelno) END AS KEYWORD,    
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    to_all
FROM tmp_es_goods_data_01    
WHERE mod_no = '4'

)

[2018-06-05T10:40:52,458][INFO ][logstash.inputs.jdbc     ] (2.491018s) select 
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    DECODE(NVL(MODELNO_GROUP,0),0,0,1) AS MODELNO_GROUP_FLAG,
    category,
    '' as cg,
    '' as cat1,
    '' as cat2,
    '' as cat3,
    '' as cat4,
    ca_code,
    ca_dept_mcode,
    ca_dept_code,
    ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,
    shop_name,
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    MODELNM || ' ' || FACTORY as model_factory,
    minprice,
    maxprice,
    minprices,
    C_DATE,
    mallcnt,
    DECODE(NVL(MALLCNT,0),0,0,1) AS MALLCNT_FLAG,
    spec,
    openexpectflag,
    condiname,
    KEYWORD,
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    to_all
--    MODELNM || ' ' || FACTORY || ' ' || SPEC || ' ' || KEYWORD || ' ' || KEYWORD2 || ' ' || CONDINAME AS to_all
from (

select
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    CASE WHEN service_gubun='2' AND store_flag='1' AND ca_dept_code IS NOT NULL THEN RTRIM(category || ' '  || ca_dept_code) ELSE category END AS category,
    ca_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),3,8)='000000' OR SUBSTR(RTRIM(ca_dept_code),3,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,4) END AS ca_dept_mcode,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),5,8)='0000' OR SUBSTR(RTRIM(ca_dept_code),5,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,6) END AS ca_dept_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),7,8)='00' OR SUBSTR(RTRIM(ca_dept_code),7,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,8) END AS ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,    
    shop_name,    
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    model_factory,
    minprice,
    maxprice,
    replace(minprices, ' ', '    ') as minprices,
    C_DATE,
    mallcnt,
    replace(replace(spec,',',' '),'/',' ') spec,
    openexpectflag,
    replace(condiname, ' ', '    ') as condiname,    
    CASE WHEN socialprice=0 THEN keyword ELSE keyword || ' ' || UDF_SOCIAL_GOODSNM(modelno_group,modelno) END AS KEYWORD,    
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    to_all
FROM tmp_es_goods_data_01    
WHERE mod_no = '1'

)

[2018-06-05T10:40:52,462][INFO ][logstash.inputs.jdbc     ] (2.491849s) select
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    DECODE(NVL(MODELNO_GROUP,0),0,0,1) AS MODELNO_GROUP_FLAG,
    category,
    '' as cg,
    '' as cat1,
    '' as cat2,
    '' as cat3,
    '' as cat4,
    ca_code,
    ca_dept_mcode,
    ca_dept_code,
    ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,
    shop_name,
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    '' as model_factory,
    minprice,
    maxprice,
    minprices,
    C_DATE,
    mallcnt,
    DECODE(NVL(MALLCNT,0),0,0,1) AS MALLCNT_FLAG,
    spec,
    openexpectflag,
    condiname,
    KEYWORD,
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    to_all
--    MODELNM || ' ' || FACTORY || ' ' || SPEC || ' ' || KEYWORD || ' ' || KEYWORD2 || ' ' || CONDINAME AS to_all
from (

select
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    CASE WHEN service_gubun='2' AND store_flag='1' AND ca_dept_code IS NOT NULL THEN RTRIM(category || ' '  || ca_dept_code) ELSE category END AS category,
    ca_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),3,8)='000000' OR SUBSTR(RTRIM(ca_dept_code),3,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,4) END AS ca_dept_mcode,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),5,8)='0000' OR SUBSTR(RTRIM(ca_dept_code),5,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,6) END AS ca_dept_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),7,8)='00' OR SUBSTR(RTRIM(ca_dept_code),7,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,8) END AS ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,    
    shop_name,    
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    model_factory,
    minprice,
    maxprice,
    replace(minprices, ' ', '    ') as minprices,
    C_DATE,
    mallcnt,
    replace(replace(spec,',',' '),'/',' ') spec,
    openexpectflag,
    replace(condiname, ' ', '    ') as condiname,    
    CASE WHEN socialprice=0 THEN keyword ELSE keyword || ' ' || UDF_SOCIAL_GOODSNM(modelno_group,modelno) END AS KEYWORD,    
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    to_all
FROM tmp_es_price_data_01
WHERE mod_no = '1'

)

[2018-06-05T10:40:52,874][INFO ][logstash.inputs.jdbc     ] (2.636267s) select
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    DECODE(NVL(MODELNO_GROUP,0),0,0,1) AS MODELNO_GROUP_FLAG,
    category,
    '' as cg,
    '' as cat1,
    '' as cat2,
    '' as cat3,
    '' as cat4,
    ca_code,
    ca_dept_mcode,
    ca_dept_code,
    ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,
    shop_name,
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    '' as model_factory,
    minprice,
    maxprice,
    minprices,
    C_DATE,
    mallcnt,
    DECODE(NVL(MALLCNT,0),0,0,1) AS MALLCNT_FLAG,
    spec,
    openexpectflag,
    condiname,
    KEYWORD,
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    to_all
--    MODELNM || ' ' || FACTORY || ' ' || SPEC || ' ' || KEYWORD || ' ' || KEYWORD2 || ' ' || CONDINAME AS to_all
from (

select
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    CASE WHEN service_gubun='2' AND store_flag='1' AND ca_dept_code IS NOT NULL THEN RTRIM(category || ' '  || ca_dept_code) ELSE category END AS category,
    ca_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),3,8)='000000' OR SUBSTR(RTRIM(ca_dept_code),3,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,4) END AS ca_dept_mcode,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),5,8)='0000' OR SUBSTR(RTRIM(ca_dept_code),5,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,6) END AS ca_dept_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),7,8)='00' OR SUBSTR(RTRIM(ca_dept_code),7,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,8) END AS ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,    
    shop_name,    
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    model_factory,
    minprice,
    maxprice,
    replace(minprices, ' ', '    ') as minprices,
    C_DATE,
    mallcnt,
    replace(replace(spec,',',' '),'/',' ') spec,
    openexpectflag,
    replace(condiname, ' ', '    ') as condiname,    
    CASE WHEN socialprice=0 THEN keyword ELSE keyword || ' ' || UDF_SOCIAL_GOODSNM(modelno_group,modelno) END AS KEYWORD,    
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    to_all
FROM tmp_es_price_data_01
WHERE mod_no = '2'

)

[2018-06-05T10:40:52,922][INFO ][logstash.inputs.jdbc     ] (2.664592s) select 
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    DECODE(NVL(MODELNO_GROUP,0),0,0,1) AS MODELNO_GROUP_FLAG,
    category,
    '' as cg,
    '' as cat1,
    '' as cat2,
    '' as cat3,
    '' as cat4,
    ca_code,
    ca_dept_mcode,
    ca_dept_code,
    ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,
    shop_name,
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    MODELNM || ' ' || FACTORY as model_factory,
    minprice,
    maxprice,
    minprices,
    C_DATE,
    mallcnt,
    DECODE(NVL(MALLCNT,0),0,0,1) AS MALLCNT_FLAG,
    spec,
    openexpectflag,
    condiname,
    KEYWORD,
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    to_all
--    MODELNM || ' ' || FACTORY || ' ' || SPEC || ' ' || KEYWORD || ' ' || KEYWORD2 || ' ' || CONDINAME AS to_all
from (

select
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    CASE WHEN service_gubun='2' AND store_flag='1' AND ca_dept_code IS NOT NULL THEN RTRIM(category || ' '  || ca_dept_code) ELSE category END AS category,
    ca_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),3,8)='000000' OR SUBSTR(RTRIM(ca_dept_code),3,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,4) END AS ca_dept_mcode,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),5,8)='0000' OR SUBSTR(RTRIM(ca_dept_code),5,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,6) END AS ca_dept_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),7,8)='00' OR SUBSTR(RTRIM(ca_dept_code),7,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,8) END AS ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,    
    shop_name,    
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    model_factory,
    minprice,
    maxprice,
    replace(minprices, ' ', '    ') as minprices,
    C_DATE,
    mallcnt,
    replace(replace(spec,',',' '),'/',' ') spec,
    openexpectflag,
    replace(condiname, ' ', '    ') as condiname,    
    CASE WHEN socialprice=0 THEN keyword ELSE keyword || ' ' || UDF_SOCIAL_GOODSNM(modelno_group,modelno) END AS KEYWORD,    
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    to_all
FROM tmp_es_goods_data_01    
WHERE mod_no = '2'

)

[2018-06-05T10:40:54,037][INFO ][logstash.inputs.jdbc     ] (3.317022s) select
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    DECODE(NVL(MODELNO_GROUP,0),0,0,1) AS MODELNO_GROUP_FLAG,
    category,
    '' as cg,
    '' as cat1,
    '' as cat2,
    '' as cat3,
    '' as cat4,
    ca_code,
    ca_dept_mcode,
    ca_dept_code,
    ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,
    shop_name,
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    '' as model_factory,
    minprice,
    maxprice,
    minprices,
    C_DATE,
    mallcnt,
    DECODE(NVL(MALLCNT,0),0,0,1) AS MALLCNT_FLAG,
    spec,
    openexpectflag,
    condiname,
    KEYWORD,
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    to_all
--    MODELNM || ' ' || FACTORY || ' ' || SPEC || ' ' || KEYWORD || ' ' || KEYWORD2 || ' ' || CONDINAME AS to_all
from (

select
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    CASE WHEN service_gubun='2' AND store_flag='1' AND ca_dept_code IS NOT NULL THEN RTRIM(category || ' '  || ca_dept_code) ELSE category END AS category,
    ca_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),3,8)='000000' OR SUBSTR(RTRIM(ca_dept_code),3,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,4) END AS ca_dept_mcode,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),5,8)='0000' OR SUBSTR(RTRIM(ca_dept_code),5,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,6) END AS ca_dept_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),7,8)='00' OR SUBSTR(RTRIM(ca_dept_code),7,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,8) END AS ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,    
    shop_name,    
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    model_factory,
    minprice,
    maxprice,
    replace(minprices, ' ', '    ') as minprices,
    C_DATE,
    mallcnt,
    replace(replace(spec,',',' '),'/',' ') spec,
    openexpectflag,
    replace(condiname, ' ', '    ') as condiname,    
    CASE WHEN socialprice=0 THEN keyword ELSE keyword || ' ' || UDF_SOCIAL_GOODSNM(modelno_group,modelno) END AS KEYWORD,    
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    to_all
FROM tmp_es_price_data_01
WHERE mod_no = '0'

)

[2018-06-05T10:40:54,037][INFO ][logstash.inputs.jdbc     ] (3.324304s) select 
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    DECODE(NVL(MODELNO_GROUP,0),0,0,1) AS MODELNO_GROUP_FLAG,
    category,
    '' as cg,
    '' as cat1,
    '' as cat2,
    '' as cat3,
    '' as cat4,
    ca_code,
    ca_dept_mcode,
    ca_dept_code,
    ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,
    shop_name,
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    MODELNM || ' ' || FACTORY as model_factory,
    minprice,
    maxprice,
    minprices,
    C_DATE,
    mallcnt,
    DECODE(NVL(MALLCNT,0),0,0,1) AS MALLCNT_FLAG,
    spec,
    openexpectflag,
    condiname,
    KEYWORD,
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    to_all
--    MODELNM || ' ' || FACTORY || ' ' || SPEC || ' ' || KEYWORD || ' ' || KEYWORD2 || ' ' || CONDINAME AS to_all
from (

select
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    CASE WHEN service_gubun='2' AND store_flag='1' AND ca_dept_code IS NOT NULL THEN RTRIM(category || ' '  || ca_dept_code) ELSE category END AS category,
    ca_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),3,8)='000000' OR SUBSTR(RTRIM(ca_dept_code),3,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,4) END AS ca_dept_mcode,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),5,8)='0000' OR SUBSTR(RTRIM(ca_dept_code),5,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,6) END AS ca_dept_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),7,8)='00' OR SUBSTR(RTRIM(ca_dept_code),7,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,8) END AS ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,    
    shop_name,    
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    model_factory,
    minprice,
    maxprice,
    replace(minprices, ' ', '    ') as minprices,
    C_DATE,
    mallcnt,
    replace(replace(spec,',',' '),'/',' ') spec,
    openexpectflag,
    replace(condiname, ' ', '    ') as condiname,    
    CASE WHEN socialprice=0 THEN keyword ELSE keyword || ' ' || UDF_SOCIAL_GOODSNM(modelno_group,modelno) END AS KEYWORD,    
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    to_all
FROM tmp_es_goods_data_01    
WHERE mod_no = '0'

)

[2018-06-05T10:40:56,456][INFO ][logstash.inputs.jdbc     ] (1.595966s) select 
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    DECODE(NVL(MODELNO_GROUP,0),0,0,1) AS MODELNO_GROUP_FLAG,
    category,
    '' as cg,
    '' as cat1,
    '' as cat2,
    '' as cat3,
    '' as cat4,
    ca_code,
    ca_dept_mcode,
    ca_dept_code,
    ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,
    shop_name,
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    MODELNM || ' ' || FACTORY as model_factory,
    minprice,
    maxprice,
    minprices,
    C_DATE,
    mallcnt,
    DECODE(NVL(MALLCNT,0),0,0,1) AS MALLCNT_FLAG,
    spec,
    openexpectflag,
    condiname,
    KEYWORD,
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    to_all
--    MODELNM || ' ' || FACTORY || ' ' || SPEC || ' ' || KEYWORD || ' ' || KEYWORD2 || ' ' || CONDINAME AS to_all
from (

select
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    CASE WHEN service_gubun='2' AND store_flag='1' AND ca_dept_code IS NOT NULL THEN RTRIM(category || ' '  || ca_dept_code) ELSE category END AS category,
    ca_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),3,8)='000000' OR SUBSTR(RTRIM(ca_dept_code),3,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,4) END AS ca_dept_mcode,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),5,8)='0000' OR SUBSTR(RTRIM(ca_dept_code),5,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,6) END AS ca_dept_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),7,8)='00' OR SUBSTR(RTRIM(ca_dept_code),7,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,8) END AS ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,    
    shop_name,    
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    model_factory,
    minprice,
    maxprice,
    replace(minprices, ' ', '    ') as minprices,
    C_DATE,
    mallcnt,
    replace(replace(spec,',',' '),'/',' ') spec,
    openexpectflag,
    replace(condiname, ' ', '    ') as condiname,    
    CASE WHEN socialprice=0 THEN keyword ELSE keyword || ' ' || UDF_SOCIAL_GOODSNM(modelno_group,modelno) END AS KEYWORD,    
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    to_all
FROM tmp_es_goods_data_01    
WHERE mod_no = '5'

)

[2018-06-05T10:40:56,457][INFO ][logstash.inputs.jdbc     ] (1.598824s) select
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    DECODE(NVL(MODELNO_GROUP,0),0,0,1) AS MODELNO_GROUP_FLAG,
    category,
    '' as cg,
    '' as cat1,
    '' as cat2,
    '' as cat3,
    '' as cat4,
    ca_code,
    ca_dept_mcode,
    ca_dept_code,
    ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,
    shop_name,
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    '' as model_factory,
    minprice,
    maxprice,
    minprices,
    C_DATE,
    mallcnt,
    DECODE(NVL(MALLCNT,0),0,0,1) AS MALLCNT_FLAG,
    spec,
    openexpectflag,
    condiname,
    KEYWORD,
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    to_all
--    MODELNM || ' ' || FACTORY || ' ' || SPEC || ' ' || KEYWORD || ' ' || KEYWORD2 || ' ' || CONDINAME AS to_all
from (

select
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    CASE WHEN service_gubun='2' AND store_flag='1' AND ca_dept_code IS NOT NULL THEN RTRIM(category || ' '  || ca_dept_code) ELSE category END AS category,
    ca_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),3,8)='000000' OR SUBSTR(RTRIM(ca_dept_code),3,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,4) END AS ca_dept_mcode,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),5,8)='0000' OR SUBSTR(RTRIM(ca_dept_code),5,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,6) END AS ca_dept_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),7,8)='00' OR SUBSTR(RTRIM(ca_dept_code),7,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,8) END AS ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,    
    shop_name,    
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    model_factory,
    minprice,
    maxprice,
    replace(minprices, ' ', '    ') as minprices,
    C_DATE,
    mallcnt,
    replace(replace(spec,',',' '),'/',' ') spec,
    openexpectflag,
    replace(condiname, ' ', '    ') as condiname,    
    CASE WHEN socialprice=0 THEN keyword ELSE keyword || ' ' || UDF_SOCIAL_GOODSNM(modelno_group,modelno) END AS KEYWORD,    
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    to_all
FROM tmp_es_price_data_01
WHERE mod_no = '5'

)

[2018-06-05T11:16:41,447][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"fb_apache", :directory=>"/usr/share/logstash/modules/fb_apache/configuration"}
[2018-06-05T11:16:41,475][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"netflow", :directory=>"/usr/share/logstash/modules/netflow/configuration"}
[2018-06-05T11:16:42,640][WARN ][logstash.config.source.multilocal] Ignoring the 'pipelines.yml' file because modules or command line options are specified
[2018-06-05T11:16:42,959][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"fb_apache", :directory=>"/usr/share/logstash/modules/fb_apache/configuration"}
[2018-06-05T11:16:42,966][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"netflow", :directory=>"/usr/share/logstash/modules/netflow/configuration"}
[2018-06-05T11:16:43,107][INFO ][logstash.runner          ] Starting Logstash {"logstash.version"=>"6.2.3"}
[2018-06-05T11:16:43,332][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"fb_apache", :directory=>"/usr/share/logstash/modules/fb_apache/configuration"}
[2018-06-05T11:16:43,377][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"netflow", :directory=>"/usr/share/logstash/modules/netflow/configuration"}
[2018-06-05T11:16:43,750][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=>9600}
[2018-06-05T11:16:43,951][WARN ][logstash.config.source.multilocal] Ignoring the 'pipelines.yml' file because modules or command line options are specified
[2018-06-05T11:16:44,562][WARN ][logstash.config.source.multilocal] Ignoring the 'pipelines.yml' file because modules or command line options are specified
[2018-06-05T11:16:44,583][INFO ][logstash.runner          ] Starting Logstash {"logstash.version"=>"6.2.3"}
[2018-06-05T11:16:44,912][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"fb_apache", :directory=>"/usr/share/logstash/modules/fb_apache/configuration"}
[2018-06-05T11:16:44,951][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"netflow", :directory=>"/usr/share/logstash/modules/netflow/configuration"}
[2018-06-05T11:16:45,074][INFO ][logstash.runner          ] Starting Logstash {"logstash.version"=>"6.2.3"}
[2018-06-05T11:16:45,369][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=>9601}
[2018-06-05T11:16:45,782][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=>9602}
[2018-06-05T11:16:45,923][DEBUG][org.logstash.secret.store.SecretStoreFactory] Attempting to exists or secret store with implementation: org.logstash.secret.store.backend.JavaKeyStore
[2018-06-05T11:16:46,154][DEBUG][org.logstash.secret.store.SecretStoreFactory] Attempting to exists or secret store with implementation: org.logstash.secret.store.backend.JavaKeyStore
[2018-06-05T11:16:46,156][WARN ][logstash.config.source.multilocal] Ignoring the 'pipelines.yml' file because modules or command line options are specified
[2018-06-05T11:16:46,346][INFO ][logstash.filters.ruby.script] Test run complete {:script_path=>"rubyfilter.rb", :results=>{:passed=>0, :failed=>0, :errored=>0}}
[2018-06-05T11:16:46,509][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"fb_apache", :directory=>"/usr/share/logstash/modules/fb_apache/configuration"}
[2018-06-05T11:16:46,538][DEBUG][org.logstash.secret.store.SecretStoreFactory] Attempting to exists or secret store with implementation: org.logstash.secret.store.backend.JavaKeyStore
[2018-06-05T11:16:46,605][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"netflow", :directory=>"/usr/share/logstash/modules/netflow/configuration"}
[2018-06-05T11:16:46,591][WARN ][logstash.outputs.elasticsearch] You are using a deprecated config setting "document_type" set in elasticsearch. Deprecated settings will continue to work, but are scheduled for removal from logstash in the future. Document types are being deprecated in Elasticsearch 6.0, and removed entirely in 7.0. You should avoid this feature If you have any questions about this, please visit the #logstash channel on freenode irc. {:name=>"document_type", :plugin=><LogStash::Outputs::ElasticSearch hosts=>[//100.100.100.111:9200, //100.100.100.112:9200, //100.100.100.113:9200], index=>"qa-enuri-main-as-is-2018.06.05.02.15", document_type=>"_doc", document_id=>"%{id}", action=>"index", id=>"6ecd11524c84e5de286546b0de40f57503392aeab1548c7913e69855f4645bbc", enable_metric=>true, codec=><LogStash::Codecs::Plain id=>"plain_39d14e90-86b8-4dc1-9fea-8149cc1cad76", enable_metric=>true, charset=>"UTF-8">, workers=>1, manage_template=>true, template_name=>"logstash", template_overwrite=>false, doc_as_upsert=>false, script_type=>"inline", script_lang=>"painless", script_var_name=>"event", scripted_upsert=>false, retry_initial_interval=>2, retry_max_interval=>64, retry_on_conflict=>1, ssl_certificate_verification=>true, sniffing=>false, sniffing_delay=>5, timeout=>60, pool_max=>1000, pool_max_per_route=>100, resurrect_delay=>5, validate_after_inactivity=>10000, http_compression=>false>}
[2018-06-05T11:16:46,627][INFO ][logstash.pipeline        ] Starting pipeline {:pipeline_id=>"main", "pipeline.workers"=>8, "pipeline.batch.size"=>125, "pipeline.batch.delay"=>50}
[2018-06-05T11:16:46,730][INFO ][logstash.runner          ] Starting Logstash {"logstash.version"=>"6.2.3"}
[2018-06-05T11:16:47,398][INFO ][logstash.outputs.elasticsearch] Elasticsearch pool URLs updated {:changes=>{:removed=>[], :added=>[http://100.100.100.111:9200/, http://100.100.100.112:9200/, http://100.100.100.113:9200/]}}
[2018-06-05T11:16:47,403][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://100.100.100.111:9200/, :path=>"/"}
[2018-06-05T11:16:47,548][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=>9603}
[2018-06-05T11:16:47,697][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://100.100.100.111:9200/"}
[2018-06-05T11:16:47,794][INFO ][logstash.outputs.elasticsearch] ES Output version determined {:es_version=>6}
[2018-06-05T11:16:47,795][WARN ][logstash.outputs.elasticsearch] Detected a 6.x and above cluster: the `type` event field won't be used to determine the document _type {:es_version=>6}
[2018-06-05T11:16:47,795][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://100.100.100.112:9200/, :path=>"/"}
[2018-06-05T11:16:47,813][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://100.100.100.112:9200/"}
[2018-06-05T11:16:47,833][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://100.100.100.113:9200/, :path=>"/"}
[2018-06-05T11:16:47,846][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://100.100.100.113:9200/"}
[2018-06-05T11:16:47,872][INFO ][logstash.outputs.elasticsearch] Using mapping template from {:path=>nil}
[2018-06-05T11:16:47,876][INFO ][logstash.outputs.elasticsearch] Attempting to install template {:manage_template=>{"template"=>"logstash-*", "version"=>60001, "settings"=>{"index.refresh_interval"=>"5s"}, "mappings"=>{"_default_"=>{"dynamic_templates"=>[{"message_field"=>{"path_match"=>"message", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false}}}, {"string_fields"=>{"match"=>"*", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false, "fields"=>{"keyword"=>{"type"=>"keyword", "ignore_above"=>256}}}}}], "properties"=>{"@timestamp"=>{"type"=>"date"}, "@version"=>{"type"=>"keyword"}, "geoip"=>{"dynamic"=>true, "properties"=>{"ip"=>{"type"=>"ip"}, "location"=>{"type"=>"geo_point"}, "latitude"=>{"type"=>"half_float"}, "longitude"=>{"type"=>"half_float"}}}}}}}}
[2018-06-05T11:16:47,892][INFO ][logstash.outputs.elasticsearch] New Elasticsearch output {:class=>"LogStash::Outputs::ElasticSearch", :hosts=>["//100.100.100.111:9200", "//100.100.100.112:9200", "//100.100.100.113:9200"]}
[2018-06-05T11:16:47,978][WARN ][logstash.config.source.multilocal] Ignoring the 'pipelines.yml' file because modules or command line options are specified
[2018-06-05T11:16:48,281][DEBUG][org.logstash.secret.store.SecretStoreFactory] Attempting to exists or secret store with implementation: org.logstash.secret.store.backend.JavaKeyStore
[2018-06-05T11:16:48,493][DEBUG][org.logstash.secret.store.SecretStoreFactory] Attempting to exists or secret store with implementation: org.logstash.secret.store.backend.JavaKeyStore
[2018-06-05T11:16:48,579][INFO ][logstash.filters.ruby.script] Test run complete {:script_path=>"rubyfilter.rb", :results=>{:passed=>0, :failed=>0, :errored=>0}}
[2018-06-05T11:16:48,771][INFO ][logstash.runner          ] Starting Logstash {"logstash.version"=>"6.2.3"}
[2018-06-05T11:16:49,101][DEBUG][org.logstash.secret.store.SecretStoreFactory] Attempting to exists or secret store with implementation: org.logstash.secret.store.backend.JavaKeyStore
[2018-06-05T11:16:49,158][WARN ][logstash.outputs.elasticsearch] You are using a deprecated config setting "document_type" set in elasticsearch. Deprecated settings will continue to work, but are scheduled for removal from logstash in the future. Document types are being deprecated in Elasticsearch 6.0, and removed entirely in 7.0. You should avoid this feature If you have any questions about this, please visit the #logstash channel on freenode irc. {:name=>"document_type", :plugin=><LogStash::Outputs::ElasticSearch hosts=>[//100.100.100.111:9200, //100.100.100.112:9200, //100.100.100.113:9200], index=>"qa-enuri-main-as-is-2018.06.05.02.15", document_type=>"_doc", document_id=>"%{id}", action=>"index", id=>"6ecd11524c84e5de286546b0de40f57503392aeab1548c7913e69855f4645bbc", enable_metric=>true, codec=><LogStash::Codecs::Plain id=>"plain_ccf9cdf2-6f25-46a0-817f-8ca9ca15235e", enable_metric=>true, charset=>"UTF-8">, workers=>1, manage_template=>true, template_name=>"logstash", template_overwrite=>false, doc_as_upsert=>false, script_type=>"inline", script_lang=>"painless", script_var_name=>"event", scripted_upsert=>false, retry_initial_interval=>2, retry_max_interval=>64, retry_on_conflict=>1, ssl_certificate_verification=>true, sniffing=>false, sniffing_delay=>5, timeout=>60, pool_max=>1000, pool_max_per_route=>100, resurrect_delay=>5, validate_after_inactivity=>10000, http_compression=>false>}
[2018-06-05T11:16:49,193][DEBUG][org.logstash.secret.store.SecretStoreFactory] Attempting to exists or secret store with implementation: org.logstash.secret.store.backend.JavaKeyStore
[2018-06-05T11:16:49,226][INFO ][logstash.pipeline        ] Starting pipeline {:pipeline_id=>"main", "pipeline.workers"=>8, "pipeline.batch.size"=>125, "pipeline.batch.delay"=>50}
[2018-06-05T11:16:49,519][INFO ][logstash.pipeline        ] Pipeline started succesfully {:pipeline_id=>"main", :thread=>"#<Thread:0x6fc988d9@/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:246 run>"}
[2018-06-05T11:16:49,554][DEBUG][org.logstash.secret.store.SecretStoreFactory] Attempting to exists or secret store with implementation: org.logstash.secret.store.backend.JavaKeyStore
[2018-06-05T11:16:49,593][INFO ][logstash.agent           ] Pipelines running {:count=>1, :pipelines=>["main"]}
[2018-06-05T11:16:49,571][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=>9604}
[2018-06-05T11:16:49,753][INFO ][logstash.filters.ruby.script] Test run complete {:script_path=>"rubyfilter.rb", :results=>{:passed=>0, :failed=>0, :errored=>0}}
[2018-06-05T11:16:49,847][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"fb_apache", :directory=>"/usr/share/logstash/modules/fb_apache/configuration"}
[2018-06-05T11:16:49,936][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"netflow", :directory=>"/usr/share/logstash/modules/netflow/configuration"}
[2018-06-05T11:16:50,051][DEBUG][org.logstash.secret.store.SecretStoreFactory] Attempting to exists or secret store with implementation: org.logstash.secret.store.backend.JavaKeyStore
[2018-06-05T11:16:50,222][DEBUG][org.logstash.secret.store.SecretStoreFactory] Attempting to exists or secret store with implementation: org.logstash.secret.store.backend.JavaKeyStore
[2018-06-05T11:16:50,340][WARN ][logstash.outputs.elasticsearch] You are using a deprecated config setting "document_type" set in elasticsearch. Deprecated settings will continue to work, but are scheduled for removal from logstash in the future. Document types are being deprecated in Elasticsearch 6.0, and removed entirely in 7.0. You should avoid this feature If you have any questions about this, please visit the #logstash channel on freenode irc. {:name=>"document_type", :plugin=><LogStash::Outputs::ElasticSearch hosts=>[//100.100.100.111:9200, //100.100.100.112:9200, //100.100.100.113:9200], index=>"qa-enuri-main-as-is-2018.06.05.02.15", document_type=>"_doc", document_id=>"%{id}", action=>"index", id=>"6ecd11524c84e5de286546b0de40f57503392aeab1548c7913e69855f4645bbc", enable_metric=>true, codec=><LogStash::Codecs::Plain id=>"plain_0d5cb6e3-f738-480e-9882-f07165256846", enable_metric=>true, charset=>"UTF-8">, workers=>1, manage_template=>true, template_name=>"logstash", template_overwrite=>false, doc_as_upsert=>false, script_type=>"inline", script_lang=>"painless", script_var_name=>"event", scripted_upsert=>false, retry_initial_interval=>2, retry_max_interval=>64, retry_on_conflict=>1, ssl_certificate_verification=>true, sniffing=>false, sniffing_delay=>5, timeout=>60, pool_max=>1000, pool_max_per_route=>100, resurrect_delay=>5, validate_after_inactivity=>10000, http_compression=>false>}
[2018-06-05T11:16:50,348][DEBUG][org.logstash.secret.store.SecretStoreFactory] Attempting to exists or secret store with implementation: org.logstash.secret.store.backend.JavaKeyStore
[2018-06-05T11:16:50,354][INFO ][logstash.pipeline        ] Starting pipeline {:pipeline_id=>"main", "pipeline.workers"=>8, "pipeline.batch.size"=>125, "pipeline.batch.delay"=>50}
[2018-06-05T11:16:50,429][INFO ][logstash.outputs.elasticsearch] Elasticsearch pool URLs updated {:changes=>{:removed=>[], :added=>[http://100.100.100.111:9200/, http://100.100.100.112:9200/, http://100.100.100.113:9200/]}}
[2018-06-05T11:16:50,432][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://100.100.100.111:9200/, :path=>"/"}
[2018-06-05T11:16:50,545][INFO ][logstash.filters.ruby.script] Test run complete {:script_path=>"rubyfilter.rb", :results=>{:passed=>0, :failed=>0, :errored=>0}}
[2018-06-05T11:16:50,660][INFO ][logstash.outputs.elasticsearch] Elasticsearch pool URLs updated {:changes=>{:removed=>[], :added=>[http://100.100.100.111:9200/, http://100.100.100.112:9200/, http://100.100.100.113:9200/]}}
[2018-06-05T11:16:50,663][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://100.100.100.111:9200/, :path=>"/"}
[2018-06-05T11:16:50,832][DEBUG][org.logstash.secret.store.SecretStoreFactory] Attempting to exists or secret store with implementation: org.logstash.secret.store.backend.JavaKeyStore
[2018-06-05T11:16:50,929][WARN ][logstash.outputs.elasticsearch] You are using a deprecated config setting "document_type" set in elasticsearch. Deprecated settings will continue to work, but are scheduled for removal from logstash in the future. Document types are being deprecated in Elasticsearch 6.0, and removed entirely in 7.0. You should avoid this feature If you have any questions about this, please visit the #logstash channel on freenode irc. {:name=>"document_type", :plugin=><LogStash::Outputs::ElasticSearch hosts=>[//100.100.100.111:9200, //100.100.100.112:9200, //100.100.100.113:9200], index=>"qa-enuri-main-as-is-2018.06.05.02.15", document_type=>"_doc", document_id=>"%{id}", action=>"index", id=>"6ecd11524c84e5de286546b0de40f57503392aeab1548c7913e69855f4645bbc", enable_metric=>true, codec=><LogStash::Codecs::Plain id=>"plain_a8206b4f-d38b-45b2-bd9d-c0aa8a97d3d5", enable_metric=>true, charset=>"UTF-8">, workers=>1, manage_template=>true, template_name=>"logstash", template_overwrite=>false, doc_as_upsert=>false, script_type=>"inline", script_lang=>"painless", script_var_name=>"event", scripted_upsert=>false, retry_initial_interval=>2, retry_max_interval=>64, retry_on_conflict=>1, ssl_certificate_verification=>true, sniffing=>false, sniffing_delay=>5, timeout=>60, pool_max=>1000, pool_max_per_route=>100, resurrect_delay=>5, validate_after_inactivity=>10000, http_compression=>false>}
[2018-06-05T11:16:50,944][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://100.100.100.111:9200/"}
[2018-06-05T11:16:50,981][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://100.100.100.111:9200/"}
[2018-06-05T11:16:51,023][INFO ][logstash.pipeline        ] Starting pipeline {:pipeline_id=>"main", "pipeline.workers"=>8, "pipeline.batch.size"=>125, "pipeline.batch.delay"=>50}
[2018-06-05T11:16:51,024][WARN ][logstash.config.source.multilocal] Ignoring the 'pipelines.yml' file because modules or command line options are specified
[2018-06-05T11:16:51,121][INFO ][logstash.outputs.elasticsearch] ES Output version determined {:es_version=>6}
[2018-06-05T11:16:51,122][WARN ][logstash.outputs.elasticsearch] Detected a 6.x and above cluster: the `type` event field won't be used to determine the document _type {:es_version=>6}
[2018-06-05T11:16:51,122][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://100.100.100.112:9200/, :path=>"/"}
[2018-06-05T11:16:51,153][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://100.100.100.112:9200/"}
[2018-06-05T11:16:51,173][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://100.100.100.113:9200/, :path=>"/"}
[2018-06-05T11:16:51,178][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://100.100.100.113:9200/"}
[2018-06-05T11:16:51,203][INFO ][logstash.outputs.elasticsearch] ES Output version determined {:es_version=>6}
[2018-06-05T11:16:51,204][WARN ][logstash.outputs.elasticsearch] Detected a 6.x and above cluster: the `type` event field won't be used to determine the document _type {:es_version=>6}
[2018-06-05T11:16:51,204][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://100.100.100.112:9200/, :path=>"/"}
[2018-06-05T11:16:51,218][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://100.100.100.112:9200/"}
[2018-06-05T11:16:51,225][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://100.100.100.113:9200/, :path=>"/"}
[2018-06-05T11:16:51,239][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://100.100.100.113:9200/"}
[2018-06-05T11:16:51,265][INFO ][logstash.outputs.elasticsearch] Using mapping template from {:path=>nil}
[2018-06-05T11:16:51,274][INFO ][logstash.outputs.elasticsearch] Attempting to install template {:manage_template=>{"template"=>"logstash-*", "version"=>60001, "settings"=>{"index.refresh_interval"=>"5s"}, "mappings"=>{"_default_"=>{"dynamic_templates"=>[{"message_field"=>{"path_match"=>"message", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false}}}, {"string_fields"=>{"match"=>"*", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false, "fields"=>{"keyword"=>{"type"=>"keyword", "ignore_above"=>256}}}}}], "properties"=>{"@timestamp"=>{"type"=>"date"}, "@version"=>{"type"=>"keyword"}, "geoip"=>{"dynamic"=>true, "properties"=>{"ip"=>{"type"=>"ip"}, "location"=>{"type"=>"geo_point"}, "latitude"=>{"type"=>"half_float"}, "longitude"=>{"type"=>"half_float"}}}}}}}}
[2018-06-05T11:16:51,295][INFO ][logstash.outputs.elasticsearch] New Elasticsearch output {:class=>"LogStash::Outputs::ElasticSearch", :hosts=>["//100.100.100.111:9200", "//100.100.100.112:9200", "//100.100.100.113:9200"]}
[2018-06-05T11:16:51,341][INFO ][logstash.outputs.elasticsearch] Using mapping template from {:path=>nil}
[2018-06-05T11:16:51,358][INFO ][logstash.outputs.elasticsearch] Attempting to install template {:manage_template=>{"template"=>"logstash-*", "version"=>60001, "settings"=>{"index.refresh_interval"=>"5s"}, "mappings"=>{"_default_"=>{"dynamic_templates"=>[{"message_field"=>{"path_match"=>"message", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false}}}, {"string_fields"=>{"match"=>"*", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false, "fields"=>{"keyword"=>{"type"=>"keyword", "ignore_above"=>256}}}}}], "properties"=>{"@timestamp"=>{"type"=>"date"}, "@version"=>{"type"=>"keyword"}, "geoip"=>{"dynamic"=>true, "properties"=>{"ip"=>{"type"=>"ip"}, "location"=>{"type"=>"geo_point"}, "latitude"=>{"type"=>"half_float"}, "longitude"=>{"type"=>"half_float"}}}}}}}}
[2018-06-05T11:16:51,398][INFO ][logstash.outputs.elasticsearch] New Elasticsearch output {:class=>"LogStash::Outputs::ElasticSearch", :hosts=>["//100.100.100.111:9200", "//100.100.100.112:9200", "//100.100.100.113:9200"]}
[2018-06-05T11:16:51,482][INFO ][logstash.runner          ] Starting Logstash {"logstash.version"=>"6.2.3"}
[2018-06-05T11:16:51,874][INFO ][logstash.pipeline        ] Pipeline started succesfully {:pipeline_id=>"main", :thread=>"#<Thread:0x7615deeb@/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:246 run>"}
[2018-06-05T11:16:51,913][INFO ][logstash.agent           ] Pipelines running {:count=>1, :pipelines=>["main"]}
[2018-06-05T11:16:51,990][INFO ][logstash.pipeline        ] Pipeline started succesfully {:pipeline_id=>"main", :thread=>"#<Thread:0x595a0db2@/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:246 run>"}
[2018-06-05T11:16:51,998][DEBUG][org.logstash.secret.store.SecretStoreFactory] Attempting to exists or secret store with implementation: org.logstash.secret.store.backend.JavaKeyStore
[2018-06-05T11:16:52,093][INFO ][logstash.agent           ] Pipelines running {:count=>1, :pipelines=>["main"]}
[2018-06-05T11:16:52,087][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=>9605}
[2018-06-05T11:16:52,060][INFO ][logstash.outputs.elasticsearch] Elasticsearch pool URLs updated {:changes=>{:removed=>[], :added=>[http://100.100.100.111:9200/, http://100.100.100.112:9200/, http://100.100.100.113:9200/]}}
[2018-06-05T11:16:52,128][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://100.100.100.111:9200/, :path=>"/"}
[2018-06-05T11:16:52,403][DEBUG][org.logstash.secret.store.SecretStoreFactory] Attempting to exists or secret store with implementation: org.logstash.secret.store.backend.JavaKeyStore
[2018-06-05T11:16:52,637][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://100.100.100.111:9200/"}
[2018-06-05T11:16:52,674][INFO ][logstash.filters.ruby.script] Test run complete {:script_path=>"rubyfilter.rb", :results=>{:passed=>0, :failed=>0, :errored=>0}}
[2018-06-05T11:16:52,807][INFO ][logstash.outputs.elasticsearch] ES Output version determined {:es_version=>6}
[2018-06-05T11:16:52,807][WARN ][logstash.outputs.elasticsearch] Detected a 6.x and above cluster: the `type` event field won't be used to determine the document _type {:es_version=>6}
[2018-06-05T11:16:52,808][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://100.100.100.112:9200/, :path=>"/"}
[2018-06-05T11:16:52,846][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://100.100.100.112:9200/"}
[2018-06-05T11:16:52,867][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://100.100.100.113:9200/, :path=>"/"}
[2018-06-05T11:16:52,880][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://100.100.100.113:9200/"}
[2018-06-05T11:16:52,945][INFO ][logstash.outputs.elasticsearch] Using mapping template from {:path=>nil}
[2018-06-05T11:16:52,983][DEBUG][org.logstash.secret.store.SecretStoreFactory] Attempting to exists or secret store with implementation: org.logstash.secret.store.backend.JavaKeyStore
[2018-06-05T11:16:52,986][INFO ][logstash.outputs.elasticsearch] Attempting to install template {:manage_template=>{"template"=>"logstash-*", "version"=>60001, "settings"=>{"index.refresh_interval"=>"5s"}, "mappings"=>{"_default_"=>{"dynamic_templates"=>[{"message_field"=>{"path_match"=>"message", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false}}}, {"string_fields"=>{"match"=>"*", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false, "fields"=>{"keyword"=>{"type"=>"keyword", "ignore_above"=>256}}}}}], "properties"=>{"@timestamp"=>{"type"=>"date"}, "@version"=>{"type"=>"keyword"}, "geoip"=>{"dynamic"=>true, "properties"=>{"ip"=>{"type"=>"ip"}, "location"=>{"type"=>"geo_point"}, "latitude"=>{"type"=>"half_float"}, "longitude"=>{"type"=>"half_float"}}}}}}}}
[2018-06-05T11:16:53,047][INFO ][logstash.outputs.elasticsearch] New Elasticsearch output {:class=>"LogStash::Outputs::ElasticSearch", :hosts=>["//100.100.100.111:9200", "//100.100.100.112:9200", "//100.100.100.113:9200"]}
[2018-06-05T11:16:53,070][WARN ][logstash.outputs.elasticsearch] You are using a deprecated config setting "document_type" set in elasticsearch. Deprecated settings will continue to work, but are scheduled for removal from logstash in the future. Document types are being deprecated in Elasticsearch 6.0, and removed entirely in 7.0. You should avoid this feature If you have any questions about this, please visit the #logstash channel on freenode irc. {:name=>"document_type", :plugin=><LogStash::Outputs::ElasticSearch hosts=>[//100.100.100.111:9200, //100.100.100.112:9200, //100.100.100.113:9200], index=>"qa-enuri-main-as-is-2018.06.05.02.15", document_type=>"_doc", document_id=>"%{id}", action=>"index", id=>"6ecd11524c84e5de286546b0de40f57503392aeab1548c7913e69855f4645bbc", enable_metric=>true, codec=><LogStash::Codecs::Plain id=>"plain_92ec5196-5945-4912-b391-1bd8e64b95e7", enable_metric=>true, charset=>"UTF-8">, workers=>1, manage_template=>true, template_name=>"logstash", template_overwrite=>false, doc_as_upsert=>false, script_type=>"inline", script_lang=>"painless", script_var_name=>"event", scripted_upsert=>false, retry_initial_interval=>2, retry_max_interval=>64, retry_on_conflict=>1, ssl_certificate_verification=>true, sniffing=>false, sniffing_delay=>5, timeout=>60, pool_max=>1000, pool_max_per_route=>100, resurrect_delay=>5, validate_after_inactivity=>10000, http_compression=>false>}
[2018-06-05T11:16:53,120][INFO ][logstash.pipeline        ] Starting pipeline {:pipeline_id=>"main", "pipeline.workers"=>8, "pipeline.batch.size"=>125, "pipeline.batch.delay"=>50}
[2018-06-05T11:16:53,745][ERROR][logstash.pipeline        ] A plugin had an unrecoverable error. Will restart this plugin.
  Pipeline_id:main
  Plugin: <LogStash::Inputs::Jdbc jdbc_driver_library=>"/etc/logstash/ojdbc6.jar", jdbc_driver_class=>"Java::oracle.jdbc.driver.OracleDriver", jdbc_connection_string=>"jdbc:oracle:thin:@100.100.100.194:1521:tenuri", jdbc_user=>"es_app", jdbc_password=><password>, jdbc_fetch_size=>1024, parameters=>{"favorite_mod_no"=>"5", "sql_last_value"=>2018-06-01 20:03:43 +0900}, statement_filepath=>"as-is_goods.sql", id=>"f9fe485cfb266bbda9e95238cef1d0c47d4bacb2fc19cd30f60f4115954541a2", enable_metric=>true, codec=><LogStash::Codecs::Plain id=>"plain_e80bbe8d-2863-499a-90bb-fc112b66bc46", enable_metric=>true, charset=>"UTF-8">, jdbc_paging_enabled=>false, jdbc_page_size=>100000, jdbc_validate_connection=>false, jdbc_validation_timeout=>3600, jdbc_pool_timeout=>5, sql_log_level=>"info", connection_retry_attempts=>1, connection_retry_attempts_wait_time=>0.5, last_run_metadata_path=>"/home/elastic/.logstash_jdbc_last_run", use_column_value=>false, tracking_column_type=>"numeric", clean_run=>false, record_last_run=>true, lowercase_column_names=>true>
  Error: uninitialized constant Sequel::JDBC::Oracle::DatabaseMethods
Did you mean?  Sequel::JDBC::Database
  Exception: NameError
  Stack: org/jruby/RubyModule.java:3343:in `const_missing'
/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/adapters/jdbc/oracle.rb:11:in `block in JDBC'
/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/adapters/jdbc.rb:343:in `adapter_initialize'
/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/misc.rb:144:in `initialize'
/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/database/connecting.rb:57:in `connect'
/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/sequel-5.5.0/lib/sequel/core.rb:116:in `connect'
/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:114:in `block in jdbc_connect'
org/jruby/RubyKernel.java:1292:in `loop'
/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:111:in `jdbc_connect'
/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:163:in `open_jdbc_connection'
/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/plugin_mixins/jdbc.rb:219:in `execute_statement'
/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/inputs/jdbc.rb:264:in `execute_query'
/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/logstash-input-jdbc-4.3.5/lib/logstash/inputs/jdbc.rb:250:in `run'
/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:516:in `inputworker'
/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:509:in `block in start_input'
[2018-06-05T11:16:54,270][INFO ][logstash.pipeline        ] Pipeline started succesfully {:pipeline_id=>"main", :thread=>"#<Thread:0x372b83cc@/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:246 run>"}
[2018-06-05T11:16:54,321][INFO ][logstash.agent           ] Pipelines running {:count=>1, :pipelines=>["main"]}
[2018-06-05T11:16:54,823][INFO ][logstash.inputs.jdbc     ] (2.604855s) select 
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    DECODE(NVL(MODELNO_GROUP,0),0,0,1) AS MODELNO_GROUP_FLAG,
    category,
    '' as cg,
    '' as cat1,
    '' as cat2,
    '' as cat3,
    '' as cat4,
    ca_code,
    ca_dept_mcode,
    ca_dept_code,
    ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,
    shop_name,
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    MODELNM || ' ' || FACTORY as model_factory,
    minprice,
    maxprice,
    minprices,
    C_DATE,
    mallcnt,
    DECODE(NVL(MALLCNT,0),0,0,1) AS MALLCNT_FLAG,
    spec,
    openexpectflag,
    condiname,
    KEYWORD,
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    to_all
--    MODELNM || ' ' || FACTORY || ' ' || SPEC || ' ' || KEYWORD || ' ' || KEYWORD2 || ' ' || CONDINAME AS to_all
from (

select
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    CASE WHEN service_gubun='2' AND store_flag='1' AND ca_dept_code IS NOT NULL THEN RTRIM(category || ' '  || ca_dept_code) ELSE category END AS category,
    ca_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),3,8)='000000' OR SUBSTR(RTRIM(ca_dept_code),3,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,4) END AS ca_dept_mcode,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),5,8)='0000' OR SUBSTR(RTRIM(ca_dept_code),5,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,6) END AS ca_dept_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),7,8)='00' OR SUBSTR(RTRIM(ca_dept_code),7,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,8) END AS ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,    
    shop_name,    
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    model_factory,
    minprice,
    maxprice,
    replace(minprices, ' ', '    ') as minprices,
    C_DATE,
    mallcnt,
    replace(replace(spec,',',' '),'/',' ') spec,
    openexpectflag,
    replace(condiname, ' ', '    ') as condiname,    
    CASE WHEN socialprice=0 THEN keyword ELSE keyword || ' ' || UDF_SOCIAL_GOODSNM(modelno_group,modelno) END AS KEYWORD,    
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    to_all
FROM tmp_es_goods_data_01    
WHERE mod_no = '1'

)

[2018-06-05T11:16:54,832][INFO ][logstash.inputs.jdbc     ] (2.651163s) select
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    DECODE(NVL(MODELNO_GROUP,0),0,0,1) AS MODELNO_GROUP_FLAG,
    category,
    '' as cg,
    '' as cat1,
    '' as cat2,
    '' as cat3,
    '' as cat4,
    ca_code,
    ca_dept_mcode,
    ca_dept_code,
    ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,
    shop_name,
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    '' as model_factory,
    minprice,
    maxprice,
    minprices,
    C_DATE,
    mallcnt,
    DECODE(NVL(MALLCNT,0),0,0,1) AS MALLCNT_FLAG,
    spec,
    openexpectflag,
    condiname,
    KEYWORD,
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    to_all
--    MODELNM || ' ' || FACTORY || ' ' || SPEC || ' ' || KEYWORD || ' ' || KEYWORD2 || ' ' || CONDINAME AS to_all
from (

select
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    CASE WHEN service_gubun='2' AND store_flag='1' AND ca_dept_code IS NOT NULL THEN RTRIM(category || ' '  || ca_dept_code) ELSE category END AS category,
    ca_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),3,8)='000000' OR SUBSTR(RTRIM(ca_dept_code),3,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,4) END AS ca_dept_mcode,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),5,8)='0000' OR SUBSTR(RTRIM(ca_dept_code),5,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,6) END AS ca_dept_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),7,8)='00' OR SUBSTR(RTRIM(ca_dept_code),7,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,8) END AS ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,    
    shop_name,    
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    model_factory,
    minprice,
    maxprice,
    replace(minprices, ' ', '    ') as minprices,
    C_DATE,
    mallcnt,
    replace(replace(spec,',',' '),'/',' ') spec,
    openexpectflag,
    replace(condiname, ' ', '    ') as condiname,    
    CASE WHEN socialprice=0 THEN keyword ELSE keyword || ' ' || UDF_SOCIAL_GOODSNM(modelno_group,modelno) END AS KEYWORD,    
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    to_all
FROM tmp_es_price_data_01
WHERE mod_no = '1'

)

[2018-06-05T11:16:54,959][INFO ][logstash.outputs.elasticsearch] Elasticsearch pool URLs updated {:changes=>{:removed=>[], :added=>[http://100.100.100.111:9200/, http://100.100.100.112:9200/, http://100.100.100.113:9200/]}}
[2018-06-05T11:16:54,965][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://100.100.100.111:9200/, :path=>"/"}
[2018-06-05T11:16:55,318][DEBUG][org.logstash.secret.store.SecretStoreFactory] Attempting to exists or secret store with implementation: org.logstash.secret.store.backend.JavaKeyStore
[2018-06-05T11:16:55,587][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://100.100.100.111:9200/"}
[2018-06-05T11:16:55,748][DEBUG][org.logstash.secret.store.SecretStoreFactory] Attempting to exists or secret store with implementation: org.logstash.secret.store.backend.JavaKeyStore
[2018-06-05T11:16:55,842][INFO ][logstash.outputs.elasticsearch] ES Output version determined {:es_version=>6}
[2018-06-05T11:16:55,842][WARN ][logstash.outputs.elasticsearch] Detected a 6.x and above cluster: the `type` event field won't be used to determine the document _type {:es_version=>6}
[2018-06-05T11:16:55,842][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://100.100.100.112:9200/, :path=>"/"}
[2018-06-05T11:16:55,874][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://100.100.100.112:9200/"}
[2018-06-05T11:16:55,911][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://100.100.100.113:9200/, :path=>"/"}
[2018-06-05T11:16:55,915][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://100.100.100.113:9200/"}
[2018-06-05T11:16:55,969][INFO ][logstash.outputs.elasticsearch] Using mapping template from {:path=>nil}
[2018-06-05T11:16:55,983][INFO ][logstash.outputs.elasticsearch] Attempting to install template {:manage_template=>{"template"=>"logstash-*", "version"=>60001, "settings"=>{"index.refresh_interval"=>"5s"}, "mappings"=>{"_default_"=>{"dynamic_templates"=>[{"message_field"=>{"path_match"=>"message", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false}}}, {"string_fields"=>{"match"=>"*", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false, "fields"=>{"keyword"=>{"type"=>"keyword", "ignore_above"=>256}}}}}], "properties"=>{"@timestamp"=>{"type"=>"date"}, "@version"=>{"type"=>"keyword"}, "geoip"=>{"dynamic"=>true, "properties"=>{"ip"=>{"type"=>"ip"}, "location"=>{"type"=>"geo_point"}, "latitude"=>{"type"=>"half_float"}, "longitude"=>{"type"=>"half_float"}}}}}}}}
[2018-06-05T11:16:56,020][INFO ][logstash.outputs.elasticsearch] New Elasticsearch output {:class=>"LogStash::Outputs::ElasticSearch", :hosts=>["//100.100.100.111:9200", "//100.100.100.112:9200", "//100.100.100.113:9200"]}
[2018-06-05T11:16:56,275][INFO ][logstash.filters.ruby.script] Test run complete {:script_path=>"rubyfilter.rb", :results=>{:passed=>0, :failed=>0, :errored=>0}}
[2018-06-05T11:16:56,710][DEBUG][org.logstash.secret.store.SecretStoreFactory] Attempting to exists or secret store with implementation: org.logstash.secret.store.backend.JavaKeyStore
[2018-06-05T11:16:56,758][INFO ][logstash.inputs.jdbc     ] (2.628466s) select
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    DECODE(NVL(MODELNO_GROUP,0),0,0,1) AS MODELNO_GROUP_FLAG,
    category,
    '' as cg,
    '' as cat1,
    '' as cat2,
    '' as cat3,
    '' as cat4,
    ca_code,
    ca_dept_mcode,
    ca_dept_code,
    ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,
    shop_name,
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    '' as model_factory,
    minprice,
    maxprice,
    minprices,
    C_DATE,
    mallcnt,
    DECODE(NVL(MALLCNT,0),0,0,1) AS MALLCNT_FLAG,
    spec,
    openexpectflag,
    condiname,
    KEYWORD,
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    to_all
--    MODELNM || ' ' || FACTORY || ' ' || SPEC || ' ' || KEYWORD || ' ' || KEYWORD2 || ' ' || CONDINAME AS to_all
from (

select
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    CASE WHEN service_gubun='2' AND store_flag='1' AND ca_dept_code IS NOT NULL THEN RTRIM(category || ' '  || ca_dept_code) ELSE category END AS category,
    ca_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),3,8)='000000' OR SUBSTR(RTRIM(ca_dept_code),3,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,4) END AS ca_dept_mcode,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),5,8)='0000' OR SUBSTR(RTRIM(ca_dept_code),5,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,6) END AS ca_dept_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),7,8)='00' OR SUBSTR(RTRIM(ca_dept_code),7,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,8) END AS ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,    
    shop_name,    
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    model_factory,
    minprice,
    maxprice,
    replace(minprices, ' ', '    ') as minprices,
    C_DATE,
    mallcnt,
    replace(replace(spec,',',' '),'/',' ') spec,
    openexpectflag,
    replace(condiname, ' ', '    ') as condiname,    
    CASE WHEN socialprice=0 THEN keyword ELSE keyword || ' ' || UDF_SOCIAL_GOODSNM(modelno_group,modelno) END AS KEYWORD,    
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    to_all
FROM tmp_es_price_data_01
WHERE mod_no = '0'

)

[2018-06-05T11:16:56,779][INFO ][logstash.inputs.jdbc     ] (2.670308s) select 
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    DECODE(NVL(MODELNO_GROUP,0),0,0,1) AS MODELNO_GROUP_FLAG,
    category,
    '' as cg,
    '' as cat1,
    '' as cat2,
    '' as cat3,
    '' as cat4,
    ca_code,
    ca_dept_mcode,
    ca_dept_code,
    ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,
    shop_name,
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    MODELNM || ' ' || FACTORY as model_factory,
    minprice,
    maxprice,
    minprices,
    C_DATE,
    mallcnt,
    DECODE(NVL(MALLCNT,0),0,0,1) AS MALLCNT_FLAG,
    spec,
    openexpectflag,
    condiname,
    KEYWORD,
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    to_all
--    MODELNM || ' ' || FACTORY || ' ' || SPEC || ' ' || KEYWORD || ' ' || KEYWORD2 || ' ' || CONDINAME AS to_all
from (

select
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    CASE WHEN service_gubun='2' AND store_flag='1' AND ca_dept_code IS NOT NULL THEN RTRIM(category || ' '  || ca_dept_code) ELSE category END AS category,
    ca_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),3,8)='000000' OR SUBSTR(RTRIM(ca_dept_code),3,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,4) END AS ca_dept_mcode,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),5,8)='0000' OR SUBSTR(RTRIM(ca_dept_code),5,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,6) END AS ca_dept_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),7,8)='00' OR SUBSTR(RTRIM(ca_dept_code),7,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,8) END AS ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,    
    shop_name,    
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    model_factory,
    minprice,
    maxprice,
    replace(minprices, ' ', '    ') as minprices,
    C_DATE,
    mallcnt,
    replace(replace(spec,',',' '),'/',' ') spec,
    openexpectflag,
    replace(condiname, ' ', '    ') as condiname,    
    CASE WHEN socialprice=0 THEN keyword ELSE keyword || ' ' || UDF_SOCIAL_GOODSNM(modelno_group,modelno) END AS KEYWORD,    
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    to_all
FROM tmp_es_goods_data_01    
WHERE mod_no = '0'

)

[2018-06-05T11:16:56,853][WARN ][logstash.outputs.elasticsearch] You are using a deprecated config setting "document_type" set in elasticsearch. Deprecated settings will continue to work, but are scheduled for removal from logstash in the future. Document types are being deprecated in Elasticsearch 6.0, and removed entirely in 7.0. You should avoid this feature If you have any questions about this, please visit the #logstash channel on freenode irc. {:name=>"document_type", :plugin=><LogStash::Outputs::ElasticSearch hosts=>[//100.100.100.111:9200, //100.100.100.112:9200, //100.100.100.113:9200], index=>"qa-enuri-main-as-is-2018.06.05.02.15", document_type=>"_doc", document_id=>"%{id}", action=>"index", id=>"6ecd11524c84e5de286546b0de40f57503392aeab1548c7913e69855f4645bbc", enable_metric=>true, codec=><LogStash::Codecs::Plain id=>"plain_6ebbf7b5-3eda-4ee3-ba36-af8b6b738ef1", enable_metric=>true, charset=>"UTF-8">, workers=>1, manage_template=>true, template_name=>"logstash", template_overwrite=>false, doc_as_upsert=>false, script_type=>"inline", script_lang=>"painless", script_var_name=>"event", scripted_upsert=>false, retry_initial_interval=>2, retry_max_interval=>64, retry_on_conflict=>1, ssl_certificate_verification=>true, sniffing=>false, sniffing_delay=>5, timeout=>60, pool_max=>1000, pool_max_per_route=>100, resurrect_delay=>5, validate_after_inactivity=>10000, http_compression=>false>}
[2018-06-05T11:16:56,898][INFO ][logstash.pipeline        ] Starting pipeline {:pipeline_id=>"main", "pipeline.workers"=>8, "pipeline.batch.size"=>125, "pipeline.batch.delay"=>50}
[2018-06-05T11:16:57,291][INFO ][logstash.pipeline        ] Pipeline started succesfully {:pipeline_id=>"main", :thread=>"#<Thread:0x5317a1ef@/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:246 run>"}
[2018-06-05T11:16:57,390][INFO ][logstash.agent           ] Pipelines running {:count=>1, :pipelines=>["main"]}
[2018-06-05T11:16:57,517][INFO ][logstash.inputs.jdbc     ] (2.875842s) select
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    DECODE(NVL(MODELNO_GROUP,0),0,0,1) AS MODELNO_GROUP_FLAG,
    category,
    '' as cg,
    '' as cat1,
    '' as cat2,
    '' as cat3,
    '' as cat4,
    ca_code,
    ca_dept_mcode,
    ca_dept_code,
    ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,
    shop_name,
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    '' as model_factory,
    minprice,
    maxprice,
    minprices,
    C_DATE,
    mallcnt,
    DECODE(NVL(MALLCNT,0),0,0,1) AS MALLCNT_FLAG,
    spec,
    openexpectflag,
    condiname,
    KEYWORD,
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    to_all
--    MODELNM || ' ' || FACTORY || ' ' || SPEC || ' ' || KEYWORD || ' ' || KEYWORD2 || ' ' || CONDINAME AS to_all
from (

select
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    CASE WHEN service_gubun='2' AND store_flag='1' AND ca_dept_code IS NOT NULL THEN RTRIM(category || ' '  || ca_dept_code) ELSE category END AS category,
    ca_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),3,8)='000000' OR SUBSTR(RTRIM(ca_dept_code),3,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,4) END AS ca_dept_mcode,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),5,8)='0000' OR SUBSTR(RTRIM(ca_dept_code),5,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,6) END AS ca_dept_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),7,8)='00' OR SUBSTR(RTRIM(ca_dept_code),7,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,8) END AS ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,    
    shop_name,    
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    model_factory,
    minprice,
    maxprice,
    replace(minprices, ' ', '    ') as minprices,
    C_DATE,
    mallcnt,
    replace(replace(spec,',',' '),'/',' ') spec,
    openexpectflag,
    replace(condiname, ' ', '    ') as condiname,    
    CASE WHEN socialprice=0 THEN keyword ELSE keyword || ' ' || UDF_SOCIAL_GOODSNM(modelno_group,modelno) END AS KEYWORD,    
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    to_all
FROM tmp_es_price_data_01
WHERE mod_no = '5'

)

[2018-06-05T11:16:57,568][INFO ][logstash.inputs.jdbc     ] (1.855313s) select 
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    DECODE(NVL(MODELNO_GROUP,0),0,0,1) AS MODELNO_GROUP_FLAG,
    category,
    '' as cg,
    '' as cat1,
    '' as cat2,
    '' as cat3,
    '' as cat4,
    ca_code,
    ca_dept_mcode,
    ca_dept_code,
    ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,
    shop_name,
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    MODELNM || ' ' || FACTORY as model_factory,
    minprice,
    maxprice,
    minprices,
    C_DATE,
    mallcnt,
    DECODE(NVL(MALLCNT,0),0,0,1) AS MALLCNT_FLAG,
    spec,
    openexpectflag,
    condiname,
    KEYWORD,
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    to_all
--    MODELNM || ' ' || FACTORY || ' ' || SPEC || ' ' || KEYWORD || ' ' || KEYWORD2 || ' ' || CONDINAME AS to_all
from (

select
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    CASE WHEN service_gubun='2' AND store_flag='1' AND ca_dept_code IS NOT NULL THEN RTRIM(category || ' '  || ca_dept_code) ELSE category END AS category,
    ca_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),3,8)='000000' OR SUBSTR(RTRIM(ca_dept_code),3,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,4) END AS ca_dept_mcode,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),5,8)='0000' OR SUBSTR(RTRIM(ca_dept_code),5,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,6) END AS ca_dept_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),7,8)='00' OR SUBSTR(RTRIM(ca_dept_code),7,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,8) END AS ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,    
    shop_name,    
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    model_factory,
    minprice,
    maxprice,
    replace(minprices, ' ', '    ') as minprices,
    C_DATE,
    mallcnt,
    replace(replace(spec,',',' '),'/',' ') spec,
    openexpectflag,
    replace(condiname, ' ', '    ') as condiname,    
    CASE WHEN socialprice=0 THEN keyword ELSE keyword || ' ' || UDF_SOCIAL_GOODSNM(modelno_group,modelno) END AS KEYWORD,    
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    to_all
FROM tmp_es_goods_data_01    
WHERE mod_no = '5'

)

[2018-06-05T11:16:58,051][INFO ][logstash.outputs.elasticsearch] Elasticsearch pool URLs updated {:changes=>{:removed=>[], :added=>[http://100.100.100.111:9200/, http://100.100.100.112:9200/, http://100.100.100.113:9200/]}}
[2018-06-05T11:16:58,054][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://100.100.100.111:9200/, :path=>"/"}
[2018-06-05T11:16:58,641][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://100.100.100.111:9200/"}
[2018-06-05T11:16:58,906][INFO ][logstash.outputs.elasticsearch] ES Output version determined {:es_version=>6}
[2018-06-05T11:16:58,906][WARN ][logstash.outputs.elasticsearch] Detected a 6.x and above cluster: the `type` event field won't be used to determine the document _type {:es_version=>6}
[2018-06-05T11:16:58,906][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://100.100.100.112:9200/, :path=>"/"}
[2018-06-05T11:16:58,930][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://100.100.100.112:9200/"}
[2018-06-05T11:16:58,951][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://100.100.100.113:9200/, :path=>"/"}
[2018-06-05T11:16:58,969][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://100.100.100.113:9200/"}
[2018-06-05T11:16:59,034][INFO ][logstash.outputs.elasticsearch] Using mapping template from {:path=>nil}
[2018-06-05T11:16:59,050][INFO ][logstash.outputs.elasticsearch] Attempting to install template {:manage_template=>{"template"=>"logstash-*", "version"=>60001, "settings"=>{"index.refresh_interval"=>"5s"}, "mappings"=>{"_default_"=>{"dynamic_templates"=>[{"message_field"=>{"path_match"=>"message", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false}}}, {"string_fields"=>{"match"=>"*", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false, "fields"=>{"keyword"=>{"type"=>"keyword", "ignore_above"=>256}}}}}], "properties"=>{"@timestamp"=>{"type"=>"date"}, "@version"=>{"type"=>"keyword"}, "geoip"=>{"dynamic"=>true, "properties"=>{"ip"=>{"type"=>"ip"}, "location"=>{"type"=>"geo_point"}, "latitude"=>{"type"=>"half_float"}, "longitude"=>{"type"=>"half_float"}}}}}}}}
[2018-06-05T11:16:59,065][INFO ][logstash.outputs.elasticsearch] New Elasticsearch output {:class=>"LogStash::Outputs::ElasticSearch", :hosts=>["//100.100.100.111:9200", "//100.100.100.112:9200", "//100.100.100.113:9200"]}
[2018-06-05T11:16:59,390][INFO ][logstash.inputs.jdbc     ] (3.475615s) select
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    DECODE(NVL(MODELNO_GROUP,0),0,0,1) AS MODELNO_GROUP_FLAG,
    category,
    '' as cg,
    '' as cat1,
    '' as cat2,
    '' as cat3,
    '' as cat4,
    ca_code,
    ca_dept_mcode,
    ca_dept_code,
    ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,
    shop_name,
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    '' as model_factory,
    minprice,
    maxprice,
    minprices,
    C_DATE,
    mallcnt,
    DECODE(NVL(MALLCNT,0),0,0,1) AS MALLCNT_FLAG,
    spec,
    openexpectflag,
    condiname,
    KEYWORD,
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    to_all
--    MODELNM || ' ' || FACTORY || ' ' || SPEC || ' ' || KEYWORD || ' ' || KEYWORD2 || ' ' || CONDINAME AS to_all
from (

select
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    CASE WHEN service_gubun='2' AND store_flag='1' AND ca_dept_code IS NOT NULL THEN RTRIM(category || ' '  || ca_dept_code) ELSE category END AS category,
    ca_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),3,8)='000000' OR SUBSTR(RTRIM(ca_dept_code),3,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,4) END AS ca_dept_mcode,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),5,8)='0000' OR SUBSTR(RTRIM(ca_dept_code),5,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,6) END AS ca_dept_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),7,8)='00' OR SUBSTR(RTRIM(ca_dept_code),7,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,8) END AS ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,    
    shop_name,    
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    model_factory,
    minprice,
    maxprice,
    replace(minprices, ' ', '    ') as minprices,
    C_DATE,
    mallcnt,
    replace(replace(spec,',',' '),'/',' ') spec,
    openexpectflag,
    replace(condiname, ' ', '    ') as condiname,    
    CASE WHEN socialprice=0 THEN keyword ELSE keyword || ' ' || UDF_SOCIAL_GOODSNM(modelno_group,modelno) END AS KEYWORD,    
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    to_all
FROM tmp_es_price_data_01
WHERE mod_no = '4'

)

[2018-06-05T11:16:59,388][INFO ][logstash.inputs.jdbc     ] (3.474085s) select 
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    DECODE(NVL(MODELNO_GROUP,0),0,0,1) AS MODELNO_GROUP_FLAG,
    category,
    '' as cg,
    '' as cat1,
    '' as cat2,
    '' as cat3,
    '' as cat4,
    ca_code,
    ca_dept_mcode,
    ca_dept_code,
    ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,
    shop_name,
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    MODELNM || ' ' || FACTORY as model_factory,
    minprice,
    maxprice,
    minprices,
    C_DATE,
    mallcnt,
    DECODE(NVL(MALLCNT,0),0,0,1) AS MALLCNT_FLAG,
    spec,
    openexpectflag,
    condiname,
    KEYWORD,
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    to_all
--    MODELNM || ' ' || FACTORY || ' ' || SPEC || ' ' || KEYWORD || ' ' || KEYWORD2 || ' ' || CONDINAME AS to_all
from (

select
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    CASE WHEN service_gubun='2' AND store_flag='1' AND ca_dept_code IS NOT NULL THEN RTRIM(category || ' '  || ca_dept_code) ELSE category END AS category,
    ca_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),3,8)='000000' OR SUBSTR(RTRIM(ca_dept_code),3,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,4) END AS ca_dept_mcode,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),5,8)='0000' OR SUBSTR(RTRIM(ca_dept_code),5,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,6) END AS ca_dept_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),7,8)='00' OR SUBSTR(RTRIM(ca_dept_code),7,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,8) END AS ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,    
    shop_name,    
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    model_factory,
    minprice,
    maxprice,
    replace(minprices, ' ', '    ') as minprices,
    C_DATE,
    mallcnt,
    replace(replace(spec,',',' '),'/',' ') spec,
    openexpectflag,
    replace(condiname, ' ', '    ') as condiname,    
    CASE WHEN socialprice=0 THEN keyword ELSE keyword || ' ' || UDF_SOCIAL_GOODSNM(modelno_group,modelno) END AS KEYWORD,    
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    to_all
FROM tmp_es_goods_data_01    
WHERE mod_no = '4'

)

[2018-06-05T11:16:59,972][INFO ][logstash.pipeline        ] Pipeline started succesfully {:pipeline_id=>"main", :thread=>"#<Thread:0x26c3f895@/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:246 run>"}
[2018-06-05T11:17:00,032][INFO ][logstash.agent           ] Pipelines running {:count=>1, :pipelines=>["main"]}
[2018-06-05T11:17:01,193][INFO ][logstash.inputs.jdbc     ] (2.319969s) select
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    DECODE(NVL(MODELNO_GROUP,0),0,0,1) AS MODELNO_GROUP_FLAG,
    category,
    '' as cg,
    '' as cat1,
    '' as cat2,
    '' as cat3,
    '' as cat4,
    ca_code,
    ca_dept_mcode,
    ca_dept_code,
    ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,
    shop_name,
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    '' as model_factory,
    minprice,
    maxprice,
    minprices,
    C_DATE,
    mallcnt,
    DECODE(NVL(MALLCNT,0),0,0,1) AS MALLCNT_FLAG,
    spec,
    openexpectflag,
    condiname,
    KEYWORD,
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    to_all
--    MODELNM || ' ' || FACTORY || ' ' || SPEC || ' ' || KEYWORD || ' ' || KEYWORD2 || ' ' || CONDINAME AS to_all
from (

select
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    CASE WHEN service_gubun='2' AND store_flag='1' AND ca_dept_code IS NOT NULL THEN RTRIM(category || ' '  || ca_dept_code) ELSE category END AS category,
    ca_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),3,8)='000000' OR SUBSTR(RTRIM(ca_dept_code),3,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,4) END AS ca_dept_mcode,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),5,8)='0000' OR SUBSTR(RTRIM(ca_dept_code),5,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,6) END AS ca_dept_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),7,8)='00' OR SUBSTR(RTRIM(ca_dept_code),7,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,8) END AS ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,    
    shop_name,    
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    model_factory,
    minprice,
    maxprice,
    replace(minprices, ' ', '    ') as minprices,
    C_DATE,
    mallcnt,
    replace(replace(spec,',',' '),'/',' ') spec,
    openexpectflag,
    replace(condiname, ' ', '    ') as condiname,    
    CASE WHEN socialprice=0 THEN keyword ELSE keyword || ' ' || UDF_SOCIAL_GOODSNM(modelno_group,modelno) END AS KEYWORD,    
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    to_all
FROM tmp_es_price_data_01
WHERE mod_no = '2'

)

[2018-06-05T11:17:01,222][INFO ][logstash.inputs.jdbc     ] (2.330170s) select 
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    DECODE(NVL(MODELNO_GROUP,0),0,0,1) AS MODELNO_GROUP_FLAG,
    category,
    '' as cg,
    '' as cat1,
    '' as cat2,
    '' as cat3,
    '' as cat4,
    ca_code,
    ca_dept_mcode,
    ca_dept_code,
    ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,
    shop_name,
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    MODELNM || ' ' || FACTORY as model_factory,
    minprice,
    maxprice,
    minprices,
    C_DATE,
    mallcnt,
    DECODE(NVL(MALLCNT,0),0,0,1) AS MALLCNT_FLAG,
    spec,
    openexpectflag,
    condiname,
    KEYWORD,
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    to_all
--    MODELNM || ' ' || FACTORY || ' ' || SPEC || ' ' || KEYWORD || ' ' || KEYWORD2 || ' ' || CONDINAME AS to_all
from (

select
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    CASE WHEN service_gubun='2' AND store_flag='1' AND ca_dept_code IS NOT NULL THEN RTRIM(category || ' '  || ca_dept_code) ELSE category END AS category,
    ca_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),3,8)='000000' OR SUBSTR(RTRIM(ca_dept_code),3,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,4) END AS ca_dept_mcode,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),5,8)='0000' OR SUBSTR(RTRIM(ca_dept_code),5,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,6) END AS ca_dept_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),7,8)='00' OR SUBSTR(RTRIM(ca_dept_code),7,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,8) END AS ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,    
    shop_name,    
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    model_factory,
    minprice,
    maxprice,
    replace(minprices, ' ', '    ') as minprices,
    C_DATE,
    mallcnt,
    replace(replace(spec,',',' '),'/',' ') spec,
    openexpectflag,
    replace(condiname, ' ', '    ') as condiname,    
    CASE WHEN socialprice=0 THEN keyword ELSE keyword || ' ' || UDF_SOCIAL_GOODSNM(modelno_group,modelno) END AS KEYWORD,    
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    to_all
FROM tmp_es_goods_data_01    
WHERE mod_no = '2'

)

[2018-06-05T11:17:02,849][INFO ][logstash.inputs.jdbc     ] (0.937194s) select
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    DECODE(NVL(MODELNO_GROUP,0),0,0,1) AS MODELNO_GROUP_FLAG,
    category,
    '' as cg,
    '' as cat1,
    '' as cat2,
    '' as cat3,
    '' as cat4,
    ca_code,
    ca_dept_mcode,
    ca_dept_code,
    ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,
    shop_name,
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    '' as model_factory,
    minprice,
    maxprice,
    minprices,
    C_DATE,
    mallcnt,
    DECODE(NVL(MALLCNT,0),0,0,1) AS MALLCNT_FLAG,
    spec,
    openexpectflag,
    condiname,
    KEYWORD,
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    to_all
--    MODELNM || ' ' || FACTORY || ' ' || SPEC || ' ' || KEYWORD || ' ' || KEYWORD2 || ' ' || CONDINAME AS to_all
from (

select
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    CASE WHEN service_gubun='2' AND store_flag='1' AND ca_dept_code IS NOT NULL THEN RTRIM(category || ' '  || ca_dept_code) ELSE category END AS category,
    ca_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),3,8)='000000' OR SUBSTR(RTRIM(ca_dept_code),3,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,4) END AS ca_dept_mcode,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),5,8)='0000' OR SUBSTR(RTRIM(ca_dept_code),5,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,6) END AS ca_dept_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),7,8)='00' OR SUBSTR(RTRIM(ca_dept_code),7,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,8) END AS ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,    
    shop_name,    
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    model_factory,
    minprice,
    maxprice,
    replace(minprices, ' ', '    ') as minprices,
    C_DATE,
    mallcnt,
    replace(replace(spec,',',' '),'/',' ') spec,
    openexpectflag,
    replace(condiname, ' ', '    ') as condiname,    
    CASE WHEN socialprice=0 THEN keyword ELSE keyword || ' ' || UDF_SOCIAL_GOODSNM(modelno_group,modelno) END AS KEYWORD,    
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    to_all
FROM tmp_es_price_data_01
WHERE mod_no = '3'

)

[2018-06-05T11:17:02,849][INFO ][logstash.inputs.jdbc     ] (0.934896s) select 
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    DECODE(NVL(MODELNO_GROUP,0),0,0,1) AS MODELNO_GROUP_FLAG,
    category,
    '' as cg,
    '' as cat1,
    '' as cat2,
    '' as cat3,
    '' as cat4,
    ca_code,
    ca_dept_mcode,
    ca_dept_code,
    ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,
    shop_name,
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    MODELNM || ' ' || FACTORY as model_factory,
    minprice,
    maxprice,
    minprices,
    C_DATE,
    mallcnt,
    DECODE(NVL(MALLCNT,0),0,0,1) AS MALLCNT_FLAG,
    spec,
    openexpectflag,
    condiname,
    KEYWORD,
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    to_all
--    MODELNM || ' ' || FACTORY || ' ' || SPEC || ' ' || KEYWORD || ' ' || KEYWORD2 || ' ' || CONDINAME AS to_all
from (

select
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    CASE WHEN service_gubun='2' AND store_flag='1' AND ca_dept_code IS NOT NULL THEN RTRIM(category || ' '  || ca_dept_code) ELSE category END AS category,
    ca_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),3,8)='000000' OR SUBSTR(RTRIM(ca_dept_code),3,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,4) END AS ca_dept_mcode,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),5,8)='0000' OR SUBSTR(RTRIM(ca_dept_code),5,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,6) END AS ca_dept_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),7,8)='00' OR SUBSTR(RTRIM(ca_dept_code),7,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,8) END AS ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,    
    shop_name,    
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    model_factory,
    minprice,
    maxprice,
    replace(minprices, ' ', '    ') as minprices,
    C_DATE,
    mallcnt,
    replace(replace(spec,',',' '),'/',' ') spec,
    openexpectflag,
    replace(condiname, ' ', '    ') as condiname,    
    CASE WHEN socialprice=0 THEN keyword ELSE keyword || ' ' || UDF_SOCIAL_GOODSNM(modelno_group,modelno) END AS KEYWORD,    
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    to_all
FROM tmp_es_goods_data_01    
WHERE mod_no = '3'

)

[2018-06-05T12:46:05,250][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"fb_apache", :directory=>"/usr/share/logstash/modules/fb_apache/configuration"}
[2018-06-05T12:46:05,257][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"netflow", :directory=>"/usr/share/logstash/modules/netflow/configuration"}
[2018-06-05T12:46:06,121][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"fb_apache", :directory=>"/usr/share/logstash/modules/fb_apache/configuration"}
[2018-06-05T12:46:06,128][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"netflow", :directory=>"/usr/share/logstash/modules/netflow/configuration"}
[2018-06-05T12:46:06,549][WARN ][logstash.config.source.multilocal] Ignoring the 'pipelines.yml' file because modules or command line options are specified
[2018-06-05T12:46:07,033][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"fb_apache", :directory=>"/usr/share/logstash/modules/fb_apache/configuration"}
[2018-06-05T12:46:07,057][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"netflow", :directory=>"/usr/share/logstash/modules/netflow/configuration"}
[2018-06-05T12:46:07,128][INFO ][logstash.runner          ] Starting Logstash {"logstash.version"=>"6.2.3"}
[2018-06-05T12:46:07,244][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"fb_apache", :directory=>"/usr/share/logstash/modules/fb_apache/configuration"}
[2018-06-05T12:46:07,252][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"netflow", :directory=>"/usr/share/logstash/modules/netflow/configuration"}
[2018-06-05T12:46:07,451][WARN ][logstash.config.source.multilocal] Ignoring the 'pipelines.yml' file because modules or command line options are specified
[2018-06-05T12:46:07,713][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=>9600}
[2018-06-05T12:46:08,054][INFO ][logstash.runner          ] Starting Logstash {"logstash.version"=>"6.2.3"}
[2018-06-05T12:46:08,346][WARN ][logstash.config.source.multilocal] Ignoring the 'pipelines.yml' file because modules or command line options are specified
[2018-06-05T12:46:08,453][WARN ][logstash.config.source.multilocal] Ignoring the 'pipelines.yml' file because modules or command line options are specified
[2018-06-05T12:46:08,824][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=>9601}
[2018-06-05T12:46:09,013][INFO ][logstash.runner          ] Starting Logstash {"logstash.version"=>"6.2.3"}
[2018-06-05T12:46:09,020][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"fb_apache", :directory=>"/usr/share/logstash/modules/fb_apache/configuration"}
[2018-06-05T12:46:09,075][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"netflow", :directory=>"/usr/share/logstash/modules/netflow/configuration"}
[2018-06-05T12:46:09,276][INFO ][logstash.runner          ] Starting Logstash {"logstash.version"=>"6.2.3"}
[2018-06-05T12:46:09,678][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"fb_apache", :directory=>"/usr/share/logstash/modules/fb_apache/configuration"}
[2018-06-05T12:46:09,749][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"netflow", :directory=>"/usr/share/logstash/modules/netflow/configuration"}
[2018-06-05T12:46:09,825][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=>9602}
[2018-06-05T12:46:10,180][DEBUG][org.logstash.secret.store.SecretStoreFactory] Attempting to exists or secret store with implementation: org.logstash.secret.store.backend.JavaKeyStore
[2018-06-05T12:46:10,335][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=>9603}
[2018-06-05T12:46:10,479][DEBUG][org.logstash.secret.store.SecretStoreFactory] Attempting to exists or secret store with implementation: org.logstash.secret.store.backend.JavaKeyStore
[2018-06-05T12:46:10,674][INFO ][logstash.filters.ruby.script] Test run complete {:script_path=>"rubyfilter.rb", :results=>{:passed=>0, :failed=>0, :errored=>0}}
[2018-06-05T12:46:10,897][WARN ][logstash.config.source.multilocal] Ignoring the 'pipelines.yml' file because modules or command line options are specified
[2018-06-05T12:46:10,921][WARN ][logstash.config.source.multilocal] Ignoring the 'pipelines.yml' file because modules or command line options are specified
[2018-06-05T12:46:11,457][INFO ][logstash.runner          ] Starting Logstash {"logstash.version"=>"6.2.3"}
[2018-06-05T12:46:11,496][DEBUG][org.logstash.secret.store.SecretStoreFactory] Attempting to exists or secret store with implementation: org.logstash.secret.store.backend.JavaKeyStore
[2018-06-05T12:46:11,556][INFO ][logstash.runner          ] Starting Logstash {"logstash.version"=>"6.2.3"}
[2018-06-05T12:46:11,598][WARN ][logstash.outputs.elasticsearch] You are using a deprecated config setting "document_type" set in elasticsearch. Deprecated settings will continue to work, but are scheduled for removal from logstash in the future. Document types are being deprecated in Elasticsearch 6.0, and removed entirely in 7.0. You should avoid this feature If you have any questions about this, please visit the #logstash channel on freenode irc. {:name=>"document_type", :plugin=><LogStash::Outputs::ElasticSearch hosts=>[//100.100.100.111:9200, //100.100.100.112:9200, //100.100.100.113:9200], index=>"qa-enuri-main-as-is-2018.06.05.03.45", document_type=>"_doc", document_id=>"%{id}", action=>"index", id=>"6ecd11524c84e5de286546b0de40f57503392aeab1548c7913e69855f4645bbc", enable_metric=>true, codec=><LogStash::Codecs::Plain id=>"plain_24634353-cd13-4f9e-8582-85f9bb99836c", enable_metric=>true, charset=>"UTF-8">, workers=>1, manage_template=>true, template_name=>"logstash", template_overwrite=>false, doc_as_upsert=>false, script_type=>"inline", script_lang=>"painless", script_var_name=>"event", scripted_upsert=>false, retry_initial_interval=>2, retry_max_interval=>64, retry_on_conflict=>1, ssl_certificate_verification=>true, sniffing=>false, sniffing_delay=>5, timeout=>60, pool_max=>1000, pool_max_per_route=>100, resurrect_delay=>5, validate_after_inactivity=>10000, http_compression=>false>}
[2018-06-05T12:46:11,611][INFO ][logstash.pipeline        ] Starting pipeline {:pipeline_id=>"main", "pipeline.workers"=>8, "pipeline.batch.size"=>125, "pipeline.batch.delay"=>50}
[2018-06-05T12:46:11,835][DEBUG][org.logstash.secret.store.SecretStoreFactory] Attempting to exists or secret store with implementation: org.logstash.secret.store.backend.JavaKeyStore
[2018-06-05T12:46:11,974][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=>9604}
[2018-06-05T12:46:12,215][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=>9605}
[2018-06-05T12:46:12,468][DEBUG][org.logstash.secret.store.SecretStoreFactory] Attempting to exists or secret store with implementation: org.logstash.secret.store.backend.JavaKeyStore
[2018-06-05T12:46:12,738][DEBUG][org.logstash.secret.store.SecretStoreFactory] Attempting to exists or secret store with implementation: org.logstash.secret.store.backend.JavaKeyStore
[2018-06-05T12:46:12,885][INFO ][logstash.filters.ruby.script] Test run complete {:script_path=>"rubyfilter.rb", :results=>{:passed=>0, :failed=>0, :errored=>0}}
[2018-06-05T12:46:13,015][DEBUG][org.logstash.secret.store.SecretStoreFactory] Attempting to exists or secret store with implementation: org.logstash.secret.store.backend.JavaKeyStore
[2018-06-05T12:46:13,139][INFO ][logstash.filters.ruby.script] Test run complete {:script_path=>"rubyfilter.rb", :results=>{:passed=>0, :failed=>0, :errored=>0}}
[2018-06-05T12:46:13,387][INFO ][logstash.outputs.elasticsearch] Elasticsearch pool URLs updated {:changes=>{:removed=>[], :added=>[http://100.100.100.111:9200/, http://100.100.100.112:9200/, http://100.100.100.113:9200/]}}
[2018-06-05T12:46:13,390][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://100.100.100.111:9200/, :path=>"/"}
[2018-06-05T12:46:13,505][DEBUG][org.logstash.secret.store.SecretStoreFactory] Attempting to exists or secret store with implementation: org.logstash.secret.store.backend.JavaKeyStore
[2018-06-05T12:46:13,578][DEBUG][org.logstash.secret.store.SecretStoreFactory] Attempting to exists or secret store with implementation: org.logstash.secret.store.backend.JavaKeyStore
[2018-06-05T12:46:13,692][WARN ][logstash.outputs.elasticsearch] You are using a deprecated config setting "document_type" set in elasticsearch. Deprecated settings will continue to work, but are scheduled for removal from logstash in the future. Document types are being deprecated in Elasticsearch 6.0, and removed entirely in 7.0. You should avoid this feature If you have any questions about this, please visit the #logstash channel on freenode irc. {:name=>"document_type", :plugin=><LogStash::Outputs::ElasticSearch hosts=>[//100.100.100.111:9200, //100.100.100.112:9200, //100.100.100.113:9200], index=>"qa-enuri-main-as-is-2018.06.05.03.45", document_type=>"_doc", document_id=>"%{id}", action=>"index", id=>"6ecd11524c84e5de286546b0de40f57503392aeab1548c7913e69855f4645bbc", enable_metric=>true, codec=><LogStash::Codecs::Plain id=>"plain_2106f99d-6a73-40e1-9fa0-18ff126ead04", enable_metric=>true, charset=>"UTF-8">, workers=>1, manage_template=>true, template_name=>"logstash", template_overwrite=>false, doc_as_upsert=>false, script_type=>"inline", script_lang=>"painless", script_var_name=>"event", scripted_upsert=>false, retry_initial_interval=>2, retry_max_interval=>64, retry_on_conflict=>1, ssl_certificate_verification=>true, sniffing=>false, sniffing_delay=>5, timeout=>60, pool_max=>1000, pool_max_per_route=>100, resurrect_delay=>5, validate_after_inactivity=>10000, http_compression=>false>}
[2018-06-05T12:46:13,804][INFO ][logstash.pipeline        ] Starting pipeline {:pipeline_id=>"main", "pipeline.workers"=>8, "pipeline.batch.size"=>125, "pipeline.batch.delay"=>50}
[2018-06-05T12:46:14,012][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://100.100.100.111:9200/"}
[2018-06-05T12:46:14,125][WARN ][logstash.outputs.elasticsearch] You are using a deprecated config setting "document_type" set in elasticsearch. Deprecated settings will continue to work, but are scheduled for removal from logstash in the future. Document types are being deprecated in Elasticsearch 6.0, and removed entirely in 7.0. You should avoid this feature If you have any questions about this, please visit the #logstash channel on freenode irc. {:name=>"document_type", :plugin=><LogStash::Outputs::ElasticSearch hosts=>[//100.100.100.111:9200, //100.100.100.112:9200, //100.100.100.113:9200], index=>"qa-enuri-main-as-is-2018.06.05.03.45", document_type=>"_doc", document_id=>"%{id}", action=>"index", id=>"6ecd11524c84e5de286546b0de40f57503392aeab1548c7913e69855f4645bbc", enable_metric=>true, codec=><LogStash::Codecs::Plain id=>"plain_2d8a739a-203f-4af4-b044-a60fe6342351", enable_metric=>true, charset=>"UTF-8">, workers=>1, manage_template=>true, template_name=>"logstash", template_overwrite=>false, doc_as_upsert=>false, script_type=>"inline", script_lang=>"painless", script_var_name=>"event", scripted_upsert=>false, retry_initial_interval=>2, retry_max_interval=>64, retry_on_conflict=>1, ssl_certificate_verification=>true, sniffing=>false, sniffing_delay=>5, timeout=>60, pool_max=>1000, pool_max_per_route=>100, resurrect_delay=>5, validate_after_inactivity=>10000, http_compression=>false>}
[2018-06-05T12:46:14,156][INFO ][logstash.pipeline        ] Starting pipeline {:pipeline_id=>"main", "pipeline.workers"=>8, "pipeline.batch.size"=>125, "pipeline.batch.delay"=>50}
[2018-06-05T12:46:14,162][DEBUG][org.logstash.secret.store.SecretStoreFactory] Attempting to exists or secret store with implementation: org.logstash.secret.store.backend.JavaKeyStore
[2018-06-05T12:46:14,341][INFO ][logstash.outputs.elasticsearch] ES Output version determined {:es_version=>6}
[2018-06-05T12:46:14,342][WARN ][logstash.outputs.elasticsearch] Detected a 6.x and above cluster: the `type` event field won't be used to determine the document _type {:es_version=>6}
[2018-06-05T12:46:14,342][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://100.100.100.112:9200/, :path=>"/"}
[2018-06-05T12:46:14,351][DEBUG][org.logstash.secret.store.SecretStoreFactory] Attempting to exists or secret store with implementation: org.logstash.secret.store.backend.JavaKeyStore
[2018-06-05T12:46:14,398][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://100.100.100.112:9200/"}
[2018-06-05T12:46:14,410][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://100.100.100.113:9200/, :path=>"/"}
[2018-06-05T12:46:14,433][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://100.100.100.113:9200/"}
[2018-06-05T12:46:14,495][INFO ][logstash.filters.ruby.script] Test run complete {:script_path=>"rubyfilter.rb", :results=>{:passed=>0, :failed=>0, :errored=>0}}
[2018-06-05T12:46:14,488][INFO ][logstash.outputs.elasticsearch] Using mapping template from {:path=>nil}
[2018-06-05T12:46:14,521][INFO ][logstash.outputs.elasticsearch] Attempting to install template {:manage_template=>{"template"=>"logstash-*", "version"=>60001, "settings"=>{"index.refresh_interval"=>"5s"}, "mappings"=>{"_default_"=>{"dynamic_templates"=>[{"message_field"=>{"path_match"=>"message", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false}}}, {"string_fields"=>{"match"=>"*", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false, "fields"=>{"keyword"=>{"type"=>"keyword", "ignore_above"=>256}}}}}], "properties"=>{"@timestamp"=>{"type"=>"date"}, "@version"=>{"type"=>"keyword"}, "geoip"=>{"dynamic"=>true, "properties"=>{"ip"=>{"type"=>"ip"}, "location"=>{"type"=>"geo_point"}, "latitude"=>{"type"=>"half_float"}, "longitude"=>{"type"=>"half_float"}}}}}}}}
[2018-06-05T12:46:14,543][INFO ][logstash.outputs.elasticsearch] New Elasticsearch output {:class=>"LogStash::Outputs::ElasticSearch", :hosts=>["//100.100.100.111:9200", "//100.100.100.112:9200", "//100.100.100.113:9200"]}
[2018-06-05T12:46:14,606][DEBUG][org.logstash.secret.store.SecretStoreFactory] Attempting to exists or secret store with implementation: org.logstash.secret.store.backend.JavaKeyStore
[2018-06-05T12:46:14,733][DEBUG][org.logstash.secret.store.SecretStoreFactory] Attempting to exists or secret store with implementation: org.logstash.secret.store.backend.JavaKeyStore
[2018-06-05T12:46:14,771][DEBUG][org.logstash.secret.store.SecretStoreFactory] Attempting to exists or secret store with implementation: org.logstash.secret.store.backend.JavaKeyStore
[2018-06-05T12:46:14,773][WARN ][logstash.outputs.elasticsearch] You are using a deprecated config setting "document_type" set in elasticsearch. Deprecated settings will continue to work, but are scheduled for removal from logstash in the future. Document types are being deprecated in Elasticsearch 6.0, and removed entirely in 7.0. You should avoid this feature If you have any questions about this, please visit the #logstash channel on freenode irc. {:name=>"document_type", :plugin=><LogStash::Outputs::ElasticSearch hosts=>[//100.100.100.111:9200, //100.100.100.112:9200, //100.100.100.113:9200], index=>"qa-enuri-main-as-is-2018.06.05.03.45", document_type=>"_doc", document_id=>"%{id}", action=>"index", id=>"6ecd11524c84e5de286546b0de40f57503392aeab1548c7913e69855f4645bbc", enable_metric=>true, codec=><LogStash::Codecs::Plain id=>"plain_8f6085a2-bbaa-4a53-8b60-fc19dafbeb6d", enable_metric=>true, charset=>"UTF-8">, workers=>1, manage_template=>true, template_name=>"logstash", template_overwrite=>false, doc_as_upsert=>false, script_type=>"inline", script_lang=>"painless", script_var_name=>"event", scripted_upsert=>false, retry_initial_interval=>2, retry_max_interval=>64, retry_on_conflict=>1, ssl_certificate_verification=>true, sniffing=>false, sniffing_delay=>5, timeout=>60, pool_max=>1000, pool_max_per_route=>100, resurrect_delay=>5, validate_after_inactivity=>10000, http_compression=>false>}
[2018-06-05T12:46:14,843][INFO ][logstash.pipeline        ] Starting pipeline {:pipeline_id=>"main", "pipeline.workers"=>8, "pipeline.batch.size"=>125, "pipeline.batch.delay"=>50}
[2018-06-05T12:46:14,990][DEBUG][org.logstash.secret.store.SecretStoreFactory] Attempting to exists or secret store with implementation: org.logstash.secret.store.backend.JavaKeyStore
[2018-06-05T12:46:15,084][INFO ][logstash.filters.ruby.script] Test run complete {:script_path=>"rubyfilter.rb", :results=>{:passed=>0, :failed=>0, :errored=>0}}
[2018-06-05T12:46:15,109][INFO ][logstash.outputs.elasticsearch] Elasticsearch pool URLs updated {:changes=>{:removed=>[], :added=>[http://100.100.100.111:9200/, http://100.100.100.112:9200/, http://100.100.100.113:9200/]}}
[2018-06-05T12:46:15,116][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://100.100.100.111:9200/, :path=>"/"}
[2018-06-05T12:46:15,287][DEBUG][org.logstash.secret.store.SecretStoreFactory] Attempting to exists or secret store with implementation: org.logstash.secret.store.backend.JavaKeyStore
[2018-06-05T12:46:15,433][INFO ][logstash.outputs.elasticsearch] Elasticsearch pool URLs updated {:changes=>{:removed=>[], :added=>[http://100.100.100.111:9200/, http://100.100.100.112:9200/, http://100.100.100.113:9200/]}}
[2018-06-05T12:46:15,435][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://100.100.100.111:9200/, :path=>"/"}
[2018-06-05T12:46:15,435][WARN ][logstash.outputs.elasticsearch] You are using a deprecated config setting "document_type" set in elasticsearch. Deprecated settings will continue to work, but are scheduled for removal from logstash in the future. Document types are being deprecated in Elasticsearch 6.0, and removed entirely in 7.0. You should avoid this feature If you have any questions about this, please visit the #logstash channel on freenode irc. {:name=>"document_type", :plugin=><LogStash::Outputs::ElasticSearch hosts=>[//100.100.100.111:9200, //100.100.100.112:9200, //100.100.100.113:9200], index=>"qa-enuri-main-as-is-2018.06.05.03.45", document_type=>"_doc", document_id=>"%{id}", action=>"index", id=>"6ecd11524c84e5de286546b0de40f57503392aeab1548c7913e69855f4645bbc", enable_metric=>true, codec=><LogStash::Codecs::Plain id=>"plain_10ac8640-12e1-4677-afa6-ac61ae547b7c", enable_metric=>true, charset=>"UTF-8">, workers=>1, manage_template=>true, template_name=>"logstash", template_overwrite=>false, doc_as_upsert=>false, script_type=>"inline", script_lang=>"painless", script_var_name=>"event", scripted_upsert=>false, retry_initial_interval=>2, retry_max_interval=>64, retry_on_conflict=>1, ssl_certificate_verification=>true, sniffing=>false, sniffing_delay=>5, timeout=>60, pool_max=>1000, pool_max_per_route=>100, resurrect_delay=>5, validate_after_inactivity=>10000, http_compression=>false>}
[2018-06-05T12:46:15,451][DEBUG][org.logstash.secret.store.SecretStoreFactory] Attempting to exists or secret store with implementation: org.logstash.secret.store.backend.JavaKeyStore
[2018-06-05T12:46:15,458][INFO ][logstash.pipeline        ] Starting pipeline {:pipeline_id=>"main", "pipeline.workers"=>8, "pipeline.batch.size"=>125, "pipeline.batch.delay"=>50}
[2018-06-05T12:46:15,503][INFO ][logstash.pipeline        ] Pipeline started succesfully {:pipeline_id=>"main", :thread=>"#<Thread:0xd21ea64@/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:246 run>"}
[2018-06-05T12:46:15,546][INFO ][logstash.agent           ] Pipelines running {:count=>1, :pipelines=>["main"]}
[2018-06-05T12:46:15,621][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://100.100.100.111:9200/"}
[2018-06-05T12:46:15,647][INFO ][logstash.filters.ruby.script] Test run complete {:script_path=>"rubyfilter.rb", :results=>{:passed=>0, :failed=>0, :errored=>0}}
[2018-06-05T12:46:15,734][INFO ][logstash.outputs.elasticsearch] ES Output version determined {:es_version=>6}
[2018-06-05T12:46:15,734][WARN ][logstash.outputs.elasticsearch] Detected a 6.x and above cluster: the `type` event field won't be used to determine the document _type {:es_version=>6}
[2018-06-05T12:46:15,735][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://100.100.100.112:9200/, :path=>"/"}
[2018-06-05T12:46:15,750][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://100.100.100.111:9200/"}
[2018-06-05T12:46:15,773][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://100.100.100.112:9200/"}
[2018-06-05T12:46:15,788][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://100.100.100.113:9200/, :path=>"/"}
[2018-06-05T12:46:15,818][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://100.100.100.113:9200/"}
[2018-06-05T12:46:15,884][INFO ][logstash.outputs.elasticsearch] Using mapping template from {:path=>nil}
[2018-06-05T12:46:15,890][INFO ][logstash.outputs.elasticsearch] Attempting to install template {:manage_template=>{"template"=>"logstash-*", "version"=>60001, "settings"=>{"index.refresh_interval"=>"5s"}, "mappings"=>{"_default_"=>{"dynamic_templates"=>[{"message_field"=>{"path_match"=>"message", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false}}}, {"string_fields"=>{"match"=>"*", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false, "fields"=>{"keyword"=>{"type"=>"keyword", "ignore_above"=>256}}}}}], "properties"=>{"@timestamp"=>{"type"=>"date"}, "@version"=>{"type"=>"keyword"}, "geoip"=>{"dynamic"=>true, "properties"=>{"ip"=>{"type"=>"ip"}, "location"=>{"type"=>"geo_point"}, "latitude"=>{"type"=>"half_float"}, "longitude"=>{"type"=>"half_float"}}}}}}}}
[2018-06-05T12:46:15,912][INFO ][logstash.outputs.elasticsearch] ES Output version determined {:es_version=>6}
[2018-06-05T12:46:15,913][WARN ][logstash.outputs.elasticsearch] Detected a 6.x and above cluster: the `type` event field won't be used to determine the document _type {:es_version=>6}
[2018-06-05T12:46:15,913][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://100.100.100.112:9200/, :path=>"/"}
[2018-06-05T12:46:15,943][INFO ][logstash.outputs.elasticsearch] New Elasticsearch output {:class=>"LogStash::Outputs::ElasticSearch", :hosts=>["//100.100.100.111:9200", "//100.100.100.112:9200", "//100.100.100.113:9200"]}
[2018-06-05T12:46:15,954][DEBUG][org.logstash.secret.store.SecretStoreFactory] Attempting to exists or secret store with implementation: org.logstash.secret.store.backend.JavaKeyStore
[2018-06-05T12:46:15,966][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://100.100.100.112:9200/"}
[2018-06-05T12:46:15,987][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://100.100.100.113:9200/, :path=>"/"}
[2018-06-05T12:46:15,996][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://100.100.100.113:9200/"}
[2018-06-05T12:46:16,033][INFO ][logstash.outputs.elasticsearch] Using mapping template from {:path=>nil}
[2018-06-05T12:46:16,046][INFO ][logstash.outputs.elasticsearch] Elasticsearch pool URLs updated {:changes=>{:removed=>[], :added=>[http://100.100.100.111:9200/, http://100.100.100.112:9200/, http://100.100.100.113:9200/]}}
[2018-06-05T12:46:16,063][INFO ][logstash.outputs.elasticsearch] Attempting to install template {:manage_template=>{"template"=>"logstash-*", "version"=>60001, "settings"=>{"index.refresh_interval"=>"5s"}, "mappings"=>{"_default_"=>{"dynamic_templates"=>[{"message_field"=>{"path_match"=>"message", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false}}}, {"string_fields"=>{"match"=>"*", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false, "fields"=>{"keyword"=>{"type"=>"keyword", "ignore_above"=>256}}}}}], "properties"=>{"@timestamp"=>{"type"=>"date"}, "@version"=>{"type"=>"keyword"}, "geoip"=>{"dynamic"=>true, "properties"=>{"ip"=>{"type"=>"ip"}, "location"=>{"type"=>"geo_point"}, "latitude"=>{"type"=>"half_float"}, "longitude"=>{"type"=>"half_float"}}}}}}}}
[2018-06-05T12:46:16,074][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://100.100.100.111:9200/, :path=>"/"}
[2018-06-05T12:46:16,084][INFO ][logstash.outputs.elasticsearch] New Elasticsearch output {:class=>"LogStash::Outputs::ElasticSearch", :hosts=>["//100.100.100.111:9200", "//100.100.100.112:9200", "//100.100.100.113:9200"]}
[2018-06-05T12:46:16,083][WARN ][logstash.outputs.elasticsearch] You are using a deprecated config setting "document_type" set in elasticsearch. Deprecated settings will continue to work, but are scheduled for removal from logstash in the future. Document types are being deprecated in Elasticsearch 6.0, and removed entirely in 7.0. You should avoid this feature If you have any questions about this, please visit the #logstash channel on freenode irc. {:name=>"document_type", :plugin=><LogStash::Outputs::ElasticSearch hosts=>[//100.100.100.111:9200, //100.100.100.112:9200, //100.100.100.113:9200], index=>"qa-enuri-main-as-is-2018.06.05.03.45", document_type=>"_doc", document_id=>"%{id}", action=>"index", id=>"6ecd11524c84e5de286546b0de40f57503392aeab1548c7913e69855f4645bbc", enable_metric=>true, codec=><LogStash::Codecs::Plain id=>"plain_63b6ac90-6d8e-4040-ab41-cb553d2c2d96", enable_metric=>true, charset=>"UTF-8">, workers=>1, manage_template=>true, template_name=>"logstash", template_overwrite=>false, doc_as_upsert=>false, script_type=>"inline", script_lang=>"painless", script_var_name=>"event", scripted_upsert=>false, retry_initial_interval=>2, retry_max_interval=>64, retry_on_conflict=>1, ssl_certificate_verification=>true, sniffing=>false, sniffing_delay=>5, timeout=>60, pool_max=>1000, pool_max_per_route=>100, resurrect_delay=>5, validate_after_inactivity=>10000, http_compression=>false>}
[2018-06-05T12:46:16,160][INFO ][logstash.pipeline        ] Starting pipeline {:pipeline_id=>"main", "pipeline.workers"=>8, "pipeline.batch.size"=>125, "pipeline.batch.delay"=>50}
[2018-06-05T12:46:16,486][INFO ][logstash.outputs.elasticsearch] Elasticsearch pool URLs updated {:changes=>{:removed=>[], :added=>[http://100.100.100.111:9200/, http://100.100.100.112:9200/, http://100.100.100.113:9200/]}}
[2018-06-05T12:46:16,527][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://100.100.100.111:9200/, :path=>"/"}
[2018-06-05T12:46:16,715][INFO ][logstash.pipeline        ] Pipeline started succesfully {:pipeline_id=>"main", :thread=>"#<Thread:0x77c5a9aa@/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:246 sleep>"}
[2018-06-05T12:46:16,763][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://100.100.100.111:9200/"}
[2018-06-05T12:46:16,806][INFO ][logstash.agent           ] Pipelines running {:count=>1, :pipelines=>["main"]}
[2018-06-05T12:46:16,835][INFO ][logstash.pipeline        ] Pipeline started succesfully {:pipeline_id=>"main", :thread=>"#<Thread:0x3dc6fd13@/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:246 run>"}
[2018-06-05T12:46:16,933][INFO ][logstash.agent           ] Pipelines running {:count=>1, :pipelines=>["main"]}
[2018-06-05T12:46:17,046][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://100.100.100.111:9200/"}
[2018-06-05T12:46:17,103][INFO ][logstash.outputs.elasticsearch] ES Output version determined {:es_version=>6}
[2018-06-05T12:46:17,103][WARN ][logstash.outputs.elasticsearch] Detected a 6.x and above cluster: the `type` event field won't be used to determine the document _type {:es_version=>6}
[2018-06-05T12:46:17,104][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://100.100.100.112:9200/, :path=>"/"}
[2018-06-05T12:46:17,128][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://100.100.100.112:9200/"}
[2018-06-05T12:46:17,149][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://100.100.100.113:9200/, :path=>"/"}
[2018-06-05T12:46:17,171][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://100.100.100.113:9200/"}
[2018-06-05T12:46:17,209][INFO ][logstash.outputs.elasticsearch] Using mapping template from {:path=>nil}
[2018-06-05T12:46:17,215][INFO ][logstash.outputs.elasticsearch] Attempting to install template {:manage_template=>{"template"=>"logstash-*", "version"=>60001, "settings"=>{"index.refresh_interval"=>"5s"}, "mappings"=>{"_default_"=>{"dynamic_templates"=>[{"message_field"=>{"path_match"=>"message", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false}}}, {"string_fields"=>{"match"=>"*", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false, "fields"=>{"keyword"=>{"type"=>"keyword", "ignore_above"=>256}}}}}], "properties"=>{"@timestamp"=>{"type"=>"date"}, "@version"=>{"type"=>"keyword"}, "geoip"=>{"dynamic"=>true, "properties"=>{"ip"=>{"type"=>"ip"}, "location"=>{"type"=>"geo_point"}, "latitude"=>{"type"=>"half_float"}, "longitude"=>{"type"=>"half_float"}}}}}}}}
[2018-06-05T12:46:17,250][INFO ][logstash.outputs.elasticsearch] New Elasticsearch output {:class=>"LogStash::Outputs::ElasticSearch", :hosts=>["//100.100.100.111:9200", "//100.100.100.112:9200", "//100.100.100.113:9200"]}
[2018-06-05T12:46:17,259][INFO ][logstash.outputs.elasticsearch] ES Output version determined {:es_version=>6}
[2018-06-05T12:46:17,260][WARN ][logstash.outputs.elasticsearch] Detected a 6.x and above cluster: the `type` event field won't be used to determine the document _type {:es_version=>6}
[2018-06-05T12:46:17,260][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://100.100.100.112:9200/, :path=>"/"}
[2018-06-05T12:46:17,285][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://100.100.100.112:9200/"}
[2018-06-05T12:46:17,290][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://100.100.100.113:9200/, :path=>"/"}
[2018-06-05T12:46:17,305][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://100.100.100.113:9200/"}
[2018-06-05T12:46:17,365][INFO ][logstash.outputs.elasticsearch] Using mapping template from {:path=>nil}
[2018-06-05T12:46:17,401][INFO ][logstash.outputs.elasticsearch] Attempting to install template {:manage_template=>{"template"=>"logstash-*", "version"=>60001, "settings"=>{"index.refresh_interval"=>"5s"}, "mappings"=>{"_default_"=>{"dynamic_templates"=>[{"message_field"=>{"path_match"=>"message", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false}}}, {"string_fields"=>{"match"=>"*", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false, "fields"=>{"keyword"=>{"type"=>"keyword", "ignore_above"=>256}}}}}], "properties"=>{"@timestamp"=>{"type"=>"date"}, "@version"=>{"type"=>"keyword"}, "geoip"=>{"dynamic"=>true, "properties"=>{"ip"=>{"type"=>"ip"}, "location"=>{"type"=>"geo_point"}, "latitude"=>{"type"=>"half_float"}, "longitude"=>{"type"=>"half_float"}}}}}}}}
[2018-06-05T12:46:17,415][INFO ][logstash.outputs.elasticsearch] New Elasticsearch output {:class=>"LogStash::Outputs::ElasticSearch", :hosts=>["//100.100.100.111:9200", "//100.100.100.112:9200", "//100.100.100.113:9200"]}
[2018-06-05T12:46:17,429][INFO ][logstash.outputs.elasticsearch] Elasticsearch pool URLs updated {:changes=>{:removed=>[], :added=>[http://100.100.100.111:9200/, http://100.100.100.112:9200/, http://100.100.100.113:9200/]}}
[2018-06-05T12:46:17,432][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://100.100.100.111:9200/, :path=>"/"}
[2018-06-05T12:46:17,797][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://100.100.100.111:9200/"}
[2018-06-05T12:46:17,951][INFO ][logstash.outputs.elasticsearch] ES Output version determined {:es_version=>6}
[2018-06-05T12:46:17,952][WARN ][logstash.outputs.elasticsearch] Detected a 6.x and above cluster: the `type` event field won't be used to determine the document _type {:es_version=>6}
[2018-06-05T12:46:17,952][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://100.100.100.112:9200/, :path=>"/"}
[2018-06-05T12:46:17,970][INFO ][logstash.pipeline        ] Pipeline started succesfully {:pipeline_id=>"main", :thread=>"#<Thread:0x6856da3@/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:246 run>"}
[2018-06-05T12:46:17,978][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://100.100.100.112:9200/"}
[2018-06-05T12:46:17,986][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://100.100.100.113:9200/, :path=>"/"}
[2018-06-05T12:46:18,000][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://100.100.100.113:9200/"}
[2018-06-05T12:46:18,007][INFO ][logstash.agent           ] Pipelines running {:count=>1, :pipelines=>["main"]}
[2018-06-05T12:46:18,062][INFO ][logstash.outputs.elasticsearch] Using mapping template from {:path=>nil}
[2018-06-05T12:46:18,087][INFO ][logstash.outputs.elasticsearch] Attempting to install template {:manage_template=>{"template"=>"logstash-*", "version"=>60001, "settings"=>{"index.refresh_interval"=>"5s"}, "mappings"=>{"_default_"=>{"dynamic_templates"=>[{"message_field"=>{"path_match"=>"message", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false}}}, {"string_fields"=>{"match"=>"*", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false, "fields"=>{"keyword"=>{"type"=>"keyword", "ignore_above"=>256}}}}}], "properties"=>{"@timestamp"=>{"type"=>"date"}, "@version"=>{"type"=>"keyword"}, "geoip"=>{"dynamic"=>true, "properties"=>{"ip"=>{"type"=>"ip"}, "location"=>{"type"=>"geo_point"}, "latitude"=>{"type"=>"half_float"}, "longitude"=>{"type"=>"half_float"}}}}}}}}
[2018-06-05T12:46:18,127][INFO ][logstash.pipeline        ] Pipeline started succesfully {:pipeline_id=>"main", :thread=>"#<Thread:0x78e4a26a@/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:246 run>"}
[2018-06-05T12:46:18,133][INFO ][logstash.outputs.elasticsearch] New Elasticsearch output {:class=>"LogStash::Outputs::ElasticSearch", :hosts=>["//100.100.100.111:9200", "//100.100.100.112:9200", "//100.100.100.113:9200"]}
[2018-06-05T12:46:18,221][INFO ][logstash.agent           ] Pipelines running {:count=>1, :pipelines=>["main"]}
[2018-06-05T12:46:19,302][INFO ][logstash.pipeline        ] Pipeline started succesfully {:pipeline_id=>"main", :thread=>"#<Thread:0x5f3f7d9@/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:246 run>"}
[2018-06-05T12:46:19,435][INFO ][logstash.agent           ] Pipelines running {:count=>1, :pipelines=>["main"]}
[2018-06-05T12:46:20,417][INFO ][logstash.inputs.jdbc     ] (1.783753s) select
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    DECODE(NVL(MODELNO_GROUP,0),0,0,1) AS MODELNO_GROUP_FLAG,
    category,
    '' as cg,
    '' as cat1,
    '' as cat2,
    '' as cat3,
    '' as cat4,
    ca_code,
    ca_dept_mcode,
    ca_dept_code,
    ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,
    shop_name,
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    '' as model_factory,
    minprice,
    maxprice,
    minprices,
    C_DATE,
    mallcnt,
    DECODE(NVL(MALLCNT,0),0,0,1) AS MALLCNT_FLAG,
    spec,
    openexpectflag,
    condiname,
    KEYWORD,
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    to_all
--    MODELNM || ' ' || FACTORY || ' ' || SPEC || ' ' || KEYWORD || ' ' || KEYWORD2 || ' ' || CONDINAME AS to_all
from (

select
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    CASE WHEN service_gubun='2' AND store_flag='1' AND ca_dept_code IS NOT NULL THEN RTRIM(category || ' '  || ca_dept_code) ELSE category END AS category,
    ca_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),3,8)='000000' OR SUBSTR(RTRIM(ca_dept_code),3,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,4) END AS ca_dept_mcode,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),5,8)='0000' OR SUBSTR(RTRIM(ca_dept_code),5,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,6) END AS ca_dept_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),7,8)='00' OR SUBSTR(RTRIM(ca_dept_code),7,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,8) END AS ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,    
    shop_name,    
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    model_factory,
    minprice,
    maxprice,
    replace(minprices, ' ', '    ') as minprices,
    C_DATE,
    mallcnt,
    replace(replace(spec,',',' '),'/',' ') spec,
    openexpectflag,
    replace(condiname, ' ', '    ') as condiname,    
    CASE WHEN socialprice=0 THEN keyword ELSE keyword || ' ' || UDF_SOCIAL_GOODSNM(modelno_group,modelno) END AS KEYWORD,    
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    to_all
FROM tmp_es_price_data_01
WHERE mod_no = '5'

)

[2018-06-05T12:46:20,419][INFO ][logstash.inputs.jdbc     ] (1.759883s) select
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    DECODE(NVL(MODELNO_GROUP,0),0,0,1) AS MODELNO_GROUP_FLAG,
    category,
    '' as cg,
    '' as cat1,
    '' as cat2,
    '' as cat3,
    '' as cat4,
    ca_code,
    ca_dept_mcode,
    ca_dept_code,
    ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,
    shop_name,
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    '' as model_factory,
    minprice,
    maxprice,
    minprices,
    C_DATE,
    mallcnt,
    DECODE(NVL(MALLCNT,0),0,0,1) AS MALLCNT_FLAG,
    spec,
    openexpectflag,
    condiname,
    KEYWORD,
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    to_all
--    MODELNM || ' ' || FACTORY || ' ' || SPEC || ' ' || KEYWORD || ' ' || KEYWORD2 || ' ' || CONDINAME AS to_all
from (

select
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    CASE WHEN service_gubun='2' AND store_flag='1' AND ca_dept_code IS NOT NULL THEN RTRIM(category || ' '  || ca_dept_code) ELSE category END AS category,
    ca_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),3,8)='000000' OR SUBSTR(RTRIM(ca_dept_code),3,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,4) END AS ca_dept_mcode,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),5,8)='0000' OR SUBSTR(RTRIM(ca_dept_code),5,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,6) END AS ca_dept_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),7,8)='00' OR SUBSTR(RTRIM(ca_dept_code),7,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,8) END AS ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,    
    shop_name,    
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    model_factory,
    minprice,
    maxprice,
    replace(minprices, ' ', '    ') as minprices,
    C_DATE,
    mallcnt,
    replace(replace(spec,',',' '),'/',' ') spec,
    openexpectflag,
    replace(condiname, ' ', '    ') as condiname,    
    CASE WHEN socialprice=0 THEN keyword ELSE keyword || ' ' || UDF_SOCIAL_GOODSNM(modelno_group,modelno) END AS KEYWORD,    
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    to_all
FROM tmp_es_price_data_01
WHERE mod_no = '3'

)

[2018-06-05T12:46:20,423][INFO ][logstash.inputs.jdbc     ] (1.795004s) select 
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    DECODE(NVL(MODELNO_GROUP,0),0,0,1) AS MODELNO_GROUP_FLAG,
    category,
    '' as cg,
    '' as cat1,
    '' as cat2,
    '' as cat3,
    '' as cat4,
    ca_code,
    ca_dept_mcode,
    ca_dept_code,
    ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,
    shop_name,
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    MODELNM || ' ' || FACTORY as model_factory,
    minprice,
    maxprice,
    minprices,
    C_DATE,
    mallcnt,
    DECODE(NVL(MALLCNT,0),0,0,1) AS MALLCNT_FLAG,
    spec,
    openexpectflag,
    condiname,
    KEYWORD,
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    to_all
--    MODELNM || ' ' || FACTORY || ' ' || SPEC || ' ' || KEYWORD || ' ' || KEYWORD2 || ' ' || CONDINAME AS to_all
from (

select
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    CASE WHEN service_gubun='2' AND store_flag='1' AND ca_dept_code IS NOT NULL THEN RTRIM(category || ' '  || ca_dept_code) ELSE category END AS category,
    ca_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),3,8)='000000' OR SUBSTR(RTRIM(ca_dept_code),3,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,4) END AS ca_dept_mcode,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),5,8)='0000' OR SUBSTR(RTRIM(ca_dept_code),5,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,6) END AS ca_dept_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),7,8)='00' OR SUBSTR(RTRIM(ca_dept_code),7,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,8) END AS ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,    
    shop_name,    
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    model_factory,
    minprice,
    maxprice,
    replace(minprices, ' ', '    ') as minprices,
    C_DATE,
    mallcnt,
    replace(replace(spec,',',' '),'/',' ') spec,
    openexpectflag,
    replace(condiname, ' ', '    ') as condiname,    
    CASE WHEN socialprice=0 THEN keyword ELSE keyword || ' ' || UDF_SOCIAL_GOODSNM(modelno_group,modelno) END AS KEYWORD,    
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    to_all
FROM tmp_es_goods_data_01    
WHERE mod_no = '5'

)

[2018-06-05T12:46:20,431][INFO ][logstash.inputs.jdbc     ] (1.759882s) select 
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    DECODE(NVL(MODELNO_GROUP,0),0,0,1) AS MODELNO_GROUP_FLAG,
    category,
    '' as cg,
    '' as cat1,
    '' as cat2,
    '' as cat3,
    '' as cat4,
    ca_code,
    ca_dept_mcode,
    ca_dept_code,
    ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,
    shop_name,
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    MODELNM || ' ' || FACTORY as model_factory,
    minprice,
    maxprice,
    minprices,
    C_DATE,
    mallcnt,
    DECODE(NVL(MALLCNT,0),0,0,1) AS MALLCNT_FLAG,
    spec,
    openexpectflag,
    condiname,
    KEYWORD,
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    to_all
--    MODELNM || ' ' || FACTORY || ' ' || SPEC || ' ' || KEYWORD || ' ' || KEYWORD2 || ' ' || CONDINAME AS to_all
from (

select
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    CASE WHEN service_gubun='2' AND store_flag='1' AND ca_dept_code IS NOT NULL THEN RTRIM(category || ' '  || ca_dept_code) ELSE category END AS category,
    ca_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),3,8)='000000' OR SUBSTR(RTRIM(ca_dept_code),3,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,4) END AS ca_dept_mcode,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),5,8)='0000' OR SUBSTR(RTRIM(ca_dept_code),5,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,6) END AS ca_dept_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),7,8)='00' OR SUBSTR(RTRIM(ca_dept_code),7,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,8) END AS ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,    
    shop_name,    
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    model_factory,
    minprice,
    maxprice,
    replace(minprices, ' ', '    ') as minprices,
    C_DATE,
    mallcnt,
    replace(replace(spec,',',' '),'/',' ') spec,
    openexpectflag,
    replace(condiname, ' ', '    ') as condiname,    
    CASE WHEN socialprice=0 THEN keyword ELSE keyword || ' ' || UDF_SOCIAL_GOODSNM(modelno_group,modelno) END AS KEYWORD,    
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    to_all
FROM tmp_es_goods_data_01    
WHERE mod_no = '3'

)

[2018-06-05T12:46:21,146][INFO ][logstash.inputs.jdbc     ] (2.871624s) select
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    DECODE(NVL(MODELNO_GROUP,0),0,0,1) AS MODELNO_GROUP_FLAG,
    category,
    '' as cg,
    '' as cat1,
    '' as cat2,
    '' as cat3,
    '' as cat4,
    ca_code,
    ca_dept_mcode,
    ca_dept_code,
    ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,
    shop_name,
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    '' as model_factory,
    minprice,
    maxprice,
    minprices,
    C_DATE,
    mallcnt,
    DECODE(NVL(MALLCNT,0),0,0,1) AS MALLCNT_FLAG,
    spec,
    openexpectflag,
    condiname,
    KEYWORD,
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    to_all
--    MODELNM || ' ' || FACTORY || ' ' || SPEC || ' ' || KEYWORD || ' ' || KEYWORD2 || ' ' || CONDINAME AS to_all
from (

select
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    CASE WHEN service_gubun='2' AND store_flag='1' AND ca_dept_code IS NOT NULL THEN RTRIM(category || ' '  || ca_dept_code) ELSE category END AS category,
    ca_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),3,8)='000000' OR SUBSTR(RTRIM(ca_dept_code),3,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,4) END AS ca_dept_mcode,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),5,8)='0000' OR SUBSTR(RTRIM(ca_dept_code),5,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,6) END AS ca_dept_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),7,8)='00' OR SUBSTR(RTRIM(ca_dept_code),7,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,8) END AS ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,    
    shop_name,    
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    model_factory,
    minprice,
    maxprice,
    replace(minprices, ' ', '    ') as minprices,
    C_DATE,
    mallcnt,
    replace(replace(spec,',',' '),'/',' ') spec,
    openexpectflag,
    replace(condiname, ' ', '    ') as condiname,    
    CASE WHEN socialprice=0 THEN keyword ELSE keyword || ' ' || UDF_SOCIAL_GOODSNM(modelno_group,modelno) END AS KEYWORD,    
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    to_all
FROM tmp_es_price_data_01
WHERE mod_no = '4'

)

[2018-06-05T12:46:21,155][INFO ][logstash.inputs.jdbc     ] (2.876697s) select 
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    DECODE(NVL(MODELNO_GROUP,0),0,0,1) AS MODELNO_GROUP_FLAG,
    category,
    '' as cg,
    '' as cat1,
    '' as cat2,
    '' as cat3,
    '' as cat4,
    ca_code,
    ca_dept_mcode,
    ca_dept_code,
    ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,
    shop_name,
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    MODELNM || ' ' || FACTORY as model_factory,
    minprice,
    maxprice,
    minprices,
    C_DATE,
    mallcnt,
    DECODE(NVL(MALLCNT,0),0,0,1) AS MALLCNT_FLAG,
    spec,
    openexpectflag,
    condiname,
    KEYWORD,
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    to_all
--    MODELNM || ' ' || FACTORY || ' ' || SPEC || ' ' || KEYWORD || ' ' || KEYWORD2 || ' ' || CONDINAME AS to_all
from (

select
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    CASE WHEN service_gubun='2' AND store_flag='1' AND ca_dept_code IS NOT NULL THEN RTRIM(category || ' '  || ca_dept_code) ELSE category END AS category,
    ca_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),3,8)='000000' OR SUBSTR(RTRIM(ca_dept_code),3,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,4) END AS ca_dept_mcode,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),5,8)='0000' OR SUBSTR(RTRIM(ca_dept_code),5,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,6) END AS ca_dept_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),7,8)='00' OR SUBSTR(RTRIM(ca_dept_code),7,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,8) END AS ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,    
    shop_name,    
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    model_factory,
    minprice,
    maxprice,
    replace(minprices, ' ', '    ') as minprices,
    C_DATE,
    mallcnt,
    replace(replace(spec,',',' '),'/',' ') spec,
    openexpectflag,
    replace(condiname, ' ', '    ') as condiname,    
    CASE WHEN socialprice=0 THEN keyword ELSE keyword || ' ' || UDF_SOCIAL_GOODSNM(modelno_group,modelno) END AS KEYWORD,    
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    to_all
FROM tmp_es_goods_data_01    
WHERE mod_no = '4'

)

[2018-06-05T12:46:23,811][INFO ][logstash.inputs.jdbc     ] (3.428512s) select 
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    DECODE(NVL(MODELNO_GROUP,0),0,0,1) AS MODELNO_GROUP_FLAG,
    category,
    '' as cg,
    '' as cat1,
    '' as cat2,
    '' as cat3,
    '' as cat4,
    ca_code,
    ca_dept_mcode,
    ca_dept_code,
    ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,
    shop_name,
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    MODELNM || ' ' || FACTORY as model_factory,
    minprice,
    maxprice,
    minprices,
    C_DATE,
    mallcnt,
    DECODE(NVL(MALLCNT,0),0,0,1) AS MALLCNT_FLAG,
    spec,
    openexpectflag,
    condiname,
    KEYWORD,
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    to_all
--    MODELNM || ' ' || FACTORY || ' ' || SPEC || ' ' || KEYWORD || ' ' || KEYWORD2 || ' ' || CONDINAME AS to_all
from (

select
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    CASE WHEN service_gubun='2' AND store_flag='1' AND ca_dept_code IS NOT NULL THEN RTRIM(category || ' '  || ca_dept_code) ELSE category END AS category,
    ca_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),3,8)='000000' OR SUBSTR(RTRIM(ca_dept_code),3,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,4) END AS ca_dept_mcode,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),5,8)='0000' OR SUBSTR(RTRIM(ca_dept_code),5,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,6) END AS ca_dept_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),7,8)='00' OR SUBSTR(RTRIM(ca_dept_code),7,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,8) END AS ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,    
    shop_name,    
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    model_factory,
    minprice,
    maxprice,
    replace(minprices, ' ', '    ') as minprices,
    C_DATE,
    mallcnt,
    replace(replace(spec,',',' '),'/',' ') spec,
    openexpectflag,
    replace(condiname, ' ', '    ') as condiname,    
    CASE WHEN socialprice=0 THEN keyword ELSE keyword || ' ' || UDF_SOCIAL_GOODSNM(modelno_group,modelno) END AS KEYWORD,    
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    to_all
FROM tmp_es_goods_data_01    
WHERE mod_no = '0'

)

[2018-06-05T12:46:23,819][INFO ][logstash.inputs.jdbc     ] (3.437173s) select
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    DECODE(NVL(MODELNO_GROUP,0),0,0,1) AS MODELNO_GROUP_FLAG,
    category,
    '' as cg,
    '' as cat1,
    '' as cat2,
    '' as cat3,
    '' as cat4,
    ca_code,
    ca_dept_mcode,
    ca_dept_code,
    ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,
    shop_name,
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    '' as model_factory,
    minprice,
    maxprice,
    minprices,
    C_DATE,
    mallcnt,
    DECODE(NVL(MALLCNT,0),0,0,1) AS MALLCNT_FLAG,
    spec,
    openexpectflag,
    condiname,
    KEYWORD,
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    to_all
--    MODELNM || ' ' || FACTORY || ' ' || SPEC || ' ' || KEYWORD || ' ' || KEYWORD2 || ' ' || CONDINAME AS to_all
from (

select
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    CASE WHEN service_gubun='2' AND store_flag='1' AND ca_dept_code IS NOT NULL THEN RTRIM(category || ' '  || ca_dept_code) ELSE category END AS category,
    ca_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),3,8)='000000' OR SUBSTR(RTRIM(ca_dept_code),3,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,4) END AS ca_dept_mcode,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),5,8)='0000' OR SUBSTR(RTRIM(ca_dept_code),5,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,6) END AS ca_dept_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),7,8)='00' OR SUBSTR(RTRIM(ca_dept_code),7,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,8) END AS ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,    
    shop_name,    
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    model_factory,
    minprice,
    maxprice,
    replace(minprices, ' ', '    ') as minprices,
    C_DATE,
    mallcnt,
    replace(replace(spec,',',' '),'/',' ') spec,
    openexpectflag,
    replace(condiname, ' ', '    ') as condiname,    
    CASE WHEN socialprice=0 THEN keyword ELSE keyword || ' ' || UDF_SOCIAL_GOODSNM(modelno_group,modelno) END AS KEYWORD,    
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    to_all
FROM tmp_es_price_data_01
WHERE mod_no = '0'

)

[2018-06-05T12:46:24,040][INFO ][logstash.inputs.jdbc     ] (3.743302s) select
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    DECODE(NVL(MODELNO_GROUP,0),0,0,1) AS MODELNO_GROUP_FLAG,
    category,
    '' as cg,
    '' as cat1,
    '' as cat2,
    '' as cat3,
    '' as cat4,
    ca_code,
    ca_dept_mcode,
    ca_dept_code,
    ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,
    shop_name,
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    '' as model_factory,
    minprice,
    maxprice,
    minprices,
    C_DATE,
    mallcnt,
    DECODE(NVL(MALLCNT,0),0,0,1) AS MALLCNT_FLAG,
    spec,
    openexpectflag,
    condiname,
    KEYWORD,
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    to_all
--    MODELNM || ' ' || FACTORY || ' ' || SPEC || ' ' || KEYWORD || ' ' || KEYWORD2 || ' ' || CONDINAME AS to_all
from (

select
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    CASE WHEN service_gubun='2' AND store_flag='1' AND ca_dept_code IS NOT NULL THEN RTRIM(category || ' '  || ca_dept_code) ELSE category END AS category,
    ca_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),3,8)='000000' OR SUBSTR(RTRIM(ca_dept_code),3,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,4) END AS ca_dept_mcode,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),5,8)='0000' OR SUBSTR(RTRIM(ca_dept_code),5,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,6) END AS ca_dept_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),7,8)='00' OR SUBSTR(RTRIM(ca_dept_code),7,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,8) END AS ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,    
    shop_name,    
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    model_factory,
    minprice,
    maxprice,
    replace(minprices, ' ', '    ') as minprices,
    C_DATE,
    mallcnt,
    replace(replace(spec,',',' '),'/',' ') spec,
    openexpectflag,
    replace(condiname, ' ', '    ') as condiname,    
    CASE WHEN socialprice=0 THEN keyword ELSE keyword || ' ' || UDF_SOCIAL_GOODSNM(modelno_group,modelno) END AS KEYWORD,    
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    to_all
FROM tmp_es_price_data_01
WHERE mod_no = '1'

)

[2018-06-05T12:46:24,042][INFO ][logstash.inputs.jdbc     ] (3.740357s) select 
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    DECODE(NVL(MODELNO_GROUP,0),0,0,1) AS MODELNO_GROUP_FLAG,
    category,
    '' as cg,
    '' as cat1,
    '' as cat2,
    '' as cat3,
    '' as cat4,
    ca_code,
    ca_dept_mcode,
    ca_dept_code,
    ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,
    shop_name,
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    MODELNM || ' ' || FACTORY as model_factory,
    minprice,
    maxprice,
    minprices,
    C_DATE,
    mallcnt,
    DECODE(NVL(MALLCNT,0),0,0,1) AS MALLCNT_FLAG,
    spec,
    openexpectflag,
    condiname,
    KEYWORD,
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    to_all
--    MODELNM || ' ' || FACTORY || ' ' || SPEC || ' ' || KEYWORD || ' ' || KEYWORD2 || ' ' || CONDINAME AS to_all
from (

select
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    CASE WHEN service_gubun='2' AND store_flag='1' AND ca_dept_code IS NOT NULL THEN RTRIM(category || ' '  || ca_dept_code) ELSE category END AS category,
    ca_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),3,8)='000000' OR SUBSTR(RTRIM(ca_dept_code),3,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,4) END AS ca_dept_mcode,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),5,8)='0000' OR SUBSTR(RTRIM(ca_dept_code),5,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,6) END AS ca_dept_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),7,8)='00' OR SUBSTR(RTRIM(ca_dept_code),7,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,8) END AS ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,    
    shop_name,    
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    model_factory,
    minprice,
    maxprice,
    replace(minprices, ' ', '    ') as minprices,
    C_DATE,
    mallcnt,
    replace(replace(spec,',',' '),'/',' ') spec,
    openexpectflag,
    replace(condiname, ' ', '    ') as condiname,    
    CASE WHEN socialprice=0 THEN keyword ELSE keyword || ' ' || UDF_SOCIAL_GOODSNM(modelno_group,modelno) END AS KEYWORD,    
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    to_all
FROM tmp_es_goods_data_01    
WHERE mod_no = '1'

)

[2018-06-05T12:46:25,511][INFO ][logstash.inputs.jdbc     ] (2.490808s) select 
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    DECODE(NVL(MODELNO_GROUP,0),0,0,1) AS MODELNO_GROUP_FLAG,
    category,
    '' as cg,
    '' as cat1,
    '' as cat2,
    '' as cat3,
    '' as cat4,
    ca_code,
    ca_dept_mcode,
    ca_dept_code,
    ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,
    shop_name,
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    MODELNM || ' ' || FACTORY as model_factory,
    minprice,
    maxprice,
    minprices,
    C_DATE,
    mallcnt,
    DECODE(NVL(MALLCNT,0),0,0,1) AS MALLCNT_FLAG,
    spec,
    openexpectflag,
    condiname,
    KEYWORD,
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    to_all
--    MODELNM || ' ' || FACTORY || ' ' || SPEC || ' ' || KEYWORD || ' ' || KEYWORD2 || ' ' || CONDINAME AS to_all
from (

select
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    CASE WHEN service_gubun='2' AND store_flag='1' AND ca_dept_code IS NOT NULL THEN RTRIM(category || ' '  || ca_dept_code) ELSE category END AS category,
    ca_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),3,8)='000000' OR SUBSTR(RTRIM(ca_dept_code),3,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,4) END AS ca_dept_mcode,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),5,8)='0000' OR SUBSTR(RTRIM(ca_dept_code),5,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,6) END AS ca_dept_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),7,8)='00' OR SUBSTR(RTRIM(ca_dept_code),7,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,8) END AS ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,    
    shop_name,    
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    model_factory,
    minprice,
    maxprice,
    replace(minprices, ' ', '    ') as minprices,
    C_DATE,
    mallcnt,
    replace(replace(spec,',',' '),'/',' ') spec,
    openexpectflag,
    replace(condiname, ' ', '    ') as condiname,    
    CASE WHEN socialprice=0 THEN keyword ELSE keyword || ' ' || UDF_SOCIAL_GOODSNM(modelno_group,modelno) END AS KEYWORD,    
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    to_all
FROM tmp_es_goods_data_01    
WHERE mod_no = '2'

)

[2018-06-05T12:46:25,516][INFO ][logstash.inputs.jdbc     ] (2.490712s) select
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    DECODE(NVL(MODELNO_GROUP,0),0,0,1) AS MODELNO_GROUP_FLAG,
    category,
    '' as cg,
    '' as cat1,
    '' as cat2,
    '' as cat3,
    '' as cat4,
    ca_code,
    ca_dept_mcode,
    ca_dept_code,
    ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,
    shop_name,
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    '' as model_factory,
    minprice,
    maxprice,
    minprices,
    C_DATE,
    mallcnt,
    DECODE(NVL(MALLCNT,0),0,0,1) AS MALLCNT_FLAG,
    spec,
    openexpectflag,
    condiname,
    KEYWORD,
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    to_all
--    MODELNM || ' ' || FACTORY || ' ' || SPEC || ' ' || KEYWORD || ' ' || KEYWORD2 || ' ' || CONDINAME AS to_all
from (

select
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    CASE WHEN service_gubun='2' AND store_flag='1' AND ca_dept_code IS NOT NULL THEN RTRIM(category || ' '  || ca_dept_code) ELSE category END AS category,
    ca_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),3,8)='000000' OR SUBSTR(RTRIM(ca_dept_code),3,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,4) END AS ca_dept_mcode,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),5,8)='0000' OR SUBSTR(RTRIM(ca_dept_code),5,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,6) END AS ca_dept_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),7,8)='00' OR SUBSTR(RTRIM(ca_dept_code),7,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,8) END AS ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,    
    shop_name,    
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    model_factory,
    minprice,
    maxprice,
    replace(minprices, ' ', '    ') as minprices,
    C_DATE,
    mallcnt,
    replace(replace(spec,',',' '),'/',' ') spec,
    openexpectflag,
    replace(condiname, ' ', '    ') as condiname,    
    CASE WHEN socialprice=0 THEN keyword ELSE keyword || ' ' || UDF_SOCIAL_GOODSNM(modelno_group,modelno) END AS KEYWORD,    
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    to_all
FROM tmp_es_price_data_01
WHERE mod_no = '2'

)

[2018-06-05T12:51:34,127][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"fb_apache", :directory=>"/usr/share/logstash/modules/fb_apache/configuration"}
[2018-06-05T12:51:34,175][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"netflow", :directory=>"/usr/share/logstash/modules/netflow/configuration"}
[2018-06-05T12:51:34,553][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"fb_apache", :directory=>"/usr/share/logstash/modules/fb_apache/configuration"}
[2018-06-05T12:51:34,560][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"netflow", :directory=>"/usr/share/logstash/modules/netflow/configuration"}
[2018-06-05T12:51:35,512][WARN ][logstash.config.source.multilocal] Ignoring the 'pipelines.yml' file because modules or command line options are specified
[2018-06-05T12:51:36,015][WARN ][logstash.config.source.multilocal] Ignoring the 'pipelines.yml' file because modules or command line options are specified
[2018-06-05T12:51:36,033][INFO ][logstash.runner          ] Starting Logstash {"logstash.version"=>"6.2.3"}
[2018-06-05T12:51:36,575][INFO ][logstash.runner          ] Starting Logstash {"logstash.version"=>"6.2.3"}
[2018-06-05T12:51:36,991][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=>9600}
[2018-06-05T12:51:37,316][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=>9601}
[2018-06-05T12:51:37,638][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"fb_apache", :directory=>"/usr/share/logstash/modules/fb_apache/configuration"}
[2018-06-05T12:51:37,648][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"netflow", :directory=>"/usr/share/logstash/modules/netflow/configuration"}
[2018-06-05T12:51:38,145][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"fb_apache", :directory=>"/usr/share/logstash/modules/fb_apache/configuration"}
[2018-06-05T12:51:38,170][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"netflow", :directory=>"/usr/share/logstash/modules/netflow/configuration"}
[2018-06-05T12:51:39,216][WARN ][logstash.config.source.multilocal] Ignoring the 'pipelines.yml' file because modules or command line options are specified
[2018-06-05T12:51:39,539][WARN ][logstash.config.source.multilocal] Ignoring the 'pipelines.yml' file because modules or command line options are specified
[2018-06-05T12:51:39,570][DEBUG][org.logstash.secret.store.SecretStoreFactory] Attempting to exists or secret store with implementation: org.logstash.secret.store.backend.JavaKeyStore
[2018-06-05T12:51:39,614][INFO ][logstash.runner          ] Starting Logstash {"logstash.version"=>"6.2.3"}
[2018-06-05T12:51:39,781][DEBUG][org.logstash.secret.store.SecretStoreFactory] Attempting to exists or secret store with implementation: org.logstash.secret.store.backend.JavaKeyStore
[2018-06-05T12:51:39,972][INFO ][logstash.filters.ruby.script] Test run complete {:script_path=>"rubyfilter.rb", :results=>{:passed=>0, :failed=>0, :errored=>0}}
[2018-06-05T12:51:40,029][INFO ][logstash.runner          ] Starting Logstash {"logstash.version"=>"6.2.3"}
[2018-06-05T12:51:40,181][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=>9602}
[2018-06-05T12:51:40,261][DEBUG][org.logstash.secret.store.SecretStoreFactory] Attempting to exists or secret store with implementation: org.logstash.secret.store.backend.JavaKeyStore
[2018-06-05T12:51:40,310][WARN ][logstash.outputs.elasticsearch] You are using a deprecated config setting "document_type" set in elasticsearch. Deprecated settings will continue to work, but are scheduled for removal from logstash in the future. Document types are being deprecated in Elasticsearch 6.0, and removed entirely in 7.0. You should avoid this feature If you have any questions about this, please visit the #logstash channel on freenode irc. {:name=>"document_type", :plugin=><LogStash::Outputs::ElasticSearch hosts=>[//100.100.100.111:9200, //100.100.100.112:9200, //100.100.100.113:9200], index=>"qa-enuri-main-as-is-2018.06.05.03.50", document_type=>"_doc", document_id=>"%{id}", action=>"index", id=>"6ecd11524c84e5de286546b0de40f57503392aeab1548c7913e69855f4645bbc", enable_metric=>true, codec=><LogStash::Codecs::Plain id=>"plain_cb685d3c-29fe-4859-a4f7-7cb7fbfe4f44", enable_metric=>true, charset=>"UTF-8">, workers=>1, manage_template=>true, template_name=>"logstash", template_overwrite=>false, doc_as_upsert=>false, script_type=>"inline", script_lang=>"painless", script_var_name=>"event", scripted_upsert=>false, retry_initial_interval=>2, retry_max_interval=>64, retry_on_conflict=>1, ssl_certificate_verification=>true, sniffing=>false, sniffing_delay=>5, timeout=>60, pool_max=>1000, pool_max_per_route=>100, resurrect_delay=>5, validate_after_inactivity=>10000, http_compression=>false>}
[2018-06-05T12:51:40,322][INFO ][logstash.pipeline        ] Starting pipeline {:pipeline_id=>"main", "pipeline.workers"=>8, "pipeline.batch.size"=>125, "pipeline.batch.delay"=>50}
[2018-06-05T12:51:40,333][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"fb_apache", :directory=>"/usr/share/logstash/modules/fb_apache/configuration"}
[2018-06-05T12:51:40,359][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"netflow", :directory=>"/usr/share/logstash/modules/netflow/configuration"}
[2018-06-05T12:51:40,384][DEBUG][org.logstash.secret.store.SecretStoreFactory] Attempting to exists or secret store with implementation: org.logstash.secret.store.backend.JavaKeyStore
[2018-06-05T12:51:40,387][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"fb_apache", :directory=>"/usr/share/logstash/modules/fb_apache/configuration"}
[2018-06-05T12:51:40,445][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"netflow", :directory=>"/usr/share/logstash/modules/netflow/configuration"}
[2018-06-05T12:51:40,632][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=>9603}
[2018-06-05T12:51:40,778][DEBUG][org.logstash.secret.store.SecretStoreFactory] Attempting to exists or secret store with implementation: org.logstash.secret.store.backend.JavaKeyStore
[2018-06-05T12:51:41,041][INFO ][logstash.filters.ruby.script] Test run complete {:script_path=>"rubyfilter.rb", :results=>{:passed=>0, :failed=>0, :errored=>0}}
[2018-06-05T12:51:41,361][DEBUG][org.logstash.secret.store.SecretStoreFactory] Attempting to exists or secret store with implementation: org.logstash.secret.store.backend.JavaKeyStore
[2018-06-05T12:51:41,649][WARN ][logstash.outputs.elasticsearch] You are using a deprecated config setting "document_type" set in elasticsearch. Deprecated settings will continue to work, but are scheduled for removal from logstash in the future. Document types are being deprecated in Elasticsearch 6.0, and removed entirely in 7.0. You should avoid this feature If you have any questions about this, please visit the #logstash channel on freenode irc. {:name=>"document_type", :plugin=><LogStash::Outputs::ElasticSearch hosts=>[//100.100.100.111:9200, //100.100.100.112:9200, //100.100.100.113:9200], index=>"qa-enuri-main-as-is-2018.06.05.03.50", document_type=>"_doc", document_id=>"%{id}", action=>"index", id=>"6ecd11524c84e5de286546b0de40f57503392aeab1548c7913e69855f4645bbc", enable_metric=>true, codec=><LogStash::Codecs::Plain id=>"plain_428e8a3b-6ebd-4125-b339-601a86e3458b", enable_metric=>true, charset=>"UTF-8">, workers=>1, manage_template=>true, template_name=>"logstash", template_overwrite=>false, doc_as_upsert=>false, script_type=>"inline", script_lang=>"painless", script_var_name=>"event", scripted_upsert=>false, retry_initial_interval=>2, retry_max_interval=>64, retry_on_conflict=>1, ssl_certificate_verification=>true, sniffing=>false, sniffing_delay=>5, timeout=>60, pool_max=>1000, pool_max_per_route=>100, resurrect_delay=>5, validate_after_inactivity=>10000, http_compression=>false>}
[2018-06-05T12:51:41,683][INFO ][logstash.outputs.elasticsearch] Elasticsearch pool URLs updated {:changes=>{:removed=>[], :added=>[http://100.100.100.111:9200/, http://100.100.100.112:9200/, http://100.100.100.113:9200/]}}
[2018-06-05T12:51:41,742][INFO ][logstash.pipeline        ] Starting pipeline {:pipeline_id=>"main", "pipeline.workers"=>8, "pipeline.batch.size"=>125, "pipeline.batch.delay"=>50}
[2018-06-05T12:51:41,746][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://100.100.100.111:9200/, :path=>"/"}
[2018-06-05T12:51:42,010][WARN ][logstash.config.source.multilocal] Ignoring the 'pipelines.yml' file because modules or command line options are specified
[2018-06-05T12:51:42,038][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://100.100.100.111:9200/"}
[2018-06-05T12:51:42,081][WARN ][logstash.config.source.multilocal] Ignoring the 'pipelines.yml' file because modules or command line options are specified
[2018-06-05T12:51:42,142][INFO ][logstash.outputs.elasticsearch] ES Output version determined {:es_version=>6}
[2018-06-05T12:51:42,142][WARN ][logstash.outputs.elasticsearch] Detected a 6.x and above cluster: the `type` event field won't be used to determine the document _type {:es_version=>6}
[2018-06-05T12:51:42,143][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://100.100.100.112:9200/, :path=>"/"}
[2018-06-05T12:51:42,196][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://100.100.100.112:9200/"}
[2018-06-05T12:51:42,208][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://100.100.100.113:9200/, :path=>"/"}
[2018-06-05T12:51:42,226][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://100.100.100.113:9200/"}
[2018-06-05T12:51:42,266][INFO ][logstash.outputs.elasticsearch] Using mapping template from {:path=>nil}
[2018-06-05T12:51:42,322][INFO ][logstash.outputs.elasticsearch] Attempting to install template {:manage_template=>{"template"=>"logstash-*", "version"=>60001, "settings"=>{"index.refresh_interval"=>"5s"}, "mappings"=>{"_default_"=>{"dynamic_templates"=>[{"message_field"=>{"path_match"=>"message", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false}}}, {"string_fields"=>{"match"=>"*", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false, "fields"=>{"keyword"=>{"type"=>"keyword", "ignore_above"=>256}}}}}], "properties"=>{"@timestamp"=>{"type"=>"date"}, "@version"=>{"type"=>"keyword"}, "geoip"=>{"dynamic"=>true, "properties"=>{"ip"=>{"type"=>"ip"}, "location"=>{"type"=>"geo_point"}, "latitude"=>{"type"=>"half_float"}, "longitude"=>{"type"=>"half_float"}}}}}}}}
[2018-06-05T12:51:42,362][INFO ][logstash.outputs.elasticsearch] New Elasticsearch output {:class=>"LogStash::Outputs::ElasticSearch", :hosts=>["//100.100.100.111:9200", "//100.100.100.112:9200", "//100.100.100.113:9200"]}
[2018-06-05T12:51:42,598][INFO ][logstash.runner          ] Starting Logstash {"logstash.version"=>"6.2.3"}
[2018-06-05T12:51:42,679][DEBUG][org.logstash.secret.store.SecretStoreFactory] Attempting to exists or secret store with implementation: org.logstash.secret.store.backend.JavaKeyStore
[2018-06-05T12:51:42,806][DEBUG][org.logstash.secret.store.SecretStoreFactory] Attempting to exists or secret store with implementation: org.logstash.secret.store.backend.JavaKeyStore
[2018-06-05T12:51:42,864][INFO ][logstash.runner          ] Starting Logstash {"logstash.version"=>"6.2.3"}
[2018-06-05T12:51:42,891][DEBUG][org.logstash.secret.store.SecretStoreFactory] Attempting to exists or secret store with implementation: org.logstash.secret.store.backend.JavaKeyStore
[2018-06-05T12:51:43,021][DEBUG][org.logstash.secret.store.SecretStoreFactory] Attempting to exists or secret store with implementation: org.logstash.secret.store.backend.JavaKeyStore
[2018-06-05T12:51:43,143][INFO ][logstash.outputs.elasticsearch] Elasticsearch pool URLs updated {:changes=>{:removed=>[], :added=>[http://100.100.100.111:9200/, http://100.100.100.112:9200/, http://100.100.100.113:9200/]}}
[2018-06-05T12:51:43,146][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://100.100.100.111:9200/, :path=>"/"}
[2018-06-05T12:51:43,163][INFO ][logstash.filters.ruby.script] Test run complete {:script_path=>"rubyfilter.rb", :results=>{:passed=>0, :failed=>0, :errored=>0}}
[2018-06-05T12:51:43,316][INFO ][logstash.filters.ruby.script] Test run complete {:script_path=>"rubyfilter.rb", :results=>{:passed=>0, :failed=>0, :errored=>0}}
[2018-06-05T12:51:43,289][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=>9604}
[2018-06-05T12:51:43,460][DEBUG][org.logstash.secret.store.SecretStoreFactory] Attempting to exists or secret store with implementation: org.logstash.secret.store.backend.JavaKeyStore
[2018-06-05T12:51:43,493][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://100.100.100.111:9200/"}
[2018-06-05T12:51:43,476][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=>9605}
[2018-06-05T12:51:43,527][WARN ][logstash.outputs.elasticsearch] You are using a deprecated config setting "document_type" set in elasticsearch. Deprecated settings will continue to work, but are scheduled for removal from logstash in the future. Document types are being deprecated in Elasticsearch 6.0, and removed entirely in 7.0. You should avoid this feature If you have any questions about this, please visit the #logstash channel on freenode irc. {:name=>"document_type", :plugin=><LogStash::Outputs::ElasticSearch hosts=>[//100.100.100.111:9200, //100.100.100.112:9200, //100.100.100.113:9200], index=>"qa-enuri-main-as-is-2018.06.05.03.50", document_type=>"_doc", document_id=>"%{id}", action=>"index", id=>"6ecd11524c84e5de286546b0de40f57503392aeab1548c7913e69855f4645bbc", enable_metric=>true, codec=><LogStash::Codecs::Plain id=>"plain_06efdfbd-ee39-45af-bf93-75152af96e30", enable_metric=>true, charset=>"UTF-8">, workers=>1, manage_template=>true, template_name=>"logstash", template_overwrite=>false, doc_as_upsert=>false, script_type=>"inline", script_lang=>"painless", script_var_name=>"event", scripted_upsert=>false, retry_initial_interval=>2, retry_max_interval=>64, retry_on_conflict=>1, ssl_certificate_verification=>true, sniffing=>false, sniffing_delay=>5, timeout=>60, pool_max=>1000, pool_max_per_route=>100, resurrect_delay=>5, validate_after_inactivity=>10000, http_compression=>false>}
[2018-06-05T12:51:43,562][INFO ][logstash.outputs.elasticsearch] ES Output version determined {:es_version=>6}
[2018-06-05T12:51:43,562][WARN ][logstash.outputs.elasticsearch] Detected a 6.x and above cluster: the `type` event field won't be used to determine the document _type {:es_version=>6}
[2018-06-05T12:51:43,563][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://100.100.100.112:9200/, :path=>"/"}
[2018-06-05T12:51:43,607][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://100.100.100.112:9200/"}
[2018-06-05T12:51:43,610][INFO ][logstash.pipeline        ] Pipeline started succesfully {:pipeline_id=>"main", :thread=>"#<Thread:0x1b79825f@/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:246 sleep>"}
[2018-06-05T12:51:43,612][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://100.100.100.113:9200/, :path=>"/"}
[2018-06-05T12:51:43,616][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://100.100.100.113:9200/"}
[2018-06-05T12:51:43,627][INFO ][logstash.pipeline        ] Starting pipeline {:pipeline_id=>"main", "pipeline.workers"=>8, "pipeline.batch.size"=>125, "pipeline.batch.delay"=>50}
[2018-06-05T12:51:43,632][INFO ][logstash.agent           ] Pipelines running {:count=>1, :pipelines=>["main"]}
[2018-06-05T12:51:43,655][INFO ][logstash.outputs.elasticsearch] Using mapping template from {:path=>nil}
[2018-06-05T12:51:43,665][DEBUG][org.logstash.secret.store.SecretStoreFactory] Attempting to exists or secret store with implementation: org.logstash.secret.store.backend.JavaKeyStore
[2018-06-05T12:51:43,666][INFO ][logstash.outputs.elasticsearch] Attempting to install template {:manage_template=>{"template"=>"logstash-*", "version"=>60001, "settings"=>{"index.refresh_interval"=>"5s"}, "mappings"=>{"_default_"=>{"dynamic_templates"=>[{"message_field"=>{"path_match"=>"message", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false}}}, {"string_fields"=>{"match"=>"*", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false, "fields"=>{"keyword"=>{"type"=>"keyword", "ignore_above"=>256}}}}}], "properties"=>{"@timestamp"=>{"type"=>"date"}, "@version"=>{"type"=>"keyword"}, "geoip"=>{"dynamic"=>true, "properties"=>{"ip"=>{"type"=>"ip"}, "location"=>{"type"=>"geo_point"}, "latitude"=>{"type"=>"half_float"}, "longitude"=>{"type"=>"half_float"}}}}}}}}
[2018-06-05T12:51:43,718][INFO ][logstash.outputs.elasticsearch] New Elasticsearch output {:class=>"LogStash::Outputs::ElasticSearch", :hosts=>["//100.100.100.111:9200", "//100.100.100.112:9200", "//100.100.100.113:9200"]}
[2018-06-05T12:51:43,762][WARN ][logstash.outputs.elasticsearch] You are using a deprecated config setting "document_type" set in elasticsearch. Deprecated settings will continue to work, but are scheduled for removal from logstash in the future. Document types are being deprecated in Elasticsearch 6.0, and removed entirely in 7.0. You should avoid this feature If you have any questions about this, please visit the #logstash channel on freenode irc. {:name=>"document_type", :plugin=><LogStash::Outputs::ElasticSearch hosts=>[//100.100.100.111:9200, //100.100.100.112:9200, //100.100.100.113:9200], index=>"qa-enuri-main-as-is-2018.06.05.03.50", document_type=>"_doc", document_id=>"%{id}", action=>"index", id=>"6ecd11524c84e5de286546b0de40f57503392aeab1548c7913e69855f4645bbc", enable_metric=>true, codec=><LogStash::Codecs::Plain id=>"plain_59da51ca-b1e9-4c97-a16e-7984ade6c1aa", enable_metric=>true, charset=>"UTF-8">, workers=>1, manage_template=>true, template_name=>"logstash", template_overwrite=>false, doc_as_upsert=>false, script_type=>"inline", script_lang=>"painless", script_var_name=>"event", scripted_upsert=>false, retry_initial_interval=>2, retry_max_interval=>64, retry_on_conflict=>1, ssl_certificate_verification=>true, sniffing=>false, sniffing_delay=>5, timeout=>60, pool_max=>1000, pool_max_per_route=>100, resurrect_delay=>5, validate_after_inactivity=>10000, http_compression=>false>}
[2018-06-05T12:51:43,783][INFO ][logstash.pipeline        ] Starting pipeline {:pipeline_id=>"main", "pipeline.workers"=>8, "pipeline.batch.size"=>125, "pipeline.batch.delay"=>50}
[2018-06-05T12:51:44,510][INFO ][logstash.outputs.elasticsearch] Elasticsearch pool URLs updated {:changes=>{:removed=>[], :added=>[http://100.100.100.111:9200/, http://100.100.100.112:9200/, http://100.100.100.113:9200/]}}
[2018-06-05T12:51:44,519][INFO ][logstash.pipeline        ] Pipeline started succesfully {:pipeline_id=>"main", :thread=>"#<Thread:0x79c588d8@/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:246 run>"}
[2018-06-05T12:51:44,542][INFO ][logstash.agent           ] Pipelines running {:count=>1, :pipelines=>["main"]}
[2018-06-05T12:51:44,551][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://100.100.100.111:9200/, :path=>"/"}
[2018-06-05T12:51:44,731][INFO ][logstash.outputs.elasticsearch] Elasticsearch pool URLs updated {:changes=>{:removed=>[], :added=>[http://100.100.100.111:9200/, http://100.100.100.112:9200/, http://100.100.100.113:9200/]}}
[2018-06-05T12:51:44,734][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://100.100.100.111:9200/, :path=>"/"}
[2018-06-05T12:51:45,202][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://100.100.100.111:9200/"}
[2018-06-05T12:51:45,226][DEBUG][org.logstash.secret.store.SecretStoreFactory] Attempting to exists or secret store with implementation: org.logstash.secret.store.backend.JavaKeyStore
[2018-06-05T12:51:45,325][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://100.100.100.111:9200/"}
[2018-06-05T12:51:45,356][DEBUG][org.logstash.secret.store.SecretStoreFactory] Attempting to exists or secret store with implementation: org.logstash.secret.store.backend.JavaKeyStore
[2018-06-05T12:51:45,489][INFO ][logstash.outputs.elasticsearch] ES Output version determined {:es_version=>6}
[2018-06-05T12:51:45,490][WARN ][logstash.outputs.elasticsearch] Detected a 6.x and above cluster: the `type` event field won't be used to determine the document _type {:es_version=>6}
[2018-06-05T12:51:45,490][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://100.100.100.112:9200/, :path=>"/"}
[2018-06-05T12:51:45,511][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://100.100.100.112:9200/"}
[2018-06-05T12:51:45,517][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://100.100.100.113:9200/, :path=>"/"}
[2018-06-05T12:51:45,519][DEBUG][org.logstash.secret.store.SecretStoreFactory] Attempting to exists or secret store with implementation: org.logstash.secret.store.backend.JavaKeyStore
[2018-06-05T12:51:45,526][INFO ][logstash.outputs.elasticsearch] ES Output version determined {:es_version=>6}
[2018-06-05T12:51:45,527][WARN ][logstash.outputs.elasticsearch] Detected a 6.x and above cluster: the `type` event field won't be used to determine the document _type {:es_version=>6}
[2018-06-05T12:51:45,527][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://100.100.100.112:9200/, :path=>"/"}
[2018-06-05T12:51:45,528][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://100.100.100.113:9200/"}
[2018-06-05T12:51:45,558][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://100.100.100.112:9200/"}
[2018-06-05T12:51:45,567][DEBUG][org.logstash.secret.store.SecretStoreFactory] Attempting to exists or secret store with implementation: org.logstash.secret.store.backend.JavaKeyStore
[2018-06-05T12:51:45,591][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://100.100.100.113:9200/, :path=>"/"}
[2018-06-05T12:51:45,602][INFO ][logstash.outputs.elasticsearch] Using mapping template from {:path=>nil}
[2018-06-05T12:51:45,636][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://100.100.100.113:9200/"}
[2018-06-05T12:51:45,665][INFO ][logstash.outputs.elasticsearch] Attempting to install template {:manage_template=>{"template"=>"logstash-*", "version"=>60001, "settings"=>{"index.refresh_interval"=>"5s"}, "mappings"=>{"_default_"=>{"dynamic_templates"=>[{"message_field"=>{"path_match"=>"message", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false}}}, {"string_fields"=>{"match"=>"*", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false, "fields"=>{"keyword"=>{"type"=>"keyword", "ignore_above"=>256}}}}}], "properties"=>{"@timestamp"=>{"type"=>"date"}, "@version"=>{"type"=>"keyword"}, "geoip"=>{"dynamic"=>true, "properties"=>{"ip"=>{"type"=>"ip"}, "location"=>{"type"=>"geo_point"}, "latitude"=>{"type"=>"half_float"}, "longitude"=>{"type"=>"half_float"}}}}}}}}
[2018-06-05T12:51:45,687][INFO ][logstash.outputs.elasticsearch] New Elasticsearch output {:class=>"LogStash::Outputs::ElasticSearch", :hosts=>["//100.100.100.111:9200", "//100.100.100.112:9200", "//100.100.100.113:9200"]}
[2018-06-05T12:51:45,715][INFO ][logstash.outputs.elasticsearch] Using mapping template from {:path=>nil}
[2018-06-05T12:51:45,725][INFO ][logstash.outputs.elasticsearch] Attempting to install template {:manage_template=>{"template"=>"logstash-*", "version"=>60001, "settings"=>{"index.refresh_interval"=>"5s"}, "mappings"=>{"_default_"=>{"dynamic_templates"=>[{"message_field"=>{"path_match"=>"message", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false}}}, {"string_fields"=>{"match"=>"*", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false, "fields"=>{"keyword"=>{"type"=>"keyword", "ignore_above"=>256}}}}}], "properties"=>{"@timestamp"=>{"type"=>"date"}, "@version"=>{"type"=>"keyword"}, "geoip"=>{"dynamic"=>true, "properties"=>{"ip"=>{"type"=>"ip"}, "location"=>{"type"=>"geo_point"}, "latitude"=>{"type"=>"half_float"}, "longitude"=>{"type"=>"half_float"}}}}}}}}
[2018-06-05T12:51:45,739][INFO ][logstash.outputs.elasticsearch] New Elasticsearch output {:class=>"LogStash::Outputs::ElasticSearch", :hosts=>["//100.100.100.111:9200", "//100.100.100.112:9200", "//100.100.100.113:9200"]}
[2018-06-05T12:51:45,801][INFO ][logstash.filters.ruby.script] Test run complete {:script_path=>"rubyfilter.rb", :results=>{:passed=>0, :failed=>0, :errored=>0}}
[2018-06-05T12:51:45,820][INFO ][logstash.filters.ruby.script] Test run complete {:script_path=>"rubyfilter.rb", :results=>{:passed=>0, :failed=>0, :errored=>0}}
[2018-06-05T12:51:46,015][DEBUG][org.logstash.secret.store.SecretStoreFactory] Attempting to exists or secret store with implementation: org.logstash.secret.store.backend.JavaKeyStore
[2018-06-05T12:51:46,101][WARN ][logstash.outputs.elasticsearch] You are using a deprecated config setting "document_type" set in elasticsearch. Deprecated settings will continue to work, but are scheduled for removal from logstash in the future. Document types are being deprecated in Elasticsearch 6.0, and removed entirely in 7.0. You should avoid this feature If you have any questions about this, please visit the #logstash channel on freenode irc. {:name=>"document_type", :plugin=><LogStash::Outputs::ElasticSearch hosts=>[//100.100.100.111:9200, //100.100.100.112:9200, //100.100.100.113:9200], index=>"qa-enuri-main-as-is-2018.06.05.03.50", document_type=>"_doc", document_id=>"%{id}", action=>"index", id=>"6ecd11524c84e5de286546b0de40f57503392aeab1548c7913e69855f4645bbc", enable_metric=>true, codec=><LogStash::Codecs::Plain id=>"plain_936c0a39-54f6-470a-b610-a7a11095324e", enable_metric=>true, charset=>"UTF-8">, workers=>1, manage_template=>true, template_name=>"logstash", template_overwrite=>false, doc_as_upsert=>false, script_type=>"inline", script_lang=>"painless", script_var_name=>"event", scripted_upsert=>false, retry_initial_interval=>2, retry_max_interval=>64, retry_on_conflict=>1, ssl_certificate_verification=>true, sniffing=>false, sniffing_delay=>5, timeout=>60, pool_max=>1000, pool_max_per_route=>100, resurrect_delay=>5, validate_after_inactivity=>10000, http_compression=>false>}
[2018-06-05T12:51:46,120][DEBUG][org.logstash.secret.store.SecretStoreFactory] Attempting to exists or secret store with implementation: org.logstash.secret.store.backend.JavaKeyStore
[2018-06-05T12:51:46,138][INFO ][logstash.pipeline        ] Pipeline started succesfully {:pipeline_id=>"main", :thread=>"#<Thread:0x3627f881@/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:246 run>"}
[2018-06-05T12:51:46,156][INFO ][logstash.agent           ] Pipelines running {:count=>1, :pipelines=>["main"]}
[2018-06-05T12:51:46,193][INFO ][logstash.pipeline        ] Starting pipeline {:pipeline_id=>"main", "pipeline.workers"=>8, "pipeline.batch.size"=>125, "pipeline.batch.delay"=>50}
[2018-06-05T12:51:46,217][WARN ][logstash.outputs.elasticsearch] You are using a deprecated config setting "document_type" set in elasticsearch. Deprecated settings will continue to work, but are scheduled for removal from logstash in the future. Document types are being deprecated in Elasticsearch 6.0, and removed entirely in 7.0. You should avoid this feature If you have any questions about this, please visit the #logstash channel on freenode irc. {:name=>"document_type", :plugin=><LogStash::Outputs::ElasticSearch hosts=>[//100.100.100.111:9200, //100.100.100.112:9200, //100.100.100.113:9200], index=>"qa-enuri-main-as-is-2018.06.05.03.50", document_type=>"_doc", document_id=>"%{id}", action=>"index", id=>"6ecd11524c84e5de286546b0de40f57503392aeab1548c7913e69855f4645bbc", enable_metric=>true, codec=><LogStash::Codecs::Plain id=>"plain_bc08ab67-9f83-4e35-8afc-4dee95579aa5", enable_metric=>true, charset=>"UTF-8">, workers=>1, manage_template=>true, template_name=>"logstash", template_overwrite=>false, doc_as_upsert=>false, script_type=>"inline", script_lang=>"painless", script_var_name=>"event", scripted_upsert=>false, retry_initial_interval=>2, retry_max_interval=>64, retry_on_conflict=>1, ssl_certificate_verification=>true, sniffing=>false, sniffing_delay=>5, timeout=>60, pool_max=>1000, pool_max_per_route=>100, resurrect_delay=>5, validate_after_inactivity=>10000, http_compression=>false>}
[2018-06-05T12:51:46,243][INFO ][logstash.pipeline        ] Starting pipeline {:pipeline_id=>"main", "pipeline.workers"=>8, "pipeline.batch.size"=>125, "pipeline.batch.delay"=>50}
[2018-06-05T12:51:46,639][INFO ][logstash.pipeline        ] Pipeline started succesfully {:pipeline_id=>"main", :thread=>"#<Thread:0x7dbae797@/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:246 run>"}
[2018-06-05T12:51:46,865][INFO ][logstash.agent           ] Pipelines running {:count=>1, :pipelines=>["main"]}
[2018-06-05T12:51:47,016][INFO ][logstash.outputs.elasticsearch] Elasticsearch pool URLs updated {:changes=>{:removed=>[], :added=>[http://100.100.100.111:9200/, http://100.100.100.112:9200/, http://100.100.100.113:9200/]}}
[2018-06-05T12:51:47,019][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://100.100.100.111:9200/, :path=>"/"}
[2018-06-05T12:51:47,151][INFO ][logstash.outputs.elasticsearch] Elasticsearch pool URLs updated {:changes=>{:removed=>[], :added=>[http://100.100.100.111:9200/, http://100.100.100.112:9200/, http://100.100.100.113:9200/]}}
[2018-06-05T12:51:47,159][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://100.100.100.111:9200/, :path=>"/"}
[2018-06-05T12:51:47,305][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://100.100.100.111:9200/"}
[2018-06-05T12:51:47,475][INFO ][logstash.outputs.elasticsearch] ES Output version determined {:es_version=>6}
[2018-06-05T12:51:47,476][WARN ][logstash.outputs.elasticsearch] Detected a 6.x and above cluster: the `type` event field won't be used to determine the document _type {:es_version=>6}
[2018-06-05T12:51:47,479][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://100.100.100.112:9200/, :path=>"/"}
[2018-06-05T12:51:47,559][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://100.100.100.112:9200/"}
[2018-06-05T12:51:47,566][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://100.100.100.113:9200/, :path=>"/"}
[2018-06-05T12:51:47,576][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://100.100.100.113:9200/"}
[2018-06-05T12:51:47,674][INFO ][logstash.outputs.elasticsearch] Using mapping template from {:path=>nil}
[2018-06-05T12:51:47,695][INFO ][logstash.outputs.elasticsearch] Attempting to install template {:manage_template=>{"template"=>"logstash-*", "version"=>60001, "settings"=>{"index.refresh_interval"=>"5s"}, "mappings"=>{"_default_"=>{"dynamic_templates"=>[{"message_field"=>{"path_match"=>"message", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false}}}, {"string_fields"=>{"match"=>"*", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false, "fields"=>{"keyword"=>{"type"=>"keyword", "ignore_above"=>256}}}}}], "properties"=>{"@timestamp"=>{"type"=>"date"}, "@version"=>{"type"=>"keyword"}, "geoip"=>{"dynamic"=>true, "properties"=>{"ip"=>{"type"=>"ip"}, "location"=>{"type"=>"geo_point"}, "latitude"=>{"type"=>"half_float"}, "longitude"=>{"type"=>"half_float"}}}}}}}}
[2018-06-05T12:51:47,700][INFO ][logstash.inputs.jdbc     ] (1.932114s) select
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    DECODE(NVL(MODELNO_GROUP,0),0,0,1) AS MODELNO_GROUP_FLAG,
    category,
    '' as cg,
    '' as cat1,
    '' as cat2,
    '' as cat3,
    '' as cat4,
    ca_code,
    ca_dept_mcode,
    ca_dept_code,
    ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,
    shop_name,
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    '' as model_factory,
    minprice,
    maxprice,
    minprices,
    C_DATE,
    mallcnt,
    DECODE(NVL(MALLCNT,0),0,0,1) AS MALLCNT_FLAG,
    spec,
    openexpectflag,
    condiname,
    KEYWORD,
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    to_all
--    MODELNM || ' ' || FACTORY || ' ' || SPEC || ' ' || KEYWORD || ' ' || KEYWORD2 || ' ' || CONDINAME AS to_all
from (

select
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    CASE WHEN service_gubun='2' AND store_flag='1' AND ca_dept_code IS NOT NULL THEN RTRIM(category || ' '  || ca_dept_code) ELSE category END AS category,
    ca_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),3,8)='000000' OR SUBSTR(RTRIM(ca_dept_code),3,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,4) END AS ca_dept_mcode,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),5,8)='0000' OR SUBSTR(RTRIM(ca_dept_code),5,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,6) END AS ca_dept_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),7,8)='00' OR SUBSTR(RTRIM(ca_dept_code),7,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,8) END AS ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,    
    shop_name,    
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    model_factory,
    minprice,
    maxprice,
    replace(minprices, ' ', '    ') as minprices,
    C_DATE,
    mallcnt,
    replace(replace(spec,',',' '),'/',' ') spec,
    openexpectflag,
    replace(condiname, ' ', '    ') as condiname,    
    CASE WHEN socialprice=0 THEN keyword ELSE keyword || ' ' || UDF_SOCIAL_GOODSNM(modelno_group,modelno) END AS KEYWORD,    
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    to_all
FROM tmp_es_price_data_01
WHERE mod_no = '2'

)

[2018-06-05T12:51:47,708][INFO ][logstash.inputs.jdbc     ] (1.938308s) select 
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    DECODE(NVL(MODELNO_GROUP,0),0,0,1) AS MODELNO_GROUP_FLAG,
    category,
    '' as cg,
    '' as cat1,
    '' as cat2,
    '' as cat3,
    '' as cat4,
    ca_code,
    ca_dept_mcode,
    ca_dept_code,
    ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,
    shop_name,
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    MODELNM || ' ' || FACTORY as model_factory,
    minprice,
    maxprice,
    minprices,
    C_DATE,
    mallcnt,
    DECODE(NVL(MALLCNT,0),0,0,1) AS MALLCNT_FLAG,
    spec,
    openexpectflag,
    condiname,
    KEYWORD,
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    to_all
--    MODELNM || ' ' || FACTORY || ' ' || SPEC || ' ' || KEYWORD || ' ' || KEYWORD2 || ' ' || CONDINAME AS to_all
from (

select
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    CASE WHEN service_gubun='2' AND store_flag='1' AND ca_dept_code IS NOT NULL THEN RTRIM(category || ' '  || ca_dept_code) ELSE category END AS category,
    ca_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),3,8)='000000' OR SUBSTR(RTRIM(ca_dept_code),3,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,4) END AS ca_dept_mcode,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),5,8)='0000' OR SUBSTR(RTRIM(ca_dept_code),5,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,6) END AS ca_dept_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),7,8)='00' OR SUBSTR(RTRIM(ca_dept_code),7,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,8) END AS ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,    
    shop_name,    
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    model_factory,
    minprice,
    maxprice,
    replace(minprices, ' ', '    ') as minprices,
    C_DATE,
    mallcnt,
    replace(replace(spec,',',' '),'/',' ') spec,
    openexpectflag,
    replace(condiname, ' ', '    ') as condiname,    
    CASE WHEN socialprice=0 THEN keyword ELSE keyword || ' ' || UDF_SOCIAL_GOODSNM(modelno_group,modelno) END AS KEYWORD,    
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    to_all
FROM tmp_es_goods_data_01    
WHERE mod_no = '2'

)

[2018-06-05T12:51:47,726][INFO ][logstash.outputs.elasticsearch] New Elasticsearch output {:class=>"LogStash::Outputs::ElasticSearch", :hosts=>["//100.100.100.111:9200", "//100.100.100.112:9200", "//100.100.100.113:9200"]}
[2018-06-05T12:51:47,781][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://100.100.100.111:9200/"}
[2018-06-05T12:51:47,923][INFO ][logstash.outputs.elasticsearch] ES Output version determined {:es_version=>6}
[2018-06-05T12:51:47,923][WARN ][logstash.outputs.elasticsearch] Detected a 6.x and above cluster: the `type` event field won't be used to determine the document _type {:es_version=>6}
[2018-06-05T12:51:47,923][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://100.100.100.112:9200/, :path=>"/"}
[2018-06-05T12:51:47,938][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://100.100.100.112:9200/"}
[2018-06-05T12:51:47,943][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://100.100.100.113:9200/, :path=>"/"}
[2018-06-05T12:51:47,956][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://100.100.100.113:9200/"}
[2018-06-05T12:51:48,012][INFO ][logstash.outputs.elasticsearch] Using mapping template from {:path=>nil}
[2018-06-05T12:51:48,027][INFO ][logstash.outputs.elasticsearch] Attempting to install template {:manage_template=>{"template"=>"logstash-*", "version"=>60001, "settings"=>{"index.refresh_interval"=>"5s"}, "mappings"=>{"_default_"=>{"dynamic_templates"=>[{"message_field"=>{"path_match"=>"message", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false}}}, {"string_fields"=>{"match"=>"*", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false, "fields"=>{"keyword"=>{"type"=>"keyword", "ignore_above"=>256}}}}}], "properties"=>{"@timestamp"=>{"type"=>"date"}, "@version"=>{"type"=>"keyword"}, "geoip"=>{"dynamic"=>true, "properties"=>{"ip"=>{"type"=>"ip"}, "location"=>{"type"=>"geo_point"}, "latitude"=>{"type"=>"half_float"}, "longitude"=>{"type"=>"half_float"}}}}}}}}
[2018-06-05T12:51:48,041][INFO ][logstash.outputs.elasticsearch] New Elasticsearch output {:class=>"LogStash::Outputs::ElasticSearch", :hosts=>["//100.100.100.111:9200", "//100.100.100.112:9200", "//100.100.100.113:9200"]}
[2018-06-05T12:51:48,352][INFO ][logstash.pipeline        ] Pipeline started succesfully {:pipeline_id=>"main", :thread=>"#<Thread:0x5775096@/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:246 run>"}
[2018-06-05T12:51:48,532][INFO ][logstash.agent           ] Pipelines running {:count=>1, :pipelines=>["main"]}
[2018-06-05T12:51:48,974][INFO ][logstash.inputs.jdbc     ] (2.630667s) select 
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    DECODE(NVL(MODELNO_GROUP,0),0,0,1) AS MODELNO_GROUP_FLAG,
    category,
    '' as cg,
    '' as cat1,
    '' as cat2,
    '' as cat3,
    '' as cat4,
    ca_code,
    ca_dept_mcode,
    ca_dept_code,
    ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,
    shop_name,
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    MODELNM || ' ' || FACTORY as model_factory,
    minprice,
    maxprice,
    minprices,
    C_DATE,
    mallcnt,
    DECODE(NVL(MALLCNT,0),0,0,1) AS MALLCNT_FLAG,
    spec,
    openexpectflag,
    condiname,
    KEYWORD,
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    to_all
--    MODELNM || ' ' || FACTORY || ' ' || SPEC || ' ' || KEYWORD || ' ' || KEYWORD2 || ' ' || CONDINAME AS to_all
from (

select
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    CASE WHEN service_gubun='2' AND store_flag='1' AND ca_dept_code IS NOT NULL THEN RTRIM(category || ' '  || ca_dept_code) ELSE category END AS category,
    ca_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),3,8)='000000' OR SUBSTR(RTRIM(ca_dept_code),3,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,4) END AS ca_dept_mcode,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),5,8)='0000' OR SUBSTR(RTRIM(ca_dept_code),5,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,6) END AS ca_dept_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),7,8)='00' OR SUBSTR(RTRIM(ca_dept_code),7,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,8) END AS ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,    
    shop_name,    
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    model_factory,
    minprice,
    maxprice,
    replace(minprices, ' ', '    ') as minprices,
    C_DATE,
    mallcnt,
    replace(replace(spec,',',' '),'/',' ') spec,
    openexpectflag,
    replace(condiname, ' ', '    ') as condiname,    
    CASE WHEN socialprice=0 THEN keyword ELSE keyword || ' ' || UDF_SOCIAL_GOODSNM(modelno_group,modelno) END AS KEYWORD,    
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    to_all
FROM tmp_es_goods_data_01    
WHERE mod_no = '4'

)

[2018-06-05T12:51:48,978][INFO ][logstash.inputs.jdbc     ] (2.654767s) select
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    DECODE(NVL(MODELNO_GROUP,0),0,0,1) AS MODELNO_GROUP_FLAG,
    category,
    '' as cg,
    '' as cat1,
    '' as cat2,
    '' as cat3,
    '' as cat4,
    ca_code,
    ca_dept_mcode,
    ca_dept_code,
    ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,
    shop_name,
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    '' as model_factory,
    minprice,
    maxprice,
    minprices,
    C_DATE,
    mallcnt,
    DECODE(NVL(MALLCNT,0),0,0,1) AS MALLCNT_FLAG,
    spec,
    openexpectflag,
    condiname,
    KEYWORD,
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    to_all
--    MODELNM || ' ' || FACTORY || ' ' || SPEC || ' ' || KEYWORD || ' ' || KEYWORD2 || ' ' || CONDINAME AS to_all
from (

select
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    CASE WHEN service_gubun='2' AND store_flag='1' AND ca_dept_code IS NOT NULL THEN RTRIM(category || ' '  || ca_dept_code) ELSE category END AS category,
    ca_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),3,8)='000000' OR SUBSTR(RTRIM(ca_dept_code),3,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,4) END AS ca_dept_mcode,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),5,8)='0000' OR SUBSTR(RTRIM(ca_dept_code),5,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,6) END AS ca_dept_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),7,8)='00' OR SUBSTR(RTRIM(ca_dept_code),7,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,8) END AS ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,    
    shop_name,    
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    model_factory,
    minprice,
    maxprice,
    replace(minprices, ' ', '    ') as minprices,
    C_DATE,
    mallcnt,
    replace(replace(spec,',',' '),'/',' ') spec,
    openexpectflag,
    replace(condiname, ' ', '    ') as condiname,    
    CASE WHEN socialprice=0 THEN keyword ELSE keyword || ' ' || UDF_SOCIAL_GOODSNM(modelno_group,modelno) END AS KEYWORD,    
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    to_all
FROM tmp_es_price_data_01
WHERE mod_no = '4'

)

[2018-06-05T12:51:49,076][INFO ][logstash.pipeline        ] Pipeline started succesfully {:pipeline_id=>"main", :thread=>"#<Thread:0x6e5ed998@/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:246 run>"}
[2018-06-05T12:51:49,185][INFO ][logstash.agent           ] Pipelines running {:count=>1, :pipelines=>["main"]}
[2018-06-05T12:54:53,649][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"fb_apache", :directory=>"/usr/share/logstash/modules/fb_apache/configuration"}
[2018-06-05T12:54:53,656][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"netflow", :directory=>"/usr/share/logstash/modules/netflow/configuration"}
[2018-06-05T12:54:54,995][WARN ][logstash.config.source.multilocal] Ignoring the 'pipelines.yml' file because modules or command line options are specified
[2018-06-05T12:54:55,629][INFO ][logstash.runner          ] Starting Logstash {"logstash.version"=>"6.2.3"}
[2018-06-05T12:54:55,722][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"fb_apache", :directory=>"/usr/share/logstash/modules/fb_apache/configuration"}
[2018-06-05T12:54:55,778][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"netflow", :directory=>"/usr/share/logstash/modules/netflow/configuration"}
[2018-06-05T12:54:56,073][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=>9600}
[2018-06-05T12:54:57,112][WARN ][logstash.config.source.multilocal] Ignoring the 'pipelines.yml' file because modules or command line options are specified
[2018-06-05T12:54:57,717][INFO ][logstash.runner          ] Starting Logstash {"logstash.version"=>"6.2.3"}
[2018-06-05T12:54:57,762][DEBUG][org.logstash.secret.store.SecretStoreFactory] Attempting to exists or secret store with implementation: org.logstash.secret.store.backend.JavaKeyStore
[2018-06-05T12:54:57,768][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"fb_apache", :directory=>"/usr/share/logstash/modules/fb_apache/configuration"}
[2018-06-05T12:54:57,798][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"netflow", :directory=>"/usr/share/logstash/modules/netflow/configuration"}
[2018-06-05T12:54:57,997][DEBUG][org.logstash.secret.store.SecretStoreFactory] Attempting to exists or secret store with implementation: org.logstash.secret.store.backend.JavaKeyStore
[2018-06-05T12:54:58,235][INFO ][logstash.filters.ruby.script] Test run complete {:script_path=>"rubyfilter.rb", :results=>{:passed=>0, :failed=>0, :errored=>0}}
[2018-06-05T12:54:58,540][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=>9601}
[2018-06-05T12:54:58,619][DEBUG][org.logstash.secret.store.SecretStoreFactory] Attempting to exists or secret store with implementation: org.logstash.secret.store.backend.JavaKeyStore
[2018-06-05T12:54:58,792][WARN ][logstash.outputs.elasticsearch] You are using a deprecated config setting "document_type" set in elasticsearch. Deprecated settings will continue to work, but are scheduled for removal from logstash in the future. Document types are being deprecated in Elasticsearch 6.0, and removed entirely in 7.0. You should avoid this feature If you have any questions about this, please visit the #logstash channel on freenode irc. {:name=>"document_type", :plugin=><LogStash::Outputs::ElasticSearch hosts=>[//100.100.100.111:9200, //100.100.100.112:9200, //100.100.100.113:9200], index=>"qa-enuri-main-as-is-2018.06.05.03.54", document_type=>"_doc", document_id=>"%{id}", action=>"index", id=>"6ecd11524c84e5de286546b0de40f57503392aeab1548c7913e69855f4645bbc", enable_metric=>true, codec=><LogStash::Codecs::Plain id=>"plain_b3c15e4b-4f25-40c3-8855-172863a46cc1", enable_metric=>true, charset=>"UTF-8">, workers=>1, manage_template=>true, template_name=>"logstash", template_overwrite=>false, doc_as_upsert=>false, script_type=>"inline", script_lang=>"painless", script_var_name=>"event", scripted_upsert=>false, retry_initial_interval=>2, retry_max_interval=>64, retry_on_conflict=>1, ssl_certificate_verification=>true, sniffing=>false, sniffing_delay=>5, timeout=>60, pool_max=>1000, pool_max_per_route=>100, resurrect_delay=>5, validate_after_inactivity=>10000, http_compression=>false>}
[2018-06-05T12:54:58,863][INFO ][logstash.pipeline        ] Starting pipeline {:pipeline_id=>"main", "pipeline.workers"=>8, "pipeline.batch.size"=>125, "pipeline.batch.delay"=>50}
[2018-06-05T12:54:59,936][WARN ][logstash.config.source.multilocal] Ignoring the 'pipelines.yml' file because modules or command line options are specified
[2018-06-05T12:55:00,159][INFO ][logstash.outputs.elasticsearch] Elasticsearch pool URLs updated {:changes=>{:removed=>[], :added=>[http://100.100.100.111:9200/, http://100.100.100.112:9200/, http://100.100.100.113:9200/]}}
[2018-06-05T12:55:00,215][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://100.100.100.111:9200/, :path=>"/"}
[2018-06-05T12:55:00,672][DEBUG][org.logstash.secret.store.SecretStoreFactory] Attempting to exists or secret store with implementation: org.logstash.secret.store.backend.JavaKeyStore
[2018-06-05T12:55:00,844][INFO ][logstash.runner          ] Starting Logstash {"logstash.version"=>"6.2.3"}
[2018-06-05T12:55:01,027][DEBUG][org.logstash.secret.store.SecretStoreFactory] Attempting to exists or secret store with implementation: org.logstash.secret.store.backend.JavaKeyStore
[2018-06-05T12:55:01,061][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"fb_apache", :directory=>"/usr/share/logstash/modules/fb_apache/configuration"}
[2018-06-05T12:55:01,099][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"netflow", :directory=>"/usr/share/logstash/modules/netflow/configuration"}
[2018-06-05T12:55:01,283][INFO ][logstash.filters.ruby.script] Test run complete {:script_path=>"rubyfilter.rb", :results=>{:passed=>0, :failed=>0, :errored=>0}}
[2018-06-05T12:55:01,370][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://100.100.100.111:9200/"}
[2018-06-05T12:55:01,679][INFO ][logstash.outputs.elasticsearch] ES Output version determined {:es_version=>6}
[2018-06-05T12:55:01,680][WARN ][logstash.outputs.elasticsearch] Detected a 6.x and above cluster: the `type` event field won't be used to determine the document _type {:es_version=>6}
[2018-06-05T12:55:01,680][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://100.100.100.112:9200/, :path=>"/"}
[2018-06-05T12:55:01,718][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://100.100.100.112:9200/"}
[2018-06-05T12:55:01,733][DEBUG][org.logstash.secret.store.SecretStoreFactory] Attempting to exists or secret store with implementation: org.logstash.secret.store.backend.JavaKeyStore
[2018-06-05T12:55:01,734][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://100.100.100.113:9200/, :path=>"/"}
[2018-06-05T12:55:01,758][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://100.100.100.113:9200/"}
[2018-06-05T12:55:01,830][WARN ][logstash.outputs.elasticsearch] You are using a deprecated config setting "document_type" set in elasticsearch. Deprecated settings will continue to work, but are scheduled for removal from logstash in the future. Document types are being deprecated in Elasticsearch 6.0, and removed entirely in 7.0. You should avoid this feature If you have any questions about this, please visit the #logstash channel on freenode irc. {:name=>"document_type", :plugin=><LogStash::Outputs::ElasticSearch hosts=>[//100.100.100.111:9200, //100.100.100.112:9200, //100.100.100.113:9200], index=>"qa-enuri-main-as-is-2018.06.05.03.54", document_type=>"_doc", document_id=>"%{id}", action=>"index", id=>"6ecd11524c84e5de286546b0de40f57503392aeab1548c7913e69855f4645bbc", enable_metric=>true, codec=><LogStash::Codecs::Plain id=>"plain_d93803b1-1125-49ac-bcb5-efb2b92d4f1b", enable_metric=>true, charset=>"UTF-8">, workers=>1, manage_template=>true, template_name=>"logstash", template_overwrite=>false, doc_as_upsert=>false, script_type=>"inline", script_lang=>"painless", script_var_name=>"event", scripted_upsert=>false, retry_initial_interval=>2, retry_max_interval=>64, retry_on_conflict=>1, ssl_certificate_verification=>true, sniffing=>false, sniffing_delay=>5, timeout=>60, pool_max=>1000, pool_max_per_route=>100, resurrect_delay=>5, validate_after_inactivity=>10000, http_compression=>false>}
[2018-06-05T12:55:01,838][INFO ][logstash.outputs.elasticsearch] Using mapping template from {:path=>nil}
[2018-06-05T12:55:01,841][INFO ][logstash.outputs.elasticsearch] Attempting to install template {:manage_template=>{"template"=>"logstash-*", "version"=>60001, "settings"=>{"index.refresh_interval"=>"5s"}, "mappings"=>{"_default_"=>{"dynamic_templates"=>[{"message_field"=>{"path_match"=>"message", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false}}}, {"string_fields"=>{"match"=>"*", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false, "fields"=>{"keyword"=>{"type"=>"keyword", "ignore_above"=>256}}}}}], "properties"=>{"@timestamp"=>{"type"=>"date"}, "@version"=>{"type"=>"keyword"}, "geoip"=>{"dynamic"=>true, "properties"=>{"ip"=>{"type"=>"ip"}, "location"=>{"type"=>"geo_point"}, "latitude"=>{"type"=>"half_float"}, "longitude"=>{"type"=>"half_float"}}}}}}}}
[2018-06-05T12:55:01,869][INFO ][logstash.outputs.elasticsearch] New Elasticsearch output {:class=>"LogStash::Outputs::ElasticSearch", :hosts=>["//100.100.100.111:9200", "//100.100.100.112:9200", "//100.100.100.113:9200"]}
[2018-06-05T12:55:01,873][INFO ][logstash.pipeline        ] Starting pipeline {:pipeline_id=>"main", "pipeline.workers"=>8, "pipeline.batch.size"=>125, "pipeline.batch.delay"=>50}
[2018-06-05T12:55:01,870][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=>9602}
[2018-06-05T12:55:02,502][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"fb_apache", :directory=>"/usr/share/logstash/modules/fb_apache/configuration"}
[2018-06-05T12:55:02,530][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"netflow", :directory=>"/usr/share/logstash/modules/netflow/configuration"}
[2018-06-05T12:55:02,713][INFO ][logstash.pipeline        ] Pipeline started succesfully {:pipeline_id=>"main", :thread=>"#<Thread:0x6d19b52d@/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:246 run>"}
[2018-06-05T12:55:02,753][INFO ][logstash.agent           ] Pipelines running {:count=>1, :pipelines=>["main"]}
[2018-06-05T12:55:02,888][WARN ][logstash.config.source.multilocal] Ignoring the 'pipelines.yml' file because modules or command line options are specified
[2018-06-05T12:55:02,940][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"fb_apache", :directory=>"/usr/share/logstash/modules/fb_apache/configuration"}
[2018-06-05T12:55:02,961][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"netflow", :directory=>"/usr/share/logstash/modules/netflow/configuration"}
[2018-06-05T12:55:03,659][INFO ][logstash.outputs.elasticsearch] Elasticsearch pool URLs updated {:changes=>{:removed=>[], :added=>[http://100.100.100.111:9200/, http://100.100.100.112:9200/, http://100.100.100.113:9200/]}}
[2018-06-05T12:55:03,661][INFO ][logstash.runner          ] Starting Logstash {"logstash.version"=>"6.2.3"}
[2018-06-05T12:55:03,671][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://100.100.100.111:9200/, :path=>"/"}
[2018-06-05T12:55:03,693][WARN ][logstash.config.source.multilocal] Ignoring the 'pipelines.yml' file because modules or command line options are specified
[2018-06-05T12:55:03,824][WARN ][logstash.config.source.multilocal] Ignoring the 'pipelines.yml' file because modules or command line options are specified
[2018-06-05T12:55:03,946][DEBUG][org.logstash.secret.store.SecretStoreFactory] Attempting to exists or secret store with implementation: org.logstash.secret.store.backend.JavaKeyStore
[2018-06-05T12:55:04,016][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://100.100.100.111:9200/"}
[2018-06-05T12:55:04,168][INFO ][logstash.runner          ] Starting Logstash {"logstash.version"=>"6.2.3"}
[2018-06-05T12:55:04,192][DEBUG][org.logstash.secret.store.SecretStoreFactory] Attempting to exists or secret store with implementation: org.logstash.secret.store.backend.JavaKeyStore
[2018-06-05T12:55:04,208][INFO ][logstash.outputs.elasticsearch] ES Output version determined {:es_version=>6}
[2018-06-05T12:55:04,209][WARN ][logstash.outputs.elasticsearch] Detected a 6.x and above cluster: the `type` event field won't be used to determine the document _type {:es_version=>6}
[2018-06-05T12:55:04,209][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://100.100.100.112:9200/, :path=>"/"}
[2018-06-05T12:55:04,218][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://100.100.100.112:9200/"}
[2018-06-05T12:55:04,235][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://100.100.100.113:9200/, :path=>"/"}
[2018-06-05T12:55:04,275][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://100.100.100.113:9200/"}
[2018-06-05T12:55:04,308][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=>9603}
[2018-06-05T12:55:04,349][INFO ][logstash.runner          ] Starting Logstash {"logstash.version"=>"6.2.3"}
[2018-06-05T12:55:04,374][INFO ][logstash.outputs.elasticsearch] Using mapping template from {:path=>nil}
[2018-06-05T12:55:04,385][INFO ][logstash.outputs.elasticsearch] Attempting to install template {:manage_template=>{"template"=>"logstash-*", "version"=>60001, "settings"=>{"index.refresh_interval"=>"5s"}, "mappings"=>{"_default_"=>{"dynamic_templates"=>[{"message_field"=>{"path_match"=>"message", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false}}}, {"string_fields"=>{"match"=>"*", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false, "fields"=>{"keyword"=>{"type"=>"keyword", "ignore_above"=>256}}}}}], "properties"=>{"@timestamp"=>{"type"=>"date"}, "@version"=>{"type"=>"keyword"}, "geoip"=>{"dynamic"=>true, "properties"=>{"ip"=>{"type"=>"ip"}, "location"=>{"type"=>"geo_point"}, "latitude"=>{"type"=>"half_float"}, "longitude"=>{"type"=>"half_float"}}}}}}}}
[2018-06-05T12:55:04,413][INFO ][logstash.outputs.elasticsearch] New Elasticsearch output {:class=>"LogStash::Outputs::ElasticSearch", :hosts=>["//100.100.100.111:9200", "//100.100.100.112:9200", "//100.100.100.113:9200"]}
[2018-06-05T12:55:04,426][INFO ][logstash.filters.ruby.script] Test run complete {:script_path=>"rubyfilter.rb", :results=>{:passed=>0, :failed=>0, :errored=>0}}
[2018-06-05T12:55:04,738][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=>9604}
[2018-06-05T12:55:05,107][DEBUG][org.logstash.secret.store.SecretStoreFactory] Attempting to exists or secret store with implementation: org.logstash.secret.store.backend.JavaKeyStore
[2018-06-05T12:55:05,149][WARN ][logstash.outputs.elasticsearch] You are using a deprecated config setting "document_type" set in elasticsearch. Deprecated settings will continue to work, but are scheduled for removal from logstash in the future. Document types are being deprecated in Elasticsearch 6.0, and removed entirely in 7.0. You should avoid this feature If you have any questions about this, please visit the #logstash channel on freenode irc. {:name=>"document_type", :plugin=><LogStash::Outputs::ElasticSearch hosts=>[//100.100.100.111:9200, //100.100.100.112:9200, //100.100.100.113:9200], index=>"qa-enuri-main-as-is-2018.06.05.03.54", document_type=>"_doc", document_id=>"%{id}", action=>"index", id=>"6ecd11524c84e5de286546b0de40f57503392aeab1548c7913e69855f4645bbc", enable_metric=>true, codec=><LogStash::Codecs::Plain id=>"plain_849c2e3e-6b7b-40aa-817d-b42616cfbfcb", enable_metric=>true, charset=>"UTF-8">, workers=>1, manage_template=>true, template_name=>"logstash", template_overwrite=>false, doc_as_upsert=>false, script_type=>"inline", script_lang=>"painless", script_var_name=>"event", scripted_upsert=>false, retry_initial_interval=>2, retry_max_interval=>64, retry_on_conflict=>1, ssl_certificate_verification=>true, sniffing=>false, sniffing_delay=>5, timeout=>60, pool_max=>1000, pool_max_per_route=>100, resurrect_delay=>5, validate_after_inactivity=>10000, http_compression=>false>}
[2018-06-05T12:55:05,170][INFO ][logstash.pipeline        ] Pipeline started succesfully {:pipeline_id=>"main", :thread=>"#<Thread:0x26ae6e86@/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:246 run>"}
[2018-06-05T12:55:05,188][INFO ][logstash.pipeline        ] Starting pipeline {:pipeline_id=>"main", "pipeline.workers"=>8, "pipeline.batch.size"=>125, "pipeline.batch.delay"=>50}
[2018-06-05T12:55:05,306][INFO ][logstash.agent           ] Pipelines running {:count=>1, :pipelines=>["main"]}
[2018-06-05T12:55:05,544][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=>9605}
[2018-06-05T12:55:06,872][INFO ][logstash.outputs.elasticsearch] Elasticsearch pool URLs updated {:changes=>{:removed=>[], :added=>[http://100.100.100.111:9200/, http://100.100.100.112:9200/, http://100.100.100.113:9200/]}}
[2018-06-05T12:55:06,874][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://100.100.100.111:9200/, :path=>"/"}
[2018-06-05T12:55:06,981][INFO ][logstash.inputs.jdbc     ] (2.436665s) select
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    DECODE(NVL(MODELNO_GROUP,0),0,0,1) AS MODELNO_GROUP_FLAG,
    category,
    '' as cg,
    '' as cat1,
    '' as cat2,
    '' as cat3,
    '' as cat4,
    ca_code,
    ca_dept_mcode,
    ca_dept_code,
    ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,
    shop_name,
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    '' as model_factory,
    minprice,
    maxprice,
    minprices,
    C_DATE,
    mallcnt,
    DECODE(NVL(MALLCNT,0),0,0,1) AS MALLCNT_FLAG,
    spec,
    openexpectflag,
    condiname,
    KEYWORD,
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    to_all
--    MODELNM || ' ' || FACTORY || ' ' || SPEC || ' ' || KEYWORD || ' ' || KEYWORD2 || ' ' || CONDINAME AS to_all
from (

select
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    CASE WHEN service_gubun='2' AND store_flag='1' AND ca_dept_code IS NOT NULL THEN RTRIM(category || ' '  || ca_dept_code) ELSE category END AS category,
    ca_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),3,8)='000000' OR SUBSTR(RTRIM(ca_dept_code),3,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,4) END AS ca_dept_mcode,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),5,8)='0000' OR SUBSTR(RTRIM(ca_dept_code),5,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,6) END AS ca_dept_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),7,8)='00' OR SUBSTR(RTRIM(ca_dept_code),7,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,8) END AS ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,    
    shop_name,    
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    model_factory,
    minprice,
    maxprice,
    replace(minprices, ' ', '    ') as minprices,
    C_DATE,
    mallcnt,
    replace(replace(spec,',',' '),'/',' ') spec,
    openexpectflag,
    replace(condiname, ' ', '    ') as condiname,    
    CASE WHEN socialprice=0 THEN keyword ELSE keyword || ' ' || UDF_SOCIAL_GOODSNM(modelno_group,modelno) END AS KEYWORD,    
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    to_all
FROM tmp_es_price_data_01
WHERE mod_no = '3'

)

[2018-06-05T12:55:07,072][INFO ][logstash.inputs.jdbc     ] (2.525057s) select 
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    DECODE(NVL(MODELNO_GROUP,0),0,0,1) AS MODELNO_GROUP_FLAG,
    category,
    '' as cg,
    '' as cat1,
    '' as cat2,
    '' as cat3,
    '' as cat4,
    ca_code,
    ca_dept_mcode,
    ca_dept_code,
    ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,
    shop_name,
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    MODELNM || ' ' || FACTORY as model_factory,
    minprice,
    maxprice,
    minprices,
    C_DATE,
    mallcnt,
    DECODE(NVL(MALLCNT,0),0,0,1) AS MALLCNT_FLAG,
    spec,
    openexpectflag,
    condiname,
    KEYWORD,
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    to_all
--    MODELNM || ' ' || FACTORY || ' ' || SPEC || ' ' || KEYWORD || ' ' || KEYWORD2 || ' ' || CONDINAME AS to_all
from (

select
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    CASE WHEN service_gubun='2' AND store_flag='1' AND ca_dept_code IS NOT NULL THEN RTRIM(category || ' '  || ca_dept_code) ELSE category END AS category,
    ca_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),3,8)='000000' OR SUBSTR(RTRIM(ca_dept_code),3,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,4) END AS ca_dept_mcode,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),5,8)='0000' OR SUBSTR(RTRIM(ca_dept_code),5,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,6) END AS ca_dept_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),7,8)='00' OR SUBSTR(RTRIM(ca_dept_code),7,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,8) END AS ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,    
    shop_name,    
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    model_factory,
    minprice,
    maxprice,
    replace(minprices, ' ', '    ') as minprices,
    C_DATE,
    mallcnt,
    replace(replace(spec,',',' '),'/',' ') spec,
    openexpectflag,
    replace(condiname, ' ', '    ') as condiname,    
    CASE WHEN socialprice=0 THEN keyword ELSE keyword || ' ' || UDF_SOCIAL_GOODSNM(modelno_group,modelno) END AS KEYWORD,    
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    to_all
FROM tmp_es_goods_data_01    
WHERE mod_no = '3'

)

[2018-06-05T12:55:07,095][DEBUG][org.logstash.secret.store.SecretStoreFactory] Attempting to exists or secret store with implementation: org.logstash.secret.store.backend.JavaKeyStore
[2018-06-05T12:55:07,216][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://100.100.100.111:9200/"}
[2018-06-05T12:55:07,290][DEBUG][org.logstash.secret.store.SecretStoreFactory] Attempting to exists or secret store with implementation: org.logstash.secret.store.backend.JavaKeyStore
[2018-06-05T12:55:07,353][INFO ][logstash.outputs.elasticsearch] ES Output version determined {:es_version=>6}
[2018-06-05T12:55:07,353][WARN ][logstash.outputs.elasticsearch] Detected a 6.x and above cluster: the `type` event field won't be used to determine the document _type {:es_version=>6}
[2018-06-05T12:55:07,354][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://100.100.100.112:9200/, :path=>"/"}
[2018-06-05T12:55:07,394][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://100.100.100.112:9200/"}
[2018-06-05T12:55:07,399][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://100.100.100.113:9200/, :path=>"/"}
[2018-06-05T12:55:07,425][DEBUG][org.logstash.secret.store.SecretStoreFactory] Attempting to exists or secret store with implementation: org.logstash.secret.store.backend.JavaKeyStore
[2018-06-05T12:55:07,425][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://100.100.100.113:9200/"}
[2018-06-05T12:55:07,507][INFO ][logstash.outputs.elasticsearch] Using mapping template from {:path=>nil}
[2018-06-05T12:55:07,528][DEBUG][org.logstash.secret.store.SecretStoreFactory] Attempting to exists or secret store with implementation: org.logstash.secret.store.backend.JavaKeyStore
[2018-06-05T12:55:07,531][INFO ][logstash.outputs.elasticsearch] Attempting to install template {:manage_template=>{"template"=>"logstash-*", "version"=>60001, "settings"=>{"index.refresh_interval"=>"5s"}, "mappings"=>{"_default_"=>{"dynamic_templates"=>[{"message_field"=>{"path_match"=>"message", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false}}}, {"string_fields"=>{"match"=>"*", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false, "fields"=>{"keyword"=>{"type"=>"keyword", "ignore_above"=>256}}}}}], "properties"=>{"@timestamp"=>{"type"=>"date"}, "@version"=>{"type"=>"keyword"}, "geoip"=>{"dynamic"=>true, "properties"=>{"ip"=>{"type"=>"ip"}, "location"=>{"type"=>"geo_point"}, "latitude"=>{"type"=>"half_float"}, "longitude"=>{"type"=>"half_float"}}}}}}}}
[2018-06-05T12:55:07,542][INFO ][logstash.outputs.elasticsearch] New Elasticsearch output {:class=>"LogStash::Outputs::ElasticSearch", :hosts=>["//100.100.100.111:9200", "//100.100.100.112:9200", "//100.100.100.113:9200"]}
[2018-06-05T12:55:07,568][INFO ][logstash.filters.ruby.script] Test run complete {:script_path=>"rubyfilter.rb", :results=>{:passed=>0, :failed=>0, :errored=>0}}
[2018-06-05T12:55:07,789][DEBUG][org.logstash.secret.store.SecretStoreFactory] Attempting to exists or secret store with implementation: org.logstash.secret.store.backend.JavaKeyStore
[2018-06-05T12:55:07,801][INFO ][logstash.filters.ruby.script] Test run complete {:script_path=>"rubyfilter.rb", :results=>{:passed=>0, :failed=>0, :errored=>0}}
[2018-06-05T12:55:07,973][WARN ][logstash.outputs.elasticsearch] You are using a deprecated config setting "document_type" set in elasticsearch. Deprecated settings will continue to work, but are scheduled for removal from logstash in the future. Document types are being deprecated in Elasticsearch 6.0, and removed entirely in 7.0. You should avoid this feature If you have any questions about this, please visit the #logstash channel on freenode irc. {:name=>"document_type", :plugin=><LogStash::Outputs::ElasticSearch hosts=>[//100.100.100.111:9200, //100.100.100.112:9200, //100.100.100.113:9200], index=>"qa-enuri-main-as-is-2018.06.05.03.54", document_type=>"_doc", document_id=>"%{id}", action=>"index", id=>"6ecd11524c84e5de286546b0de40f57503392aeab1548c7913e69855f4645bbc", enable_metric=>true, codec=><LogStash::Codecs::Plain id=>"plain_bc2c910d-a2dd-48d7-a82c-aa55855dfe59", enable_metric=>true, charset=>"UTF-8">, workers=>1, manage_template=>true, template_name=>"logstash", template_overwrite=>false, doc_as_upsert=>false, script_type=>"inline", script_lang=>"painless", script_var_name=>"event", scripted_upsert=>false, retry_initial_interval=>2, retry_max_interval=>64, retry_on_conflict=>1, ssl_certificate_verification=>true, sniffing=>false, sniffing_delay=>5, timeout=>60, pool_max=>1000, pool_max_per_route=>100, resurrect_delay=>5, validate_after_inactivity=>10000, http_compression=>false>}
[2018-06-05T12:55:07,983][INFO ][logstash.pipeline        ] Starting pipeline {:pipeline_id=>"main", "pipeline.workers"=>8, "pipeline.batch.size"=>125, "pipeline.batch.delay"=>50}
[2018-06-05T12:55:08,417][DEBUG][org.logstash.secret.store.SecretStoreFactory] Attempting to exists or secret store with implementation: org.logstash.secret.store.backend.JavaKeyStore
[2018-06-05T12:55:08,493][INFO ][logstash.pipeline        ] Pipeline started succesfully {:pipeline_id=>"main", :thread=>"#<Thread:0xb469b44@/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:246 sleep>"}
[2018-06-05T12:55:08,550][DEBUG][org.logstash.secret.store.SecretStoreFactory] Attempting to exists or secret store with implementation: org.logstash.secret.store.backend.JavaKeyStore
[2018-06-05T12:55:08,584][INFO ][logstash.agent           ] Pipelines running {:count=>1, :pipelines=>["main"]}
[2018-06-05T12:55:08,615][WARN ][logstash.outputs.elasticsearch] You are using a deprecated config setting "document_type" set in elasticsearch. Deprecated settings will continue to work, but are scheduled for removal from logstash in the future. Document types are being deprecated in Elasticsearch 6.0, and removed entirely in 7.0. You should avoid this feature If you have any questions about this, please visit the #logstash channel on freenode irc. {:name=>"document_type", :plugin=><LogStash::Outputs::ElasticSearch hosts=>[//100.100.100.111:9200, //100.100.100.112:9200, //100.100.100.113:9200], index=>"qa-enuri-main-as-is-2018.06.05.03.54", document_type=>"_doc", document_id=>"%{id}", action=>"index", id=>"6ecd11524c84e5de286546b0de40f57503392aeab1548c7913e69855f4645bbc", enable_metric=>true, codec=><LogStash::Codecs::Plain id=>"plain_4cee9390-248d-45b9-9c2f-1a7893e45e1b", enable_metric=>true, charset=>"UTF-8">, workers=>1, manage_template=>true, template_name=>"logstash", template_overwrite=>false, doc_as_upsert=>false, script_type=>"inline", script_lang=>"painless", script_var_name=>"event", scripted_upsert=>false, retry_initial_interval=>2, retry_max_interval=>64, retry_on_conflict=>1, ssl_certificate_verification=>true, sniffing=>false, sniffing_delay=>5, timeout=>60, pool_max=>1000, pool_max_per_route=>100, resurrect_delay=>5, validate_after_inactivity=>10000, http_compression=>false>}
[2018-06-05T12:55:08,689][INFO ][logstash.pipeline        ] Starting pipeline {:pipeline_id=>"main", "pipeline.workers"=>8, "pipeline.batch.size"=>125, "pipeline.batch.delay"=>50}
[2018-06-05T12:55:08,920][INFO ][logstash.outputs.elasticsearch] Elasticsearch pool URLs updated {:changes=>{:removed=>[], :added=>[http://100.100.100.111:9200/, http://100.100.100.112:9200/, http://100.100.100.113:9200/]}}
[2018-06-05T12:55:08,937][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://100.100.100.111:9200/, :path=>"/"}
[2018-06-05T12:55:09,010][DEBUG][org.logstash.secret.store.SecretStoreFactory] Attempting to exists or secret store with implementation: org.logstash.secret.store.backend.JavaKeyStore
[2018-06-05T12:55:09,515][INFO ][logstash.filters.ruby.script] Test run complete {:script_path=>"rubyfilter.rb", :results=>{:passed=>0, :failed=>0, :errored=>0}}
[2018-06-05T12:55:09,628][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://100.100.100.111:9200/"}
[2018-06-05T12:55:09,739][INFO ][logstash.outputs.elasticsearch] Elasticsearch pool URLs updated {:changes=>{:removed=>[], :added=>[http://100.100.100.111:9200/, http://100.100.100.112:9200/, http://100.100.100.113:9200/]}}
[2018-06-05T12:55:09,743][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://100.100.100.111:9200/, :path=>"/"}
[2018-06-05T12:55:09,771][INFO ][logstash.outputs.elasticsearch] ES Output version determined {:es_version=>6}
[2018-06-05T12:55:09,772][WARN ][logstash.outputs.elasticsearch] Detected a 6.x and above cluster: the `type` event field won't be used to determine the document _type {:es_version=>6}
[2018-06-05T12:55:09,772][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://100.100.100.112:9200/, :path=>"/"}
[2018-06-05T12:55:09,835][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://100.100.100.112:9200/"}
[2018-06-05T12:55:09,843][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://100.100.100.113:9200/, :path=>"/"}
[2018-06-05T12:55:09,866][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://100.100.100.113:9200/"}
[2018-06-05T12:55:09,897][INFO ][logstash.outputs.elasticsearch] Using mapping template from {:path=>nil}
[2018-06-05T12:55:09,908][INFO ][logstash.outputs.elasticsearch] Attempting to install template {:manage_template=>{"template"=>"logstash-*", "version"=>60001, "settings"=>{"index.refresh_interval"=>"5s"}, "mappings"=>{"_default_"=>{"dynamic_templates"=>[{"message_field"=>{"path_match"=>"message", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false}}}, {"string_fields"=>{"match"=>"*", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false, "fields"=>{"keyword"=>{"type"=>"keyword", "ignore_above"=>256}}}}}], "properties"=>{"@timestamp"=>{"type"=>"date"}, "@version"=>{"type"=>"keyword"}, "geoip"=>{"dynamic"=>true, "properties"=>{"ip"=>{"type"=>"ip"}, "location"=>{"type"=>"geo_point"}, "latitude"=>{"type"=>"half_float"}, "longitude"=>{"type"=>"half_float"}}}}}}}}
[2018-06-05T12:55:09,937][INFO ][logstash.outputs.elasticsearch] New Elasticsearch output {:class=>"LogStash::Outputs::ElasticSearch", :hosts=>["//100.100.100.111:9200", "//100.100.100.112:9200", "//100.100.100.113:9200"]}
[2018-06-05T12:55:09,982][DEBUG][org.logstash.secret.store.SecretStoreFactory] Attempting to exists or secret store with implementation: org.logstash.secret.store.backend.JavaKeyStore
[2018-06-05T12:55:10,028][INFO ][logstash.inputs.jdbc     ] (2.200829s) select
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    DECODE(NVL(MODELNO_GROUP,0),0,0,1) AS MODELNO_GROUP_FLAG,
    category,
    '' as cg,
    '' as cat1,
    '' as cat2,
    '' as cat3,
    '' as cat4,
    ca_code,
    ca_dept_mcode,
    ca_dept_code,
    ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,
    shop_name,
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    '' as model_factory,
    minprice,
    maxprice,
    minprices,
    C_DATE,
    mallcnt,
    DECODE(NVL(MALLCNT,0),0,0,1) AS MALLCNT_FLAG,
    spec,
    openexpectflag,
    condiname,
    KEYWORD,
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    to_all
--    MODELNM || ' ' || FACTORY || ' ' || SPEC || ' ' || KEYWORD || ' ' || KEYWORD2 || ' ' || CONDINAME AS to_all
from (

select
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    CASE WHEN service_gubun='2' AND store_flag='1' AND ca_dept_code IS NOT NULL THEN RTRIM(category || ' '  || ca_dept_code) ELSE category END AS category,
    ca_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),3,8)='000000' OR SUBSTR(RTRIM(ca_dept_code),3,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,4) END AS ca_dept_mcode,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),5,8)='0000' OR SUBSTR(RTRIM(ca_dept_code),5,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,6) END AS ca_dept_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),7,8)='00' OR SUBSTR(RTRIM(ca_dept_code),7,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,8) END AS ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,    
    shop_name,    
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    model_factory,
    minprice,
    maxprice,
    replace(minprices, ' ', '    ') as minprices,
    C_DATE,
    mallcnt,
    replace(replace(spec,',',' '),'/',' ') spec,
    openexpectflag,
    replace(condiname, ' ', '    ') as condiname,    
    CASE WHEN socialprice=0 THEN keyword ELSE keyword || ' ' || UDF_SOCIAL_GOODSNM(modelno_group,modelno) END AS KEYWORD,    
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    to_all
FROM tmp_es_price_data_01
WHERE mod_no = '5'

)

[2018-06-05T12:55:10,047][INFO ][logstash.inputs.jdbc     ] (2.222621s) select 
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    DECODE(NVL(MODELNO_GROUP,0),0,0,1) AS MODELNO_GROUP_FLAG,
    category,
    '' as cg,
    '' as cat1,
    '' as cat2,
    '' as cat3,
    '' as cat4,
    ca_code,
    ca_dept_mcode,
    ca_dept_code,
    ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,
    shop_name,
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    MODELNM || ' ' || FACTORY as model_factory,
    minprice,
    maxprice,
    minprices,
    C_DATE,
    mallcnt,
    DECODE(NVL(MALLCNT,0),0,0,1) AS MALLCNT_FLAG,
    spec,
    openexpectflag,
    condiname,
    KEYWORD,
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    to_all
--    MODELNM || ' ' || FACTORY || ' ' || SPEC || ' ' || KEYWORD || ' ' || KEYWORD2 || ' ' || CONDINAME AS to_all
from (

select
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    CASE WHEN service_gubun='2' AND store_flag='1' AND ca_dept_code IS NOT NULL THEN RTRIM(category || ' '  || ca_dept_code) ELSE category END AS category,
    ca_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),3,8)='000000' OR SUBSTR(RTRIM(ca_dept_code),3,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,4) END AS ca_dept_mcode,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),5,8)='0000' OR SUBSTR(RTRIM(ca_dept_code),5,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,6) END AS ca_dept_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),7,8)='00' OR SUBSTR(RTRIM(ca_dept_code),7,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,8) END AS ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,    
    shop_name,    
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    model_factory,
    minprice,
    maxprice,
    replace(minprices, ' ', '    ') as minprices,
    C_DATE,
    mallcnt,
    replace(replace(spec,',',' '),'/',' ') spec,
    openexpectflag,
    replace(condiname, ' ', '    ') as condiname,    
    CASE WHEN socialprice=0 THEN keyword ELSE keyword || ' ' || UDF_SOCIAL_GOODSNM(modelno_group,modelno) END AS KEYWORD,    
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    to_all
FROM tmp_es_goods_data_01    
WHERE mod_no = '5'

)

[2018-06-05T12:55:10,088][WARN ][logstash.outputs.elasticsearch] You are using a deprecated config setting "document_type" set in elasticsearch. Deprecated settings will continue to work, but are scheduled for removal from logstash in the future. Document types are being deprecated in Elasticsearch 6.0, and removed entirely in 7.0. You should avoid this feature If you have any questions about this, please visit the #logstash channel on freenode irc. {:name=>"document_type", :plugin=><LogStash::Outputs::ElasticSearch hosts=>[//100.100.100.111:9200, //100.100.100.112:9200, //100.100.100.113:9200], index=>"qa-enuri-main-as-is-2018.06.05.03.54", document_type=>"_doc", document_id=>"%{id}", action=>"index", id=>"6ecd11524c84e5de286546b0de40f57503392aeab1548c7913e69855f4645bbc", enable_metric=>true, codec=><LogStash::Codecs::Plain id=>"plain_f2d9a2c7-7331-4500-972a-9ec7e218f317", enable_metric=>true, charset=>"UTF-8">, workers=>1, manage_template=>true, template_name=>"logstash", template_overwrite=>false, doc_as_upsert=>false, script_type=>"inline", script_lang=>"painless", script_var_name=>"event", scripted_upsert=>false, retry_initial_interval=>2, retry_max_interval=>64, retry_on_conflict=>1, ssl_certificate_verification=>true, sniffing=>false, sniffing_delay=>5, timeout=>60, pool_max=>1000, pool_max_per_route=>100, resurrect_delay=>5, validate_after_inactivity=>10000, http_compression=>false>}
[2018-06-05T12:55:10,139][INFO ][logstash.pipeline        ] Starting pipeline {:pipeline_id=>"main", "pipeline.workers"=>8, "pipeline.batch.size"=>125, "pipeline.batch.delay"=>50}
[2018-06-05T12:55:10,271][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://100.100.100.111:9200/"}
[2018-06-05T12:55:10,425][INFO ][logstash.outputs.elasticsearch] ES Output version determined {:es_version=>6}
[2018-06-05T12:55:10,426][WARN ][logstash.outputs.elasticsearch] Detected a 6.x and above cluster: the `type` event field won't be used to determine the document _type {:es_version=>6}
[2018-06-05T12:55:10,426][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://100.100.100.112:9200/, :path=>"/"}
[2018-06-05T12:55:10,476][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://100.100.100.112:9200/"}
[2018-06-05T12:55:10,489][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://100.100.100.113:9200/, :path=>"/"}
[2018-06-05T12:55:10,504][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://100.100.100.113:9200/"}
[2018-06-05T12:55:10,551][INFO ][logstash.outputs.elasticsearch] Using mapping template from {:path=>nil}
[2018-06-05T12:55:10,561][INFO ][logstash.outputs.elasticsearch] Attempting to install template {:manage_template=>{"template"=>"logstash-*", "version"=>60001, "settings"=>{"index.refresh_interval"=>"5s"}, "mappings"=>{"_default_"=>{"dynamic_templates"=>[{"message_field"=>{"path_match"=>"message", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false}}}, {"string_fields"=>{"match"=>"*", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false, "fields"=>{"keyword"=>{"type"=>"keyword", "ignore_above"=>256}}}}}], "properties"=>{"@timestamp"=>{"type"=>"date"}, "@version"=>{"type"=>"keyword"}, "geoip"=>{"dynamic"=>true, "properties"=>{"ip"=>{"type"=>"ip"}, "location"=>{"type"=>"geo_point"}, "latitude"=>{"type"=>"half_float"}, "longitude"=>{"type"=>"half_float"}}}}}}}}
[2018-06-05T12:55:10,575][INFO ][logstash.outputs.elasticsearch] New Elasticsearch output {:class=>"LogStash::Outputs::ElasticSearch", :hosts=>["//100.100.100.111:9200", "//100.100.100.112:9200", "//100.100.100.113:9200"]}
[2018-06-05T12:55:11,058][INFO ][logstash.outputs.elasticsearch] Elasticsearch pool URLs updated {:changes=>{:removed=>[], :added=>[http://100.100.100.111:9200/, http://100.100.100.112:9200/, http://100.100.100.113:9200/]}}
[2018-06-05T12:55:11,060][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://100.100.100.111:9200/, :path=>"/"}
[2018-06-05T12:55:11,073][INFO ][logstash.pipeline        ] Pipeline started succesfully {:pipeline_id=>"main", :thread=>"#<Thread:0x4c3e2cf3@/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:246 run>"}
[2018-06-05T12:55:11,120][INFO ][logstash.pipeline        ] Pipeline started succesfully {:pipeline_id=>"main", :thread=>"#<Thread:0x6e307fa0@/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:246 run>"}
[2018-06-05T12:55:11,156][INFO ][logstash.agent           ] Pipelines running {:count=>1, :pipelines=>["main"]}
[2018-06-05T12:55:11,266][INFO ][logstash.agent           ] Pipelines running {:count=>1, :pipelines=>["main"]}
[2018-06-05T12:55:11,539][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://100.100.100.111:9200/"}
[2018-06-05T12:55:11,665][INFO ][logstash.outputs.elasticsearch] ES Output version determined {:es_version=>6}
[2018-06-05T12:55:11,665][WARN ][logstash.outputs.elasticsearch] Detected a 6.x and above cluster: the `type` event field won't be used to determine the document _type {:es_version=>6}
[2018-06-05T12:55:11,665][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://100.100.100.112:9200/, :path=>"/"}
[2018-06-05T12:55:11,691][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://100.100.100.112:9200/"}
[2018-06-05T12:55:11,717][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://100.100.100.113:9200/, :path=>"/"}
[2018-06-05T12:55:11,729][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://100.100.100.113:9200/"}
[2018-06-05T12:55:11,829][INFO ][logstash.outputs.elasticsearch] Using mapping template from {:path=>nil}
[2018-06-05T12:55:11,834][INFO ][logstash.outputs.elasticsearch] Attempting to install template {:manage_template=>{"template"=>"logstash-*", "version"=>60001, "settings"=>{"index.refresh_interval"=>"5s"}, "mappings"=>{"_default_"=>{"dynamic_templates"=>[{"message_field"=>{"path_match"=>"message", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false}}}, {"string_fields"=>{"match"=>"*", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false, "fields"=>{"keyword"=>{"type"=>"keyword", "ignore_above"=>256}}}}}], "properties"=>{"@timestamp"=>{"type"=>"date"}, "@version"=>{"type"=>"keyword"}, "geoip"=>{"dynamic"=>true, "properties"=>{"ip"=>{"type"=>"ip"}, "location"=>{"type"=>"geo_point"}, "latitude"=>{"type"=>"half_float"}, "longitude"=>{"type"=>"half_float"}}}}}}}}
[2018-06-05T12:55:11,848][INFO ][logstash.outputs.elasticsearch] New Elasticsearch output {:class=>"LogStash::Outputs::ElasticSearch", :hosts=>["//100.100.100.111:9200", "//100.100.100.112:9200", "//100.100.100.113:9200"]}
[2018-06-05T12:55:12,591][INFO ][logstash.pipeline        ] Pipeline started succesfully {:pipeline_id=>"main", :thread=>"#<Thread:0x4372c4bb@/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:246 run>"}
[2018-06-05T12:55:12,747][INFO ][logstash.inputs.jdbc     ] (1.913649s) select
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    DECODE(NVL(MODELNO_GROUP,0),0,0,1) AS MODELNO_GROUP_FLAG,
    category,
    '' as cg,
    '' as cat1,
    '' as cat2,
    '' as cat3,
    '' as cat4,
    ca_code,
    ca_dept_mcode,
    ca_dept_code,
    ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,
    shop_name,
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    '' as model_factory,
    minprice,
    maxprice,
    minprices,
    C_DATE,
    mallcnt,
    DECODE(NVL(MALLCNT,0),0,0,1) AS MALLCNT_FLAG,
    spec,
    openexpectflag,
    condiname,
    KEYWORD,
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    to_all
--    MODELNM || ' ' || FACTORY || ' ' || SPEC || ' ' || KEYWORD || ' ' || KEYWORD2 || ' ' || CONDINAME AS to_all
from (

select
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    CASE WHEN service_gubun='2' AND store_flag='1' AND ca_dept_code IS NOT NULL THEN RTRIM(category || ' '  || ca_dept_code) ELSE category END AS category,
    ca_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),3,8)='000000' OR SUBSTR(RTRIM(ca_dept_code),3,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,4) END AS ca_dept_mcode,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),5,8)='0000' OR SUBSTR(RTRIM(ca_dept_code),5,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,6) END AS ca_dept_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),7,8)='00' OR SUBSTR(RTRIM(ca_dept_code),7,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,8) END AS ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,    
    shop_name,    
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    model_factory,
    minprice,
    maxprice,
    replace(minprices, ' ', '    ') as minprices,
    C_DATE,
    mallcnt,
    replace(replace(spec,',',' '),'/',' ') spec,
    openexpectflag,
    replace(condiname, ' ', '    ') as condiname,    
    CASE WHEN socialprice=0 THEN keyword ELSE keyword || ' ' || UDF_SOCIAL_GOODSNM(modelno_group,modelno) END AS KEYWORD,    
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    to_all
FROM tmp_es_price_data_01
WHERE mod_no = '2'

)

[2018-06-05T12:55:12,752][INFO ][logstash.inputs.jdbc     ] (1.924201s) select 
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    DECODE(NVL(MODELNO_GROUP,0),0,0,1) AS MODELNO_GROUP_FLAG,
    category,
    '' as cg,
    '' as cat1,
    '' as cat2,
    '' as cat3,
    '' as cat4,
    ca_code,
    ca_dept_mcode,
    ca_dept_code,
    ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,
    shop_name,
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    MODELNM || ' ' || FACTORY as model_factory,
    minprice,
    maxprice,
    minprices,
    C_DATE,
    mallcnt,
    DECODE(NVL(MALLCNT,0),0,0,1) AS MALLCNT_FLAG,
    spec,
    openexpectflag,
    condiname,
    KEYWORD,
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    to_all
--    MODELNM || ' ' || FACTORY || ' ' || SPEC || ' ' || KEYWORD || ' ' || KEYWORD2 || ' ' || CONDINAME AS to_all
from (

select
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    CASE WHEN service_gubun='2' AND store_flag='1' AND ca_dept_code IS NOT NULL THEN RTRIM(category || ' '  || ca_dept_code) ELSE category END AS category,
    ca_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),3,8)='000000' OR SUBSTR(RTRIM(ca_dept_code),3,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,4) END AS ca_dept_mcode,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),5,8)='0000' OR SUBSTR(RTRIM(ca_dept_code),5,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,6) END AS ca_dept_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),7,8)='00' OR SUBSTR(RTRIM(ca_dept_code),7,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,8) END AS ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,    
    shop_name,    
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    model_factory,
    minprice,
    maxprice,
    replace(minprices, ' ', '    ') as minprices,
    C_DATE,
    mallcnt,
    replace(replace(spec,',',' '),'/',' ') spec,
    openexpectflag,
    replace(condiname, ' ', '    ') as condiname,    
    CASE WHEN socialprice=0 THEN keyword ELSE keyword || ' ' || UDF_SOCIAL_GOODSNM(modelno_group,modelno) END AS KEYWORD,    
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    to_all
FROM tmp_es_goods_data_01    
WHERE mod_no = '2'

)

[2018-06-05T12:55:12,776][INFO ][logstash.agent           ] Pipelines running {:count=>1, :pipelines=>["main"]}
[2018-06-05T12:55:14,272][INFO ][logstash.inputs.jdbc     ] (1.652314s) select 
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    DECODE(NVL(MODELNO_GROUP,0),0,0,1) AS MODELNO_GROUP_FLAG,
    category,
    '' as cg,
    '' as cat1,
    '' as cat2,
    '' as cat3,
    '' as cat4,
    ca_code,
    ca_dept_mcode,
    ca_dept_code,
    ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,
    shop_name,
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    MODELNM || ' ' || FACTORY as model_factory,
    minprice,
    maxprice,
    minprices,
    C_DATE,
    mallcnt,
    DECODE(NVL(MALLCNT,0),0,0,1) AS MALLCNT_FLAG,
    spec,
    openexpectflag,
    condiname,
    KEYWORD,
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    to_all
--    MODELNM || ' ' || FACTORY || ' ' || SPEC || ' ' || KEYWORD || ' ' || KEYWORD2 || ' ' || CONDINAME AS to_all
from (

select
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    CASE WHEN service_gubun='2' AND store_flag='1' AND ca_dept_code IS NOT NULL THEN RTRIM(category || ' '  || ca_dept_code) ELSE category END AS category,
    ca_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),3,8)='000000' OR SUBSTR(RTRIM(ca_dept_code),3,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,4) END AS ca_dept_mcode,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),5,8)='0000' OR SUBSTR(RTRIM(ca_dept_code),5,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,6) END AS ca_dept_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),7,8)='00' OR SUBSTR(RTRIM(ca_dept_code),7,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,8) END AS ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,    
    shop_name,    
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    model_factory,
    minprice,
    maxprice,
    replace(minprices, ' ', '    ') as minprices,
    C_DATE,
    mallcnt,
    replace(replace(spec,',',' '),'/',' ') spec,
    openexpectflag,
    replace(condiname, ' ', '    ') as condiname,    
    CASE WHEN socialprice=0 THEN keyword ELSE keyword || ' ' || UDF_SOCIAL_GOODSNM(modelno_group,modelno) END AS KEYWORD,    
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    to_all
FROM tmp_es_goods_data_01    
WHERE mod_no = '0'

)

[2018-06-05T12:55:14,273][INFO ][logstash.inputs.jdbc     ] (1.657888s) select
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    DECODE(NVL(MODELNO_GROUP,0),0,0,1) AS MODELNO_GROUP_FLAG,
    category,
    '' as cg,
    '' as cat1,
    '' as cat2,
    '' as cat3,
    '' as cat4,
    ca_code,
    ca_dept_mcode,
    ca_dept_code,
    ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,
    shop_name,
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    '' as model_factory,
    minprice,
    maxprice,
    minprices,
    C_DATE,
    mallcnt,
    DECODE(NVL(MALLCNT,0),0,0,1) AS MALLCNT_FLAG,
    spec,
    openexpectflag,
    condiname,
    KEYWORD,
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    to_all
--    MODELNM || ' ' || FACTORY || ' ' || SPEC || ' ' || KEYWORD || ' ' || KEYWORD2 || ' ' || CONDINAME AS to_all
from (

select
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    CASE WHEN service_gubun='2' AND store_flag='1' AND ca_dept_code IS NOT NULL THEN RTRIM(category || ' '  || ca_dept_code) ELSE category END AS category,
    ca_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),3,8)='000000' OR SUBSTR(RTRIM(ca_dept_code),3,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,4) END AS ca_dept_mcode,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),5,8)='0000' OR SUBSTR(RTRIM(ca_dept_code),5,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,6) END AS ca_dept_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),7,8)='00' OR SUBSTR(RTRIM(ca_dept_code),7,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,8) END AS ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,    
    shop_name,    
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    model_factory,
    minprice,
    maxprice,
    replace(minprices, ' ', '    ') as minprices,
    C_DATE,
    mallcnt,
    replace(replace(spec,',',' '),'/',' ') spec,
    openexpectflag,
    replace(condiname, ' ', '    ') as condiname,    
    CASE WHEN socialprice=0 THEN keyword ELSE keyword || ' ' || UDF_SOCIAL_GOODSNM(modelno_group,modelno) END AS KEYWORD,    
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    to_all
FROM tmp_es_price_data_01
WHERE mod_no = '0'

)

[2018-06-05T12:55:14,990][INFO ][logstash.inputs.jdbc     ] (1.962138s) select 
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    DECODE(NVL(MODELNO_GROUP,0),0,0,1) AS MODELNO_GROUP_FLAG,
    category,
    '' as cg,
    '' as cat1,
    '' as cat2,
    '' as cat3,
    '' as cat4,
    ca_code,
    ca_dept_mcode,
    ca_dept_code,
    ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,
    shop_name,
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    MODELNM || ' ' || FACTORY as model_factory,
    minprice,
    maxprice,
    minprices,
    C_DATE,
    mallcnt,
    DECODE(NVL(MALLCNT,0),0,0,1) AS MALLCNT_FLAG,
    spec,
    openexpectflag,
    condiname,
    KEYWORD,
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    to_all
--    MODELNM || ' ' || FACTORY || ' ' || SPEC || ' ' || KEYWORD || ' ' || KEYWORD2 || ' ' || CONDINAME AS to_all
from (

select
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    CASE WHEN service_gubun='2' AND store_flag='1' AND ca_dept_code IS NOT NULL THEN RTRIM(category || ' '  || ca_dept_code) ELSE category END AS category,
    ca_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),3,8)='000000' OR SUBSTR(RTRIM(ca_dept_code),3,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,4) END AS ca_dept_mcode,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),5,8)='0000' OR SUBSTR(RTRIM(ca_dept_code),5,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,6) END AS ca_dept_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),7,8)='00' OR SUBSTR(RTRIM(ca_dept_code),7,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,8) END AS ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,    
    shop_name,    
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    model_factory,
    minprice,
    maxprice,
    replace(minprices, ' ', '    ') as minprices,
    C_DATE,
    mallcnt,
    replace(replace(spec,',',' '),'/',' ') spec,
    openexpectflag,
    replace(condiname, ' ', '    ') as condiname,    
    CASE WHEN socialprice=0 THEN keyword ELSE keyword || ' ' || UDF_SOCIAL_GOODSNM(modelno_group,modelno) END AS KEYWORD,    
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    to_all
FROM tmp_es_goods_data_01    
WHERE mod_no = '1'

)

[2018-06-05T12:55:14,997][INFO ][logstash.inputs.jdbc     ] (1.938361s) select
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    DECODE(NVL(MODELNO_GROUP,0),0,0,1) AS MODELNO_GROUP_FLAG,
    category,
    '' as cg,
    '' as cat1,
    '' as cat2,
    '' as cat3,
    '' as cat4,
    ca_code,
    ca_dept_mcode,
    ca_dept_code,
    ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,
    shop_name,
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    '' as model_factory,
    minprice,
    maxprice,
    minprices,
    C_DATE,
    mallcnt,
    DECODE(NVL(MALLCNT,0),0,0,1) AS MALLCNT_FLAG,
    spec,
    openexpectflag,
    condiname,
    KEYWORD,
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    to_all
--    MODELNM || ' ' || FACTORY || ' ' || SPEC || ' ' || KEYWORD || ' ' || KEYWORD2 || ' ' || CONDINAME AS to_all
from (

select
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    CASE WHEN service_gubun='2' AND store_flag='1' AND ca_dept_code IS NOT NULL THEN RTRIM(category || ' '  || ca_dept_code) ELSE category END AS category,
    ca_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),3,8)='000000' OR SUBSTR(RTRIM(ca_dept_code),3,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,4) END AS ca_dept_mcode,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),5,8)='0000' OR SUBSTR(RTRIM(ca_dept_code),5,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,6) END AS ca_dept_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),7,8)='00' OR SUBSTR(RTRIM(ca_dept_code),7,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,8) END AS ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,    
    shop_name,    
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    model_factory,
    minprice,
    maxprice,
    replace(minprices, ' ', '    ') as minprices,
    C_DATE,
    mallcnt,
    replace(replace(spec,',',' '),'/',' ') spec,
    openexpectflag,
    replace(condiname, ' ', '    ') as condiname,    
    CASE WHEN socialprice=0 THEN keyword ELSE keyword || ' ' || UDF_SOCIAL_GOODSNM(modelno_group,modelno) END AS KEYWORD,    
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    to_all
FROM tmp_es_price_data_01
WHERE mod_no = '1'

)

[2018-06-05T12:55:15,973][INFO ][logstash.inputs.jdbc     ] (1.248122s) select 
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    DECODE(NVL(MODELNO_GROUP,0),0,0,1) AS MODELNO_GROUP_FLAG,
    category,
    '' as cg,
    '' as cat1,
    '' as cat2,
    '' as cat3,
    '' as cat4,
    ca_code,
    ca_dept_mcode,
    ca_dept_code,
    ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,
    shop_name,
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    MODELNM || ' ' || FACTORY as model_factory,
    minprice,
    maxprice,
    minprices,
    C_DATE,
    mallcnt,
    DECODE(NVL(MALLCNT,0),0,0,1) AS MALLCNT_FLAG,
    spec,
    openexpectflag,
    condiname,
    KEYWORD,
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    to_all
--    MODELNM || ' ' || FACTORY || ' ' || SPEC || ' ' || KEYWORD || ' ' || KEYWORD2 || ' ' || CONDINAME AS to_all
from (

select
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    CASE WHEN service_gubun='2' AND store_flag='1' AND ca_dept_code IS NOT NULL THEN RTRIM(category || ' '  || ca_dept_code) ELSE category END AS category,
    ca_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),3,8)='000000' OR SUBSTR(RTRIM(ca_dept_code),3,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,4) END AS ca_dept_mcode,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),5,8)='0000' OR SUBSTR(RTRIM(ca_dept_code),5,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,6) END AS ca_dept_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),7,8)='00' OR SUBSTR(RTRIM(ca_dept_code),7,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,8) END AS ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,    
    shop_name,    
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    model_factory,
    minprice,
    maxprice,
    replace(minprices, ' ', '    ') as minprices,
    C_DATE,
    mallcnt,
    replace(replace(spec,',',' '),'/',' ') spec,
    openexpectflag,
    replace(condiname, ' ', '    ') as condiname,    
    CASE WHEN socialprice=0 THEN keyword ELSE keyword || ' ' || UDF_SOCIAL_GOODSNM(modelno_group,modelno) END AS KEYWORD,    
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    to_all
FROM tmp_es_goods_data_01    
WHERE mod_no = '4'

)

[2018-06-05T12:55:15,981][INFO ][logstash.inputs.jdbc     ] (1.254106s) select
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    DECODE(NVL(MODELNO_GROUP,0),0,0,1) AS MODELNO_GROUP_FLAG,
    category,
    '' as cg,
    '' as cat1,
    '' as cat2,
    '' as cat3,
    '' as cat4,
    ca_code,
    ca_dept_mcode,
    ca_dept_code,
    ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,
    shop_name,
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    '' as model_factory,
    minprice,
    maxprice,
    minprices,
    C_DATE,
    mallcnt,
    DECODE(NVL(MALLCNT,0),0,0,1) AS MALLCNT_FLAG,
    spec,
    openexpectflag,
    condiname,
    KEYWORD,
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    to_all
--    MODELNM || ' ' || FACTORY || ' ' || SPEC || ' ' || KEYWORD || ' ' || KEYWORD2 || ' ' || CONDINAME AS to_all
from (

select
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    CASE WHEN service_gubun='2' AND store_flag='1' AND ca_dept_code IS NOT NULL THEN RTRIM(category || ' '  || ca_dept_code) ELSE category END AS category,
    ca_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),3,8)='000000' OR SUBSTR(RTRIM(ca_dept_code),3,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,4) END AS ca_dept_mcode,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),5,8)='0000' OR SUBSTR(RTRIM(ca_dept_code),5,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,6) END AS ca_dept_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),7,8)='00' OR SUBSTR(RTRIM(ca_dept_code),7,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,8) END AS ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,    
    shop_name,    
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    model_factory,
    minprice,
    maxprice,
    replace(minprices, ' ', '    ') as minprices,
    C_DATE,
    mallcnt,
    replace(replace(spec,',',' '),'/',' ') spec,
    openexpectflag,
    replace(condiname, ' ', '    ') as condiname,    
    CASE WHEN socialprice=0 THEN keyword ELSE keyword || ' ' || UDF_SOCIAL_GOODSNM(modelno_group,modelno) END AS KEYWORD,    
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    to_all
FROM tmp_es_price_data_01
WHERE mod_no = '4'

)

[2018-06-05T13:30:07,143][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"fb_apache", :directory=>"/usr/share/logstash/modules/fb_apache/configuration"}
[2018-06-05T13:30:07,193][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"netflow", :directory=>"/usr/share/logstash/modules/netflow/configuration"}
[2018-06-05T13:30:09,260][WARN ][logstash.config.source.multilocal] Ignoring the 'pipelines.yml' file because modules or command line options are specified
[2018-06-05T13:30:10,397][INFO ][logstash.runner          ] Starting Logstash {"logstash.version"=>"6.2.3"}
[2018-06-05T13:30:10,582][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"fb_apache", :directory=>"/usr/share/logstash/modules/fb_apache/configuration"}
[2018-06-05T13:30:10,603][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"netflow", :directory=>"/usr/share/logstash/modules/netflow/configuration"}
[2018-06-05T13:30:10,991][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=>9600}
[2018-06-05T13:30:11,337][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"fb_apache", :directory=>"/usr/share/logstash/modules/fb_apache/configuration"}
[2018-06-05T13:30:11,413][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"netflow", :directory=>"/usr/share/logstash/modules/netflow/configuration"}
[2018-06-05T13:30:12,056][WARN ][logstash.config.source.multilocal] Ignoring the 'pipelines.yml' file because modules or command line options are specified
[2018-06-05T13:30:12,131][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"fb_apache", :directory=>"/usr/share/logstash/modules/fb_apache/configuration"}
[2018-06-05T13:30:12,161][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"netflow", :directory=>"/usr/share/logstash/modules/netflow/configuration"}
[2018-06-05T13:30:12,383][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"fb_apache", :directory=>"/usr/share/logstash/modules/fb_apache/configuration"}
[2018-06-05T13:30:12,416][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"netflow", :directory=>"/usr/share/logstash/modules/netflow/configuration"}
[2018-06-05T13:30:12,759][INFO ][logstash.runner          ] Starting Logstash {"logstash.version"=>"6.2.3"}
[2018-06-05T13:30:13,031][DEBUG][org.logstash.secret.store.SecretStoreFactory] Attempting to exists or secret store with implementation: org.logstash.secret.store.backend.JavaKeyStore
[2018-06-05T13:30:13,050][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"fb_apache", :directory=>"/usr/share/logstash/modules/fb_apache/configuration"}
[2018-06-05T13:30:13,138][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"netflow", :directory=>"/usr/share/logstash/modules/netflow/configuration"}
[2018-06-05T13:30:13,239][WARN ][logstash.config.source.multilocal] Ignoring the 'pipelines.yml' file because modules or command line options are specified
[2018-06-05T13:30:13,301][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=>9601}
[2018-06-05T13:30:13,473][DEBUG][org.logstash.secret.store.SecretStoreFactory] Attempting to exists or secret store with implementation: org.logstash.secret.store.backend.JavaKeyStore
[2018-06-05T13:30:13,746][INFO ][logstash.filters.ruby.script] Test run complete {:script_path=>"rubyfilter.rb", :results=>{:passed=>0, :failed=>0, :errored=>0}}
[2018-06-05T13:30:13,780][INFO ][logstash.runner          ] Starting Logstash {"logstash.version"=>"6.2.3"}
[2018-06-05T13:30:13,982][WARN ][logstash.config.source.multilocal] Ignoring the 'pipelines.yml' file because modules or command line options are specified
[2018-06-05T13:30:14,014][WARN ][logstash.config.source.multilocal] Ignoring the 'pipelines.yml' file because modules or command line options are specified
[2018-06-05T13:30:14,340][WARN ][logstash.config.source.multilocal] Ignoring the 'pipelines.yml' file because modules or command line options are specified
[2018-06-05T13:30:14,341][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=>9602}
[2018-06-05T13:30:14,392][DEBUG][org.logstash.secret.store.SecretStoreFactory] Attempting to exists or secret store with implementation: org.logstash.secret.store.backend.JavaKeyStore
[2018-06-05T13:30:14,506][WARN ][logstash.outputs.elasticsearch] You are using a deprecated config setting "document_type" set in elasticsearch. Deprecated settings will continue to work, but are scheduled for removal from logstash in the future. Document types are being deprecated in Elasticsearch 6.0, and removed entirely in 7.0. You should avoid this feature If you have any questions about this, please visit the #logstash channel on freenode irc. {:name=>"document_type", :plugin=><LogStash::Outputs::ElasticSearch hosts=>[//100.100.100.111:9200, //100.100.100.112:9200, //100.100.100.113:9200], index=>"qa-enuri-main-as-is-2018.06.05.04.29", document_type=>"_doc", document_id=>"%{id}", action=>"index", id=>"6ecd11524c84e5de286546b0de40f57503392aeab1548c7913e69855f4645bbc", enable_metric=>true, codec=><LogStash::Codecs::Plain id=>"plain_aad7b780-3f49-4a73-8737-5279aa461b51", enable_metric=>true, charset=>"UTF-8">, workers=>1, manage_template=>true, template_name=>"logstash", template_overwrite=>false, doc_as_upsert=>false, script_type=>"inline", script_lang=>"painless", script_var_name=>"event", scripted_upsert=>false, retry_initial_interval=>2, retry_max_interval=>64, retry_on_conflict=>1, ssl_certificate_verification=>true, sniffing=>false, sniffing_delay=>5, timeout=>60, pool_max=>1000, pool_max_per_route=>100, resurrect_delay=>5, validate_after_inactivity=>10000, http_compression=>false>}
[2018-06-05T13:30:14,545][INFO ][logstash.pipeline        ] Starting pipeline {:pipeline_id=>"main", "pipeline.workers"=>8, "pipeline.batch.size"=>125, "pipeline.batch.delay"=>50}
[2018-06-05T13:30:14,585][INFO ][logstash.runner          ] Starting Logstash {"logstash.version"=>"6.2.3"}
[2018-06-05T13:30:14,925][INFO ][logstash.runner          ] Starting Logstash {"logstash.version"=>"6.2.3"}
[2018-06-05T13:30:15,095][INFO ][logstash.runner          ] Starting Logstash {"logstash.version"=>"6.2.3"}
[2018-06-05T13:30:15,236][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=>9603}
[2018-06-05T13:30:15,329][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=>9604}
[2018-06-05T13:30:15,584][INFO ][logstash.outputs.elasticsearch] Elasticsearch pool URLs updated {:changes=>{:removed=>[], :added=>[http://100.100.100.111:9200/, http://100.100.100.112:9200/, http://100.100.100.113:9200/]}}
[2018-06-05T13:30:15,660][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://100.100.100.111:9200/, :path=>"/"}
[2018-06-05T13:30:15,665][DEBUG][org.logstash.secret.store.SecretStoreFactory] Attempting to exists or secret store with implementation: org.logstash.secret.store.backend.JavaKeyStore
[2018-06-05T13:30:16,029][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=>9605}
[2018-06-05T13:30:16,104][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://100.100.100.111:9200/"}
[2018-06-05T13:30:16,202][DEBUG][org.logstash.secret.store.SecretStoreFactory] Attempting to exists or secret store with implementation: org.logstash.secret.store.backend.JavaKeyStore
[2018-06-05T13:30:16,340][INFO ][logstash.filters.ruby.script] Test run complete {:script_path=>"rubyfilter.rb", :results=>{:passed=>0, :failed=>0, :errored=>0}}
[2018-06-05T13:30:16,344][INFO ][logstash.outputs.elasticsearch] ES Output version determined {:es_version=>6}
[2018-06-05T13:30:16,568][DEBUG][org.logstash.secret.store.SecretStoreFactory] Attempting to exists or secret store with implementation: org.logstash.secret.store.backend.JavaKeyStore
[2018-06-05T13:30:16,628][DEBUG][org.logstash.secret.store.SecretStoreFactory] Attempting to exists or secret store with implementation: org.logstash.secret.store.backend.JavaKeyStore
[2018-06-05T13:30:17,313][WARN ][logstash.outputs.elasticsearch] Detected a 6.x and above cluster: the `type` event field won't be used to determine the document _type {:es_version=>6}
[2018-06-05T13:30:17,314][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://100.100.100.112:9200/, :path=>"/"}
[2018-06-05T13:30:17,054][DEBUG][org.logstash.secret.store.SecretStoreFactory] Attempting to exists or secret store with implementation: org.logstash.secret.store.backend.JavaKeyStore
[2018-06-05T13:30:17,378][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://100.100.100.112:9200/"}
[2018-06-05T13:30:17,385][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://100.100.100.113:9200/, :path=>"/"}
[2018-06-05T13:30:17,409][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://100.100.100.113:9200/"}
[2018-06-05T13:30:17,447][WARN ][logstash.outputs.elasticsearch] You are using a deprecated config setting "document_type" set in elasticsearch. Deprecated settings will continue to work, but are scheduled for removal from logstash in the future. Document types are being deprecated in Elasticsearch 6.0, and removed entirely in 7.0. You should avoid this feature If you have any questions about this, please visit the #logstash channel on freenode irc. {:name=>"document_type", :plugin=><LogStash::Outputs::ElasticSearch hosts=>[//100.100.100.111:9200, //100.100.100.112:9200, //100.100.100.113:9200], index=>"qa-enuri-main-as-is-2018.06.05.04.29", document_type=>"_doc", document_id=>"%{id}", action=>"index", id=>"6ecd11524c84e5de286546b0de40f57503392aeab1548c7913e69855f4645bbc", enable_metric=>true, codec=><LogStash::Codecs::Plain id=>"plain_8dc62afb-51da-44ad-935a-6f37ce29bb33", enable_metric=>true, charset=>"UTF-8">, workers=>1, manage_template=>true, template_name=>"logstash", template_overwrite=>false, doc_as_upsert=>false, script_type=>"inline", script_lang=>"painless", script_var_name=>"event", scripted_upsert=>false, retry_initial_interval=>2, retry_max_interval=>64, retry_on_conflict=>1, ssl_certificate_verification=>true, sniffing=>false, sniffing_delay=>5, timeout=>60, pool_max=>1000, pool_max_per_route=>100, resurrect_delay=>5, validate_after_inactivity=>10000, http_compression=>false>}
[2018-06-05T13:30:17,469][DEBUG][org.logstash.secret.store.SecretStoreFactory] Attempting to exists or secret store with implementation: org.logstash.secret.store.backend.JavaKeyStore
[2018-06-05T13:30:17,483][INFO ][logstash.pipeline        ] Starting pipeline {:pipeline_id=>"main", "pipeline.workers"=>8, "pipeline.batch.size"=>125, "pipeline.batch.delay"=>50}
[2018-06-05T13:30:17,490][INFO ][logstash.outputs.elasticsearch] Using mapping template from {:path=>nil}
[2018-06-05T13:30:17,506][INFO ][logstash.outputs.elasticsearch] Attempting to install template {:manage_template=>{"template"=>"logstash-*", "version"=>60001, "settings"=>{"index.refresh_interval"=>"5s"}, "mappings"=>{"_default_"=>{"dynamic_templates"=>[{"message_field"=>{"path_match"=>"message", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false}}}, {"string_fields"=>{"match"=>"*", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false, "fields"=>{"keyword"=>{"type"=>"keyword", "ignore_above"=>256}}}}}], "properties"=>{"@timestamp"=>{"type"=>"date"}, "@version"=>{"type"=>"keyword"}, "geoip"=>{"dynamic"=>true, "properties"=>{"ip"=>{"type"=>"ip"}, "location"=>{"type"=>"geo_point"}, "latitude"=>{"type"=>"half_float"}, "longitude"=>{"type"=>"half_float"}}}}}}}}
[2018-06-05T13:30:17,517][DEBUG][org.logstash.secret.store.SecretStoreFactory] Attempting to exists or secret store with implementation: org.logstash.secret.store.backend.JavaKeyStore
[2018-06-05T13:30:17,531][INFO ][logstash.outputs.elasticsearch] New Elasticsearch output {:class=>"LogStash::Outputs::ElasticSearch", :hosts=>["//100.100.100.111:9200", "//100.100.100.112:9200", "//100.100.100.113:9200"]}
[2018-06-05T13:30:17,604][DEBUG][org.logstash.secret.store.SecretStoreFactory] Attempting to exists or secret store with implementation: org.logstash.secret.store.backend.JavaKeyStore
[2018-06-05T13:30:17,640][INFO ][logstash.filters.ruby.script] Test run complete {:script_path=>"rubyfilter.rb", :results=>{:passed=>0, :failed=>0, :errored=>0}}
[2018-06-05T13:30:17,776][INFO ][logstash.filters.ruby.script] Test run complete {:script_path=>"rubyfilter.rb", :results=>{:passed=>0, :failed=>0, :errored=>0}}
[2018-06-05T13:30:17,850][DEBUG][org.logstash.secret.store.SecretStoreFactory] Attempting to exists or secret store with implementation: org.logstash.secret.store.backend.JavaKeyStore
[2018-06-05T13:30:17,891][WARN ][logstash.outputs.elasticsearch] You are using a deprecated config setting "document_type" set in elasticsearch. Deprecated settings will continue to work, but are scheduled for removal from logstash in the future. Document types are being deprecated in Elasticsearch 6.0, and removed entirely in 7.0. You should avoid this feature If you have any questions about this, please visit the #logstash channel on freenode irc. {:name=>"document_type", :plugin=><LogStash::Outputs::ElasticSearch hosts=>[//100.100.100.111:9200, //100.100.100.112:9200, //100.100.100.113:9200], index=>"qa-enuri-main-as-is-2018.06.05.04.29", document_type=>"_doc", document_id=>"%{id}", action=>"index", id=>"6ecd11524c84e5de286546b0de40f57503392aeab1548c7913e69855f4645bbc", enable_metric=>true, codec=><LogStash::Codecs::Plain id=>"plain_24ae2752-ab2d-49c7-91d1-2d0f56b8362d", enable_metric=>true, charset=>"UTF-8">, workers=>1, manage_template=>true, template_name=>"logstash", template_overwrite=>false, doc_as_upsert=>false, script_type=>"inline", script_lang=>"painless", script_var_name=>"event", scripted_upsert=>false, retry_initial_interval=>2, retry_max_interval=>64, retry_on_conflict=>1, ssl_certificate_verification=>true, sniffing=>false, sniffing_delay=>5, timeout=>60, pool_max=>1000, pool_max_per_route=>100, resurrect_delay=>5, validate_after_inactivity=>10000, http_compression=>false>}
[2018-06-05T13:30:17,910][INFO ][logstash.pipeline        ] Starting pipeline {:pipeline_id=>"main", "pipeline.workers"=>8, "pipeline.batch.size"=>125, "pipeline.batch.delay"=>50}
[2018-06-05T13:30:18,056][DEBUG][org.logstash.secret.store.SecretStoreFactory] Attempting to exists or secret store with implementation: org.logstash.secret.store.backend.JavaKeyStore
[2018-06-05T13:30:18,086][DEBUG][org.logstash.secret.store.SecretStoreFactory] Attempting to exists or secret store with implementation: org.logstash.secret.store.backend.JavaKeyStore
[2018-06-05T13:30:18,228][WARN ][logstash.outputs.elasticsearch] You are using a deprecated config setting "document_type" set in elasticsearch. Deprecated settings will continue to work, but are scheduled for removal from logstash in the future. Document types are being deprecated in Elasticsearch 6.0, and removed entirely in 7.0. You should avoid this feature If you have any questions about this, please visit the #logstash channel on freenode irc. {:name=>"document_type", :plugin=><LogStash::Outputs::ElasticSearch hosts=>[//100.100.100.111:9200, //100.100.100.112:9200, //100.100.100.113:9200], index=>"qa-enuri-main-as-is-2018.06.05.04.29", document_type=>"_doc", document_id=>"%{id}", action=>"index", id=>"6ecd11524c84e5de286546b0de40f57503392aeab1548c7913e69855f4645bbc", enable_metric=>true, codec=><LogStash::Codecs::Plain id=>"plain_ce55fc42-7868-41b8-88bb-40a48a3cc238", enable_metric=>true, charset=>"UTF-8">, workers=>1, manage_template=>true, template_name=>"logstash", template_overwrite=>false, doc_as_upsert=>false, script_type=>"inline", script_lang=>"painless", script_var_name=>"event", scripted_upsert=>false, retry_initial_interval=>2, retry_max_interval=>64, retry_on_conflict=>1, ssl_certificate_verification=>true, sniffing=>false, sniffing_delay=>5, timeout=>60, pool_max=>1000, pool_max_per_route=>100, resurrect_delay=>5, validate_after_inactivity=>10000, http_compression=>false>}
[2018-06-05T13:30:18,285][INFO ][logstash.pipeline        ] Starting pipeline {:pipeline_id=>"main", "pipeline.workers"=>8, "pipeline.batch.size"=>125, "pipeline.batch.delay"=>50}
[2018-06-05T13:30:18,450][DEBUG][org.logstash.secret.store.SecretStoreFactory] Attempting to exists or secret store with implementation: org.logstash.secret.store.backend.JavaKeyStore
[2018-06-05T13:30:18,703][DEBUG][org.logstash.secret.store.SecretStoreFactory] Attempting to exists or secret store with implementation: org.logstash.secret.store.backend.JavaKeyStore
[2018-06-05T13:30:18,840][INFO ][logstash.filters.ruby.script] Test run complete {:script_path=>"rubyfilter.rb", :results=>{:passed=>0, :failed=>0, :errored=>0}}
[2018-06-05T13:30:18,854][INFO ][logstash.filters.ruby.script] Test run complete {:script_path=>"rubyfilter.rb", :results=>{:passed=>0, :failed=>0, :errored=>0}}
[2018-06-05T13:30:18,973][INFO ][logstash.pipeline        ] Pipeline started succesfully {:pipeline_id=>"main", :thread=>"#<Thread:0x724e7966@/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:246 run>"}
[2018-06-05T13:30:19,047][INFO ][logstash.outputs.elasticsearch] Elasticsearch pool URLs updated {:changes=>{:removed=>[], :added=>[http://100.100.100.111:9200/, http://100.100.100.112:9200/, http://100.100.100.113:9200/]}}
[2018-06-05T13:30:19,050][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://100.100.100.111:9200/, :path=>"/"}
[2018-06-05T13:30:19,054][INFO ][logstash.agent           ] Pipelines running {:count=>1, :pipelines=>["main"]}
[2018-06-05T13:30:19,279][INFO ][logstash.outputs.elasticsearch] Elasticsearch pool URLs updated {:changes=>{:removed=>[], :added=>[http://100.100.100.111:9200/, http://100.100.100.112:9200/, http://100.100.100.113:9200/]}}
[2018-06-05T13:30:19,291][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://100.100.100.111:9200/, :path=>"/"}
[2018-06-05T13:30:19,305][DEBUG][org.logstash.secret.store.SecretStoreFactory] Attempting to exists or secret store with implementation: org.logstash.secret.store.backend.JavaKeyStore
[2018-06-05T13:30:19,395][DEBUG][org.logstash.secret.store.SecretStoreFactory] Attempting to exists or secret store with implementation: org.logstash.secret.store.backend.JavaKeyStore
[2018-06-05T13:30:19,428][WARN ][logstash.outputs.elasticsearch] You are using a deprecated config setting "document_type" set in elasticsearch. Deprecated settings will continue to work, but are scheduled for removal from logstash in the future. Document types are being deprecated in Elasticsearch 6.0, and removed entirely in 7.0. You should avoid this feature If you have any questions about this, please visit the #logstash channel on freenode irc. {:name=>"document_type", :plugin=><LogStash::Outputs::ElasticSearch hosts=>[//100.100.100.111:9200, //100.100.100.112:9200, //100.100.100.113:9200], index=>"qa-enuri-main-as-is-2018.06.05.04.29", document_type=>"_doc", document_id=>"%{id}", action=>"index", id=>"6ecd11524c84e5de286546b0de40f57503392aeab1548c7913e69855f4645bbc", enable_metric=>true, codec=><LogStash::Codecs::Plain id=>"plain_9aebaac4-d2e6-483e-8c5d-a5177c051cd2", enable_metric=>true, charset=>"UTF-8">, workers=>1, manage_template=>true, template_name=>"logstash", template_overwrite=>false, doc_as_upsert=>false, script_type=>"inline", script_lang=>"painless", script_var_name=>"event", scripted_upsert=>false, retry_initial_interval=>2, retry_max_interval=>64, retry_on_conflict=>1, ssl_certificate_verification=>true, sniffing=>false, sniffing_delay=>5, timeout=>60, pool_max=>1000, pool_max_per_route=>100, resurrect_delay=>5, validate_after_inactivity=>10000, http_compression=>false>}
[2018-06-05T13:30:19,479][INFO ][logstash.pipeline        ] Starting pipeline {:pipeline_id=>"main", "pipeline.workers"=>8, "pipeline.batch.size"=>125, "pipeline.batch.delay"=>50}
[2018-06-05T13:30:19,496][WARN ][logstash.outputs.elasticsearch] You are using a deprecated config setting "document_type" set in elasticsearch. Deprecated settings will continue to work, but are scheduled for removal from logstash in the future. Document types are being deprecated in Elasticsearch 6.0, and removed entirely in 7.0. You should avoid this feature If you have any questions about this, please visit the #logstash channel on freenode irc. {:name=>"document_type", :plugin=><LogStash::Outputs::ElasticSearch hosts=>[//100.100.100.111:9200, //100.100.100.112:9200, //100.100.100.113:9200], index=>"qa-enuri-main-as-is-2018.06.05.04.29", document_type=>"_doc", document_id=>"%{id}", action=>"index", id=>"6ecd11524c84e5de286546b0de40f57503392aeab1548c7913e69855f4645bbc", enable_metric=>true, codec=><LogStash::Codecs::Plain id=>"plain_87664aa9-d1c1-4d10-943a-92d1ba31bf7c", enable_metric=>true, charset=>"UTF-8">, workers=>1, manage_template=>true, template_name=>"logstash", template_overwrite=>false, doc_as_upsert=>false, script_type=>"inline", script_lang=>"painless", script_var_name=>"event", scripted_upsert=>false, retry_initial_interval=>2, retry_max_interval=>64, retry_on_conflict=>1, ssl_certificate_verification=>true, sniffing=>false, sniffing_delay=>5, timeout=>60, pool_max=>1000, pool_max_per_route=>100, resurrect_delay=>5, validate_after_inactivity=>10000, http_compression=>false>}
[2018-06-05T13:30:19,482][INFO ][logstash.outputs.elasticsearch] Elasticsearch pool URLs updated {:changes=>{:removed=>[], :added=>[http://100.100.100.111:9200/, http://100.100.100.112:9200/, http://100.100.100.113:9200/]}}
[2018-06-05T13:30:19,505][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://100.100.100.111:9200/, :path=>"/"}
[2018-06-05T13:30:19,523][INFO ][logstash.pipeline        ] Starting pipeline {:pipeline_id=>"main", "pipeline.workers"=>8, "pipeline.batch.size"=>125, "pipeline.batch.delay"=>50}
[2018-06-05T13:30:19,555][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://100.100.100.111:9200/"}
[2018-06-05T13:30:19,709][INFO ][logstash.outputs.elasticsearch] ES Output version determined {:es_version=>6}
[2018-06-05T13:30:19,709][WARN ][logstash.outputs.elasticsearch] Detected a 6.x and above cluster: the `type` event field won't be used to determine the document _type {:es_version=>6}
[2018-06-05T13:30:19,710][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://100.100.100.112:9200/, :path=>"/"}
[2018-06-05T13:30:19,757][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://100.100.100.112:9200/"}
[2018-06-05T13:30:19,764][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://100.100.100.113:9200/, :path=>"/"}
[2018-06-05T13:30:19,779][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://100.100.100.111:9200/"}
[2018-06-05T13:30:19,789][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://100.100.100.113:9200/"}
[2018-06-05T13:30:19,894][INFO ][logstash.outputs.elasticsearch] Using mapping template from {:path=>nil}
[2018-06-05T13:30:19,927][INFO ][logstash.outputs.elasticsearch] Attempting to install template {:manage_template=>{"template"=>"logstash-*", "version"=>60001, "settings"=>{"index.refresh_interval"=>"5s"}, "mappings"=>{"_default_"=>{"dynamic_templates"=>[{"message_field"=>{"path_match"=>"message", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false}}}, {"string_fields"=>{"match"=>"*", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false, "fields"=>{"keyword"=>{"type"=>"keyword", "ignore_above"=>256}}}}}], "properties"=>{"@timestamp"=>{"type"=>"date"}, "@version"=>{"type"=>"keyword"}, "geoip"=>{"dynamic"=>true, "properties"=>{"ip"=>{"type"=>"ip"}, "location"=>{"type"=>"geo_point"}, "latitude"=>{"type"=>"half_float"}, "longitude"=>{"type"=>"half_float"}}}}}}}}
[2018-06-05T13:30:19,951][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://100.100.100.111:9200/"}
[2018-06-05T13:30:19,973][INFO ][logstash.outputs.elasticsearch] New Elasticsearch output {:class=>"LogStash::Outputs::ElasticSearch", :hosts=>["//100.100.100.111:9200", "//100.100.100.112:9200", "//100.100.100.113:9200"]}
[2018-06-05T13:30:20,024][INFO ][logstash.outputs.elasticsearch] ES Output version determined {:es_version=>6}
[2018-06-05T13:30:20,025][WARN ][logstash.outputs.elasticsearch] Detected a 6.x and above cluster: the `type` event field won't be used to determine the document _type {:es_version=>6}
[2018-06-05T13:30:20,026][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://100.100.100.112:9200/, :path=>"/"}
[2018-06-05T13:30:20,068][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://100.100.100.112:9200/"}
[2018-06-05T13:30:20,078][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://100.100.100.113:9200/, :path=>"/"}
[2018-06-05T13:30:20,096][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://100.100.100.113:9200/"}
[2018-06-05T13:30:20,129][INFO ][logstash.outputs.elasticsearch] ES Output version determined {:es_version=>6}
[2018-06-05T13:30:20,130][WARN ][logstash.outputs.elasticsearch] Detected a 6.x and above cluster: the `type` event field won't be used to determine the document _type {:es_version=>6}
[2018-06-05T13:30:20,130][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://100.100.100.112:9200/, :path=>"/"}
[2018-06-05T13:30:20,119][INFO ][logstash.outputs.elasticsearch] Using mapping template from {:path=>nil}
[2018-06-05T13:30:20,164][INFO ][logstash.outputs.elasticsearch] Attempting to install template {:manage_template=>{"template"=>"logstash-*", "version"=>60001, "settings"=>{"index.refresh_interval"=>"5s"}, "mappings"=>{"_default_"=>{"dynamic_templates"=>[{"message_field"=>{"path_match"=>"message", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false}}}, {"string_fields"=>{"match"=>"*", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false, "fields"=>{"keyword"=>{"type"=>"keyword", "ignore_above"=>256}}}}}], "properties"=>{"@timestamp"=>{"type"=>"date"}, "@version"=>{"type"=>"keyword"}, "geoip"=>{"dynamic"=>true, "properties"=>{"ip"=>{"type"=>"ip"}, "location"=>{"type"=>"geo_point"}, "latitude"=>{"type"=>"half_float"}, "longitude"=>{"type"=>"half_float"}}}}}}}}
[2018-06-05T13:30:20,185][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://100.100.100.112:9200/"}
[2018-06-05T13:30:20,194][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://100.100.100.113:9200/, :path=>"/"}
[2018-06-05T13:30:20,199][INFO ][logstash.outputs.elasticsearch] New Elasticsearch output {:class=>"LogStash::Outputs::ElasticSearch", :hosts=>["//100.100.100.111:9200", "//100.100.100.112:9200", "//100.100.100.113:9200"]}
[2018-06-05T13:30:20,201][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://100.100.100.113:9200/"}
[2018-06-05T13:30:20,242][INFO ][logstash.outputs.elasticsearch] Using mapping template from {:path=>nil}
[2018-06-05T13:30:20,256][INFO ][logstash.outputs.elasticsearch] Attempting to install template {:manage_template=>{"template"=>"logstash-*", "version"=>60001, "settings"=>{"index.refresh_interval"=>"5s"}, "mappings"=>{"_default_"=>{"dynamic_templates"=>[{"message_field"=>{"path_match"=>"message", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false}}}, {"string_fields"=>{"match"=>"*", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false, "fields"=>{"keyword"=>{"type"=>"keyword", "ignore_above"=>256}}}}}], "properties"=>{"@timestamp"=>{"type"=>"date"}, "@version"=>{"type"=>"keyword"}, "geoip"=>{"dynamic"=>true, "properties"=>{"ip"=>{"type"=>"ip"}, "location"=>{"type"=>"geo_point"}, "latitude"=>{"type"=>"half_float"}, "longitude"=>{"type"=>"half_float"}}}}}}}}
[2018-06-05T13:30:20,261][INFO ][logstash.outputs.elasticsearch] Elasticsearch pool URLs updated {:changes=>{:removed=>[], :added=>[http://100.100.100.111:9200/, http://100.100.100.112:9200/, http://100.100.100.113:9200/]}}
[2018-06-05T13:30:20,263][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://100.100.100.111:9200/, :path=>"/"}
[2018-06-05T13:30:20,296][INFO ][logstash.outputs.elasticsearch] New Elasticsearch output {:class=>"LogStash::Outputs::ElasticSearch", :hosts=>["//100.100.100.111:9200", "//100.100.100.112:9200", "//100.100.100.113:9200"]}
[2018-06-05T13:30:20,724][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://100.100.100.111:9200/"}
[2018-06-05T13:30:20,737][INFO ][logstash.pipeline        ] Pipeline started succesfully {:pipeline_id=>"main", :thread=>"#<Thread:0x1844fe1@/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:246 run>"}
[2018-06-05T13:30:20,832][INFO ][logstash.outputs.elasticsearch] ES Output version determined {:es_version=>6}
[2018-06-05T13:30:20,833][WARN ][logstash.outputs.elasticsearch] Detected a 6.x and above cluster: the `type` event field won't be used to determine the document _type {:es_version=>6}
[2018-06-05T13:30:20,833][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://100.100.100.112:9200/, :path=>"/"}
[2018-06-05T13:30:20,862][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://100.100.100.112:9200/"}
[2018-06-05T13:30:20,868][INFO ][logstash.outputs.elasticsearch] Elasticsearch pool URLs updated {:changes=>{:removed=>[], :added=>[http://100.100.100.111:9200/, http://100.100.100.112:9200/, http://100.100.100.113:9200/]}}
[2018-06-05T13:30:20,883][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://100.100.100.111:9200/, :path=>"/"}
[2018-06-05T13:30:20,888][INFO ][logstash.agent           ] Pipelines running {:count=>1, :pipelines=>["main"]}
[2018-06-05T13:30:20,893][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://100.100.100.113:9200/, :path=>"/"}
[2018-06-05T13:30:20,939][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://100.100.100.113:9200/"}
[2018-06-05T13:30:20,994][INFO ][logstash.outputs.elasticsearch] Using mapping template from {:path=>nil}
[2018-06-05T13:30:21,022][INFO ][logstash.outputs.elasticsearch] Attempting to install template {:manage_template=>{"template"=>"logstash-*", "version"=>60001, "settings"=>{"index.refresh_interval"=>"5s"}, "mappings"=>{"_default_"=>{"dynamic_templates"=>[{"message_field"=>{"path_match"=>"message", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false}}}, {"string_fields"=>{"match"=>"*", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false, "fields"=>{"keyword"=>{"type"=>"keyword", "ignore_above"=>256}}}}}], "properties"=>{"@timestamp"=>{"type"=>"date"}, "@version"=>{"type"=>"keyword"}, "geoip"=>{"dynamic"=>true, "properties"=>{"ip"=>{"type"=>"ip"}, "location"=>{"type"=>"geo_point"}, "latitude"=>{"type"=>"half_float"}, "longitude"=>{"type"=>"half_float"}}}}}}}}
[2018-06-05T13:30:21,058][INFO ][logstash.outputs.elasticsearch] New Elasticsearch output {:class=>"LogStash::Outputs::ElasticSearch", :hosts=>["//100.100.100.111:9200", "//100.100.100.112:9200", "//100.100.100.113:9200"]}
[2018-06-05T13:30:21,145][INFO ][logstash.pipeline        ] Pipeline started succesfully {:pipeline_id=>"main", :thread=>"#<Thread:0x29883276@/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:246 run>"}
[2018-06-05T13:30:21,159][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://100.100.100.111:9200/"}
[2018-06-05T13:30:21,189][INFO ][logstash.agent           ] Pipelines running {:count=>1, :pipelines=>["main"]}
[2018-06-05T13:30:21,356][INFO ][logstash.outputs.elasticsearch] ES Output version determined {:es_version=>6}
[2018-06-05T13:30:21,357][WARN ][logstash.outputs.elasticsearch] Detected a 6.x and above cluster: the `type` event field won't be used to determine the document _type {:es_version=>6}
[2018-06-05T13:30:21,357][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://100.100.100.112:9200/, :path=>"/"}
[2018-06-05T13:30:21,379][INFO ][logstash.pipeline        ] Pipeline started succesfully {:pipeline_id=>"main", :thread=>"#<Thread:0x361553e5@/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:246 run>"}
[2018-06-05T13:30:21,423][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://100.100.100.112:9200/"}
[2018-06-05T13:30:21,433][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://100.100.100.113:9200/, :path=>"/"}
[2018-06-05T13:30:21,438][INFO ][logstash.agent           ] Pipelines running {:count=>1, :pipelines=>["main"]}
[2018-06-05T13:30:21,467][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://100.100.100.113:9200/"}
[2018-06-05T13:30:21,504][INFO ][logstash.outputs.elasticsearch] Using mapping template from {:path=>nil}
[2018-06-05T13:30:21,542][INFO ][logstash.outputs.elasticsearch] Attempting to install template {:manage_template=>{"template"=>"logstash-*", "version"=>60001, "settings"=>{"index.refresh_interval"=>"5s"}, "mappings"=>{"_default_"=>{"dynamic_templates"=>[{"message_field"=>{"path_match"=>"message", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false}}}, {"string_fields"=>{"match"=>"*", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false, "fields"=>{"keyword"=>{"type"=>"keyword", "ignore_above"=>256}}}}}], "properties"=>{"@timestamp"=>{"type"=>"date"}, "@version"=>{"type"=>"keyword"}, "geoip"=>{"dynamic"=>true, "properties"=>{"ip"=>{"type"=>"ip"}, "location"=>{"type"=>"geo_point"}, "latitude"=>{"type"=>"half_float"}, "longitude"=>{"type"=>"half_float"}}}}}}}}
[2018-06-05T13:30:21,580][INFO ][logstash.outputs.elasticsearch] New Elasticsearch output {:class=>"LogStash::Outputs::ElasticSearch", :hosts=>["//100.100.100.111:9200", "//100.100.100.112:9200", "//100.100.100.113:9200"]}
[2018-06-05T13:30:21,986][INFO ][logstash.pipeline        ] Pipeline started succesfully {:pipeline_id=>"main", :thread=>"#<Thread:0x58b85a0d@/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:246 run>"}
[2018-06-05T13:30:22,195][INFO ][logstash.agent           ] Pipelines running {:count=>1, :pipelines=>["main"]}
[2018-06-05T13:30:22,301][INFO ][logstash.pipeline        ] Pipeline started succesfully {:pipeline_id=>"main", :thread=>"#<Thread:0x736876fc@/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:246 sleep>"}
[2018-06-05T13:30:22,353][INFO ][logstash.agent           ] Pipelines running {:count=>1, :pipelines=>["main"]}
[2018-06-05T13:30:25,023][INFO ][logstash.inputs.jdbc     ] (3.437935s) select
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    DECODE(NVL(MODELNO_GROUP,0),0,0,1) AS MODELNO_GROUP_FLAG,
    category,
    '' as cg,
    '' as cat1,
    '' as cat2,
    '' as cat3,
    '' as cat4,
    ca_code,
    ca_dept_mcode,
    ca_dept_code,
    ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,
    shop_name,
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    '' as model_factory,
    minprice,
    maxprice,
    minprices,
    C_DATE,
    mallcnt,
    DECODE(NVL(MALLCNT,0),0,0,1) AS MALLCNT_FLAG,
    spec,
    openexpectflag,
    condiname,
    KEYWORD,
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    to_all
--    MODELNM || ' ' || FACTORY || ' ' || SPEC || ' ' || KEYWORD || ' ' || KEYWORD2 || ' ' || CONDINAME AS to_all
from (

select
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    CASE WHEN service_gubun='2' AND store_flag='1' AND ca_dept_code IS NOT NULL THEN RTRIM(category || ' '  || ca_dept_code) ELSE category END AS category,
    ca_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),3,8)='000000' OR SUBSTR(RTRIM(ca_dept_code),3,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,4) END AS ca_dept_mcode,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),5,8)='0000' OR SUBSTR(RTRIM(ca_dept_code),5,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,6) END AS ca_dept_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),7,8)='00' OR SUBSTR(RTRIM(ca_dept_code),7,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,8) END AS ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,    
    shop_name,    
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    model_factory,
    minprice,
    maxprice,
    replace(minprices, ' ', '    ') as minprices,
    C_DATE,
    mallcnt,
    replace(replace(spec,',',' '),'/',' ') spec,
    openexpectflag,
    replace(condiname, ' ', '    ') as condiname,    
    CASE WHEN socialprice=0 THEN keyword ELSE keyword || ' ' || UDF_SOCIAL_GOODSNM(modelno_group,modelno) END AS KEYWORD,    
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    to_all
FROM tmp_es_price_data_01
WHERE mod_no = '1'

)

[2018-06-05T13:30:25,059][INFO ][logstash.inputs.jdbc     ] (3.387316s) select 
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    DECODE(NVL(MODELNO_GROUP,0),0,0,1) AS MODELNO_GROUP_FLAG,
    category,
    '' as cg,
    '' as cat1,
    '' as cat2,
    '' as cat3,
    '' as cat4,
    ca_code,
    ca_dept_mcode,
    ca_dept_code,
    ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,
    shop_name,
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    MODELNM || ' ' || FACTORY as model_factory,
    minprice,
    maxprice,
    minprices,
    C_DATE,
    mallcnt,
    DECODE(NVL(MALLCNT,0),0,0,1) AS MALLCNT_FLAG,
    spec,
    openexpectflag,
    condiname,
    KEYWORD,
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    to_all
--    MODELNM || ' ' || FACTORY || ' ' || SPEC || ' ' || KEYWORD || ' ' || KEYWORD2 || ' ' || CONDINAME AS to_all
from (

select
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    CASE WHEN service_gubun='2' AND store_flag='1' AND ca_dept_code IS NOT NULL THEN RTRIM(category || ' '  || ca_dept_code) ELSE category END AS category,
    ca_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),3,8)='000000' OR SUBSTR(RTRIM(ca_dept_code),3,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,4) END AS ca_dept_mcode,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),5,8)='0000' OR SUBSTR(RTRIM(ca_dept_code),5,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,6) END AS ca_dept_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),7,8)='00' OR SUBSTR(RTRIM(ca_dept_code),7,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,8) END AS ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,    
    shop_name,    
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    model_factory,
    minprice,
    maxprice,
    replace(minprices, ' ', '    ') as minprices,
    C_DATE,
    mallcnt,
    replace(replace(spec,',',' '),'/',' ') spec,
    openexpectflag,
    replace(condiname, ' ', '    ') as condiname,    
    CASE WHEN socialprice=0 THEN keyword ELSE keyword || ' ' || UDF_SOCIAL_GOODSNM(modelno_group,modelno) END AS KEYWORD,    
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    to_all
FROM tmp_es_goods_data_01    
WHERE mod_no = '1'

)

[2018-06-05T13:30:27,518][INFO ][logstash.inputs.jdbc     ] (2.267634s) select 
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    DECODE(NVL(MODELNO_GROUP,0),0,0,1) AS MODELNO_GROUP_FLAG,
    category,
    '' as cg,
    '' as cat1,
    '' as cat2,
    '' as cat3,
    '' as cat4,
    ca_code,
    ca_dept_mcode,
    ca_dept_code,
    ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,
    shop_name,
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    MODELNM || ' ' || FACTORY as model_factory,
    minprice,
    maxprice,
    minprices,
    C_DATE,
    mallcnt,
    DECODE(NVL(MALLCNT,0),0,0,1) AS MALLCNT_FLAG,
    spec,
    openexpectflag,
    condiname,
    KEYWORD,
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    to_all
--    MODELNM || ' ' || FACTORY || ' ' || SPEC || ' ' || KEYWORD || ' ' || KEYWORD2 || ' ' || CONDINAME AS to_all
from (

select
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    CASE WHEN service_gubun='2' AND store_flag='1' AND ca_dept_code IS NOT NULL THEN RTRIM(category || ' '  || ca_dept_code) ELSE category END AS category,
    ca_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),3,8)='000000' OR SUBSTR(RTRIM(ca_dept_code),3,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,4) END AS ca_dept_mcode,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),5,8)='0000' OR SUBSTR(RTRIM(ca_dept_code),5,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,6) END AS ca_dept_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),7,8)='00' OR SUBSTR(RTRIM(ca_dept_code),7,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,8) END AS ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,    
    shop_name,    
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    model_factory,
    minprice,
    maxprice,
    replace(minprices, ' ', '    ') as minprices,
    C_DATE,
    mallcnt,
    replace(replace(spec,',',' '),'/',' ') spec,
    openexpectflag,
    replace(condiname, ' ', '    ') as condiname,    
    CASE WHEN socialprice=0 THEN keyword ELSE keyword || ' ' || UDF_SOCIAL_GOODSNM(modelno_group,modelno) END AS KEYWORD,    
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    to_all
FROM tmp_es_goods_data_01    
WHERE mod_no = '4'

)

[2018-06-05T13:30:28,022][INFO ][logstash.inputs.jdbc     ] (2.533197s) select
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    DECODE(NVL(MODELNO_GROUP,0),0,0,1) AS MODELNO_GROUP_FLAG,
    category,
    '' as cg,
    '' as cat1,
    '' as cat2,
    '' as cat3,
    '' as cat4,
    ca_code,
    ca_dept_mcode,
    ca_dept_code,
    ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,
    shop_name,
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    '' as model_factory,
    minprice,
    maxprice,
    minprices,
    C_DATE,
    mallcnt,
    DECODE(NVL(MALLCNT,0),0,0,1) AS MALLCNT_FLAG,
    spec,
    openexpectflag,
    condiname,
    KEYWORD,
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    to_all
--    MODELNM || ' ' || FACTORY || ' ' || SPEC || ' ' || KEYWORD || ' ' || KEYWORD2 || ' ' || CONDINAME AS to_all
from (

select
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    CASE WHEN service_gubun='2' AND store_flag='1' AND ca_dept_code IS NOT NULL THEN RTRIM(category || ' '  || ca_dept_code) ELSE category END AS category,
    ca_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),3,8)='000000' OR SUBSTR(RTRIM(ca_dept_code),3,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,4) END AS ca_dept_mcode,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),5,8)='0000' OR SUBSTR(RTRIM(ca_dept_code),5,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,6) END AS ca_dept_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),7,8)='00' OR SUBSTR(RTRIM(ca_dept_code),7,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,8) END AS ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,    
    shop_name,    
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    model_factory,
    minprice,
    maxprice,
    replace(minprices, ' ', '    ') as minprices,
    C_DATE,
    mallcnt,
    replace(replace(spec,',',' '),'/',' ') spec,
    openexpectflag,
    replace(condiname, ' ', '    ') as condiname,    
    CASE WHEN socialprice=0 THEN keyword ELSE keyword || ' ' || UDF_SOCIAL_GOODSNM(modelno_group,modelno) END AS KEYWORD,    
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    to_all
FROM tmp_es_price_data_01
WHERE mod_no = '5'

)

[2018-06-05T13:30:28,022][INFO ][logstash.inputs.jdbc     ] (2.535015s) select 
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    DECODE(NVL(MODELNO_GROUP,0),0,0,1) AS MODELNO_GROUP_FLAG,
    category,
    '' as cg,
    '' as cat1,
    '' as cat2,
    '' as cat3,
    '' as cat4,
    ca_code,
    ca_dept_mcode,
    ca_dept_code,
    ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,
    shop_name,
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    MODELNM || ' ' || FACTORY as model_factory,
    minprice,
    maxprice,
    minprices,
    C_DATE,
    mallcnt,
    DECODE(NVL(MALLCNT,0),0,0,1) AS MALLCNT_FLAG,
    spec,
    openexpectflag,
    condiname,
    KEYWORD,
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    to_all
--    MODELNM || ' ' || FACTORY || ' ' || SPEC || ' ' || KEYWORD || ' ' || KEYWORD2 || ' ' || CONDINAME AS to_all
from (

select
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    CASE WHEN service_gubun='2' AND store_flag='1' AND ca_dept_code IS NOT NULL THEN RTRIM(category || ' '  || ca_dept_code) ELSE category END AS category,
    ca_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),3,8)='000000' OR SUBSTR(RTRIM(ca_dept_code),3,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,4) END AS ca_dept_mcode,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),5,8)='0000' OR SUBSTR(RTRIM(ca_dept_code),5,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,6) END AS ca_dept_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),7,8)='00' OR SUBSTR(RTRIM(ca_dept_code),7,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,8) END AS ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,    
    shop_name,    
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    model_factory,
    minprice,
    maxprice,
    replace(minprices, ' ', '    ') as minprices,
    C_DATE,
    mallcnt,
    replace(replace(spec,',',' '),'/',' ') spec,
    openexpectflag,
    replace(condiname, ' ', '    ') as condiname,    
    CASE WHEN socialprice=0 THEN keyword ELSE keyword || ' ' || UDF_SOCIAL_GOODSNM(modelno_group,modelno) END AS KEYWORD,    
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    to_all
FROM tmp_es_goods_data_01    
WHERE mod_no = '5'

)

[2018-06-05T13:30:27,519][INFO ][logstash.inputs.jdbc     ] (2.272587s) select
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    DECODE(NVL(MODELNO_GROUP,0),0,0,1) AS MODELNO_GROUP_FLAG,
    category,
    '' as cg,
    '' as cat1,
    '' as cat2,
    '' as cat3,
    '' as cat4,
    ca_code,
    ca_dept_mcode,
    ca_dept_code,
    ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,
    shop_name,
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    '' as model_factory,
    minprice,
    maxprice,
    minprices,
    C_DATE,
    mallcnt,
    DECODE(NVL(MALLCNT,0),0,0,1) AS MALLCNT_FLAG,
    spec,
    openexpectflag,
    condiname,
    KEYWORD,
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    to_all
--    MODELNM || ' ' || FACTORY || ' ' || SPEC || ' ' || KEYWORD || ' ' || KEYWORD2 || ' ' || CONDINAME AS to_all
from (

select
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    CASE WHEN service_gubun='2' AND store_flag='1' AND ca_dept_code IS NOT NULL THEN RTRIM(category || ' '  || ca_dept_code) ELSE category END AS category,
    ca_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),3,8)='000000' OR SUBSTR(RTRIM(ca_dept_code),3,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,4) END AS ca_dept_mcode,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),5,8)='0000' OR SUBSTR(RTRIM(ca_dept_code),5,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,6) END AS ca_dept_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),7,8)='00' OR SUBSTR(RTRIM(ca_dept_code),7,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,8) END AS ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,    
    shop_name,    
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    model_factory,
    minprice,
    maxprice,
    replace(minprices, ' ', '    ') as minprices,
    C_DATE,
    mallcnt,
    replace(replace(spec,',',' '),'/',' ') spec,
    openexpectflag,
    replace(condiname, ' ', '    ') as condiname,    
    CASE WHEN socialprice=0 THEN keyword ELSE keyword || ' ' || UDF_SOCIAL_GOODSNM(modelno_group,modelno) END AS KEYWORD,    
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    to_all
FROM tmp_es_price_data_01
WHERE mod_no = '4'

)

[2018-06-05T13:30:28,617][INFO ][logstash.inputs.jdbc     ] (2.462991s) select
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    DECODE(NVL(MODELNO_GROUP,0),0,0,1) AS MODELNO_GROUP_FLAG,
    category,
    '' as cg,
    '' as cat1,
    '' as cat2,
    '' as cat3,
    '' as cat4,
    ca_code,
    ca_dept_mcode,
    ca_dept_code,
    ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,
    shop_name,
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    '' as model_factory,
    minprice,
    maxprice,
    minprices,
    C_DATE,
    mallcnt,
    DECODE(NVL(MALLCNT,0),0,0,1) AS MALLCNT_FLAG,
    spec,
    openexpectflag,
    condiname,
    KEYWORD,
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    to_all
--    MODELNM || ' ' || FACTORY || ' ' || SPEC || ' ' || KEYWORD || ' ' || KEYWORD2 || ' ' || CONDINAME AS to_all
from (

select
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    CASE WHEN service_gubun='2' AND store_flag='1' AND ca_dept_code IS NOT NULL THEN RTRIM(category || ' '  || ca_dept_code) ELSE category END AS category,
    ca_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),3,8)='000000' OR SUBSTR(RTRIM(ca_dept_code),3,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,4) END AS ca_dept_mcode,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),5,8)='0000' OR SUBSTR(RTRIM(ca_dept_code),5,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,6) END AS ca_dept_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),7,8)='00' OR SUBSTR(RTRIM(ca_dept_code),7,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,8) END AS ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,    
    shop_name,    
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    model_factory,
    minprice,
    maxprice,
    replace(minprices, ' ', '    ') as minprices,
    C_DATE,
    mallcnt,
    replace(replace(spec,',',' '),'/',' ') spec,
    openexpectflag,
    replace(condiname, ' ', '    ') as condiname,    
    CASE WHEN socialprice=0 THEN keyword ELSE keyword || ' ' || UDF_SOCIAL_GOODSNM(modelno_group,modelno) END AS KEYWORD,    
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    to_all
FROM tmp_es_price_data_01
WHERE mod_no = '0'

)

[2018-06-05T13:30:28,626][INFO ][logstash.inputs.jdbc     ] (2.479310s) select 
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    DECODE(NVL(MODELNO_GROUP,0),0,0,1) AS MODELNO_GROUP_FLAG,
    category,
    '' as cg,
    '' as cat1,
    '' as cat2,
    '' as cat3,
    '' as cat4,
    ca_code,
    ca_dept_mcode,
    ca_dept_code,
    ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,
    shop_name,
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    MODELNM || ' ' || FACTORY as model_factory,
    minprice,
    maxprice,
    minprices,
    C_DATE,
    mallcnt,
    DECODE(NVL(MALLCNT,0),0,0,1) AS MALLCNT_FLAG,
    spec,
    openexpectflag,
    condiname,
    KEYWORD,
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    to_all
--    MODELNM || ' ' || FACTORY || ' ' || SPEC || ' ' || KEYWORD || ' ' || KEYWORD2 || ' ' || CONDINAME AS to_all
from (

select
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    CASE WHEN service_gubun='2' AND store_flag='1' AND ca_dept_code IS NOT NULL THEN RTRIM(category || ' '  || ca_dept_code) ELSE category END AS category,
    ca_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),3,8)='000000' OR SUBSTR(RTRIM(ca_dept_code),3,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,4) END AS ca_dept_mcode,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),5,8)='0000' OR SUBSTR(RTRIM(ca_dept_code),5,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,6) END AS ca_dept_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),7,8)='00' OR SUBSTR(RTRIM(ca_dept_code),7,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,8) END AS ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,    
    shop_name,    
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    model_factory,
    minprice,
    maxprice,
    replace(minprices, ' ', '    ') as minprices,
    C_DATE,
    mallcnt,
    replace(replace(spec,',',' '),'/',' ') spec,
    openexpectflag,
    replace(condiname, ' ', '    ') as condiname,    
    CASE WHEN socialprice=0 THEN keyword ELSE keyword || ' ' || UDF_SOCIAL_GOODSNM(modelno_group,modelno) END AS KEYWORD,    
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    to_all
FROM tmp_es_goods_data_01    
WHERE mod_no = '0'

)

[2018-06-05T13:30:29,185][INFO ][logstash.inputs.jdbc     ] (2.725214s) select
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    DECODE(NVL(MODELNO_GROUP,0),0,0,1) AS MODELNO_GROUP_FLAG,
    category,
    '' as cg,
    '' as cat1,
    '' as cat2,
    '' as cat3,
    '' as cat4,
    ca_code,
    ca_dept_mcode,
    ca_dept_code,
    ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,
    shop_name,
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    '' as model_factory,
    minprice,
    maxprice,
    minprices,
    C_DATE,
    mallcnt,
    DECODE(NVL(MALLCNT,0),0,0,1) AS MALLCNT_FLAG,
    spec,
    openexpectflag,
    condiname,
    KEYWORD,
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    to_all
--    MODELNM || ' ' || FACTORY || ' ' || SPEC || ' ' || KEYWORD || ' ' || KEYWORD2 || ' ' || CONDINAME AS to_all
from (

select
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    CASE WHEN service_gubun='2' AND store_flag='1' AND ca_dept_code IS NOT NULL THEN RTRIM(category || ' '  || ca_dept_code) ELSE category END AS category,
    ca_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),3,8)='000000' OR SUBSTR(RTRIM(ca_dept_code),3,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,4) END AS ca_dept_mcode,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),5,8)='0000' OR SUBSTR(RTRIM(ca_dept_code),5,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,6) END AS ca_dept_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),7,8)='00' OR SUBSTR(RTRIM(ca_dept_code),7,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,8) END AS ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,    
    shop_name,    
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    model_factory,
    minprice,
    maxprice,
    replace(minprices, ' ', '    ') as minprices,
    C_DATE,
    mallcnt,
    replace(replace(spec,',',' '),'/',' ') spec,
    openexpectflag,
    replace(condiname, ' ', '    ') as condiname,    
    CASE WHEN socialprice=0 THEN keyword ELSE keyword || ' ' || UDF_SOCIAL_GOODSNM(modelno_group,modelno) END AS KEYWORD,    
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    to_all
FROM tmp_es_price_data_01
WHERE mod_no = '2'

)

[2018-06-05T13:30:29,217][INFO ][logstash.inputs.jdbc     ] (2.703062s) select 
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    DECODE(NVL(MODELNO_GROUP,0),0,0,1) AS MODELNO_GROUP_FLAG,
    category,
    '' as cg,
    '' as cat1,
    '' as cat2,
    '' as cat3,
    '' as cat4,
    ca_code,
    ca_dept_mcode,
    ca_dept_code,
    ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,
    shop_name,
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    MODELNM || ' ' || FACTORY as model_factory,
    minprice,
    maxprice,
    minprices,
    C_DATE,
    mallcnt,
    DECODE(NVL(MALLCNT,0),0,0,1) AS MALLCNT_FLAG,
    spec,
    openexpectflag,
    condiname,
    KEYWORD,
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    to_all
--    MODELNM || ' ' || FACTORY || ' ' || SPEC || ' ' || KEYWORD || ' ' || KEYWORD2 || ' ' || CONDINAME AS to_all
from (

select
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    CASE WHEN service_gubun='2' AND store_flag='1' AND ca_dept_code IS NOT NULL THEN RTRIM(category || ' '  || ca_dept_code) ELSE category END AS category,
    ca_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),3,8)='000000' OR SUBSTR(RTRIM(ca_dept_code),3,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,4) END AS ca_dept_mcode,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),5,8)='0000' OR SUBSTR(RTRIM(ca_dept_code),5,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,6) END AS ca_dept_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),7,8)='00' OR SUBSTR(RTRIM(ca_dept_code),7,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,8) END AS ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,    
    shop_name,    
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    model_factory,
    minprice,
    maxprice,
    replace(minprices, ' ', '    ') as minprices,
    C_DATE,
    mallcnt,
    replace(replace(spec,',',' '),'/',' ') spec,
    openexpectflag,
    replace(condiname, ' ', '    ') as condiname,    
    CASE WHEN socialprice=0 THEN keyword ELSE keyword || ' ' || UDF_SOCIAL_GOODSNM(modelno_group,modelno) END AS KEYWORD,    
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    to_all
FROM tmp_es_goods_data_01    
WHERE mod_no = '2'

)

[2018-06-05T13:30:30,629][INFO ][logstash.inputs.jdbc     ] (2.896297s) select
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    DECODE(NVL(MODELNO_GROUP,0),0,0,1) AS MODELNO_GROUP_FLAG,
    category,
    '' as cg,
    '' as cat1,
    '' as cat2,
    '' as cat3,
    '' as cat4,
    ca_code,
    ca_dept_mcode,
    ca_dept_code,
    ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,
    shop_name,
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    '' as model_factory,
    minprice,
    maxprice,
    minprices,
    C_DATE,
    mallcnt,
    DECODE(NVL(MALLCNT,0),0,0,1) AS MALLCNT_FLAG,
    spec,
    openexpectflag,
    condiname,
    KEYWORD,
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    to_all
--    MODELNM || ' ' || FACTORY || ' ' || SPEC || ' ' || KEYWORD || ' ' || KEYWORD2 || ' ' || CONDINAME AS to_all
from (

select
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    CASE WHEN service_gubun='2' AND store_flag='1' AND ca_dept_code IS NOT NULL THEN RTRIM(category || ' '  || ca_dept_code) ELSE category END AS category,
    ca_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),3,8)='000000' OR SUBSTR(RTRIM(ca_dept_code),3,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,4) END AS ca_dept_mcode,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),5,8)='0000' OR SUBSTR(RTRIM(ca_dept_code),5,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,6) END AS ca_dept_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),7,8)='00' OR SUBSTR(RTRIM(ca_dept_code),7,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,8) END AS ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,    
    shop_name,    
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    model_factory,
    minprice,
    maxprice,
    replace(minprices, ' ', '    ') as minprices,
    C_DATE,
    mallcnt,
    replace(replace(spec,',',' '),'/',' ') spec,
    openexpectflag,
    replace(condiname, ' ', '    ') as condiname,    
    CASE WHEN socialprice=0 THEN keyword ELSE keyword || ' ' || UDF_SOCIAL_GOODSNM(modelno_group,modelno) END AS KEYWORD,    
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    to_all
FROM tmp_es_price_data_01
WHERE mod_no = '3'

)

[2018-06-05T13:30:30,636][INFO ][logstash.inputs.jdbc     ] (2.968420s) select 
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    DECODE(NVL(MODELNO_GROUP,0),0,0,1) AS MODELNO_GROUP_FLAG,
    category,
    '' as cg,
    '' as cat1,
    '' as cat2,
    '' as cat3,
    '' as cat4,
    ca_code,
    ca_dept_mcode,
    ca_dept_code,
    ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,
    shop_name,
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    MODELNM || ' ' || FACTORY as model_factory,
    minprice,
    maxprice,
    minprices,
    C_DATE,
    mallcnt,
    DECODE(NVL(MALLCNT,0),0,0,1) AS MALLCNT_FLAG,
    spec,
    openexpectflag,
    condiname,
    KEYWORD,
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    to_all
--    MODELNM || ' ' || FACTORY || ' ' || SPEC || ' ' || KEYWORD || ' ' || KEYWORD2 || ' ' || CONDINAME AS to_all
from (

select
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    CASE WHEN service_gubun='2' AND store_flag='1' AND ca_dept_code IS NOT NULL THEN RTRIM(category || ' '  || ca_dept_code) ELSE category END AS category,
    ca_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),3,8)='000000' OR SUBSTR(RTRIM(ca_dept_code),3,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,4) END AS ca_dept_mcode,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),5,8)='0000' OR SUBSTR(RTRIM(ca_dept_code),5,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,6) END AS ca_dept_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),7,8)='00' OR SUBSTR(RTRIM(ca_dept_code),7,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,8) END AS ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,    
    shop_name,    
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    model_factory,
    minprice,
    maxprice,
    replace(minprices, ' ', '    ') as minprices,
    C_DATE,
    mallcnt,
    replace(replace(spec,',',' '),'/',' ') spec,
    openexpectflag,
    replace(condiname, ' ', '    ') as condiname,    
    CASE WHEN socialprice=0 THEN keyword ELSE keyword || ' ' || UDF_SOCIAL_GOODSNM(modelno_group,modelno) END AS KEYWORD,    
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    to_all
FROM tmp_es_goods_data_01    
WHERE mod_no = '3'

)

[2018-06-05T13:58:23,903][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"fb_apache", :directory=>"/usr/share/logstash/modules/fb_apache/configuration"}
[2018-06-05T13:58:23,911][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"netflow", :directory=>"/usr/share/logstash/modules/netflow/configuration"}
[2018-06-05T13:58:24,037][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"fb_apache", :directory=>"/usr/share/logstash/modules/fb_apache/configuration"}
[2018-06-05T13:58:24,044][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"netflow", :directory=>"/usr/share/logstash/modules/netflow/configuration"}
[2018-06-05T13:58:25,300][WARN ][logstash.config.source.multilocal] Ignoring the 'pipelines.yml' file because modules or command line options are specified
[2018-06-05T13:58:25,357][WARN ][logstash.config.source.multilocal] Ignoring the 'pipelines.yml' file because modules or command line options are specified
[2018-06-05T13:58:25,434][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"fb_apache", :directory=>"/usr/share/logstash/modules/fb_apache/configuration"}
[2018-06-05T13:58:25,537][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"netflow", :directory=>"/usr/share/logstash/modules/netflow/configuration"}
[2018-06-05T13:58:25,710][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"fb_apache", :directory=>"/usr/share/logstash/modules/fb_apache/configuration"}
[2018-06-05T13:58:25,747][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"netflow", :directory=>"/usr/share/logstash/modules/netflow/configuration"}
[2018-06-05T13:58:25,828][INFO ][logstash.runner          ] Starting Logstash {"logstash.version"=>"6.2.3"}
[2018-06-05T13:58:26,022][INFO ][logstash.runner          ] Starting Logstash {"logstash.version"=>"6.2.3"}
[2018-06-05T13:58:26,579][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=>9600}
[2018-06-05T13:58:26,644][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"fb_apache", :directory=>"/usr/share/logstash/modules/fb_apache/configuration"}
[2018-06-05T13:58:26,682][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"netflow", :directory=>"/usr/share/logstash/modules/netflow/configuration"}
[2018-06-05T13:58:26,728][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=>9601}
[2018-06-05T13:58:26,796][WARN ][logstash.config.source.multilocal] Ignoring the 'pipelines.yml' file because modules or command line options are specified
[2018-06-05T13:58:26,951][WARN ][logstash.config.source.multilocal] Ignoring the 'pipelines.yml' file because modules or command line options are specified
[2018-06-05T13:58:27,058][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"fb_apache", :directory=>"/usr/share/logstash/modules/fb_apache/configuration"}
[2018-06-05T13:58:27,074][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"netflow", :directory=>"/usr/share/logstash/modules/netflow/configuration"}
[2018-06-05T13:58:27,208][INFO ][logstash.runner          ] Starting Logstash {"logstash.version"=>"6.2.3"}
[2018-06-05T13:58:27,392][INFO ][logstash.runner          ] Starting Logstash {"logstash.version"=>"6.2.3"}
[2018-06-05T13:58:27,849][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=>9603}
[2018-06-05T13:58:27,870][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=>9602}
[2018-06-05T13:58:28,077][WARN ][logstash.config.source.multilocal] Ignoring the 'pipelines.yml' file because modules or command line options are specified
[2018-06-05T13:58:28,706][INFO ][logstash.runner          ] Starting Logstash {"logstash.version"=>"6.2.3"}
[2018-06-05T13:58:28,994][DEBUG][org.logstash.secret.store.SecretStoreFactory] Attempting to exists or secret store with implementation: org.logstash.secret.store.backend.JavaKeyStore
[2018-06-05T13:58:29,014][WARN ][logstash.config.source.multilocal] Ignoring the 'pipelines.yml' file because modules or command line options are specified
[2018-06-05T13:58:29,218][DEBUG][org.logstash.secret.store.SecretStoreFactory] Attempting to exists or secret store with implementation: org.logstash.secret.store.backend.JavaKeyStore
[2018-06-05T13:58:29,333][DEBUG][org.logstash.secret.store.SecretStoreFactory] Attempting to exists or secret store with implementation: org.logstash.secret.store.backend.JavaKeyStore
[2018-06-05T13:58:29,424][INFO ][logstash.filters.ruby.script] Test run complete {:script_path=>"rubyfilter.rb", :results=>{:passed=>0, :failed=>0, :errored=>0}}
[2018-06-05T13:58:29,445][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=>9604}
[2018-06-05T13:58:29,557][DEBUG][org.logstash.secret.store.SecretStoreFactory] Attempting to exists or secret store with implementation: org.logstash.secret.store.backend.JavaKeyStore
[2018-06-05T13:58:29,721][INFO ][logstash.runner          ] Starting Logstash {"logstash.version"=>"6.2.3"}
[2018-06-05T13:58:29,743][DEBUG][org.logstash.secret.store.SecretStoreFactory] Attempting to exists or secret store with implementation: org.logstash.secret.store.backend.JavaKeyStore
[2018-06-05T13:58:29,753][DEBUG][org.logstash.secret.store.SecretStoreFactory] Attempting to exists or secret store with implementation: org.logstash.secret.store.backend.JavaKeyStore
[2018-06-05T13:58:29,769][DEBUG][org.logstash.secret.store.SecretStoreFactory] Attempting to exists or secret store with implementation: org.logstash.secret.store.backend.JavaKeyStore
[2018-06-05T13:58:29,847][WARN ][logstash.outputs.elasticsearch] You are using a deprecated config setting "document_type" set in elasticsearch. Deprecated settings will continue to work, but are scheduled for removal from logstash in the future. Document types are being deprecated in Elasticsearch 6.0, and removed entirely in 7.0. You should avoid this feature If you have any questions about this, please visit the #logstash channel on freenode irc. {:name=>"document_type", :plugin=><LogStash::Outputs::ElasticSearch hosts=>[//100.100.100.111:9200, //100.100.100.112:9200, //100.100.100.113:9200], index=>"qa-enuri-main-as-is-2018.06.05.04.57", document_type=>"_doc", document_id=>"%{id}", action=>"index", id=>"6ecd11524c84e5de286546b0de40f57503392aeab1548c7913e69855f4645bbc", enable_metric=>true, codec=><LogStash::Codecs::Plain id=>"plain_87db4e8a-8ff4-402a-bb75-3eaa086e7863", enable_metric=>true, charset=>"UTF-8">, workers=>1, manage_template=>true, template_name=>"logstash", template_overwrite=>false, doc_as_upsert=>false, script_type=>"inline", script_lang=>"painless", script_var_name=>"event", scripted_upsert=>false, retry_initial_interval=>2, retry_max_interval=>64, retry_on_conflict=>1, ssl_certificate_verification=>true, sniffing=>false, sniffing_delay=>5, timeout=>60, pool_max=>1000, pool_max_per_route=>100, resurrect_delay=>5, validate_after_inactivity=>10000, http_compression=>false>}
[2018-06-05T13:58:29,860][INFO ][logstash.pipeline        ] Starting pipeline {:pipeline_id=>"main", "pipeline.workers"=>8, "pipeline.batch.size"=>125, "pipeline.batch.delay"=>50}
[2018-06-05T13:58:29,869][INFO ][logstash.filters.ruby.script] Test run complete {:script_path=>"rubyfilter.rb", :results=>{:passed=>0, :failed=>0, :errored=>0}}
[2018-06-05T13:58:29,983][DEBUG][org.logstash.secret.store.SecretStoreFactory] Attempting to exists or secret store with implementation: org.logstash.secret.store.backend.JavaKeyStore
[2018-06-05T13:58:30,042][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=>9605}
[2018-06-05T13:58:30,091][DEBUG][org.logstash.secret.store.SecretStoreFactory] Attempting to exists or secret store with implementation: org.logstash.secret.store.backend.JavaKeyStore
[2018-06-05T13:58:30,224][INFO ][logstash.filters.ruby.script] Test run complete {:script_path=>"rubyfilter.rb", :results=>{:passed=>0, :failed=>0, :errored=>0}}
[2018-06-05T13:58:30,281][DEBUG][org.logstash.secret.store.SecretStoreFactory] Attempting to exists or secret store with implementation: org.logstash.secret.store.backend.JavaKeyStore
[2018-06-05T13:58:30,335][WARN ][logstash.outputs.elasticsearch] You are using a deprecated config setting "document_type" set in elasticsearch. Deprecated settings will continue to work, but are scheduled for removal from logstash in the future. Document types are being deprecated in Elasticsearch 6.0, and removed entirely in 7.0. You should avoid this feature If you have any questions about this, please visit the #logstash channel on freenode irc. {:name=>"document_type", :plugin=><LogStash::Outputs::ElasticSearch hosts=>[//100.100.100.111:9200, //100.100.100.112:9200, //100.100.100.113:9200], index=>"qa-enuri-main-as-is-2018.06.05.04.57", document_type=>"_doc", document_id=>"%{id}", action=>"index", id=>"6ecd11524c84e5de286546b0de40f57503392aeab1548c7913e69855f4645bbc", enable_metric=>true, codec=><LogStash::Codecs::Plain id=>"plain_499b54ce-b102-4b44-ae4e-0bb453a85356", enable_metric=>true, charset=>"UTF-8">, workers=>1, manage_template=>true, template_name=>"logstash", template_overwrite=>false, doc_as_upsert=>false, script_type=>"inline", script_lang=>"painless", script_var_name=>"event", scripted_upsert=>false, retry_initial_interval=>2, retry_max_interval=>64, retry_on_conflict=>1, ssl_certificate_verification=>true, sniffing=>false, sniffing_delay=>5, timeout=>60, pool_max=>1000, pool_max_per_route=>100, resurrect_delay=>5, validate_after_inactivity=>10000, http_compression=>false>}
[2018-06-05T13:58:30,349][INFO ][logstash.filters.ruby.script] Test run complete {:script_path=>"rubyfilter.rb", :results=>{:passed=>0, :failed=>0, :errored=>0}}
[2018-06-05T13:58:30,385][INFO ][logstash.pipeline        ] Starting pipeline {:pipeline_id=>"main", "pipeline.workers"=>8, "pipeline.batch.size"=>125, "pipeline.batch.delay"=>50}
[2018-06-05T13:58:30,580][DEBUG][org.logstash.secret.store.SecretStoreFactory] Attempting to exists or secret store with implementation: org.logstash.secret.store.backend.JavaKeyStore
[2018-06-05T13:58:30,679][WARN ][logstash.outputs.elasticsearch] You are using a deprecated config setting "document_type" set in elasticsearch. Deprecated settings will continue to work, but are scheduled for removal from logstash in the future. Document types are being deprecated in Elasticsearch 6.0, and removed entirely in 7.0. You should avoid this feature If you have any questions about this, please visit the #logstash channel on freenode irc. {:name=>"document_type", :plugin=><LogStash::Outputs::ElasticSearch hosts=>[//100.100.100.111:9200, //100.100.100.112:9200, //100.100.100.113:9200], index=>"qa-enuri-main-as-is-2018.06.05.04.57", document_type=>"_doc", document_id=>"%{id}", action=>"index", id=>"6ecd11524c84e5de286546b0de40f57503392aeab1548c7913e69855f4645bbc", enable_metric=>true, codec=><LogStash::Codecs::Plain id=>"plain_ca665b19-9d52-442e-a404-388279d7f65c", enable_metric=>true, charset=>"UTF-8">, workers=>1, manage_template=>true, template_name=>"logstash", template_overwrite=>false, doc_as_upsert=>false, script_type=>"inline", script_lang=>"painless", script_var_name=>"event", scripted_upsert=>false, retry_initial_interval=>2, retry_max_interval=>64, retry_on_conflict=>1, ssl_certificate_verification=>true, sniffing=>false, sniffing_delay=>5, timeout=>60, pool_max=>1000, pool_max_per_route=>100, resurrect_delay=>5, validate_after_inactivity=>10000, http_compression=>false>}
[2018-06-05T13:58:30,686][DEBUG][org.logstash.secret.store.SecretStoreFactory] Attempting to exists or secret store with implementation: org.logstash.secret.store.backend.JavaKeyStore
[2018-06-05T13:58:30,700][INFO ][logstash.pipeline        ] Starting pipeline {:pipeline_id=>"main", "pipeline.workers"=>8, "pipeline.batch.size"=>125, "pipeline.batch.delay"=>50}
[2018-06-05T13:58:30,713][INFO ][logstash.outputs.elasticsearch] Elasticsearch pool URLs updated {:changes=>{:removed=>[], :added=>[http://100.100.100.111:9200/, http://100.100.100.112:9200/, http://100.100.100.113:9200/]}}
[2018-06-05T13:58:30,777][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://100.100.100.111:9200/, :path=>"/"}
[2018-06-05T13:58:30,798][WARN ][logstash.outputs.elasticsearch] You are using a deprecated config setting "document_type" set in elasticsearch. Deprecated settings will continue to work, but are scheduled for removal from logstash in the future. Document types are being deprecated in Elasticsearch 6.0, and removed entirely in 7.0. You should avoid this feature If you have any questions about this, please visit the #logstash channel on freenode irc. {:name=>"document_type", :plugin=><LogStash::Outputs::ElasticSearch hosts=>[//100.100.100.111:9200, //100.100.100.112:9200, //100.100.100.113:9200], index=>"qa-enuri-main-as-is-2018.06.05.04.57", document_type=>"_doc", document_id=>"%{id}", action=>"index", id=>"6ecd11524c84e5de286546b0de40f57503392aeab1548c7913e69855f4645bbc", enable_metric=>true, codec=><LogStash::Codecs::Plain id=>"plain_3fa35d27-355b-44f9-961f-2c3e0fbcfa85", enable_metric=>true, charset=>"UTF-8">, workers=>1, manage_template=>true, template_name=>"logstash", template_overwrite=>false, doc_as_upsert=>false, script_type=>"inline", script_lang=>"painless", script_var_name=>"event", scripted_upsert=>false, retry_initial_interval=>2, retry_max_interval=>64, retry_on_conflict=>1, ssl_certificate_verification=>true, sniffing=>false, sniffing_delay=>5, timeout=>60, pool_max=>1000, pool_max_per_route=>100, resurrect_delay=>5, validate_after_inactivity=>10000, http_compression=>false>}
[2018-06-05T13:58:30,815][INFO ][logstash.pipeline        ] Starting pipeline {:pipeline_id=>"main", "pipeline.workers"=>8, "pipeline.batch.size"=>125, "pipeline.batch.delay"=>50}
[2018-06-05T13:58:31,323][INFO ][logstash.outputs.elasticsearch] Elasticsearch pool URLs updated {:changes=>{:removed=>[], :added=>[http://100.100.100.111:9200/, http://100.100.100.112:9200/, http://100.100.100.113:9200/]}}
[2018-06-05T13:58:31,325][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://100.100.100.111:9200/, :path=>"/"}
[2018-06-05T13:58:31,430][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://100.100.100.111:9200/"}
[2018-06-05T13:58:31,549][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://100.100.100.111:9200/"}
[2018-06-05T13:58:31,564][INFO ][logstash.outputs.elasticsearch] ES Output version determined {:es_version=>6}
[2018-06-05T13:58:31,564][WARN ][logstash.outputs.elasticsearch] Detected a 6.x and above cluster: the `type` event field won't be used to determine the document _type {:es_version=>6}
[2018-06-05T13:58:31,565][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://100.100.100.112:9200/, :path=>"/"}
[2018-06-05T13:58:31,610][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://100.100.100.112:9200/"}
[2018-06-05T13:58:31,618][INFO ][logstash.outputs.elasticsearch] Elasticsearch pool URLs updated {:changes=>{:removed=>[], :added=>[http://100.100.100.111:9200/, http://100.100.100.112:9200/, http://100.100.100.113:9200/]}}
[2018-06-05T13:58:31,632][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://100.100.100.111:9200/, :path=>"/"}
[2018-06-05T13:58:31,634][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://100.100.100.113:9200/, :path=>"/"}
[2018-06-05T13:58:31,651][INFO ][logstash.outputs.elasticsearch] ES Output version determined {:es_version=>6}
[2018-06-05T13:58:31,652][WARN ][logstash.outputs.elasticsearch] Detected a 6.x and above cluster: the `type` event field won't be used to determine the document _type {:es_version=>6}
[2018-06-05T13:58:31,652][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://100.100.100.112:9200/, :path=>"/"}
[2018-06-05T13:58:31,677][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://100.100.100.113:9200/"}
[2018-06-05T13:58:31,681][INFO ][logstash.outputs.elasticsearch] Elasticsearch pool URLs updated {:changes=>{:removed=>[], :added=>[http://100.100.100.111:9200/, http://100.100.100.112:9200/, http://100.100.100.113:9200/]}}
[2018-06-05T13:58:31,699][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://100.100.100.111:9200/, :path=>"/"}
[2018-06-05T13:58:31,701][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://100.100.100.112:9200/"}
[2018-06-05T13:58:31,709][INFO ][logstash.outputs.elasticsearch] Using mapping template from {:path=>nil}
[2018-06-05T13:58:31,712][INFO ][logstash.outputs.elasticsearch] Attempting to install template {:manage_template=>{"template"=>"logstash-*", "version"=>60001, "settings"=>{"index.refresh_interval"=>"5s"}, "mappings"=>{"_default_"=>{"dynamic_templates"=>[{"message_field"=>{"path_match"=>"message", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false}}}, {"string_fields"=>{"match"=>"*", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false, "fields"=>{"keyword"=>{"type"=>"keyword", "ignore_above"=>256}}}}}], "properties"=>{"@timestamp"=>{"type"=>"date"}, "@version"=>{"type"=>"keyword"}, "geoip"=>{"dynamic"=>true, "properties"=>{"ip"=>{"type"=>"ip"}, "location"=>{"type"=>"geo_point"}, "latitude"=>{"type"=>"half_float"}, "longitude"=>{"type"=>"half_float"}}}}}}}}
[2018-06-05T13:58:31,716][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://100.100.100.113:9200/, :path=>"/"}
[2018-06-05T13:58:31,724][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://100.100.100.113:9200/"}
[2018-06-05T13:58:31,729][INFO ][logstash.outputs.elasticsearch] New Elasticsearch output {:class=>"LogStash::Outputs::ElasticSearch", :hosts=>["//100.100.100.111:9200", "//100.100.100.112:9200", "//100.100.100.113:9200"]}
[2018-06-05T13:58:31,801][INFO ][logstash.outputs.elasticsearch] Using mapping template from {:path=>nil}
[2018-06-05T13:58:31,809][INFO ][logstash.outputs.elasticsearch] Attempting to install template {:manage_template=>{"template"=>"logstash-*", "version"=>60001, "settings"=>{"index.refresh_interval"=>"5s"}, "mappings"=>{"_default_"=>{"dynamic_templates"=>[{"message_field"=>{"path_match"=>"message", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false}}}, {"string_fields"=>{"match"=>"*", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false, "fields"=>{"keyword"=>{"type"=>"keyword", "ignore_above"=>256}}}}}], "properties"=>{"@timestamp"=>{"type"=>"date"}, "@version"=>{"type"=>"keyword"}, "geoip"=>{"dynamic"=>true, "properties"=>{"ip"=>{"type"=>"ip"}, "location"=>{"type"=>"geo_point"}, "latitude"=>{"type"=>"half_float"}, "longitude"=>{"type"=>"half_float"}}}}}}}}
[2018-06-05T13:58:31,858][INFO ][logstash.outputs.elasticsearch] New Elasticsearch output {:class=>"LogStash::Outputs::ElasticSearch", :hosts=>["//100.100.100.111:9200", "//100.100.100.112:9200", "//100.100.100.113:9200"]}
[2018-06-05T13:58:31,954][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://100.100.100.111:9200/"}
[2018-06-05T13:58:32,124][INFO ][logstash.outputs.elasticsearch] ES Output version determined {:es_version=>6}
[2018-06-05T13:58:32,124][WARN ][logstash.outputs.elasticsearch] Detected a 6.x and above cluster: the `type` event field won't be used to determine the document _type {:es_version=>6}
[2018-06-05T13:58:32,125][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://100.100.100.112:9200/, :path=>"/"}
[2018-06-05T13:58:32,153][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://100.100.100.112:9200/"}
[2018-06-05T13:58:32,170][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://100.100.100.113:9200/, :path=>"/"}
[2018-06-05T13:58:32,192][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://100.100.100.113:9200/"}
[2018-06-05T13:58:32,293][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://100.100.100.111:9200/"}
[2018-06-05T13:58:32,382][INFO ][logstash.outputs.elasticsearch] Using mapping template from {:path=>nil}
[2018-06-05T13:58:32,451][INFO ][logstash.pipeline        ] Pipeline started succesfully {:pipeline_id=>"main", :thread=>"#<Thread:0x2707ba52@/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:246 run>"}
[2018-06-05T13:58:32,546][INFO ][logstash.agent           ] Pipelines running {:count=>1, :pipelines=>["main"]}
[2018-06-05T13:58:32,564][DEBUG][org.logstash.secret.store.SecretStoreFactory] Attempting to exists or secret store with implementation: org.logstash.secret.store.backend.JavaKeyStore
[2018-06-05T13:58:32,542][INFO ][logstash.outputs.elasticsearch] Attempting to install template {:manage_template=>{"template"=>"logstash-*", "version"=>60001, "settings"=>{"index.refresh_interval"=>"5s"}, "mappings"=>{"_default_"=>{"dynamic_templates"=>[{"message_field"=>{"path_match"=>"message", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false}}}, {"string_fields"=>{"match"=>"*", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false, "fields"=>{"keyword"=>{"type"=>"keyword", "ignore_above"=>256}}}}}], "properties"=>{"@timestamp"=>{"type"=>"date"}, "@version"=>{"type"=>"keyword"}, "geoip"=>{"dynamic"=>true, "properties"=>{"ip"=>{"type"=>"ip"}, "location"=>{"type"=>"geo_point"}, "latitude"=>{"type"=>"half_float"}, "longitude"=>{"type"=>"half_float"}}}}}}}}
[2018-06-05T13:58:32,673][INFO ][logstash.outputs.elasticsearch] New Elasticsearch output {:class=>"LogStash::Outputs::ElasticSearch", :hosts=>["//100.100.100.111:9200", "//100.100.100.112:9200", "//100.100.100.113:9200"]}
[2018-06-05T13:58:32,693][INFO ][logstash.outputs.elasticsearch] ES Output version determined {:es_version=>6}
[2018-06-05T13:58:32,694][WARN ][logstash.outputs.elasticsearch] Detected a 6.x and above cluster: the `type` event field won't be used to determine the document _type {:es_version=>6}
[2018-06-05T13:58:32,694][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://100.100.100.112:9200/, :path=>"/"}
[2018-06-05T13:58:32,710][DEBUG][org.logstash.secret.store.SecretStoreFactory] Attempting to exists or secret store with implementation: org.logstash.secret.store.backend.JavaKeyStore
[2018-06-05T13:58:32,712][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://100.100.100.112:9200/"}
[2018-06-05T13:58:32,722][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://100.100.100.113:9200/, :path=>"/"}
[2018-06-05T13:58:32,732][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://100.100.100.113:9200/"}
[2018-06-05T13:58:32,827][INFO ][logstash.outputs.elasticsearch] Using mapping template from {:path=>nil}
[2018-06-05T13:58:32,832][INFO ][logstash.outputs.elasticsearch] Attempting to install template {:manage_template=>{"template"=>"logstash-*", "version"=>60001, "settings"=>{"index.refresh_interval"=>"5s"}, "mappings"=>{"_default_"=>{"dynamic_templates"=>[{"message_field"=>{"path_match"=>"message", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false}}}, {"string_fields"=>{"match"=>"*", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false, "fields"=>{"keyword"=>{"type"=>"keyword", "ignore_above"=>256}}}}}], "properties"=>{"@timestamp"=>{"type"=>"date"}, "@version"=>{"type"=>"keyword"}, "geoip"=>{"dynamic"=>true, "properties"=>{"ip"=>{"type"=>"ip"}, "location"=>{"type"=>"geo_point"}, "latitude"=>{"type"=>"half_float"}, "longitude"=>{"type"=>"half_float"}}}}}}}}
[2018-06-05T13:58:32,868][DEBUG][org.logstash.secret.store.SecretStoreFactory] Attempting to exists or secret store with implementation: org.logstash.secret.store.backend.JavaKeyStore
[2018-06-05T13:58:32,875][INFO ][logstash.outputs.elasticsearch] New Elasticsearch output {:class=>"LogStash::Outputs::ElasticSearch", :hosts=>["//100.100.100.111:9200", "//100.100.100.112:9200", "//100.100.100.113:9200"]}
[2018-06-05T13:58:32,907][DEBUG][org.logstash.secret.store.SecretStoreFactory] Attempting to exists or secret store with implementation: org.logstash.secret.store.backend.JavaKeyStore
[2018-06-05T13:58:33,064][INFO ][logstash.filters.ruby.script] Test run complete {:script_path=>"rubyfilter.rb", :results=>{:passed=>0, :failed=>0, :errored=>0}}
[2018-06-05T13:58:33,075][INFO ][logstash.pipeline        ] Pipeline started succesfully {:pipeline_id=>"main", :thread=>"#<Thread:0x1254c3b7@/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:246 run>"}
[2018-06-05T13:58:33,175][INFO ][logstash.agent           ] Pipelines running {:count=>1, :pipelines=>["main"]}
[2018-06-05T13:58:33,267][INFO ][logstash.filters.ruby.script] Test run complete {:script_path=>"rubyfilter.rb", :results=>{:passed=>0, :failed=>0, :errored=>0}}
[2018-06-05T13:58:33,268][DEBUG][org.logstash.secret.store.SecretStoreFactory] Attempting to exists or secret store with implementation: org.logstash.secret.store.backend.JavaKeyStore
[2018-06-05T13:58:33,314][WARN ][logstash.outputs.elasticsearch] You are using a deprecated config setting "document_type" set in elasticsearch. Deprecated settings will continue to work, but are scheduled for removal from logstash in the future. Document types are being deprecated in Elasticsearch 6.0, and removed entirely in 7.0. You should avoid this feature If you have any questions about this, please visit the #logstash channel on freenode irc. {:name=>"document_type", :plugin=><LogStash::Outputs::ElasticSearch hosts=>[//100.100.100.111:9200, //100.100.100.112:9200, //100.100.100.113:9200], index=>"qa-enuri-main-as-is-2018.06.05.04.57", document_type=>"_doc", document_id=>"%{id}", action=>"index", id=>"6ecd11524c84e5de286546b0de40f57503392aeab1548c7913e69855f4645bbc", enable_metric=>true, codec=><LogStash::Codecs::Plain id=>"plain_24d991c3-3310-4a86-9e99-f918cc8b5534", enable_metric=>true, charset=>"UTF-8">, workers=>1, manage_template=>true, template_name=>"logstash", template_overwrite=>false, doc_as_upsert=>false, script_type=>"inline", script_lang=>"painless", script_var_name=>"event", scripted_upsert=>false, retry_initial_interval=>2, retry_max_interval=>64, retry_on_conflict=>1, ssl_certificate_verification=>true, sniffing=>false, sniffing_delay=>5, timeout=>60, pool_max=>1000, pool_max_per_route=>100, resurrect_delay=>5, validate_after_inactivity=>10000, http_compression=>false>}
[2018-06-05T13:58:33,382][INFO ][logstash.pipeline        ] Starting pipeline {:pipeline_id=>"main", "pipeline.workers"=>8, "pipeline.batch.size"=>125, "pipeline.batch.delay"=>50}
[2018-06-05T13:58:33,523][INFO ][logstash.pipeline        ] Pipeline started succesfully {:pipeline_id=>"main", :thread=>"#<Thread:0x20d20e8e@/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:246 run>"}
[2018-06-05T13:58:33,586][INFO ][logstash.agent           ] Pipelines running {:count=>1, :pipelines=>["main"]}
[2018-06-05T13:58:33,825][DEBUG][org.logstash.secret.store.SecretStoreFactory] Attempting to exists or secret store with implementation: org.logstash.secret.store.backend.JavaKeyStore
[2018-06-05T13:58:34,004][WARN ][logstash.outputs.elasticsearch] You are using a deprecated config setting "document_type" set in elasticsearch. Deprecated settings will continue to work, but are scheduled for removal from logstash in the future. Document types are being deprecated in Elasticsearch 6.0, and removed entirely in 7.0. You should avoid this feature If you have any questions about this, please visit the #logstash channel on freenode irc. {:name=>"document_type", :plugin=><LogStash::Outputs::ElasticSearch hosts=>[//100.100.100.111:9200, //100.100.100.112:9200, //100.100.100.113:9200], index=>"qa-enuri-main-as-is-2018.06.05.04.57", document_type=>"_doc", document_id=>"%{id}", action=>"index", id=>"6ecd11524c84e5de286546b0de40f57503392aeab1548c7913e69855f4645bbc", enable_metric=>true, codec=><LogStash::Codecs::Plain id=>"plain_88312047-b813-4513-9beb-cb461020fcf2", enable_metric=>true, charset=>"UTF-8">, workers=>1, manage_template=>true, template_name=>"logstash", template_overwrite=>false, doc_as_upsert=>false, script_type=>"inline", script_lang=>"painless", script_var_name=>"event", scripted_upsert=>false, retry_initial_interval=>2, retry_max_interval=>64, retry_on_conflict=>1, ssl_certificate_verification=>true, sniffing=>false, sniffing_delay=>5, timeout=>60, pool_max=>1000, pool_max_per_route=>100, resurrect_delay=>5, validate_after_inactivity=>10000, http_compression=>false>}
[2018-06-05T13:58:34,016][INFO ][logstash.pipeline        ] Starting pipeline {:pipeline_id=>"main", "pipeline.workers"=>8, "pipeline.batch.size"=>125, "pipeline.batch.delay"=>50}
[2018-06-05T13:58:34,076][INFO ][logstash.pipeline        ] Pipeline started succesfully {:pipeline_id=>"main", :thread=>"#<Thread:0x61b0a4c1@/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:246 run>"}
[2018-06-05T13:58:34,141][INFO ][logstash.agent           ] Pipelines running {:count=>1, :pipelines=>["main"]}
[2018-06-05T13:58:34,389][INFO ][logstash.outputs.elasticsearch] Elasticsearch pool URLs updated {:changes=>{:removed=>[], :added=>[http://100.100.100.111:9200/, http://100.100.100.112:9200/, http://100.100.100.113:9200/]}}
[2018-06-05T13:58:34,436][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://100.100.100.111:9200/, :path=>"/"}
[2018-06-05T13:58:35,098][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://100.100.100.111:9200/"}
[2018-06-05T13:58:35,096][INFO ][logstash.outputs.elasticsearch] Elasticsearch pool URLs updated {:changes=>{:removed=>[], :added=>[http://100.100.100.111:9200/, http://100.100.100.112:9200/, http://100.100.100.113:9200/]}}
[2018-06-05T13:58:35,138][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://100.100.100.111:9200/, :path=>"/"}
[2018-06-05T13:58:35,263][INFO ][logstash.outputs.elasticsearch] ES Output version determined {:es_version=>6}
[2018-06-05T13:58:35,263][WARN ][logstash.outputs.elasticsearch] Detected a 6.x and above cluster: the `type` event field won't be used to determine the document _type {:es_version=>6}
[2018-06-05T13:58:35,264][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://100.100.100.112:9200/, :path=>"/"}
[2018-06-05T13:58:35,295][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://100.100.100.112:9200/"}
[2018-06-05T13:58:35,309][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://100.100.100.113:9200/, :path=>"/"}
[2018-06-05T13:58:35,334][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://100.100.100.113:9200/"}
[2018-06-05T13:58:35,452][INFO ][logstash.outputs.elasticsearch] Using mapping template from {:path=>nil}
[2018-06-05T13:58:35,479][INFO ][logstash.outputs.elasticsearch] Attempting to install template {:manage_template=>{"template"=>"logstash-*", "version"=>60001, "settings"=>{"index.refresh_interval"=>"5s"}, "mappings"=>{"_default_"=>{"dynamic_templates"=>[{"message_field"=>{"path_match"=>"message", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false}}}, {"string_fields"=>{"match"=>"*", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false, "fields"=>{"keyword"=>{"type"=>"keyword", "ignore_above"=>256}}}}}], "properties"=>{"@timestamp"=>{"type"=>"date"}, "@version"=>{"type"=>"keyword"}, "geoip"=>{"dynamic"=>true, "properties"=>{"ip"=>{"type"=>"ip"}, "location"=>{"type"=>"geo_point"}, "latitude"=>{"type"=>"half_float"}, "longitude"=>{"type"=>"half_float"}}}}}}}}
[2018-06-05T13:58:35,548][INFO ][logstash.outputs.elasticsearch] New Elasticsearch output {:class=>"LogStash::Outputs::ElasticSearch", :hosts=>["//100.100.100.111:9200", "//100.100.100.112:9200", "//100.100.100.113:9200"]}
[2018-06-05T13:58:35,685][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://100.100.100.111:9200/"}
[2018-06-05T13:58:35,834][INFO ][logstash.outputs.elasticsearch] ES Output version determined {:es_version=>6}
[2018-06-05T13:58:35,835][WARN ][logstash.outputs.elasticsearch] Detected a 6.x and above cluster: the `type` event field won't be used to determine the document _type {:es_version=>6}
[2018-06-05T13:58:35,835][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://100.100.100.112:9200/, :path=>"/"}
[2018-06-05T13:58:35,851][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://100.100.100.112:9200/"}
[2018-06-05T13:58:35,876][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://100.100.100.113:9200/, :path=>"/"}
[2018-06-05T13:58:35,934][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://100.100.100.113:9200/"}
[2018-06-05T13:58:35,995][INFO ][logstash.outputs.elasticsearch] Using mapping template from {:path=>nil}
[2018-06-05T13:58:36,025][INFO ][logstash.outputs.elasticsearch] Attempting to install template {:manage_template=>{"template"=>"logstash-*", "version"=>60001, "settings"=>{"index.refresh_interval"=>"5s"}, "mappings"=>{"_default_"=>{"dynamic_templates"=>[{"message_field"=>{"path_match"=>"message", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false}}}, {"string_fields"=>{"match"=>"*", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false, "fields"=>{"keyword"=>{"type"=>"keyword", "ignore_above"=>256}}}}}], "properties"=>{"@timestamp"=>{"type"=>"date"}, "@version"=>{"type"=>"keyword"}, "geoip"=>{"dynamic"=>true, "properties"=>{"ip"=>{"type"=>"ip"}, "location"=>{"type"=>"geo_point"}, "latitude"=>{"type"=>"half_float"}, "longitude"=>{"type"=>"half_float"}}}}}}}}
[2018-06-05T13:58:36,057][INFO ][logstash.outputs.elasticsearch] New Elasticsearch output {:class=>"LogStash::Outputs::ElasticSearch", :hosts=>["//100.100.100.111:9200", "//100.100.100.112:9200", "//100.100.100.113:9200"]}
[2018-06-05T13:58:36,421][INFO ][logstash.pipeline        ] Pipeline started succesfully {:pipeline_id=>"main", :thread=>"#<Thread:0x3c8f511c@/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:246 run>"}
[2018-06-05T13:58:36,546][INFO ][logstash.agent           ] Pipelines running {:count=>1, :pipelines=>["main"]}
[2018-06-05T13:58:36,771][INFO ][logstash.inputs.jdbc     ] (2.993192s) select 
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    DECODE(NVL(MODELNO_GROUP,0),0,0,1) AS MODELNO_GROUP_FLAG,
    category,
    '' as cg,
    '' as cat1,
    '' as cat2,
    '' as cat3,
    '' as cat4,
    ca_code,
    ca_dept_mcode,
    ca_dept_code,
    ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,
    shop_name,
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    MODELNM || ' ' || FACTORY as model_factory,
    minprice,
    maxprice,
    minprices,
    C_DATE,
    mallcnt,
    DECODE(NVL(MALLCNT,0),0,0,1) AS MALLCNT_FLAG,
    spec,
    openexpectflag,
    condiname,
    KEYWORD,
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    to_all
--    MODELNM || ' ' || FACTORY || ' ' || SPEC || ' ' || KEYWORD || ' ' || KEYWORD2 || ' ' || CONDINAME AS to_all
from (

select
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    CASE WHEN service_gubun='2' AND store_flag='1' AND ca_dept_code IS NOT NULL THEN RTRIM(category || ' '  || ca_dept_code) ELSE category END AS category,
    ca_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),3,8)='000000' OR SUBSTR(RTRIM(ca_dept_code),3,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,4) END AS ca_dept_mcode,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),5,8)='0000' OR SUBSTR(RTRIM(ca_dept_code),5,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,6) END AS ca_dept_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),7,8)='00' OR SUBSTR(RTRIM(ca_dept_code),7,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,8) END AS ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,    
    shop_name,    
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    model_factory,
    minprice,
    maxprice,
    replace(minprices, ' ', '    ') as minprices,
    C_DATE,
    mallcnt,
    replace(replace(spec,',',' '),'/',' ') spec,
    openexpectflag,
    replace(condiname, ' ', '    ') as condiname,    
    CASE WHEN socialprice=0 THEN keyword ELSE keyword || ' ' || UDF_SOCIAL_GOODSNM(modelno_group,modelno) END AS KEYWORD,    
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    to_all
FROM tmp_es_goods_data_01    
WHERE mod_no = '2'

)

[2018-06-05T13:58:36,811][INFO ][logstash.inputs.jdbc     ] (3.036700s) select
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    DECODE(NVL(MODELNO_GROUP,0),0,0,1) AS MODELNO_GROUP_FLAG,
    category,
    '' as cg,
    '' as cat1,
    '' as cat2,
    '' as cat3,
    '' as cat4,
    ca_code,
    ca_dept_mcode,
    ca_dept_code,
    ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,
    shop_name,
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    '' as model_factory,
    minprice,
    maxprice,
    minprices,
    C_DATE,
    mallcnt,
    DECODE(NVL(MALLCNT,0),0,0,1) AS MALLCNT_FLAG,
    spec,
    openexpectflag,
    condiname,
    KEYWORD,
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    to_all
--    MODELNM || ' ' || FACTORY || ' ' || SPEC || ' ' || KEYWORD || ' ' || KEYWORD2 || ' ' || CONDINAME AS to_all
from (

select
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    CASE WHEN service_gubun='2' AND store_flag='1' AND ca_dept_code IS NOT NULL THEN RTRIM(category || ' '  || ca_dept_code) ELSE category END AS category,
    ca_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),3,8)='000000' OR SUBSTR(RTRIM(ca_dept_code),3,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,4) END AS ca_dept_mcode,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),5,8)='0000' OR SUBSTR(RTRIM(ca_dept_code),5,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,6) END AS ca_dept_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),7,8)='00' OR SUBSTR(RTRIM(ca_dept_code),7,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,8) END AS ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,    
    shop_name,    
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    model_factory,
    minprice,
    maxprice,
    replace(minprices, ' ', '    ') as minprices,
    C_DATE,
    mallcnt,
    replace(replace(spec,',',' '),'/',' ') spec,
    openexpectflag,
    replace(condiname, ' ', '    ') as condiname,    
    CASE WHEN socialprice=0 THEN keyword ELSE keyword || ' ' || UDF_SOCIAL_GOODSNM(modelno_group,modelno) END AS KEYWORD,    
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    to_all
FROM tmp_es_price_data_01
WHERE mod_no = '2'

)

[2018-06-05T13:58:37,002][INFO ][logstash.pipeline        ] Pipeline started succesfully {:pipeline_id=>"main", :thread=>"#<Thread:0x2779dea3@/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:246 run>"}
[2018-06-05T13:58:37,365][INFO ][logstash.agent           ] Pipelines running {:count=>1, :pipelines=>["main"]}
[2018-06-05T13:58:37,716][INFO ][logstash.inputs.jdbc     ] (2.472712s) select
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    DECODE(NVL(MODELNO_GROUP,0),0,0,1) AS MODELNO_GROUP_FLAG,
    category,
    '' as cg,
    '' as cat1,
    '' as cat2,
    '' as cat3,
    '' as cat4,
    ca_code,
    ca_dept_mcode,
    ca_dept_code,
    ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,
    shop_name,
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    '' as model_factory,
    minprice,
    maxprice,
    minprices,
    C_DATE,
    mallcnt,
    DECODE(NVL(MALLCNT,0),0,0,1) AS MALLCNT_FLAG,
    spec,
    openexpectflag,
    condiname,
    KEYWORD,
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    to_all
--    MODELNM || ' ' || FACTORY || ' ' || SPEC || ' ' || KEYWORD || ' ' || KEYWORD2 || ' ' || CONDINAME AS to_all
from (

select
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    CASE WHEN service_gubun='2' AND store_flag='1' AND ca_dept_code IS NOT NULL THEN RTRIM(category || ' '  || ca_dept_code) ELSE category END AS category,
    ca_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),3,8)='000000' OR SUBSTR(RTRIM(ca_dept_code),3,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,4) END AS ca_dept_mcode,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),5,8)='0000' OR SUBSTR(RTRIM(ca_dept_code),5,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,6) END AS ca_dept_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),7,8)='00' OR SUBSTR(RTRIM(ca_dept_code),7,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,8) END AS ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,    
    shop_name,    
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    model_factory,
    minprice,
    maxprice,
    replace(minprices, ' ', '    ') as minprices,
    C_DATE,
    mallcnt,
    replace(replace(spec,',',' '),'/',' ') spec,
    openexpectflag,
    replace(condiname, ' ', '    ') as condiname,    
    CASE WHEN socialprice=0 THEN keyword ELSE keyword || ' ' || UDF_SOCIAL_GOODSNM(modelno_group,modelno) END AS KEYWORD,    
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    to_all
FROM tmp_es_price_data_01
WHERE mod_no = '1'

)

[2018-06-05T13:58:37,731][INFO ][logstash.inputs.jdbc     ] (2.481753s) select 
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    DECODE(NVL(MODELNO_GROUP,0),0,0,1) AS MODELNO_GROUP_FLAG,
    category,
    '' as cg,
    '' as cat1,
    '' as cat2,
    '' as cat3,
    '' as cat4,
    ca_code,
    ca_dept_mcode,
    ca_dept_code,
    ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,
    shop_name,
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    MODELNM || ' ' || FACTORY as model_factory,
    minprice,
    maxprice,
    minprices,
    C_DATE,
    mallcnt,
    DECODE(NVL(MALLCNT,0),0,0,1) AS MALLCNT_FLAG,
    spec,
    openexpectflag,
    condiname,
    KEYWORD,
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    to_all
--    MODELNM || ' ' || FACTORY || ' ' || SPEC || ' ' || KEYWORD || ' ' || KEYWORD2 || ' ' || CONDINAME AS to_all
from (

select
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    CASE WHEN service_gubun='2' AND store_flag='1' AND ca_dept_code IS NOT NULL THEN RTRIM(category || ' '  || ca_dept_code) ELSE category END AS category,
    ca_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),3,8)='000000' OR SUBSTR(RTRIM(ca_dept_code),3,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,4) END AS ca_dept_mcode,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),5,8)='0000' OR SUBSTR(RTRIM(ca_dept_code),5,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,6) END AS ca_dept_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),7,8)='00' OR SUBSTR(RTRIM(ca_dept_code),7,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,8) END AS ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,    
    shop_name,    
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    model_factory,
    minprice,
    maxprice,
    replace(minprices, ' ', '    ') as minprices,
    C_DATE,
    mallcnt,
    replace(replace(spec,',',' '),'/',' ') spec,
    openexpectflag,
    replace(condiname, ' ', '    ') as condiname,    
    CASE WHEN socialprice=0 THEN keyword ELSE keyword || ' ' || UDF_SOCIAL_GOODSNM(modelno_group,modelno) END AS KEYWORD,    
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    to_all
FROM tmp_es_goods_data_01    
WHERE mod_no = '1'

)

[2018-06-05T13:58:38,859][INFO ][logstash.inputs.jdbc     ] (2.583485s) select
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    DECODE(NVL(MODELNO_GROUP,0),0,0,1) AS MODELNO_GROUP_FLAG,
    category,
    '' as cg,
    '' as cat1,
    '' as cat2,
    '' as cat3,
    '' as cat4,
    ca_code,
    ca_dept_mcode,
    ca_dept_code,
    ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,
    shop_name,
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    '' as model_factory,
    minprice,
    maxprice,
    minprices,
    C_DATE,
    mallcnt,
    DECODE(NVL(MALLCNT,0),0,0,1) AS MALLCNT_FLAG,
    spec,
    openexpectflag,
    condiname,
    KEYWORD,
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    to_all
--    MODELNM || ' ' || FACTORY || ' ' || SPEC || ' ' || KEYWORD || ' ' || KEYWORD2 || ' ' || CONDINAME AS to_all
from (

select
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    CASE WHEN service_gubun='2' AND store_flag='1' AND ca_dept_code IS NOT NULL THEN RTRIM(category || ' '  || ca_dept_code) ELSE category END AS category,
    ca_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),3,8)='000000' OR SUBSTR(RTRIM(ca_dept_code),3,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,4) END AS ca_dept_mcode,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),5,8)='0000' OR SUBSTR(RTRIM(ca_dept_code),5,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,6) END AS ca_dept_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),7,8)='00' OR SUBSTR(RTRIM(ca_dept_code),7,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,8) END AS ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,    
    shop_name,    
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    model_factory,
    minprice,
    maxprice,
    replace(minprices, ' ', '    ') as minprices,
    C_DATE,
    mallcnt,
    replace(replace(spec,',',' '),'/',' ') spec,
    openexpectflag,
    replace(condiname, ' ', '    ') as condiname,    
    CASE WHEN socialprice=0 THEN keyword ELSE keyword || ' ' || UDF_SOCIAL_GOODSNM(modelno_group,modelno) END AS KEYWORD,    
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    to_all
FROM tmp_es_price_data_01
WHERE mod_no = '3'

)

[2018-06-05T13:58:38,866][INFO ][logstash.inputs.jdbc     ] (2.607329s) select 
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    DECODE(NVL(MODELNO_GROUP,0),0,0,1) AS MODELNO_GROUP_FLAG,
    category,
    '' as cg,
    '' as cat1,
    '' as cat2,
    '' as cat3,
    '' as cat4,
    ca_code,
    ca_dept_mcode,
    ca_dept_code,
    ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,
    shop_name,
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    MODELNM || ' ' || FACTORY as model_factory,
    minprice,
    maxprice,
    minprices,
    C_DATE,
    mallcnt,
    DECODE(NVL(MALLCNT,0),0,0,1) AS MALLCNT_FLAG,
    spec,
    openexpectflag,
    condiname,
    KEYWORD,
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    to_all
--    MODELNM || ' ' || FACTORY || ' ' || SPEC || ' ' || KEYWORD || ' ' || KEYWORD2 || ' ' || CONDINAME AS to_all
from (

select
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    CASE WHEN service_gubun='2' AND store_flag='1' AND ca_dept_code IS NOT NULL THEN RTRIM(category || ' '  || ca_dept_code) ELSE category END AS category,
    ca_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),3,8)='000000' OR SUBSTR(RTRIM(ca_dept_code),3,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,4) END AS ca_dept_mcode,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),5,8)='0000' OR SUBSTR(RTRIM(ca_dept_code),5,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,6) END AS ca_dept_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),7,8)='00' OR SUBSTR(RTRIM(ca_dept_code),7,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,8) END AS ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,    
    shop_name,    
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    model_factory,
    minprice,
    maxprice,
    replace(minprices, ' ', '    ') as minprices,
    C_DATE,
    mallcnt,
    replace(replace(spec,',',' '),'/',' ') spec,
    openexpectflag,
    replace(condiname, ' ', '    ') as condiname,    
    CASE WHEN socialprice=0 THEN keyword ELSE keyword || ' ' || UDF_SOCIAL_GOODSNM(modelno_group,modelno) END AS KEYWORD,    
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    to_all
FROM tmp_es_goods_data_01    
WHERE mod_no = '3'

)

[2018-06-05T13:58:40,338][INFO ][logstash.inputs.jdbc     ] (3.834704s) select
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    DECODE(NVL(MODELNO_GROUP,0),0,0,1) AS MODELNO_GROUP_FLAG,
    category,
    '' as cg,
    '' as cat1,
    '' as cat2,
    '' as cat3,
    '' as cat4,
    ca_code,
    ca_dept_mcode,
    ca_dept_code,
    ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,
    shop_name,
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    '' as model_factory,
    minprice,
    maxprice,
    minprices,
    C_DATE,
    mallcnt,
    DECODE(NVL(MALLCNT,0),0,0,1) AS MALLCNT_FLAG,
    spec,
    openexpectflag,
    condiname,
    KEYWORD,
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    to_all
--    MODELNM || ' ' || FACTORY || ' ' || SPEC || ' ' || KEYWORD || ' ' || KEYWORD2 || ' ' || CONDINAME AS to_all
from (

select
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    CASE WHEN service_gubun='2' AND store_flag='1' AND ca_dept_code IS NOT NULL THEN RTRIM(category || ' '  || ca_dept_code) ELSE category END AS category,
    ca_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),3,8)='000000' OR SUBSTR(RTRIM(ca_dept_code),3,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,4) END AS ca_dept_mcode,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),5,8)='0000' OR SUBSTR(RTRIM(ca_dept_code),5,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,6) END AS ca_dept_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),7,8)='00' OR SUBSTR(RTRIM(ca_dept_code),7,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,8) END AS ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,    
    shop_name,    
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    model_factory,
    minprice,
    maxprice,
    replace(minprices, ' ', '    ') as minprices,
    C_DATE,
    mallcnt,
    replace(replace(spec,',',' '),'/',' ') spec,
    openexpectflag,
    replace(condiname, ' ', '    ') as condiname,    
    CASE WHEN socialprice=0 THEN keyword ELSE keyword || ' ' || UDF_SOCIAL_GOODSNM(modelno_group,modelno) END AS KEYWORD,    
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    to_all
FROM tmp_es_price_data_01
WHERE mod_no = '5'

)

[2018-06-05T13:58:40,339][INFO ][logstash.inputs.jdbc     ] (3.834146s) select 
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    DECODE(NVL(MODELNO_GROUP,0),0,0,1) AS MODELNO_GROUP_FLAG,
    category,
    '' as cg,
    '' as cat1,
    '' as cat2,
    '' as cat3,
    '' as cat4,
    ca_code,
    ca_dept_mcode,
    ca_dept_code,
    ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,
    shop_name,
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    MODELNM || ' ' || FACTORY as model_factory,
    minprice,
    maxprice,
    minprices,
    C_DATE,
    mallcnt,
    DECODE(NVL(MALLCNT,0),0,0,1) AS MALLCNT_FLAG,
    spec,
    openexpectflag,
    condiname,
    KEYWORD,
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    to_all
--    MODELNM || ' ' || FACTORY || ' ' || SPEC || ' ' || KEYWORD || ' ' || KEYWORD2 || ' ' || CONDINAME AS to_all
from (

select
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    CASE WHEN service_gubun='2' AND store_flag='1' AND ca_dept_code IS NOT NULL THEN RTRIM(category || ' '  || ca_dept_code) ELSE category END AS category,
    ca_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),3,8)='000000' OR SUBSTR(RTRIM(ca_dept_code),3,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,4) END AS ca_dept_mcode,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),5,8)='0000' OR SUBSTR(RTRIM(ca_dept_code),5,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,6) END AS ca_dept_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),7,8)='00' OR SUBSTR(RTRIM(ca_dept_code),7,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,8) END AS ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,    
    shop_name,    
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    model_factory,
    minprice,
    maxprice,
    replace(minprices, ' ', '    ') as minprices,
    C_DATE,
    mallcnt,
    replace(replace(spec,',',' '),'/',' ') spec,
    openexpectflag,
    replace(condiname, ' ', '    ') as condiname,    
    CASE WHEN socialprice=0 THEN keyword ELSE keyword || ' ' || UDF_SOCIAL_GOODSNM(modelno_group,modelno) END AS KEYWORD,    
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    to_all
FROM tmp_es_goods_data_01    
WHERE mod_no = '5'

)

[2018-06-05T13:58:40,443][INFO ][logstash.inputs.jdbc     ] (2.324431s) select
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    DECODE(NVL(MODELNO_GROUP,0),0,0,1) AS MODELNO_GROUP_FLAG,
    category,
    '' as cg,
    '' as cat1,
    '' as cat2,
    '' as cat3,
    '' as cat4,
    ca_code,
    ca_dept_mcode,
    ca_dept_code,
    ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,
    shop_name,
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    '' as model_factory,
    minprice,
    maxprice,
    minprices,
    C_DATE,
    mallcnt,
    DECODE(NVL(MALLCNT,0),0,0,1) AS MALLCNT_FLAG,
    spec,
    openexpectflag,
    condiname,
    KEYWORD,
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    to_all
--    MODELNM || ' ' || FACTORY || ' ' || SPEC || ' ' || KEYWORD || ' ' || KEYWORD2 || ' ' || CONDINAME AS to_all
from (

select
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    CASE WHEN service_gubun='2' AND store_flag='1' AND ca_dept_code IS NOT NULL THEN RTRIM(category || ' '  || ca_dept_code) ELSE category END AS category,
    ca_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),3,8)='000000' OR SUBSTR(RTRIM(ca_dept_code),3,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,4) END AS ca_dept_mcode,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),5,8)='0000' OR SUBSTR(RTRIM(ca_dept_code),5,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,6) END AS ca_dept_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),7,8)='00' OR SUBSTR(RTRIM(ca_dept_code),7,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,8) END AS ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,    
    shop_name,    
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    model_factory,
    minprice,
    maxprice,
    replace(minprices, ' ', '    ') as minprices,
    C_DATE,
    mallcnt,
    replace(replace(spec,',',' '),'/',' ') spec,
    openexpectflag,
    replace(condiname, ' ', '    ') as condiname,    
    CASE WHEN socialprice=0 THEN keyword ELSE keyword || ' ' || UDF_SOCIAL_GOODSNM(modelno_group,modelno) END AS KEYWORD,    
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    to_all
FROM tmp_es_price_data_01
WHERE mod_no = '4'

)

[2018-06-05T13:58:40,458][INFO ][logstash.inputs.jdbc     ] (2.327154s) select 
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    DECODE(NVL(MODELNO_GROUP,0),0,0,1) AS MODELNO_GROUP_FLAG,
    category,
    '' as cg,
    '' as cat1,
    '' as cat2,
    '' as cat3,
    '' as cat4,
    ca_code,
    ca_dept_mcode,
    ca_dept_code,
    ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,
    shop_name,
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    MODELNM || ' ' || FACTORY as model_factory,
    minprice,
    maxprice,
    minprices,
    C_DATE,
    mallcnt,
    DECODE(NVL(MALLCNT,0),0,0,1) AS MALLCNT_FLAG,
    spec,
    openexpectflag,
    condiname,
    KEYWORD,
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    to_all
--    MODELNM || ' ' || FACTORY || ' ' || SPEC || ' ' || KEYWORD || ' ' || KEYWORD2 || ' ' || CONDINAME AS to_all
from (

select
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    CASE WHEN service_gubun='2' AND store_flag='1' AND ca_dept_code IS NOT NULL THEN RTRIM(category || ' '  || ca_dept_code) ELSE category END AS category,
    ca_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),3,8)='000000' OR SUBSTR(RTRIM(ca_dept_code),3,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,4) END AS ca_dept_mcode,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),5,8)='0000' OR SUBSTR(RTRIM(ca_dept_code),5,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,6) END AS ca_dept_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),7,8)='00' OR SUBSTR(RTRIM(ca_dept_code),7,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,8) END AS ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,    
    shop_name,    
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    model_factory,
    minprice,
    maxprice,
    replace(minprices, ' ', '    ') as minprices,
    C_DATE,
    mallcnt,
    replace(replace(spec,',',' '),'/',' ') spec,
    openexpectflag,
    replace(condiname, ' ', '    ') as condiname,    
    CASE WHEN socialprice=0 THEN keyword ELSE keyword || ' ' || UDF_SOCIAL_GOODSNM(modelno_group,modelno) END AS KEYWORD,    
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    to_all
FROM tmp_es_goods_data_01    
WHERE mod_no = '4'

)

[2018-06-05T13:58:42,090][INFO ][logstash.inputs.jdbc     ] (1.432613s) select 
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    DECODE(NVL(MODELNO_GROUP,0),0,0,1) AS MODELNO_GROUP_FLAG,
    category,
    '' as cg,
    '' as cat1,
    '' as cat2,
    '' as cat3,
    '' as cat4,
    ca_code,
    ca_dept_mcode,
    ca_dept_code,
    ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,
    shop_name,
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    MODELNM || ' ' || FACTORY as model_factory,
    minprice,
    maxprice,
    minprices,
    C_DATE,
    mallcnt,
    DECODE(NVL(MALLCNT,0),0,0,1) AS MALLCNT_FLAG,
    spec,
    openexpectflag,
    condiname,
    KEYWORD,
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    to_all
--    MODELNM || ' ' || FACTORY || ' ' || SPEC || ' ' || KEYWORD || ' ' || KEYWORD2 || ' ' || CONDINAME AS to_all
from (

select
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    CASE WHEN service_gubun='2' AND store_flag='1' AND ca_dept_code IS NOT NULL THEN RTRIM(category || ' '  || ca_dept_code) ELSE category END AS category,
    ca_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),3,8)='000000' OR SUBSTR(RTRIM(ca_dept_code),3,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,4) END AS ca_dept_mcode,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),5,8)='0000' OR SUBSTR(RTRIM(ca_dept_code),5,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,6) END AS ca_dept_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),7,8)='00' OR SUBSTR(RTRIM(ca_dept_code),7,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,8) END AS ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,    
    shop_name,    
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    model_factory,
    minprice,
    maxprice,
    replace(minprices, ' ', '    ') as minprices,
    C_DATE,
    mallcnt,
    replace(replace(spec,',',' '),'/',' ') spec,
    openexpectflag,
    replace(condiname, ' ', '    ') as condiname,    
    CASE WHEN socialprice=0 THEN keyword ELSE keyword || ' ' || UDF_SOCIAL_GOODSNM(modelno_group,modelno) END AS KEYWORD,    
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    to_all
FROM tmp_es_goods_data_01    
WHERE mod_no = '0'

)

[2018-06-05T13:58:42,090][INFO ][logstash.inputs.jdbc     ] (1.434368s) select
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    DECODE(NVL(MODELNO_GROUP,0),0,0,1) AS MODELNO_GROUP_FLAG,
    category,
    '' as cg,
    '' as cat1,
    '' as cat2,
    '' as cat3,
    '' as cat4,
    ca_code,
    ca_dept_mcode,
    ca_dept_code,
    ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,
    shop_name,
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    '' as model_factory,
    minprice,
    maxprice,
    minprices,
    C_DATE,
    mallcnt,
    DECODE(NVL(MALLCNT,0),0,0,1) AS MALLCNT_FLAG,
    spec,
    openexpectflag,
    condiname,
    KEYWORD,
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    to_all
--    MODELNM || ' ' || FACTORY || ' ' || SPEC || ' ' || KEYWORD || ' ' || KEYWORD2 || ' ' || CONDINAME AS to_all
from (

select
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    CASE WHEN service_gubun='2' AND store_flag='1' AND ca_dept_code IS NOT NULL THEN RTRIM(category || ' '  || ca_dept_code) ELSE category END AS category,
    ca_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),3,8)='000000' OR SUBSTR(RTRIM(ca_dept_code),3,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,4) END AS ca_dept_mcode,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),5,8)='0000' OR SUBSTR(RTRIM(ca_dept_code),5,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,6) END AS ca_dept_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),7,8)='00' OR SUBSTR(RTRIM(ca_dept_code),7,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,8) END AS ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,    
    shop_name,    
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    model_factory,
    minprice,
    maxprice,
    replace(minprices, ' ', '    ') as minprices,
    C_DATE,
    mallcnt,
    replace(replace(spec,',',' '),'/',' ') spec,
    openexpectflag,
    replace(condiname, ' ', '    ') as condiname,    
    CASE WHEN socialprice=0 THEN keyword ELSE keyword || ' ' || UDF_SOCIAL_GOODSNM(modelno_group,modelno) END AS KEYWORD,    
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    to_all
FROM tmp_es_price_data_01
WHERE mod_no = '0'

)

[2018-06-05T14:08:10,716][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"fb_apache", :directory=>"/usr/share/logstash/modules/fb_apache/configuration"}
[2018-06-05T14:08:10,738][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"netflow", :directory=>"/usr/share/logstash/modules/netflow/configuration"}
[2018-06-05T14:08:10,749][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"fb_apache", :directory=>"/usr/share/logstash/modules/fb_apache/configuration"}
[2018-06-05T14:08:10,797][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"netflow", :directory=>"/usr/share/logstash/modules/netflow/configuration"}
[2018-06-05T14:08:12,110][WARN ][logstash.config.source.multilocal] Ignoring the 'pipelines.yml' file because modules or command line options are specified
[2018-06-05T14:08:12,264][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"fb_apache", :directory=>"/usr/share/logstash/modules/fb_apache/configuration"}
[2018-06-05T14:08:12,272][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"netflow", :directory=>"/usr/share/logstash/modules/netflow/configuration"}
[2018-06-05T14:08:12,448][WARN ][logstash.config.source.multilocal] Ignoring the 'pipelines.yml' file because modules or command line options are specified
[2018-06-05T14:08:12,894][INFO ][logstash.runner          ] Starting Logstash {"logstash.version"=>"6.2.3"}
[2018-06-05T14:08:12,989][INFO ][logstash.runner          ] Starting Logstash {"logstash.version"=>"6.2.3"}
[2018-06-05T14:08:13,160][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"fb_apache", :directory=>"/usr/share/logstash/modules/fb_apache/configuration"}
[2018-06-05T14:08:13,199][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"netflow", :directory=>"/usr/share/logstash/modules/netflow/configuration"}
[2018-06-05T14:08:13,474][WARN ][logstash.config.source.multilocal] Ignoring the 'pipelines.yml' file because modules or command line options are specified
[2018-06-05T14:08:13,549][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=>9601}
[2018-06-05T14:08:13,468][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=>9600}
[2018-06-05T14:08:14,038][INFO ][logstash.runner          ] Starting Logstash {"logstash.version"=>"6.2.3"}
[2018-06-05T14:08:14,463][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=>9602}
[2018-06-05T14:08:14,640][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"fb_apache", :directory=>"/usr/share/logstash/modules/fb_apache/configuration"}
[2018-06-05T14:08:14,658][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"netflow", :directory=>"/usr/share/logstash/modules/netflow/configuration"}
[2018-06-05T14:08:14,727][WARN ][logstash.config.source.multilocal] Ignoring the 'pipelines.yml' file because modules or command line options are specified
[2018-06-05T14:08:15,609][INFO ][logstash.runner          ] Starting Logstash {"logstash.version"=>"6.2.3"}
[2018-06-05T14:08:15,797][DEBUG][org.logstash.secret.store.SecretStoreFactory] Attempting to exists or secret store with implementation: org.logstash.secret.store.backend.JavaKeyStore
[2018-06-05T14:08:15,862][WARN ][logstash.config.source.multilocal] Ignoring the 'pipelines.yml' file because modules or command line options are specified
[2018-06-05T14:08:16,195][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"fb_apache", :directory=>"/usr/share/logstash/modules/fb_apache/configuration"}
[2018-06-05T14:08:16,202][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"netflow", :directory=>"/usr/share/logstash/modules/netflow/configuration"}
[2018-06-05T14:08:16,312][INFO ][logstash.runner          ] Starting Logstash {"logstash.version"=>"6.2.3"}
[2018-06-05T14:08:16,328][DEBUG][org.logstash.secret.store.SecretStoreFactory] Attempting to exists or secret store with implementation: org.logstash.secret.store.backend.JavaKeyStore
[2018-06-05T14:08:16,464][DEBUG][org.logstash.secret.store.SecretStoreFactory] Attempting to exists or secret store with implementation: org.logstash.secret.store.backend.JavaKeyStore
[2018-06-05T14:08:16,582][INFO ][logstash.filters.ruby.script] Test run complete {:script_path=>"rubyfilter.rb", :results=>{:passed=>0, :failed=>0, :errored=>0}}
[2018-06-05T14:08:16,836][DEBUG][org.logstash.secret.store.SecretStoreFactory] Attempting to exists or secret store with implementation: org.logstash.secret.store.backend.JavaKeyStore
[2018-06-05T14:08:16,873][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=>9603}
[2018-06-05T14:08:16,942][WARN ][logstash.outputs.elasticsearch] You are using a deprecated config setting "document_type" set in elasticsearch. Deprecated settings will continue to work, but are scheduled for removal from logstash in the future. Document types are being deprecated in Elasticsearch 6.0, and removed entirely in 7.0. You should avoid this feature If you have any questions about this, please visit the #logstash channel on freenode irc. {:name=>"document_type", :plugin=><LogStash::Outputs::ElasticSearch hosts=>[//100.100.100.111:9200, //100.100.100.112:9200, //100.100.100.113:9200], index=>"qa-enuri-main-as-is-2018.06.05.05.07", document_type=>"_doc", document_id=>"%{id}", action=>"index", id=>"6ecd11524c84e5de286546b0de40f57503392aeab1548c7913e69855f4645bbc", enable_metric=>true, codec=><LogStash::Codecs::Plain id=>"plain_217171b0-3a71-491a-a422-6bfe7267e2e8", enable_metric=>true, charset=>"UTF-8">, workers=>1, manage_template=>true, template_name=>"logstash", template_overwrite=>false, doc_as_upsert=>false, script_type=>"inline", script_lang=>"painless", script_var_name=>"event", scripted_upsert=>false, retry_initial_interval=>2, retry_max_interval=>64, retry_on_conflict=>1, ssl_certificate_verification=>true, sniffing=>false, sniffing_delay=>5, timeout=>60, pool_max=>1000, pool_max_per_route=>100, resurrect_delay=>5, validate_after_inactivity=>10000, http_compression=>false>}
[2018-06-05T14:08:17,026][INFO ][logstash.pipeline        ] Starting pipeline {:pipeline_id=>"main", "pipeline.workers"=>8, "pipeline.batch.size"=>125, "pipeline.batch.delay"=>50}
[2018-06-05T14:08:17,048][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=>9604}
[2018-06-05T14:08:17,081][DEBUG][org.logstash.secret.store.SecretStoreFactory] Attempting to exists or secret store with implementation: org.logstash.secret.store.backend.JavaKeyStore
[2018-06-05T14:08:17,144][DEBUG][org.logstash.secret.store.SecretStoreFactory] Attempting to exists or secret store with implementation: org.logstash.secret.store.backend.JavaKeyStore
[2018-06-05T14:08:17,435][DEBUG][org.logstash.secret.store.SecretStoreFactory] Attempting to exists or secret store with implementation: org.logstash.secret.store.backend.JavaKeyStore
[2018-06-05T14:08:17,486][INFO ][logstash.filters.ruby.script] Test run complete {:script_path=>"rubyfilter.rb", :results=>{:passed=>0, :failed=>0, :errored=>0}}
[2018-06-05T14:08:17,686][WARN ][logstash.config.source.multilocal] Ignoring the 'pipelines.yml' file because modules or command line options are specified
[2018-06-05T14:08:17,781][INFO ][logstash.filters.ruby.script] Test run complete {:script_path=>"rubyfilter.rb", :results=>{:passed=>0, :failed=>0, :errored=>0}}
[2018-06-05T14:08:18,019][DEBUG][org.logstash.secret.store.SecretStoreFactory] Attempting to exists or secret store with implementation: org.logstash.secret.store.backend.JavaKeyStore
[2018-06-05T14:08:18,328][INFO ][logstash.runner          ] Starting Logstash {"logstash.version"=>"6.2.3"}
[2018-06-05T14:08:18,391][DEBUG][org.logstash.secret.store.SecretStoreFactory] Attempting to exists or secret store with implementation: org.logstash.secret.store.backend.JavaKeyStore
[2018-06-05T14:08:18,497][WARN ][logstash.outputs.elasticsearch] You are using a deprecated config setting "document_type" set in elasticsearch. Deprecated settings will continue to work, but are scheduled for removal from logstash in the future. Document types are being deprecated in Elasticsearch 6.0, and removed entirely in 7.0. You should avoid this feature If you have any questions about this, please visit the #logstash channel on freenode irc. {:name=>"document_type", :plugin=><LogStash::Outputs::ElasticSearch hosts=>[//100.100.100.111:9200, //100.100.100.112:9200, //100.100.100.113:9200], index=>"qa-enuri-main-as-is-2018.06.05.05.07", document_type=>"_doc", document_id=>"%{id}", action=>"index", id=>"6ecd11524c84e5de286546b0de40f57503392aeab1548c7913e69855f4645bbc", enable_metric=>true, codec=><LogStash::Codecs::Plain id=>"plain_01d57703-af15-4f63-845f-b43d148a6f51", enable_metric=>true, charset=>"UTF-8">, workers=>1, manage_template=>true, template_name=>"logstash", template_overwrite=>false, doc_as_upsert=>false, script_type=>"inline", script_lang=>"painless", script_var_name=>"event", scripted_upsert=>false, retry_initial_interval=>2, retry_max_interval=>64, retry_on_conflict=>1, ssl_certificate_verification=>true, sniffing=>false, sniffing_delay=>5, timeout=>60, pool_max=>1000, pool_max_per_route=>100, resurrect_delay=>5, validate_after_inactivity=>10000, http_compression=>false>}
[2018-06-05T14:08:18,539][INFO ][logstash.pipeline        ] Starting pipeline {:pipeline_id=>"main", "pipeline.workers"=>8, "pipeline.batch.size"=>125, "pipeline.batch.delay"=>50}
[2018-06-05T14:08:18,674][WARN ][logstash.outputs.elasticsearch] You are using a deprecated config setting "document_type" set in elasticsearch. Deprecated settings will continue to work, but are scheduled for removal from logstash in the future. Document types are being deprecated in Elasticsearch 6.0, and removed entirely in 7.0. You should avoid this feature If you have any questions about this, please visit the #logstash channel on freenode irc. {:name=>"document_type", :plugin=><LogStash::Outputs::ElasticSearch hosts=>[//100.100.100.111:9200, //100.100.100.112:9200, //100.100.100.113:9200], index=>"qa-enuri-main-as-is-2018.06.05.05.07", document_type=>"_doc", document_id=>"%{id}", action=>"index", id=>"6ecd11524c84e5de286546b0de40f57503392aeab1548c7913e69855f4645bbc", enable_metric=>true, codec=><LogStash::Codecs::Plain id=>"plain_6750058a-8f7a-4784-8b77-d6bbb9dd53de", enable_metric=>true, charset=>"UTF-8">, workers=>1, manage_template=>true, template_name=>"logstash", template_overwrite=>false, doc_as_upsert=>false, script_type=>"inline", script_lang=>"painless", script_var_name=>"event", scripted_upsert=>false, retry_initial_interval=>2, retry_max_interval=>64, retry_on_conflict=>1, ssl_certificate_verification=>true, sniffing=>false, sniffing_delay=>5, timeout=>60, pool_max=>1000, pool_max_per_route=>100, resurrect_delay=>5, validate_after_inactivity=>10000, http_compression=>false>}
[2018-06-05T14:08:18,712][INFO ][logstash.pipeline        ] Starting pipeline {:pipeline_id=>"main", "pipeline.workers"=>8, "pipeline.batch.size"=>125, "pipeline.batch.delay"=>50}
[2018-06-05T14:08:18,922][DEBUG][org.logstash.secret.store.SecretStoreFactory] Attempting to exists or secret store with implementation: org.logstash.secret.store.backend.JavaKeyStore
[2018-06-05T14:08:18,935][INFO ][logstash.outputs.elasticsearch] Elasticsearch pool URLs updated {:changes=>{:removed=>[], :added=>[http://100.100.100.111:9200/, http://100.100.100.112:9200/, http://100.100.100.113:9200/]}}
[2018-06-05T14:08:18,937][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://100.100.100.111:9200/, :path=>"/"}
[2018-06-05T14:08:19,254][DEBUG][org.logstash.secret.store.SecretStoreFactory] Attempting to exists or secret store with implementation: org.logstash.secret.store.backend.JavaKeyStore
[2018-06-05T14:08:19,221][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=>9605}
[2018-06-05T14:08:19,354][DEBUG][org.logstash.secret.store.SecretStoreFactory] Attempting to exists or secret store with implementation: org.logstash.secret.store.backend.JavaKeyStore
[2018-06-05T14:08:19,366][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://100.100.100.111:9200/"}
[2018-06-05T14:08:19,479][INFO ][logstash.filters.ruby.script] Test run complete {:script_path=>"rubyfilter.rb", :results=>{:passed=>0, :failed=>0, :errored=>0}}
[2018-06-05T14:08:19,540][INFO ][logstash.outputs.elasticsearch] ES Output version determined {:es_version=>6}
[2018-06-05T14:08:19,543][WARN ][logstash.outputs.elasticsearch] Detected a 6.x and above cluster: the `type` event field won't be used to determine the document _type {:es_version=>6}
[2018-06-05T14:08:19,543][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://100.100.100.112:9200/, :path=>"/"}
[2018-06-05T14:08:19,575][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://100.100.100.112:9200/"}
[2018-06-05T14:08:19,604][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://100.100.100.113:9200/, :path=>"/"}
[2018-06-05T14:08:19,616][DEBUG][org.logstash.secret.store.SecretStoreFactory] Attempting to exists or secret store with implementation: org.logstash.secret.store.backend.JavaKeyStore
[2018-06-05T14:08:19,660][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://100.100.100.113:9200/"}
[2018-06-05T14:08:19,707][INFO ][logstash.outputs.elasticsearch] Using mapping template from {:path=>nil}
[2018-06-05T14:08:19,712][INFO ][logstash.outputs.elasticsearch] Attempting to install template {:manage_template=>{"template"=>"logstash-*", "version"=>60001, "settings"=>{"index.refresh_interval"=>"5s"}, "mappings"=>{"_default_"=>{"dynamic_templates"=>[{"message_field"=>{"path_match"=>"message", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false}}}, {"string_fields"=>{"match"=>"*", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false, "fields"=>{"keyword"=>{"type"=>"keyword", "ignore_above"=>256}}}}}], "properties"=>{"@timestamp"=>{"type"=>"date"}, "@version"=>{"type"=>"keyword"}, "geoip"=>{"dynamic"=>true, "properties"=>{"ip"=>{"type"=>"ip"}, "location"=>{"type"=>"geo_point"}, "latitude"=>{"type"=>"half_float"}, "longitude"=>{"type"=>"half_float"}}}}}}}}
[2018-06-05T14:08:19,730][INFO ][logstash.outputs.elasticsearch] New Elasticsearch output {:class=>"LogStash::Outputs::ElasticSearch", :hosts=>["//100.100.100.111:9200", "//100.100.100.112:9200", "//100.100.100.113:9200"]}
[2018-06-05T14:08:19,849][INFO ][logstash.outputs.elasticsearch] Elasticsearch pool URLs updated {:changes=>{:removed=>[], :added=>[http://100.100.100.111:9200/, http://100.100.100.112:9200/, http://100.100.100.113:9200/]}}
[2018-06-05T14:08:19,852][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://100.100.100.111:9200/, :path=>"/"}
[2018-06-05T14:08:19,955][INFO ][logstash.filters.ruby.script] Test run complete {:script_path=>"rubyfilter.rb", :results=>{:passed=>0, :failed=>0, :errored=>0}}
[2018-06-05T14:08:20,073][INFO ][logstash.outputs.elasticsearch] Elasticsearch pool URLs updated {:changes=>{:removed=>[], :added=>[http://100.100.100.111:9200/, http://100.100.100.112:9200/, http://100.100.100.113:9200/]}}
[2018-06-05T14:08:20,098][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://100.100.100.111:9200/, :path=>"/"}
[2018-06-05T14:08:20,188][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://100.100.100.111:9200/"}
[2018-06-05T14:08:20,193][DEBUG][org.logstash.secret.store.SecretStoreFactory] Attempting to exists or secret store with implementation: org.logstash.secret.store.backend.JavaKeyStore
[2018-06-05T14:08:20,339][INFO ][logstash.outputs.elasticsearch] ES Output version determined {:es_version=>6}
[2018-06-05T14:08:20,339][WARN ][logstash.outputs.elasticsearch] Detected a 6.x and above cluster: the `type` event field won't be used to determine the document _type {:es_version=>6}
[2018-06-05T14:08:20,340][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://100.100.100.112:9200/, :path=>"/"}
[2018-06-05T14:08:20,356][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://100.100.100.112:9200/"}
[2018-06-05T14:08:20,368][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://100.100.100.113:9200/, :path=>"/"}
[2018-06-05T14:08:20,372][WARN ][logstash.outputs.elasticsearch] You are using a deprecated config setting "document_type" set in elasticsearch. Deprecated settings will continue to work, but are scheduled for removal from logstash in the future. Document types are being deprecated in Elasticsearch 6.0, and removed entirely in 7.0. You should avoid this feature If you have any questions about this, please visit the #logstash channel on freenode irc. {:name=>"document_type", :plugin=><LogStash::Outputs::ElasticSearch hosts=>[//100.100.100.111:9200, //100.100.100.112:9200, //100.100.100.113:9200], index=>"qa-enuri-main-as-is-2018.06.05.05.07", document_type=>"_doc", document_id=>"%{id}", action=>"index", id=>"6ecd11524c84e5de286546b0de40f57503392aeab1548c7913e69855f4645bbc", enable_metric=>true, codec=><LogStash::Codecs::Plain id=>"plain_8c21a808-fba7-49ca-bd16-2f3adc3aa51f", enable_metric=>true, charset=>"UTF-8">, workers=>1, manage_template=>true, template_name=>"logstash", template_overwrite=>false, doc_as_upsert=>false, script_type=>"inline", script_lang=>"painless", script_var_name=>"event", scripted_upsert=>false, retry_initial_interval=>2, retry_max_interval=>64, retry_on_conflict=>1, ssl_certificate_verification=>true, sniffing=>false, sniffing_delay=>5, timeout=>60, pool_max=>1000, pool_max_per_route=>100, resurrect_delay=>5, validate_after_inactivity=>10000, http_compression=>false>}
[2018-06-05T14:08:20,385][INFO ][logstash.pipeline        ] Starting pipeline {:pipeline_id=>"main", "pipeline.workers"=>8, "pipeline.batch.size"=>125, "pipeline.batch.delay"=>50}
[2018-06-05T14:08:20,386][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://100.100.100.113:9200/"}
[2018-06-05T14:08:20,449][INFO ][logstash.outputs.elasticsearch] Using mapping template from {:path=>nil}
[2018-06-05T14:08:20,464][INFO ][logstash.outputs.elasticsearch] Attempting to install template {:manage_template=>{"template"=>"logstash-*", "version"=>60001, "settings"=>{"index.refresh_interval"=>"5s"}, "mappings"=>{"_default_"=>{"dynamic_templates"=>[{"message_field"=>{"path_match"=>"message", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false}}}, {"string_fields"=>{"match"=>"*", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false, "fields"=>{"keyword"=>{"type"=>"keyword", "ignore_above"=>256}}}}}], "properties"=>{"@timestamp"=>{"type"=>"date"}, "@version"=>{"type"=>"keyword"}, "geoip"=>{"dynamic"=>true, "properties"=>{"ip"=>{"type"=>"ip"}, "location"=>{"type"=>"geo_point"}, "latitude"=>{"type"=>"half_float"}, "longitude"=>{"type"=>"half_float"}}}}}}}}
[2018-06-05T14:08:20,468][DEBUG][org.logstash.secret.store.SecretStoreFactory] Attempting to exists or secret store with implementation: org.logstash.secret.store.backend.JavaKeyStore
[2018-06-05T14:08:20,477][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://100.100.100.111:9200/"}
[2018-06-05T14:08:20,485][INFO ][logstash.outputs.elasticsearch] New Elasticsearch output {:class=>"LogStash::Outputs::ElasticSearch", :hosts=>["//100.100.100.111:9200", "//100.100.100.112:9200", "//100.100.100.113:9200"]}
[2018-06-05T14:08:20,570][WARN ][logstash.outputs.elasticsearch] You are using a deprecated config setting "document_type" set in elasticsearch. Deprecated settings will continue to work, but are scheduled for removal from logstash in the future. Document types are being deprecated in Elasticsearch 6.0, and removed entirely in 7.0. You should avoid this feature If you have any questions about this, please visit the #logstash channel on freenode irc. {:name=>"document_type", :plugin=><LogStash::Outputs::ElasticSearch hosts=>[//100.100.100.111:9200, //100.100.100.112:9200, //100.100.100.113:9200], index=>"qa-enuri-main-as-is-2018.06.05.05.07", document_type=>"_doc", document_id=>"%{id}", action=>"index", id=>"6ecd11524c84e5de286546b0de40f57503392aeab1548c7913e69855f4645bbc", enable_metric=>true, codec=><LogStash::Codecs::Plain id=>"plain_2937e0d9-132d-44dd-8a38-05c371e537bd", enable_metric=>true, charset=>"UTF-8">, workers=>1, manage_template=>true, template_name=>"logstash", template_overwrite=>false, doc_as_upsert=>false, script_type=>"inline", script_lang=>"painless", script_var_name=>"event", scripted_upsert=>false, retry_initial_interval=>2, retry_max_interval=>64, retry_on_conflict=>1, ssl_certificate_verification=>true, sniffing=>false, sniffing_delay=>5, timeout=>60, pool_max=>1000, pool_max_per_route=>100, resurrect_delay=>5, validate_after_inactivity=>10000, http_compression=>false>}
[2018-06-05T14:08:20,601][INFO ][logstash.outputs.elasticsearch] ES Output version determined {:es_version=>6}
[2018-06-05T14:08:20,602][INFO ][logstash.pipeline        ] Starting pipeline {:pipeline_id=>"main", "pipeline.workers"=>8, "pipeline.batch.size"=>125, "pipeline.batch.delay"=>50}
[2018-06-05T14:08:20,602][WARN ][logstash.outputs.elasticsearch] Detected a 6.x and above cluster: the `type` event field won't be used to determine the document _type {:es_version=>6}
[2018-06-05T14:08:20,603][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://100.100.100.112:9200/, :path=>"/"}
[2018-06-05T14:08:20,622][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://100.100.100.112:9200/"}
[2018-06-05T14:08:20,628][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://100.100.100.113:9200/, :path=>"/"}
[2018-06-05T14:08:20,644][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://100.100.100.113:9200/"}
[2018-06-05T14:08:20,701][INFO ][logstash.outputs.elasticsearch] Using mapping template from {:path=>nil}
[2018-06-05T14:08:20,709][INFO ][logstash.outputs.elasticsearch] Attempting to install template {:manage_template=>{"template"=>"logstash-*", "version"=>60001, "settings"=>{"index.refresh_interval"=>"5s"}, "mappings"=>{"_default_"=>{"dynamic_templates"=>[{"message_field"=>{"path_match"=>"message", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false}}}, {"string_fields"=>{"match"=>"*", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false, "fields"=>{"keyword"=>{"type"=>"keyword", "ignore_above"=>256}}}}}], "properties"=>{"@timestamp"=>{"type"=>"date"}, "@version"=>{"type"=>"keyword"}, "geoip"=>{"dynamic"=>true, "properties"=>{"ip"=>{"type"=>"ip"}, "location"=>{"type"=>"geo_point"}, "latitude"=>{"type"=>"half_float"}, "longitude"=>{"type"=>"half_float"}}}}}}}}
[2018-06-05T14:08:20,753][INFO ][logstash.outputs.elasticsearch] New Elasticsearch output {:class=>"LogStash::Outputs::ElasticSearch", :hosts=>["//100.100.100.111:9200", "//100.100.100.112:9200", "//100.100.100.113:9200"]}
[2018-06-05T14:08:20,819][INFO ][logstash.pipeline        ] Pipeline started succesfully {:pipeline_id=>"main", :thread=>"#<Thread:0x7a76e0ae@/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:246 run>"}
[2018-06-05T14:08:20,961][INFO ][logstash.agent           ] Pipelines running {:count=>1, :pipelines=>["main"]}
[2018-06-05T14:08:21,260][INFO ][logstash.pipeline        ] Pipeline started succesfully {:pipeline_id=>"main", :thread=>"#<Thread:0x627aad80@/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:246 sleep>"}
[2018-06-05T14:08:21,385][INFO ][logstash.agent           ] Pipelines running {:count=>1, :pipelines=>["main"]}
[2018-06-05T14:08:21,642][INFO ][logstash.outputs.elasticsearch] Elasticsearch pool URLs updated {:changes=>{:removed=>[], :added=>[http://100.100.100.111:9200/, http://100.100.100.112:9200/, http://100.100.100.113:9200/]}}
[2018-06-05T14:08:21,643][DEBUG][org.logstash.secret.store.SecretStoreFactory] Attempting to exists or secret store with implementation: org.logstash.secret.store.backend.JavaKeyStore
[2018-06-05T14:08:21,644][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://100.100.100.111:9200/, :path=>"/"}
[2018-06-05T14:08:21,825][INFO ][logstash.outputs.elasticsearch] Elasticsearch pool URLs updated {:changes=>{:removed=>[], :added=>[http://100.100.100.111:9200/, http://100.100.100.112:9200/, http://100.100.100.113:9200/]}}
[2018-06-05T14:08:21,827][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://100.100.100.111:9200/, :path=>"/"}
[2018-06-05T14:08:21,907][INFO ][logstash.pipeline        ] Pipeline started succesfully {:pipeline_id=>"main", :thread=>"#<Thread:0x610745d9@/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:246 sleep>"}
[2018-06-05T14:08:21,923][DEBUG][org.logstash.secret.store.SecretStoreFactory] Attempting to exists or secret store with implementation: org.logstash.secret.store.backend.JavaKeyStore
[2018-06-05T14:08:21,934][INFO ][logstash.agent           ] Pipelines running {:count=>1, :pipelines=>["main"]}
[2018-06-05T14:08:21,963][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://100.100.100.111:9200/"}
[2018-06-05T14:08:22,180][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://100.100.100.111:9200/"}
[2018-06-05T14:08:22,187][INFO ][logstash.filters.ruby.script] Test run complete {:script_path=>"rubyfilter.rb", :results=>{:passed=>0, :failed=>0, :errored=>0}}
[2018-06-05T14:08:22,207][INFO ][logstash.outputs.elasticsearch] ES Output version determined {:es_version=>6}
[2018-06-05T14:08:22,207][WARN ][logstash.outputs.elasticsearch] Detected a 6.x and above cluster: the `type` event field won't be used to determine the document _type {:es_version=>6}
[2018-06-05T14:08:22,208][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://100.100.100.112:9200/, :path=>"/"}
[2018-06-05T14:08:22,221][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://100.100.100.112:9200/"}
[2018-06-05T14:08:22,228][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://100.100.100.113:9200/, :path=>"/"}
[2018-06-05T14:08:22,244][INFO ][logstash.outputs.elasticsearch] ES Output version determined {:es_version=>6}
[2018-06-05T14:08:22,244][WARN ][logstash.outputs.elasticsearch] Detected a 6.x and above cluster: the `type` event field won't be used to determine the document _type {:es_version=>6}
[2018-06-05T14:08:22,244][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://100.100.100.112:9200/, :path=>"/"}
[2018-06-05T14:08:22,254][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://100.100.100.113:9200/"}
[2018-06-05T14:08:22,270][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://100.100.100.112:9200/"}
[2018-06-05T14:08:22,280][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://100.100.100.113:9200/, :path=>"/"}
[2018-06-05T14:08:22,288][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://100.100.100.113:9200/"}
[2018-06-05T14:08:22,305][INFO ][logstash.outputs.elasticsearch] Using mapping template from {:path=>nil}
[2018-06-05T14:08:22,312][INFO ][logstash.outputs.elasticsearch] Attempting to install template {:manage_template=>{"template"=>"logstash-*", "version"=>60001, "settings"=>{"index.refresh_interval"=>"5s"}, "mappings"=>{"_default_"=>{"dynamic_templates"=>[{"message_field"=>{"path_match"=>"message", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false}}}, {"string_fields"=>{"match"=>"*", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false, "fields"=>{"keyword"=>{"type"=>"keyword", "ignore_above"=>256}}}}}], "properties"=>{"@timestamp"=>{"type"=>"date"}, "@version"=>{"type"=>"keyword"}, "geoip"=>{"dynamic"=>true, "properties"=>{"ip"=>{"type"=>"ip"}, "location"=>{"type"=>"geo_point"}, "latitude"=>{"type"=>"half_float"}, "longitude"=>{"type"=>"half_float"}}}}}}}}
[2018-06-05T14:08:22,324][INFO ][logstash.outputs.elasticsearch] Using mapping template from {:path=>nil}
[2018-06-05T14:08:22,338][INFO ][logstash.outputs.elasticsearch] Attempting to install template {:manage_template=>{"template"=>"logstash-*", "version"=>60001, "settings"=>{"index.refresh_interval"=>"5s"}, "mappings"=>{"_default_"=>{"dynamic_templates"=>[{"message_field"=>{"path_match"=>"message", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false}}}, {"string_fields"=>{"match"=>"*", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false, "fields"=>{"keyword"=>{"type"=>"keyword", "ignore_above"=>256}}}}}], "properties"=>{"@timestamp"=>{"type"=>"date"}, "@version"=>{"type"=>"keyword"}, "geoip"=>{"dynamic"=>true, "properties"=>{"ip"=>{"type"=>"ip"}, "location"=>{"type"=>"geo_point"}, "latitude"=>{"type"=>"half_float"}, "longitude"=>{"type"=>"half_float"}}}}}}}}
[2018-06-05T14:08:22,354][INFO ][logstash.outputs.elasticsearch] New Elasticsearch output {:class=>"LogStash::Outputs::ElasticSearch", :hosts=>["//100.100.100.111:9200", "//100.100.100.112:9200", "//100.100.100.113:9200"]}
[2018-06-05T14:08:22,369][INFO ][logstash.outputs.elasticsearch] New Elasticsearch output {:class=>"LogStash::Outputs::ElasticSearch", :hosts=>["//100.100.100.111:9200", "//100.100.100.112:9200", "//100.100.100.113:9200"]}
[2018-06-05T14:08:22,454][DEBUG][org.logstash.secret.store.SecretStoreFactory] Attempting to exists or secret store with implementation: org.logstash.secret.store.backend.JavaKeyStore
[2018-06-05T14:08:22,543][WARN ][logstash.outputs.elasticsearch] You are using a deprecated config setting "document_type" set in elasticsearch. Deprecated settings will continue to work, but are scheduled for removal from logstash in the future. Document types are being deprecated in Elasticsearch 6.0, and removed entirely in 7.0. You should avoid this feature If you have any questions about this, please visit the #logstash channel on freenode irc. {:name=>"document_type", :plugin=><LogStash::Outputs::ElasticSearch hosts=>[//100.100.100.111:9200, //100.100.100.112:9200, //100.100.100.113:9200], index=>"qa-enuri-main-as-is-2018.06.05.05.07", document_type=>"_doc", document_id=>"%{id}", action=>"index", id=>"6ecd11524c84e5de286546b0de40f57503392aeab1548c7913e69855f4645bbc", enable_metric=>true, codec=><LogStash::Codecs::Plain id=>"plain_6fbb7e74-fc5a-4ffe-a133-a69af389fb6f", enable_metric=>true, charset=>"UTF-8">, workers=>1, manage_template=>true, template_name=>"logstash", template_overwrite=>false, doc_as_upsert=>false, script_type=>"inline", script_lang=>"painless", script_var_name=>"event", scripted_upsert=>false, retry_initial_interval=>2, retry_max_interval=>64, retry_on_conflict=>1, ssl_certificate_verification=>true, sniffing=>false, sniffing_delay=>5, timeout=>60, pool_max=>1000, pool_max_per_route=>100, resurrect_delay=>5, validate_after_inactivity=>10000, http_compression=>false>}
[2018-06-05T14:08:22,572][INFO ][logstash.pipeline        ] Starting pipeline {:pipeline_id=>"main", "pipeline.workers"=>8, "pipeline.batch.size"=>125, "pipeline.batch.delay"=>50}
[2018-06-05T14:08:23,250][INFO ][logstash.pipeline        ] Pipeline started succesfully {:pipeline_id=>"main", :thread=>"#<Thread:0x58ccb38a@/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:246 run>"}
[2018-06-05T14:08:23,306][INFO ][logstash.agent           ] Pipelines running {:count=>1, :pipelines=>["main"]}
[2018-06-05T14:08:23,332][INFO ][logstash.pipeline        ] Pipeline started succesfully {:pipeline_id=>"main", :thread=>"#<Thread:0x1f703c28@/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:246 run>"}
[2018-06-05T14:08:23,482][INFO ][logstash.agent           ] Pipelines running {:count=>1, :pipelines=>["main"]}
[2018-06-05T14:08:23,867][INFO ][logstash.outputs.elasticsearch] Elasticsearch pool URLs updated {:changes=>{:removed=>[], :added=>[http://100.100.100.111:9200/, http://100.100.100.112:9200/, http://100.100.100.113:9200/]}}
[2018-06-05T14:08:23,869][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://100.100.100.111:9200/, :path=>"/"}
[2018-06-05T14:08:24,268][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://100.100.100.111:9200/"}
[2018-06-05T14:08:24,479][INFO ][logstash.outputs.elasticsearch] ES Output version determined {:es_version=>6}
[2018-06-05T14:08:24,479][WARN ][logstash.outputs.elasticsearch] Detected a 6.x and above cluster: the `type` event field won't be used to determine the document _type {:es_version=>6}
[2018-06-05T14:08:24,480][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://100.100.100.112:9200/, :path=>"/"}
[2018-06-05T14:08:24,513][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://100.100.100.112:9200/"}
[2018-06-05T14:08:24,520][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://100.100.100.113:9200/, :path=>"/"}
[2018-06-05T14:08:24,526][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://100.100.100.113:9200/"}
[2018-06-05T14:08:24,608][INFO ][logstash.outputs.elasticsearch] Using mapping template from {:path=>nil}
[2018-06-05T14:08:24,621][INFO ][logstash.outputs.elasticsearch] Attempting to install template {:manage_template=>{"template"=>"logstash-*", "version"=>60001, "settings"=>{"index.refresh_interval"=>"5s"}, "mappings"=>{"_default_"=>{"dynamic_templates"=>[{"message_field"=>{"path_match"=>"message", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false}}}, {"string_fields"=>{"match"=>"*", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false, "fields"=>{"keyword"=>{"type"=>"keyword", "ignore_above"=>256}}}}}], "properties"=>{"@timestamp"=>{"type"=>"date"}, "@version"=>{"type"=>"keyword"}, "geoip"=>{"dynamic"=>true, "properties"=>{"ip"=>{"type"=>"ip"}, "location"=>{"type"=>"geo_point"}, "latitude"=>{"type"=>"half_float"}, "longitude"=>{"type"=>"half_float"}}}}}}}}
[2018-06-05T14:08:24,634][INFO ][logstash.outputs.elasticsearch] New Elasticsearch output {:class=>"LogStash::Outputs::ElasticSearch", :hosts=>["//100.100.100.111:9200", "//100.100.100.112:9200", "//100.100.100.113:9200"]}
[2018-06-05T14:08:25,412][INFO ][logstash.inputs.jdbc     ] (2.475294s) select
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    DECODE(NVL(MODELNO_GROUP,0),0,0,1) AS MODELNO_GROUP_FLAG,
    category,
    '' as cg,
    '' as cat1,
    '' as cat2,
    '' as cat3,
    '' as cat4,
    ca_code,
    ca_dept_mcode,
    ca_dept_code,
    ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,
    shop_name,
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    '' as model_factory,
    minprice,
    maxprice,
    minprices,
    C_DATE,
    mallcnt,
    DECODE(NVL(MALLCNT,0),0,0,1) AS MALLCNT_FLAG,
    spec,
    openexpectflag,
    condiname,
    KEYWORD,
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    to_all
--    MODELNM || ' ' || FACTORY || ' ' || SPEC || ' ' || KEYWORD || ' ' || KEYWORD2 || ' ' || CONDINAME AS to_all
from (

select
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    CASE WHEN service_gubun='2' AND store_flag='1' AND ca_dept_code IS NOT NULL THEN RTRIM(category || ' '  || ca_dept_code) ELSE category END AS category,
    ca_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),3,8)='000000' OR SUBSTR(RTRIM(ca_dept_code),3,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,4) END AS ca_dept_mcode,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),5,8)='0000' OR SUBSTR(RTRIM(ca_dept_code),5,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,6) END AS ca_dept_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),7,8)='00' OR SUBSTR(RTRIM(ca_dept_code),7,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,8) END AS ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,    
    shop_name,    
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    model_factory,
    minprice,
    maxprice,
    replace(minprices, ' ', '    ') as minprices,
    C_DATE,
    mallcnt,
    replace(replace(spec,',',' '),'/',' ') spec,
    openexpectflag,
    replace(condiname, ' ', '    ') as condiname,    
    CASE WHEN socialprice=0 THEN keyword ELSE keyword || ' ' || UDF_SOCIAL_GOODSNM(modelno_group,modelno) END AS KEYWORD,    
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    to_all
FROM tmp_es_price_data_01
WHERE mod_no = '0'

)

[2018-06-05T14:08:25,433][INFO ][logstash.inputs.jdbc     ] (2.494519s) select 
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    DECODE(NVL(MODELNO_GROUP,0),0,0,1) AS MODELNO_GROUP_FLAG,
    category,
    '' as cg,
    '' as cat1,
    '' as cat2,
    '' as cat3,
    '' as cat4,
    ca_code,
    ca_dept_mcode,
    ca_dept_code,
    ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,
    shop_name,
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    MODELNM || ' ' || FACTORY as model_factory,
    minprice,
    maxprice,
    minprices,
    C_DATE,
    mallcnt,
    DECODE(NVL(MALLCNT,0),0,0,1) AS MALLCNT_FLAG,
    spec,
    openexpectflag,
    condiname,
    KEYWORD,
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    to_all
--    MODELNM || ' ' || FACTORY || ' ' || SPEC || ' ' || KEYWORD || ' ' || KEYWORD2 || ' ' || CONDINAME AS to_all
from (

select
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    CASE WHEN service_gubun='2' AND store_flag='1' AND ca_dept_code IS NOT NULL THEN RTRIM(category || ' '  || ca_dept_code) ELSE category END AS category,
    ca_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),3,8)='000000' OR SUBSTR(RTRIM(ca_dept_code),3,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,4) END AS ca_dept_mcode,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),5,8)='0000' OR SUBSTR(RTRIM(ca_dept_code),5,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,6) END AS ca_dept_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),7,8)='00' OR SUBSTR(RTRIM(ca_dept_code),7,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,8) END AS ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,    
    shop_name,    
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    model_factory,
    minprice,
    maxprice,
    replace(minprices, ' ', '    ') as minprices,
    C_DATE,
    mallcnt,
    replace(replace(spec,',',' '),'/',' ') spec,
    openexpectflag,
    replace(condiname, ' ', '    ') as condiname,    
    CASE WHEN socialprice=0 THEN keyword ELSE keyword || ' ' || UDF_SOCIAL_GOODSNM(modelno_group,modelno) END AS KEYWORD,    
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    to_all
FROM tmp_es_goods_data_01    
WHERE mod_no = '0'

)

[2018-06-05T14:08:25,525][INFO ][logstash.pipeline        ] Pipeline started succesfully {:pipeline_id=>"main", :thread=>"#<Thread:0x371239c2@/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:246 run>"}
[2018-06-05T14:08:25,706][INFO ][logstash.agent           ] Pipelines running {:count=>1, :pipelines=>["main"]}
[2018-06-05T14:08:25,939][INFO ][logstash.inputs.jdbc     ] (2.653212s) select 
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    DECODE(NVL(MODELNO_GROUP,0),0,0,1) AS MODELNO_GROUP_FLAG,
    category,
    '' as cg,
    '' as cat1,
    '' as cat2,
    '' as cat3,
    '' as cat4,
    ca_code,
    ca_dept_mcode,
    ca_dept_code,
    ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,
    shop_name,
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    MODELNM || ' ' || FACTORY as model_factory,
    minprice,
    maxprice,
    minprices,
    C_DATE,
    mallcnt,
    DECODE(NVL(MALLCNT,0),0,0,1) AS MALLCNT_FLAG,
    spec,
    openexpectflag,
    condiname,
    KEYWORD,
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    to_all
--    MODELNM || ' ' || FACTORY || ' ' || SPEC || ' ' || KEYWORD || ' ' || KEYWORD2 || ' ' || CONDINAME AS to_all
from (

select
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    CASE WHEN service_gubun='2' AND store_flag='1' AND ca_dept_code IS NOT NULL THEN RTRIM(category || ' '  || ca_dept_code) ELSE category END AS category,
    ca_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),3,8)='000000' OR SUBSTR(RTRIM(ca_dept_code),3,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,4) END AS ca_dept_mcode,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),5,8)='0000' OR SUBSTR(RTRIM(ca_dept_code),5,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,6) END AS ca_dept_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),7,8)='00' OR SUBSTR(RTRIM(ca_dept_code),7,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,8) END AS ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,    
    shop_name,    
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    model_factory,
    minprice,
    maxprice,
    replace(minprices, ' ', '    ') as minprices,
    C_DATE,
    mallcnt,
    replace(replace(spec,',',' '),'/',' ') spec,
    openexpectflag,
    replace(condiname, ' ', '    ') as condiname,    
    CASE WHEN socialprice=0 THEN keyword ELSE keyword || ' ' || UDF_SOCIAL_GOODSNM(modelno_group,modelno) END AS KEYWORD,    
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    to_all
FROM tmp_es_goods_data_01    
WHERE mod_no = '5'

)

[2018-06-05T14:08:25,941][INFO ][logstash.inputs.jdbc     ] (2.622707s) select
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    DECODE(NVL(MODELNO_GROUP,0),0,0,1) AS MODELNO_GROUP_FLAG,
    category,
    '' as cg,
    '' as cat1,
    '' as cat2,
    '' as cat3,
    '' as cat4,
    ca_code,
    ca_dept_mcode,
    ca_dept_code,
    ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,
    shop_name,
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    '' as model_factory,
    minprice,
    maxprice,
    minprices,
    C_DATE,
    mallcnt,
    DECODE(NVL(MALLCNT,0),0,0,1) AS MALLCNT_FLAG,
    spec,
    openexpectflag,
    condiname,
    KEYWORD,
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    to_all
--    MODELNM || ' ' || FACTORY || ' ' || SPEC || ' ' || KEYWORD || ' ' || KEYWORD2 || ' ' || CONDINAME AS to_all
from (

select
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    CASE WHEN service_gubun='2' AND store_flag='1' AND ca_dept_code IS NOT NULL THEN RTRIM(category || ' '  || ca_dept_code) ELSE category END AS category,
    ca_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),3,8)='000000' OR SUBSTR(RTRIM(ca_dept_code),3,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,4) END AS ca_dept_mcode,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),5,8)='0000' OR SUBSTR(RTRIM(ca_dept_code),5,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,6) END AS ca_dept_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),7,8)='00' OR SUBSTR(RTRIM(ca_dept_code),7,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,8) END AS ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,    
    shop_name,    
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    model_factory,
    minprice,
    maxprice,
    replace(minprices, ' ', '    ') as minprices,
    C_DATE,
    mallcnt,
    replace(replace(spec,',',' '),'/',' ') spec,
    openexpectflag,
    replace(condiname, ' ', '    ') as condiname,    
    CASE WHEN socialprice=0 THEN keyword ELSE keyword || ' ' || UDF_SOCIAL_GOODSNM(modelno_group,modelno) END AS KEYWORD,    
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    to_all
FROM tmp_es_price_data_01
WHERE mod_no = '5'

)

[2018-06-05T14:08:26,276][INFO ][logstash.inputs.jdbc     ] (2.170493s) select
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    DECODE(NVL(MODELNO_GROUP,0),0,0,1) AS MODELNO_GROUP_FLAG,
    category,
    '' as cg,
    '' as cat1,
    '' as cat2,
    '' as cat3,
    '' as cat4,
    ca_code,
    ca_dept_mcode,
    ca_dept_code,
    ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,
    shop_name,
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    '' as model_factory,
    minprice,
    maxprice,
    minprices,
    C_DATE,
    mallcnt,
    DECODE(NVL(MALLCNT,0),0,0,1) AS MALLCNT_FLAG,
    spec,
    openexpectflag,
    condiname,
    KEYWORD,
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    to_all
--    MODELNM || ' ' || FACTORY || ' ' || SPEC || ' ' || KEYWORD || ' ' || KEYWORD2 || ' ' || CONDINAME AS to_all
from (

select
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    CASE WHEN service_gubun='2' AND store_flag='1' AND ca_dept_code IS NOT NULL THEN RTRIM(category || ' '  || ca_dept_code) ELSE category END AS category,
    ca_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),3,8)='000000' OR SUBSTR(RTRIM(ca_dept_code),3,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,4) END AS ca_dept_mcode,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),5,8)='0000' OR SUBSTR(RTRIM(ca_dept_code),5,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,6) END AS ca_dept_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),7,8)='00' OR SUBSTR(RTRIM(ca_dept_code),7,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,8) END AS ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,    
    shop_name,    
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    model_factory,
    minprice,
    maxprice,
    replace(minprices, ' ', '    ') as minprices,
    C_DATE,
    mallcnt,
    replace(replace(spec,',',' '),'/',' ') spec,
    openexpectflag,
    replace(condiname, ' ', '    ') as condiname,    
    CASE WHEN socialprice=0 THEN keyword ELSE keyword || ' ' || UDF_SOCIAL_GOODSNM(modelno_group,modelno) END AS KEYWORD,    
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    to_all
FROM tmp_es_price_data_01
WHERE mod_no = '1'

)

[2018-06-05T14:08:26,295][INFO ][logstash.inputs.jdbc     ] (2.170413s) select 
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    DECODE(NVL(MODELNO_GROUP,0),0,0,1) AS MODELNO_GROUP_FLAG,
    category,
    '' as cg,
    '' as cat1,
    '' as cat2,
    '' as cat3,
    '' as cat4,
    ca_code,
    ca_dept_mcode,
    ca_dept_code,
    ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,
    shop_name,
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    MODELNM || ' ' || FACTORY as model_factory,
    minprice,
    maxprice,
    minprices,
    C_DATE,
    mallcnt,
    DECODE(NVL(MALLCNT,0),0,0,1) AS MALLCNT_FLAG,
    spec,
    openexpectflag,
    condiname,
    KEYWORD,
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    to_all
--    MODELNM || ' ' || FACTORY || ' ' || SPEC || ' ' || KEYWORD || ' ' || KEYWORD2 || ' ' || CONDINAME AS to_all
from (

select
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    CASE WHEN service_gubun='2' AND store_flag='1' AND ca_dept_code IS NOT NULL THEN RTRIM(category || ' '  || ca_dept_code) ELSE category END AS category,
    ca_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),3,8)='000000' OR SUBSTR(RTRIM(ca_dept_code),3,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,4) END AS ca_dept_mcode,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),5,8)='0000' OR SUBSTR(RTRIM(ca_dept_code),5,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,6) END AS ca_dept_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),7,8)='00' OR SUBSTR(RTRIM(ca_dept_code),7,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,8) END AS ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,    
    shop_name,    
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    model_factory,
    minprice,
    maxprice,
    replace(minprices, ' ', '    ') as minprices,
    C_DATE,
    mallcnt,
    replace(replace(spec,',',' '),'/',' ') spec,
    openexpectflag,
    replace(condiname, ' ', '    ') as condiname,    
    CASE WHEN socialprice=0 THEN keyword ELSE keyword || ' ' || UDF_SOCIAL_GOODSNM(modelno_group,modelno) END AS KEYWORD,    
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    to_all
FROM tmp_es_goods_data_01    
WHERE mod_no = '1'

)

[2018-06-05T14:08:27,148][INFO ][logstash.inputs.jdbc     ] (2.153996s) select
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    DECODE(NVL(MODELNO_GROUP,0),0,0,1) AS MODELNO_GROUP_FLAG,
    category,
    '' as cg,
    '' as cat1,
    '' as cat2,
    '' as cat3,
    '' as cat4,
    ca_code,
    ca_dept_mcode,
    ca_dept_code,
    ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,
    shop_name,
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    '' as model_factory,
    minprice,
    maxprice,
    minprices,
    C_DATE,
    mallcnt,
    DECODE(NVL(MALLCNT,0),0,0,1) AS MALLCNT_FLAG,
    spec,
    openexpectflag,
    condiname,
    KEYWORD,
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    to_all
--    MODELNM || ' ' || FACTORY || ' ' || SPEC || ' ' || KEYWORD || ' ' || KEYWORD2 || ' ' || CONDINAME AS to_all
from (

select
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    CASE WHEN service_gubun='2' AND store_flag='1' AND ca_dept_code IS NOT NULL THEN RTRIM(category || ' '  || ca_dept_code) ELSE category END AS category,
    ca_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),3,8)='000000' OR SUBSTR(RTRIM(ca_dept_code),3,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,4) END AS ca_dept_mcode,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),5,8)='0000' OR SUBSTR(RTRIM(ca_dept_code),5,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,6) END AS ca_dept_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),7,8)='00' OR SUBSTR(RTRIM(ca_dept_code),7,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,8) END AS ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,    
    shop_name,    
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    model_factory,
    minprice,
    maxprice,
    replace(minprices, ' ', '    ') as minprices,
    C_DATE,
    mallcnt,
    replace(replace(spec,',',' '),'/',' ') spec,
    openexpectflag,
    replace(condiname, ' ', '    ') as condiname,    
    CASE WHEN socialprice=0 THEN keyword ELSE keyword || ' ' || UDF_SOCIAL_GOODSNM(modelno_group,modelno) END AS KEYWORD,    
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    to_all
FROM tmp_es_price_data_01
WHERE mod_no = '3'

)

[2018-06-05T14:08:27,167][INFO ][logstash.inputs.jdbc     ] (2.170098s) select 
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    DECODE(NVL(MODELNO_GROUP,0),0,0,1) AS MODELNO_GROUP_FLAG,
    category,
    '' as cg,
    '' as cat1,
    '' as cat2,
    '' as cat3,
    '' as cat4,
    ca_code,
    ca_dept_mcode,
    ca_dept_code,
    ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,
    shop_name,
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    MODELNM || ' ' || FACTORY as model_factory,
    minprice,
    maxprice,
    minprices,
    C_DATE,
    mallcnt,
    DECODE(NVL(MALLCNT,0),0,0,1) AS MALLCNT_FLAG,
    spec,
    openexpectflag,
    condiname,
    KEYWORD,
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    to_all
--    MODELNM || ' ' || FACTORY || ' ' || SPEC || ' ' || KEYWORD || ' ' || KEYWORD2 || ' ' || CONDINAME AS to_all
from (

select
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    CASE WHEN service_gubun='2' AND store_flag='1' AND ca_dept_code IS NOT NULL THEN RTRIM(category || ' '  || ca_dept_code) ELSE category END AS category,
    ca_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),3,8)='000000' OR SUBSTR(RTRIM(ca_dept_code),3,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,4) END AS ca_dept_mcode,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),5,8)='0000' OR SUBSTR(RTRIM(ca_dept_code),5,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,6) END AS ca_dept_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),7,8)='00' OR SUBSTR(RTRIM(ca_dept_code),7,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,8) END AS ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,    
    shop_name,    
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    model_factory,
    minprice,
    maxprice,
    replace(minprices, ' ', '    ') as minprices,
    C_DATE,
    mallcnt,
    replace(replace(spec,',',' '),'/',' ') spec,
    openexpectflag,
    replace(condiname, ' ', '    ') as condiname,    
    CASE WHEN socialprice=0 THEN keyword ELSE keyword || ' ' || UDF_SOCIAL_GOODSNM(modelno_group,modelno) END AS KEYWORD,    
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    to_all
FROM tmp_es_goods_data_01    
WHERE mod_no = '3'

)

[2018-06-05T14:08:27,906][INFO ][logstash.inputs.jdbc     ] (2.005787s) select 
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    DECODE(NVL(MODELNO_GROUP,0),0,0,1) AS MODELNO_GROUP_FLAG,
    category,
    '' as cg,
    '' as cat1,
    '' as cat2,
    '' as cat3,
    '' as cat4,
    ca_code,
    ca_dept_mcode,
    ca_dept_code,
    ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,
    shop_name,
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    MODELNM || ' ' || FACTORY as model_factory,
    minprice,
    maxprice,
    minprices,
    C_DATE,
    mallcnt,
    DECODE(NVL(MALLCNT,0),0,0,1) AS MALLCNT_FLAG,
    spec,
    openexpectflag,
    condiname,
    KEYWORD,
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    to_all
--    MODELNM || ' ' || FACTORY || ' ' || SPEC || ' ' || KEYWORD || ' ' || KEYWORD2 || ' ' || CONDINAME AS to_all
from (

select
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    CASE WHEN service_gubun='2' AND store_flag='1' AND ca_dept_code IS NOT NULL THEN RTRIM(category || ' '  || ca_dept_code) ELSE category END AS category,
    ca_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),3,8)='000000' OR SUBSTR(RTRIM(ca_dept_code),3,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,4) END AS ca_dept_mcode,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),5,8)='0000' OR SUBSTR(RTRIM(ca_dept_code),5,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,6) END AS ca_dept_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),7,8)='00' OR SUBSTR(RTRIM(ca_dept_code),7,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,8) END AS ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,    
    shop_name,    
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    model_factory,
    minprice,
    maxprice,
    replace(minprices, ' ', '    ') as minprices,
    C_DATE,
    mallcnt,
    replace(replace(spec,',',' '),'/',' ') spec,
    openexpectflag,
    replace(condiname, ' ', '    ') as condiname,    
    CASE WHEN socialprice=0 THEN keyword ELSE keyword || ' ' || UDF_SOCIAL_GOODSNM(modelno_group,modelno) END AS KEYWORD,    
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    to_all
FROM tmp_es_goods_data_01    
WHERE mod_no = '4'

)

[2018-06-05T14:08:27,913][INFO ][logstash.inputs.jdbc     ] (2.011054s) select
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    DECODE(NVL(MODELNO_GROUP,0),0,0,1) AS MODELNO_GROUP_FLAG,
    category,
    '' as cg,
    '' as cat1,
    '' as cat2,
    '' as cat3,
    '' as cat4,
    ca_code,
    ca_dept_mcode,
    ca_dept_code,
    ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,
    shop_name,
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    '' as model_factory,
    minprice,
    maxprice,
    minprices,
    C_DATE,
    mallcnt,
    DECODE(NVL(MALLCNT,0),0,0,1) AS MALLCNT_FLAG,
    spec,
    openexpectflag,
    condiname,
    KEYWORD,
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    to_all
--    MODELNM || ' ' || FACTORY || ' ' || SPEC || ' ' || KEYWORD || ' ' || KEYWORD2 || ' ' || CONDINAME AS to_all
from (

select
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    CASE WHEN service_gubun='2' AND store_flag='1' AND ca_dept_code IS NOT NULL THEN RTRIM(category || ' '  || ca_dept_code) ELSE category END AS category,
    ca_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),3,8)='000000' OR SUBSTR(RTRIM(ca_dept_code),3,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,4) END AS ca_dept_mcode,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),5,8)='0000' OR SUBSTR(RTRIM(ca_dept_code),5,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,6) END AS ca_dept_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),7,8)='00' OR SUBSTR(RTRIM(ca_dept_code),7,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,8) END AS ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,    
    shop_name,    
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    model_factory,
    minprice,
    maxprice,
    replace(minprices, ' ', '    ') as minprices,
    C_DATE,
    mallcnt,
    replace(replace(spec,',',' '),'/',' ') spec,
    openexpectflag,
    replace(condiname, ' ', '    ') as condiname,    
    CASE WHEN socialprice=0 THEN keyword ELSE keyword || ' ' || UDF_SOCIAL_GOODSNM(modelno_group,modelno) END AS KEYWORD,    
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    to_all
FROM tmp_es_price_data_01
WHERE mod_no = '4'

)

[2018-06-05T14:08:30,280][INFO ][logstash.inputs.jdbc     ] (2.074660s) select 
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    DECODE(NVL(MODELNO_GROUP,0),0,0,1) AS MODELNO_GROUP_FLAG,
    category,
    '' as cg,
    '' as cat1,
    '' as cat2,
    '' as cat3,
    '' as cat4,
    ca_code,
    ca_dept_mcode,
    ca_dept_code,
    ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,
    shop_name,
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    MODELNM || ' ' || FACTORY as model_factory,
    minprice,
    maxprice,
    minprices,
    C_DATE,
    mallcnt,
    DECODE(NVL(MALLCNT,0),0,0,1) AS MALLCNT_FLAG,
    spec,
    openexpectflag,
    condiname,
    KEYWORD,
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    to_all
--    MODELNM || ' ' || FACTORY || ' ' || SPEC || ' ' || KEYWORD || ' ' || KEYWORD2 || ' ' || CONDINAME AS to_all
from (

select
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    CASE WHEN service_gubun='2' AND store_flag='1' AND ca_dept_code IS NOT NULL THEN RTRIM(category || ' '  || ca_dept_code) ELSE category END AS category,
    ca_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),3,8)='000000' OR SUBSTR(RTRIM(ca_dept_code),3,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,4) END AS ca_dept_mcode,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),5,8)='0000' OR SUBSTR(RTRIM(ca_dept_code),5,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,6) END AS ca_dept_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),7,8)='00' OR SUBSTR(RTRIM(ca_dept_code),7,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,8) END AS ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,    
    shop_name,    
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    model_factory,
    minprice,
    maxprice,
    replace(minprices, ' ', '    ') as minprices,
    C_DATE,
    mallcnt,
    replace(replace(spec,',',' '),'/',' ') spec,
    openexpectflag,
    replace(condiname, ' ', '    ') as condiname,    
    CASE WHEN socialprice=0 THEN keyword ELSE keyword || ' ' || UDF_SOCIAL_GOODSNM(modelno_group,modelno) END AS KEYWORD,    
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    to_all
FROM tmp_es_goods_data_01    
WHERE mod_no = '2'

)

[2018-06-05T14:08:30,280][INFO ][logstash.inputs.jdbc     ] (2.174406s) select
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    DECODE(NVL(MODELNO_GROUP,0),0,0,1) AS MODELNO_GROUP_FLAG,
    category,
    '' as cg,
    '' as cat1,
    '' as cat2,
    '' as cat3,
    '' as cat4,
    ca_code,
    ca_dept_mcode,
    ca_dept_code,
    ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,
    shop_name,
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    '' as model_factory,
    minprice,
    maxprice,
    minprices,
    C_DATE,
    mallcnt,
    DECODE(NVL(MALLCNT,0),0,0,1) AS MALLCNT_FLAG,
    spec,
    openexpectflag,
    condiname,
    KEYWORD,
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    to_all
--    MODELNM || ' ' || FACTORY || ' ' || SPEC || ' ' || KEYWORD || ' ' || KEYWORD2 || ' ' || CONDINAME AS to_all
from (

select
    mod_no,
    ID,
    modelno,
    pl_no,
    modelno_group,
    CASE WHEN service_gubun='2' AND store_flag='1' AND ca_dept_code IS NOT NULL THEN RTRIM(category || ' '  || ca_dept_code) ELSE category END AS category,
    ca_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),3,8)='000000' OR SUBSTR(RTRIM(ca_dept_code),3,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,4) END AS ca_dept_mcode,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),5,8)='0000' OR SUBSTR(RTRIM(ca_dept_code),5,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,6) END AS ca_dept_code,
    CASE WHEN SUBSTR(RTRIM(ca_dept_code),7,8)='00' OR SUBSTR(RTRIM(ca_dept_code),7,8) IS NULL THEN '' ELSE SUBSTR(RTRIM(ca_dept_code),0,8) END AS ca_dept_dcode,
    ca_lcode_ran,
    ca_mcode_ran,
    ca_scode_ran,
    ca_dcode_ran,
    shop_code,    
    shop_name,    
    shop_name_code,
    modelnm,
    modelnm2,
    factory,
    brand,
    popular,
    popular2,
    sale_cnt,
    model_factory,
    minprice,
    maxprice,
    replace(minprices, ' ', '    ') as minprices,
    C_DATE,
    mallcnt,
    replace(replace(spec,',',' '),'/',' ') spec,
    openexpectflag,
    replace(condiname, ' ', '    ') as condiname,    
    CASE WHEN socialprice=0 THEN keyword ELSE keyword || ' ' || UDF_SOCIAL_GOODSNM(modelno_group,modelno) END AS KEYWORD,    
    keyword2,
    BRANDCODE1,
    BRANDCODE2,
    SPECOPT,
    bookflag,
    useflag,
    weight,
    minprice3,
    minprice2,
    maxprice3,
    mobile_flag,
    minprice4,
    store_flag,
    bbs_num,
    zum_check,
    service_gubun,
    minprice5,
    ext_condi_flag,
    to_all
FROM tmp_es_price_data_01
WHERE mod_no = '2'

)

[2018-06-05T21:09:36,234][WARN ][logstash.shutdownwatcher ] {"inflight_count"=>0, "stalling_thread_info"=>{["LogStash::Filters::Mutate", {"split"=>{"minprices"=>" "}, "id"=>"ca13283655a0f7111b215d2732e64980bac9fe880d0432824719ad2e4bd7b1ca"}]=>[{"thread_id"=>31, "name"=>nil, "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:90:in `read_batch'"}]}}
[2018-06-05T21:09:41,232][WARN ][logstash.shutdownwatcher ] {"inflight_count"=>0, "stalling_thread_info"=>{["LogStash::Filters::Mutate", {"split"=>{"minprices"=>" "}, "id"=>"ca13283655a0f7111b215d2732e64980bac9fe880d0432824719ad2e4bd7b1ca"}]=>[{"thread_id"=>31, "name"=>nil, "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:90:in `read_batch'"}]}}
[2018-06-05T21:09:41,232][ERROR][logstash.shutdownwatcher ] The shutdown process appears to be stalled due to busy or blocked plugins. Check the logs for more information.
[2018-06-05T21:09:46,232][WARN ][logstash.shutdownwatcher ] {"inflight_count"=>0, "stalling_thread_info"=>{["LogStash::Filters::Mutate", {"split"=>{"minprices"=>" "}, "id"=>"ca13283655a0f7111b215d2732e64980bac9fe880d0432824719ad2e4bd7b1ca"}]=>[{"thread_id"=>31, "name"=>nil, "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:90:in `read_batch'"}]}}
[2018-06-05T21:09:51,234][WARN ][logstash.shutdownwatcher ] {"inflight_count"=>0, "stalling_thread_info"=>{["LogStash::Filters::Mutate", {"split"=>{"minprices"=>" "}, "id"=>"ca13283655a0f7111b215d2732e64980bac9fe880d0432824719ad2e4bd7b1ca"}]=>[{"thread_id"=>31, "name"=>nil, "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:90:in `read_batch'"}]}}
[2018-06-05T21:09:51,234][FATAL][logstash.shutdownwatcher ] Forcefully quitting logstash..
[2018-06-05T21:11:21,456][WARN ][logstash.shutdownwatcher ] {"inflight_count"=>0, "stalling_thread_info"=>{["LogStash::Filters::Mutate", {"split"=>{"minprices"=>" "}, "id"=>"ca13283655a0f7111b215d2732e64980bac9fe880d0432824719ad2e4bd7b1ca"}]=>[{"thread_id"=>35, "name"=>nil, "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:90:in `read_batch'"}]}}
[2018-06-05T21:11:26,451][WARN ][logstash.shutdownwatcher ] {"inflight_count"=>0, "stalling_thread_info"=>{["LogStash::Filters::Mutate", {"split"=>{"minprices"=>" "}, "id"=>"ca13283655a0f7111b215d2732e64980bac9fe880d0432824719ad2e4bd7b1ca"}]=>[{"thread_id"=>35, "name"=>nil, "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:90:in `read_batch'"}]}}
[2018-06-05T21:11:26,452][ERROR][logstash.shutdownwatcher ] The shutdown process appears to be stalled due to busy or blocked plugins. Check the logs for more information.
[2018-06-05T21:11:31,452][WARN ][logstash.shutdownwatcher ] {"inflight_count"=>0, "stalling_thread_info"=>{["LogStash::Filters::Mutate", {"split"=>{"minprices"=>" "}, "id"=>"ca13283655a0f7111b215d2732e64980bac9fe880d0432824719ad2e4bd7b1ca"}]=>[{"thread_id"=>35, "name"=>nil, "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:90:in `read_batch'"}]}}
[2018-06-05T21:11:36,450][WARN ][logstash.shutdownwatcher ] {"inflight_count"=>0, "stalling_thread_info"=>{["LogStash::Filters::Mutate", {"split"=>{"minprices"=>" "}, "id"=>"ca13283655a0f7111b215d2732e64980bac9fe880d0432824719ad2e4bd7b1ca"}]=>[{"thread_id"=>35, "name"=>nil, "current_call"=>"[...]/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:90:in `read_batch'"}]}}
[2018-06-05T21:11:36,451][FATAL][logstash.shutdownwatcher ] Forcefully quitting logstash..
[2018-06-05T21:11:38,082][ERROR][logstash.agent           ] Failed to execute action {:action=>LogStash::PipelineAction::Stop/pipeline_id:main, :exception=>"NoMethodError", :message=>"undefined method `map' for nil:NilClass\nDid you mean?  tap", :backtrace=>["/usr/share/logstash/logstash-core/lib/logstash/util.rb:40:in `thread_info'", "/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:662:in `block in plugin_threads_info'", "org/jruby/RubyArray.java:2486:in `map'", "/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:662:in `plugin_threads_info'", "/usr/share/logstash/logstash-core/lib/logstash/pipeline_reporter.rb:66:in `block in to_hash'", "/usr/share/logstash/logstash-core/lib/logstash/util/wrapped_synchronous_queue.rb:80:in `inflight_batches'", "/usr/share/logstash/logstash-core/lib/logstash/pipeline_reporter.rb:56:in `to_hash'", "/usr/share/logstash/logstash-core/lib/logstash/pipeline_reporter.rb:51:in `snapshot'", "/usr/share/logstash/logstash-core/lib/logstash/shutdown_watcher.rb:88:in `pipeline_report_snapshot'", "/usr/share/logstash/logstash-core/lib/logstash/shutdown_watcher.rb:63:in `block in start'", "/usr/share/logstash/vendor/bundle/jruby/2.3.0/gems/stud-0.0.23/lib/stud/interval.rb:20:in `interval'", "/usr/share/logstash/logstash-core/lib/logstash/shutdown_watcher.rb:59:in `start'", "/usr/share/logstash/logstash-core/lib/logstash/shutdown_watcher.rb:35:in `block in start'"]}
[2018-06-05T21:11:46,779][INFO ][logstash.pipeline        ] Pipeline has terminated {:pipeline_id=>"main", :thread=>"#<Thread:0x7a76e0ae@/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:246 run>"}
[2018-06-05T21:11:56,518][INFO ][logstash.pipeline        ] Pipeline has terminated {:pipeline_id=>"main", :thread=>"#<Thread:0x58ccb38a@/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:246 run>"}
[2018-06-05T21:12:45,559][INFO ][logstash.pipeline        ] Pipeline has terminated {:pipeline_id=>"main", :thread=>"#<Thread:0x610745d9@/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:246 run>"}
